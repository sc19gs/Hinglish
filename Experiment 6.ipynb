{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/gaurav/Desktop/Hinglish/data/data4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>15581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>4692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Tweet Sentiment Polarity\n",
       "70     15581   NaN            neutral\n",
       "15978   4692   NaN            neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Tweet'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    if(type(df['Tweet'][i]) !=str):\n",
    "        df['Tweet'][i] = df['Sentiment Polarity'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Tweet, Sentiment Polarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Tweet'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"/Users/gaurav/Desktop/Hinglish/data/valid_data_cleaned4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>29711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>37114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Tweet Sentiment Polarity\n",
       "690   29711   NaN            neutral\n",
       "2663  37114   NaN            neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid[df_valid['Tweet'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_valid)):\n",
    "    if(type(df_valid['Tweet'][i]) !=str):\n",
    "        df_valid['Tweet'][i] = df_valid['Sentiment Polarity'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Tweet, Sentiment Polarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid[df_valid['Tweet'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df_valid, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4330</td>\n",
       "      <td>vist bolest vztek smutek zmatek osam lost bezn...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41616</td>\n",
       "      <td>haan yaar neha pensiv pensiv karega post loudl...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6648</td>\n",
       "      <td>televis media congress liy nahi Ye aapko pata ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2512</td>\n",
       "      <td>all india nrc lagu kare kashmir dhara khatam k...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>pagal they real issu mandir import hindu khatr</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14356</td>\n",
       "      <td>jeet dher sari subh kamnay modi asha karta jis...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5840</td>\n",
       "      <td>topi wali bo new job hogi humey choti kesi mil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32791</td>\n",
       "      <td>Ye modi media walon maza hindu muslim debat karn</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37480</td>\n",
       "      <td>baih tere itjey kya jalti pakistan chutiy khel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16395</td>\n",
       "      <td>hehe I come and actual someon shaadi star struck</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33428</td>\n",
       "      <td>can answer miscalcul vote seat one vote matter...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19222</td>\n",
       "      <td>allah pak dil darwaza ni karta lyhe ach ehsaa ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8422</td>\n",
       "      <td>bahut samajhdari cingress faisla liya aur umid...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26930</td>\n",
       "      <td>Tu safar mera Tu Hi meri manzil tere bina guza...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40285</td>\n",
       "      <td>dobar PM banan aapko dher sari shubhakamanyen ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21403</td>\n",
       "      <td>We life togeth spend money still MY money</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35826</td>\n",
       "      <td>wah kisi khub likha shama khud jala jaha rosha...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18017</td>\n",
       "      <td>tani abe hit flop logo aukad kiya chutiya log ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39736</td>\n",
       "      <td>star ohho veri beauti eye yaar</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15893</td>\n",
       "      <td>evryon shit the fuck UP</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5433</td>\n",
       "      <td>haram khor log ulta chor kotow dantey mulk tor...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23492</td>\n",
       "      <td>armi fin also stade franc prepar concert look ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13515</td>\n",
       "      <td>jai shree jarurat nahi andolan guruji modi mum...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34678</td>\n",
       "      <td>phir loot chalo gaya bjp walo tumh kuch chut r...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11310</td>\n",
       "      <td>jinko khud nahi ramcharitmana bhej rahe bjp ne...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27883</td>\n",
       "      <td>abe rajya jism sabhi sale harami Jo sale itn b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16679</td>\n",
       "      <td>mayb I fa I feel thing</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26920</td>\n",
       "      <td>duniya kabhi na daka hota dadkha pyar izhar ka...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>35982</td>\n",
       "      <td>I poor poor ever happi kase god smile halo</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14603</td>\n",
       "      <td>madam alway miss videsh mantri</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>10765</td>\n",
       "      <td>My first time make halwa sawanak guy proud bi</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>22095</td>\n",
       "      <td>all best dear amit jee never forget take care ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>18622</td>\n",
       "      <td>khaangressi bhajpaaiyon gaali rahe hain bhaajp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>26861</td>\n",
       "      <td>crb bahut badhiya</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>27940</td>\n",
       "      <td>naib tehsildar Ka paper leak gaya hajaro mehna...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>38029</td>\n",
       "      <td>adi fizakhan beta teri tere pakistaniyo maa ch...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>7523</td>\n",
       "      <td>Is shade garmi hab karan karachi rahi garmi pa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>19658</td>\n",
       "      <td>sawant dynamo I huge fan keep grow We support ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>35537</td>\n",
       "      <td>potatoo jaisay hamsi milna gawara nahi hamsi m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>28657</td>\n",
       "      <td>imad wasim hari sohail total suitabl team BC t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>28615</td>\n",
       "      <td>sabs bada gunda apna bjp adhyak khair nahi sam...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>16242</td>\n",
       "      <td>vand matharam We great hope young grassroot wo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>26715</td>\n",
       "      <td>asli rahan pucho fan lube</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>12805</td>\n",
       "      <td>waalakum salam prayer khush rahan</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>44423</td>\n",
       "      <td>ghar mere opinion koyi qadar nahi badass broth...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>45050</td>\n",
       "      <td>abay shinakht burhan teri nasal jisko malum ni...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>40898</td>\n",
       "      <td>banara ghat baat kuch modi banara bahut kuch d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>44530</td>\n",
       "      <td>choos dekhat ki favourit repli mein see intere...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>28106</td>\n",
       "      <td>hindustan tukd karn sochog iss bada tamacha tu...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>26483</td>\n",
       "      <td>yehi dmagh kharab kiy hain jais indian midea a...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>18074</td>\n",
       "      <td>digit kya bakchodi flop actor batman bana diya...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>11976</td>\n",
       "      <td>Me modi kais keht hain</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>31137</td>\n",
       "      <td>kya gaya aajkal polit parti kya bjp aisa kya</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>35199</td>\n",
       "      <td>rajya sbha aapko mauka milna chahiy good think...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>40038</td>\n",
       "      <td>krishna rahul kanwal rajdeep lag bechar dard b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>16859</td>\n",
       "      <td>kisi Ko khushi nahi nayi sarkar aati nay kaam ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2294</td>\n",
       "      <td>music life thank chhote ustad salman ali post ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>29819</td>\n",
       "      <td>gilmour hmmmm realli sam outlaw not someth I a...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>34181</td>\n",
       "      <td>Ab gala faad nahi chalna chowkidar chor sharm ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>36603</td>\n",
       "      <td>O lerki allah swt beha leti chor diffah rahi k...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              Tweet  \\\n",
       "0       4330  vist bolest vztek smutek zmatek osam lost bezn...   \n",
       "1      41616  haan yaar neha pensiv pensiv karega post loudl...   \n",
       "2       6648  televis media congress liy nahi Ye aapko pata ...   \n",
       "3       2512  all india nrc lagu kare kashmir dhara khatam k...   \n",
       "4        610     pagal they real issu mandir import hindu khatr   \n",
       "5      14356  jeet dher sari subh kamnay modi asha karta jis...   \n",
       "6       5840  topi wali bo new job hogi humey choti kesi mil...   \n",
       "7      32791   Ye modi media walon maza hindu muslim debat karn   \n",
       "8      37480  baih tere itjey kya jalti pakistan chutiy khel...   \n",
       "9      16395   hehe I come and actual someon shaadi star struck   \n",
       "10     33428  can answer miscalcul vote seat one vote matter...   \n",
       "11     19222  allah pak dil darwaza ni karta lyhe ach ehsaa ...   \n",
       "12      8422  bahut samajhdari cingress faisla liya aur umid...   \n",
       "13     26930  Tu safar mera Tu Hi meri manzil tere bina guza...   \n",
       "14     40285  dobar PM banan aapko dher sari shubhakamanyen ...   \n",
       "15     21403          We life togeth spend money still MY money   \n",
       "16     35826  wah kisi khub likha shama khud jala jaha rosha...   \n",
       "17     18017  tani abe hit flop logo aukad kiya chutiya log ...   \n",
       "18     39736                     star ohho veri beauti eye yaar   \n",
       "19     15893                            evryon shit the fuck UP   \n",
       "20      5433  haram khor log ulta chor kotow dantey mulk tor...   \n",
       "21     23492  armi fin also stade franc prepar concert look ...   \n",
       "22     13515  jai shree jarurat nahi andolan guruji modi mum...   \n",
       "23     34678  phir loot chalo gaya bjp walo tumh kuch chut r...   \n",
       "24     11310  jinko khud nahi ramcharitmana bhej rahe bjp ne...   \n",
       "25     27883  abe rajya jism sabhi sale harami Jo sale itn b...   \n",
       "26     16679                             mayb I fa I feel thing   \n",
       "27     26920  duniya kabhi na daka hota dadkha pyar izhar ka...   \n",
       "28     35982         I poor poor ever happi kase god smile halo   \n",
       "29     14603                     madam alway miss videsh mantri   \n",
       "...      ...                                                ...   \n",
       "19970  10765      My first time make halwa sawanak guy proud bi   \n",
       "19971  22095  all best dear amit jee never forget take care ...   \n",
       "19972  18622  khaangressi bhajpaaiyon gaali rahe hain bhaajp...   \n",
       "19973  26861                                  crb bahut badhiya   \n",
       "19974  27940  naib tehsildar Ka paper leak gaya hajaro mehna...   \n",
       "19975  38029  adi fizakhan beta teri tere pakistaniyo maa ch...   \n",
       "19976   7523  Is shade garmi hab karan karachi rahi garmi pa...   \n",
       "19977  19658  sawant dynamo I huge fan keep grow We support ...   \n",
       "19978  35537  potatoo jaisay hamsi milna gawara nahi hamsi m...   \n",
       "19979  28657  imad wasim hari sohail total suitabl team BC t...   \n",
       "19980  28615  sabs bada gunda apna bjp adhyak khair nahi sam...   \n",
       "19981  16242  vand matharam We great hope young grassroot wo...   \n",
       "19982  26715                          asli rahan pucho fan lube   \n",
       "19983  12805                  waalakum salam prayer khush rahan   \n",
       "19984  44423  ghar mere opinion koyi qadar nahi badass broth...   \n",
       "19985  45050  abay shinakht burhan teri nasal jisko malum ni...   \n",
       "19986  40898  banara ghat baat kuch modi banara bahut kuch d...   \n",
       "19987  44530  choos dekhat ki favourit repli mein see intere...   \n",
       "19988  28106  hindustan tukd karn sochog iss bada tamacha tu...   \n",
       "19989  26483  yehi dmagh kharab kiy hain jais indian midea a...   \n",
       "19990  18074  digit kya bakchodi flop actor batman bana diya...   \n",
       "19991  11976                             Me modi kais keht hain   \n",
       "19992  31137       kya gaya aajkal polit parti kya bjp aisa kya   \n",
       "19993  35199  rajya sbha aapko mauka milna chahiy good think...   \n",
       "19994  40038  krishna rahul kanwal rajdeep lag bechar dard b...   \n",
       "19995  16859  kisi Ko khushi nahi nayi sarkar aati nay kaam ...   \n",
       "19996   2294  music life thank chhote ustad salman ali post ...   \n",
       "19997  29819  gilmour hmmmm realli sam outlaw not someth I a...   \n",
       "19998  34181  Ab gala faad nahi chalna chowkidar chor sharm ...   \n",
       "19999  36603  O lerki allah swt beha leti chor diffah rahi k...   \n",
       "\n",
       "      Sentiment Polarity  \n",
       "0                neutral  \n",
       "1                neutral  \n",
       "2               negative  \n",
       "3               positive  \n",
       "4                neutral  \n",
       "5               positive  \n",
       "6               negative  \n",
       "7                neutral  \n",
       "8               negative  \n",
       "9                neutral  \n",
       "10               neutral  \n",
       "11               neutral  \n",
       "12               neutral  \n",
       "13              positive  \n",
       "14              positive  \n",
       "15              positive  \n",
       "16              positive  \n",
       "17              negative  \n",
       "18              positive  \n",
       "19              negative  \n",
       "20              negative  \n",
       "21              positive  \n",
       "22              positive  \n",
       "23               neutral  \n",
       "24               neutral  \n",
       "25              negative  \n",
       "26               neutral  \n",
       "27               neutral  \n",
       "28              negative  \n",
       "29              positive  \n",
       "...                  ...  \n",
       "19970           positive  \n",
       "19971           positive  \n",
       "19972           negative  \n",
       "19973           positive  \n",
       "19974           negative  \n",
       "19975           negative  \n",
       "19976            neutral  \n",
       "19977            neutral  \n",
       "19978           negative  \n",
       "19979           negative  \n",
       "19980           negative  \n",
       "19981           positive  \n",
       "19982            neutral  \n",
       "19983           positive  \n",
       "19984            neutral  \n",
       "19985           negative  \n",
       "19986           positive  \n",
       "19987            neutral  \n",
       "19988            neutral  \n",
       "19989            neutral  \n",
       "19990            neutral  \n",
       "19991            neutral  \n",
       "19992            neutral  \n",
       "19993           positive  \n",
       "19994           negative  \n",
       "19995           negative  \n",
       "19996            neutral  \n",
       "19997            neutral  \n",
       "19998           negative  \n",
       "19999            neutral  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4525035, 4733420)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = df['Tweet'].apply(lambda x: x.split()) # tokenizing\n",
    "\n",
    "model_w2v = Word2Vec(tokenized_tweet, size=300,  window=5, min_count=1)\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(df['Tweet']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "\n",
    "        vec += model_w2v[word].reshape((1, size))\n",
    "        count += 1.\n",
    "\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 300))\n",
    "\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 300)\n",
    "    \n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27861"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_w2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d['negative'] = [1., 0., 0.]\n",
    "d['neutral'] = [0., 1., 0.]\n",
    "d['positive']  = [0., 0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "out=[]\n",
    "for i in df['Sentiment Polarity']:\n",
    "    out.append(d[i])\n",
    "out = np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordvec_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(\n",
    "        wordvec_arrays, \n",
    "        sentiment,\n",
    "        train_size=0.85, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "# print(len(X_test))\n",
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        train_size=0.82352942, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 300)\n",
      "(3000, 300)\n",
      "(3000, 300)\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape))\n",
    "print((X_test.shape))\n",
    "print((X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.6473333333333333\n",
      "F1-Score =  0.6505708985194985\n",
      "[[670 202  28]\n",
      " [331 565 204]\n",
      " [ 49 244 707]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.SVC(kernel='linear',decision_function_shape='ovr', class_weight='balanced',random_state=0)\n",
    "lin_clf.fit(X_train, y_train)\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.5036666666666667\n",
      "F1-Score =  0.5082570211216728\n",
      "[[480 304 116]\n",
      " [314 504 282]\n",
      " [ 98 375 527]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "dtree_model.fit(X_train, y_train) \n",
    "y_pred = dtree_model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value =  99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "error_rate = []\n",
    "# Will take some time\n",
    "best_k = 0\n",
    "k=0\n",
    "for i in range(1,100):\n",
    " \n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(X_train,y_train)\n",
    " pred_i = knn.predict(X_test)\n",
    " f=f1_score(y_test, pred_i, average='macro')\n",
    " if f>best_k:\n",
    "        best_k = f\n",
    "        k=i\n",
    " error_rate.append(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "markerfacecolor='red', markersize=10)\n",
    "plt.title('F1-Score vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.savefig('/Users/gaurav/Desktop/Hinglish/data/k/k_ex6-wv-1.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Best K value = \",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value =  99\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "markerfacecolor='red', markersize=10)\n",
    "plt.title('F1-Score vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.savefig('/Users/gaurav/Desktop/Hinglish/data/k/k_ex6-wv-1.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Best K value = \",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.6473333333333333\n",
      "F1-Score =  0.6525135608703417\n",
      "[[637 238  25]\n",
      " [303 613 184]\n",
      " [ 46 262 692]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "clf = knn.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.589\n",
      "F1-Score =  0.5734571450158678\n",
      "[[791  70  39]\n",
      " [579 304 217]\n",
      " [122 206 672]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-53adc00c182e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMNB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Score = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    608\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    609\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "y_pred = MNB.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.5966666666666667\n",
      "F1-Score =  0.6001801896101346\n",
      "[[447 414  39]\n",
      " [190 666 244]\n",
      " [ 26 297 677]]\n"
     ]
    }
   ],
   "source": [
    "diff = (max([max(i) for i in wordvec_arrays ]) - min([min(i) for i in wordvec_arrays ]))\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train+diff, y_train)\n",
    "y_pred = MNB.predict(X_test+diff)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.656\n",
      "F1-Score =  0.6597454798457952\n",
      "[[648 220  32]\n",
      " [290 606 204]\n",
      " [ 51 235 714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "log_model = log_model.fit(X_train, y_train)\n",
    "y_pred = log_model.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8663064161936442  minutes\n",
      "Accuracy Score =  0.6563333333333333\n",
      "F1-Score =  0.6619406600802474\n",
      "[[591 279  30]\n",
      " [218 677 205]\n",
      " [ 33 266 701]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced')\n",
    "import time\n",
    "start_time=time.time()\n",
    "model.fit(X_train, y_train) \n",
    "duration = time.time()-start_time\n",
    "print(duration/60, \" minutes\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(\n",
    "        wordvec_arrays, \n",
    "        out,\n",
    "        train_size=0.85, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        train_size=0.82352942, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 300)\n",
      "(3000, 300)\n",
      "(3000, 300)\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape))\n",
    "print((X_test.shape))\n",
    "print((X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_results(nn_model_train,s): # plot performance over the training epochs\n",
    "  accuracy     = nn_model_train.history['accuracy']\n",
    "  val_accuracy = nn_model_train.history['val_accuracy']\n",
    "  loss         = nn_model_train.history['loss']\n",
    "  val_loss     = nn_model_train.history['val_loss']\n",
    "  epochs       = range(len(accuracy))\n",
    "  nb_epochs    = len(epochs)\n",
    "\n",
    "  f2 = plt.figure(2)\n",
    "  plt.figure(figsize = (30,10))\n",
    "\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.axis((0,nb_epochs,0.4,0.8))\n",
    "  plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "  plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.legend()\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.axis((0,nb_epochs,0.8,1.0))\n",
    "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "  plt.savefig('/Users/gaurav/Desktop/Hinglish/data/EX-6'+s+'.png',bbox_inches='tight')\n",
    "  plt.draw()\n",
    "  plt.pause(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 64\n",
    "epochs      = 50\n",
    "learning_rate = 0.0003\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "nr_hidden = 300\n",
    "nr_in     = 300\n",
    "nr_out    = 3 \n",
    "model.add(Dense(nr_in,activation='relu'))\n",
    "model.add(Dense(nr_hidden, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-100, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-100, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-200, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-200, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(nr_out,activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=learning_rate)\n",
    "model.compile(optimizer=opt,loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 3000 samples\n",
      "Epoch 1/1200\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 1.1100 - accuracy: 0.2934 - val_loss: 1.1054 - val_accuracy: 0.2973\n",
      "Epoch 2/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.1059 - accuracy: 0.2951 - val_loss: 1.1018 - val_accuracy: 0.3073\n",
      "Epoch 3/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 1.1023 - accuracy: 0.3128 - val_loss: 1.0987 - val_accuracy: 0.3400\n",
      "Epoch 4/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 1.0990 - accuracy: 0.3535 - val_loss: 1.0958 - val_accuracy: 0.3853\n",
      "Epoch 5/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 1.0959 - accuracy: 0.3881 - val_loss: 1.0932 - val_accuracy: 0.4087\n",
      "Epoch 6/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 1.0932 - accuracy: 0.4084 - val_loss: 1.0908 - val_accuracy: 0.4183\n",
      "Epoch 7/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 1.0906 - accuracy: 0.4191 - val_loss: 1.0886 - val_accuracy: 0.4283\n",
      "Epoch 8/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 1.0882 - accuracy: 0.4261 - val_loss: 1.0864 - val_accuracy: 0.4253\n",
      "Epoch 9/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 1.0859 - accuracy: 0.4282 - val_loss: 1.0843 - val_accuracy: 0.4183\n",
      "Epoch 10/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 1.0836 - accuracy: 0.4303 - val_loss: 1.0822 - val_accuracy: 0.4173\n",
      "Epoch 11/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0813 - accuracy: 0.4324 - val_loss: 1.0801 - val_accuracy: 0.4183\n",
      "Epoch 12/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 1.0790 - accuracy: 0.4347 - val_loss: 1.0779 - val_accuracy: 0.4220\n",
      "Epoch 13/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 1.0766 - accuracy: 0.4386 - val_loss: 1.0756 - val_accuracy: 0.4257\n",
      "Epoch 14/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 1.0741 - accuracy: 0.4445 - val_loss: 1.0733 - val_accuracy: 0.4297\n",
      "Epoch 15/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 1.0716 - accuracy: 0.4476 - val_loss: 1.0708 - val_accuracy: 0.4333\n",
      "Epoch 16/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0689 - accuracy: 0.4530 - val_loss: 1.0683 - val_accuracy: 0.4357\n",
      "Epoch 17/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0662 - accuracy: 0.4597 - val_loss: 1.0657 - val_accuracy: 0.4407\n",
      "Epoch 18/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0633 - accuracy: 0.4671 - val_loss: 1.0629 - val_accuracy: 0.4527\n",
      "Epoch 19/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 1.0604 - accuracy: 0.4726 - val_loss: 1.0600 - val_accuracy: 0.4600\n",
      "Epoch 20/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0573 - accuracy: 0.4803 - val_loss: 1.0571 - val_accuracy: 0.4647\n",
      "Epoch 21/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 1.0541 - accuracy: 0.4906 - val_loss: 1.0540 - val_accuracy: 0.4790\n",
      "Epoch 22/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 1.0508 - accuracy: 0.4994 - val_loss: 1.0508 - val_accuracy: 0.4907\n",
      "Epoch 23/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 1.0474 - accuracy: 0.5090 - val_loss: 1.0474 - val_accuracy: 0.4983\n",
      "Epoch 24/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 1.0438 - accuracy: 0.5178 - val_loss: 1.0440 - val_accuracy: 0.5070\n",
      "Epoch 25/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0401 - accuracy: 0.5273 - val_loss: 1.0404 - val_accuracy: 0.5113\n",
      "Epoch 26/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0363 - accuracy: 0.5374 - val_loss: 1.0368 - val_accuracy: 0.5237\n",
      "Epoch 27/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 1.0324 - accuracy: 0.5442 - val_loss: 1.0330 - val_accuracy: 0.5320\n",
      "Epoch 28/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0284 - accuracy: 0.5489 - val_loss: 1.0291 - val_accuracy: 0.5363\n",
      "Epoch 29/1200\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 1.0242 - accuracy: 0.5516 - val_loss: 1.0250 - val_accuracy: 0.5380\n",
      "Epoch 30/1200\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 1.0199 - accuracy: 0.5559 - val_loss: 1.0208 - val_accuracy: 0.5393\n",
      "Epoch 31/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 1.0154 - accuracy: 0.5583 - val_loss: 1.0164 - val_accuracy: 0.5383\n",
      "Epoch 32/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 1.0108 - accuracy: 0.5608 - val_loss: 1.0120 - val_accuracy: 0.5410\n",
      "Epoch 33/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 1.0060 - accuracy: 0.5594 - val_loss: 1.0073 - val_accuracy: 0.5450\n",
      "Epoch 34/1200\n",
      "14000/14000 [==============================] - 1s 77us/step - loss: 1.0011 - accuracy: 0.5604 - val_loss: 1.0026 - val_accuracy: 0.5420\n",
      "Epoch 35/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.9960 - accuracy: 0.5597 - val_loss: 0.9977 - val_accuracy: 0.5443\n",
      "Epoch 36/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.9909 - accuracy: 0.5597 - val_loss: 0.9928 - val_accuracy: 0.5473\n",
      "Epoch 37/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.9858 - accuracy: 0.5601 - val_loss: 0.9877 - val_accuracy: 0.5493\n",
      "Epoch 38/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.9805 - accuracy: 0.5617 - val_loss: 0.9827 - val_accuracy: 0.5517\n",
      "Epoch 39/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.9753 - accuracy: 0.5619 - val_loss: 0.9776 - val_accuracy: 0.5527\n",
      "Epoch 40/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9701 - accuracy: 0.5635 - val_loss: 0.9725 - val_accuracy: 0.5550\n",
      "Epoch 41/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.9648 - accuracy: 0.5646 - val_loss: 0.9675 - val_accuracy: 0.5530\n",
      "Epoch 42/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9596 - accuracy: 0.5646 - val_loss: 0.9625 - val_accuracy: 0.5523\n",
      "Epoch 43/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.9545 - accuracy: 0.5650 - val_loss: 0.9575 - val_accuracy: 0.5510\n",
      "Epoch 44/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.9494 - accuracy: 0.5661 - val_loss: 0.9526 - val_accuracy: 0.5510\n",
      "Epoch 45/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.9445 - accuracy: 0.5662 - val_loss: 0.9478 - val_accuracy: 0.5527\n",
      "Epoch 46/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.9396 - accuracy: 0.5656 - val_loss: 0.9431 - val_accuracy: 0.5540\n",
      "Epoch 47/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.9349 - accuracy: 0.5664 - val_loss: 0.9385 - val_accuracy: 0.5543\n",
      "Epoch 48/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9304 - accuracy: 0.5676 - val_loss: 0.9341 - val_accuracy: 0.5540\n",
      "Epoch 49/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.9260 - accuracy: 0.5677 - val_loss: 0.9298 - val_accuracy: 0.5560\n",
      "Epoch 50/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.9217 - accuracy: 0.5685 - val_loss: 0.9258 - val_accuracy: 0.5570\n",
      "Epoch 51/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.9177 - accuracy: 0.5687 - val_loss: 0.9217 - val_accuracy: 0.5573\n",
      "Epoch 52/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9139 - accuracy: 0.5695 - val_loss: 0.9179 - val_accuracy: 0.5580\n",
      "Epoch 53/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9102 - accuracy: 0.5702 - val_loss: 0.9144 - val_accuracy: 0.5617\n",
      "Epoch 54/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.9068 - accuracy: 0.5716 - val_loss: 0.9111 - val_accuracy: 0.5627\n",
      "Epoch 55/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9035 - accuracy: 0.5723 - val_loss: 0.9078 - val_accuracy: 0.5627\n",
      "Epoch 56/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9004 - accuracy: 0.5739 - val_loss: 0.9048 - val_accuracy: 0.5650\n",
      "Epoch 57/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8975 - accuracy: 0.5751 - val_loss: 0.9020 - val_accuracy: 0.5650\n",
      "Epoch 58/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8948 - accuracy: 0.5761 - val_loss: 0.8994 - val_accuracy: 0.5660\n",
      "Epoch 59/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8923 - accuracy: 0.5764 - val_loss: 0.8969 - val_accuracy: 0.5683\n",
      "Epoch 60/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8899 - accuracy: 0.5769 - val_loss: 0.8945 - val_accuracy: 0.5693\n",
      "Epoch 61/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8877 - accuracy: 0.5773 - val_loss: 0.8924 - val_accuracy: 0.5703\n",
      "Epoch 62/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8856 - accuracy: 0.5786 - val_loss: 0.8903 - val_accuracy: 0.5697\n",
      "Epoch 63/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8837 - accuracy: 0.5800 - val_loss: 0.8882 - val_accuracy: 0.5733\n",
      "Epoch 64/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8818 - accuracy: 0.5801 - val_loss: 0.8866 - val_accuracy: 0.5717\n",
      "Epoch 65/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8801 - accuracy: 0.5818 - val_loss: 0.8848 - val_accuracy: 0.5740\n",
      "Epoch 66/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8786 - accuracy: 0.5824 - val_loss: 0.8833 - val_accuracy: 0.5737\n",
      "Epoch 67/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8771 - accuracy: 0.5835 - val_loss: 0.8818 - val_accuracy: 0.5767\n",
      "Epoch 68/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8757 - accuracy: 0.5840 - val_loss: 0.8804 - val_accuracy: 0.5787\n",
      "Epoch 69/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8743 - accuracy: 0.5843 - val_loss: 0.8791 - val_accuracy: 0.5810\n",
      "Epoch 70/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8731 - accuracy: 0.5847 - val_loss: 0.8780 - val_accuracy: 0.5813\n",
      "Epoch 71/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8720 - accuracy: 0.5854 - val_loss: 0.8768 - val_accuracy: 0.5830\n",
      "Epoch 72/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8709 - accuracy: 0.5876 - val_loss: 0.8756 - val_accuracy: 0.5863\n",
      "Epoch 73/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8699 - accuracy: 0.5862 - val_loss: 0.8747 - val_accuracy: 0.5857\n",
      "Epoch 74/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8689 - accuracy: 0.5886 - val_loss: 0.8738 - val_accuracy: 0.5853\n",
      "Epoch 75/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8680 - accuracy: 0.5874 - val_loss: 0.8728 - val_accuracy: 0.5877\n",
      "Epoch 76/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8671 - accuracy: 0.5880 - val_loss: 0.8718 - val_accuracy: 0.5887\n",
      "Epoch 77/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8664 - accuracy: 0.5905 - val_loss: 0.8712 - val_accuracy: 0.5867\n",
      "Epoch 78/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8656 - accuracy: 0.5905 - val_loss: 0.8704 - val_accuracy: 0.5863\n",
      "Epoch 79/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8648 - accuracy: 0.5906 - val_loss: 0.8696 - val_accuracy: 0.5910\n",
      "Epoch 80/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8642 - accuracy: 0.5910 - val_loss: 0.8692 - val_accuracy: 0.5890\n",
      "Epoch 81/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.8635 - accuracy: 0.5919 - val_loss: 0.8686 - val_accuracy: 0.5883\n",
      "Epoch 82/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.8629 - accuracy: 0.5918 - val_loss: 0.8680 - val_accuracy: 0.5880\n",
      "Epoch 83/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8623 - accuracy: 0.5922 - val_loss: 0.8674 - val_accuracy: 0.5893\n",
      "Epoch 84/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8617 - accuracy: 0.5930 - val_loss: 0.8671 - val_accuracy: 0.5890\n",
      "Epoch 85/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8612 - accuracy: 0.5946 - val_loss: 0.8664 - val_accuracy: 0.5893\n",
      "Epoch 86/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8607 - accuracy: 0.5951 - val_loss: 0.8660 - val_accuracy: 0.5887\n",
      "Epoch 87/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8601 - accuracy: 0.5947 - val_loss: 0.8660 - val_accuracy: 0.5903\n",
      "Epoch 88/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8597 - accuracy: 0.5956 - val_loss: 0.8652 - val_accuracy: 0.5897\n",
      "Epoch 89/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8592 - accuracy: 0.5955 - val_loss: 0.8647 - val_accuracy: 0.5910\n",
      "Epoch 90/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8588 - accuracy: 0.5959 - val_loss: 0.8645 - val_accuracy: 0.5913\n",
      "Epoch 91/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8584 - accuracy: 0.5962 - val_loss: 0.8638 - val_accuracy: 0.5920\n",
      "Epoch 92/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8579 - accuracy: 0.5959 - val_loss: 0.8638 - val_accuracy: 0.5920\n",
      "Epoch 93/1200\n",
      "14000/14000 [==============================] - 1s 78us/step - loss: 0.8576 - accuracy: 0.5962 - val_loss: 0.8633 - val_accuracy: 0.5900\n",
      "Epoch 94/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8572 - accuracy: 0.5961 - val_loss: 0.8630 - val_accuracy: 0.5913\n",
      "Epoch 95/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8569 - accuracy: 0.5958 - val_loss: 0.8630 - val_accuracy: 0.5910\n",
      "Epoch 96/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8565 - accuracy: 0.5957 - val_loss: 0.8623 - val_accuracy: 0.5930\n",
      "Epoch 97/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8562 - accuracy: 0.5956 - val_loss: 0.8624 - val_accuracy: 0.5917\n",
      "Epoch 98/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8558 - accuracy: 0.5956 - val_loss: 0.8620 - val_accuracy: 0.5910\n",
      "Epoch 99/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8555 - accuracy: 0.5969 - val_loss: 0.8619 - val_accuracy: 0.5907\n",
      "Epoch 100/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8552 - accuracy: 0.5969 - val_loss: 0.8616 - val_accuracy: 0.5897\n",
      "Epoch 101/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8549 - accuracy: 0.5966 - val_loss: 0.8611 - val_accuracy: 0.5920\n",
      "Epoch 102/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8547 - accuracy: 0.5977 - val_loss: 0.8610 - val_accuracy: 0.5923\n",
      "Epoch 103/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.8544 - accuracy: 0.5964 - val_loss: 0.8609 - val_accuracy: 0.5907\n",
      "Epoch 104/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8541 - accuracy: 0.5964 - val_loss: 0.8607 - val_accuracy: 0.5920\n",
      "Epoch 105/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8539 - accuracy: 0.5969 - val_loss: 0.8607 - val_accuracy: 0.5913\n",
      "Epoch 106/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8536 - accuracy: 0.5971 - val_loss: 0.8607 - val_accuracy: 0.5917\n",
      "Epoch 107/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8533 - accuracy: 0.5963 - val_loss: 0.8600 - val_accuracy: 0.5923\n",
      "Epoch 108/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8531 - accuracy: 0.5986 - val_loss: 0.8602 - val_accuracy: 0.5927\n",
      "Epoch 109/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8529 - accuracy: 0.5969 - val_loss: 0.8599 - val_accuracy: 0.5933\n",
      "Epoch 110/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8526 - accuracy: 0.5976 - val_loss: 0.8596 - val_accuracy: 0.5927\n",
      "Epoch 111/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8524 - accuracy: 0.5981 - val_loss: 0.8596 - val_accuracy: 0.5927\n",
      "Epoch 112/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8522 - accuracy: 0.5976 - val_loss: 0.8592 - val_accuracy: 0.5923\n",
      "Epoch 113/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8519 - accuracy: 0.5994 - val_loss: 0.8595 - val_accuracy: 0.5940\n",
      "Epoch 114/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8518 - accuracy: 0.5986 - val_loss: 0.8591 - val_accuracy: 0.5947\n",
      "Epoch 115/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8515 - accuracy: 0.5979 - val_loss: 0.8587 - val_accuracy: 0.5927\n",
      "Epoch 116/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8513 - accuracy: 0.5988 - val_loss: 0.8592 - val_accuracy: 0.5940\n",
      "Epoch 117/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8512 - accuracy: 0.5983 - val_loss: 0.8587 - val_accuracy: 0.5943\n",
      "Epoch 118/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8509 - accuracy: 0.5998 - val_loss: 0.8584 - val_accuracy: 0.5923\n",
      "Epoch 119/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8508 - accuracy: 0.5988 - val_loss: 0.8588 - val_accuracy: 0.5943\n",
      "Epoch 120/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8506 - accuracy: 0.5989 - val_loss: 0.8584 - val_accuracy: 0.5937\n",
      "Epoch 121/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8504 - accuracy: 0.5992 - val_loss: 0.8582 - val_accuracy: 0.5943\n",
      "Epoch 122/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8503 - accuracy: 0.5991 - val_loss: 0.8583 - val_accuracy: 0.5933\n",
      "Epoch 123/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8500 - accuracy: 0.6001 - val_loss: 0.8579 - val_accuracy: 0.5937\n",
      "Epoch 124/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8499 - accuracy: 0.6000 - val_loss: 0.8581 - val_accuracy: 0.5930\n",
      "Epoch 125/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8497 - accuracy: 0.5993 - val_loss: 0.8578 - val_accuracy: 0.5933\n",
      "Epoch 126/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8495 - accuracy: 0.6011 - val_loss: 0.8579 - val_accuracy: 0.5940\n",
      "Epoch 127/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8494 - accuracy: 0.5992 - val_loss: 0.8575 - val_accuracy: 0.5927\n",
      "Epoch 128/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8492 - accuracy: 0.5996 - val_loss: 0.8573 - val_accuracy: 0.5923\n",
      "Epoch 129/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8491 - accuracy: 0.6004 - val_loss: 0.8574 - val_accuracy: 0.5937\n",
      "Epoch 130/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8489 - accuracy: 0.6006 - val_loss: 0.8572 - val_accuracy: 0.5917\n",
      "Epoch 131/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8488 - accuracy: 0.6009 - val_loss: 0.8573 - val_accuracy: 0.5943\n",
      "Epoch 132/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8486 - accuracy: 0.6009 - val_loss: 0.8571 - val_accuracy: 0.5920\n",
      "Epoch 133/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8484 - accuracy: 0.6006 - val_loss: 0.8571 - val_accuracy: 0.5940\n",
      "Epoch 134/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8483 - accuracy: 0.6006 - val_loss: 0.8570 - val_accuracy: 0.5927\n",
      "Epoch 135/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8482 - accuracy: 0.6002 - val_loss: 0.8568 - val_accuracy: 0.5930\n",
      "Epoch 136/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8480 - accuracy: 0.6013 - val_loss: 0.8569 - val_accuracy: 0.5940\n",
      "Epoch 137/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8478 - accuracy: 0.6004 - val_loss: 0.8571 - val_accuracy: 0.5930\n",
      "Epoch 138/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8477 - accuracy: 0.6009 - val_loss: 0.8567 - val_accuracy: 0.5940\n",
      "Epoch 139/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8475 - accuracy: 0.5997 - val_loss: 0.8565 - val_accuracy: 0.5930\n",
      "Epoch 140/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8474 - accuracy: 0.6017 - val_loss: 0.8564 - val_accuracy: 0.5917\n",
      "Epoch 141/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8473 - accuracy: 0.6026 - val_loss: 0.8563 - val_accuracy: 0.5920\n",
      "Epoch 142/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8471 - accuracy: 0.6014 - val_loss: 0.8561 - val_accuracy: 0.5937\n",
      "Epoch 143/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8470 - accuracy: 0.6021 - val_loss: 0.8562 - val_accuracy: 0.5920\n",
      "Epoch 144/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8468 - accuracy: 0.6019 - val_loss: 0.8561 - val_accuracy: 0.5923\n",
      "Epoch 145/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8466 - accuracy: 0.6021 - val_loss: 0.8558 - val_accuracy: 0.5933\n",
      "Epoch 146/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8466 - accuracy: 0.6034 - val_loss: 0.8559 - val_accuracy: 0.5920\n",
      "Epoch 147/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8464 - accuracy: 0.6026 - val_loss: 0.8561 - val_accuracy: 0.5943\n",
      "Epoch 148/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8462 - accuracy: 0.6019 - val_loss: 0.8562 - val_accuracy: 0.5940\n",
      "Epoch 149/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8462 - accuracy: 0.6013 - val_loss: 0.8557 - val_accuracy: 0.5923\n",
      "Epoch 150/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8460 - accuracy: 0.6024 - val_loss: 0.8555 - val_accuracy: 0.5917\n",
      "Epoch 151/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8459 - accuracy: 0.6029 - val_loss: 0.8555 - val_accuracy: 0.5927\n",
      "Epoch 152/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8458 - accuracy: 0.6033 - val_loss: 0.8555 - val_accuracy: 0.5937\n",
      "Epoch 153/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8456 - accuracy: 0.6020 - val_loss: 0.8555 - val_accuracy: 0.5937\n",
      "Epoch 154/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8455 - accuracy: 0.6029 - val_loss: 0.8557 - val_accuracy: 0.5940\n",
      "Epoch 155/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8454 - accuracy: 0.6029 - val_loss: 0.8556 - val_accuracy: 0.5947\n",
      "Epoch 156/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8453 - accuracy: 0.6019 - val_loss: 0.8552 - val_accuracy: 0.5923\n",
      "Epoch 157/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8452 - accuracy: 0.6027 - val_loss: 0.8551 - val_accuracy: 0.5927\n",
      "Epoch 158/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8450 - accuracy: 0.6034 - val_loss: 0.8551 - val_accuracy: 0.5930\n",
      "Epoch 159/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8448 - accuracy: 0.6031 - val_loss: 0.8548 - val_accuracy: 0.5967\n",
      "Epoch 160/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8448 - accuracy: 0.6039 - val_loss: 0.8549 - val_accuracy: 0.5927\n",
      "Epoch 161/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8447 - accuracy: 0.6042 - val_loss: 0.8549 - val_accuracy: 0.5933\n",
      "Epoch 162/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8446 - accuracy: 0.6026 - val_loss: 0.8547 - val_accuracy: 0.5927\n",
      "Epoch 163/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8444 - accuracy: 0.6038 - val_loss: 0.8550 - val_accuracy: 0.5937\n",
      "Epoch 164/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8443 - accuracy: 0.6041 - val_loss: 0.8550 - val_accuracy: 0.5940\n",
      "Epoch 165/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8441 - accuracy: 0.6051 - val_loss: 0.8546 - val_accuracy: 0.5947\n",
      "Epoch 166/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8441 - accuracy: 0.6040 - val_loss: 0.8546 - val_accuracy: 0.5933\n",
      "Epoch 167/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8439 - accuracy: 0.6044 - val_loss: 0.8544 - val_accuracy: 0.5940\n",
      "Epoch 168/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8438 - accuracy: 0.6046 - val_loss: 0.8544 - val_accuracy: 0.5943\n",
      "Epoch 169/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8437 - accuracy: 0.6049 - val_loss: 0.8547 - val_accuracy: 0.5933\n",
      "Epoch 170/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8436 - accuracy: 0.6035 - val_loss: 0.8541 - val_accuracy: 0.5943\n",
      "Epoch 171/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8435 - accuracy: 0.6043 - val_loss: 0.8543 - val_accuracy: 0.5943\n",
      "Epoch 172/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8434 - accuracy: 0.6044 - val_loss: 0.8541 - val_accuracy: 0.5940\n",
      "Epoch 173/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8433 - accuracy: 0.6039 - val_loss: 0.8542 - val_accuracy: 0.5943\n",
      "Epoch 174/1200\n",
      "14000/14000 [==============================] - 1s 79us/step - loss: 0.8431 - accuracy: 0.6046 - val_loss: 0.8539 - val_accuracy: 0.5940\n",
      "Epoch 175/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.8430 - accuracy: 0.6042 - val_loss: 0.8542 - val_accuracy: 0.5930\n",
      "Epoch 176/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.8430 - accuracy: 0.6058 - val_loss: 0.8539 - val_accuracy: 0.5953\n",
      "Epoch 177/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8428 - accuracy: 0.6052 - val_loss: 0.8539 - val_accuracy: 0.5947\n",
      "Epoch 178/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8427 - accuracy: 0.6051 - val_loss: 0.8538 - val_accuracy: 0.5947\n",
      "Epoch 179/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8426 - accuracy: 0.6059 - val_loss: 0.8536 - val_accuracy: 0.5953\n",
      "Epoch 180/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8425 - accuracy: 0.6059 - val_loss: 0.8540 - val_accuracy: 0.5933\n",
      "Epoch 181/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8424 - accuracy: 0.6053 - val_loss: 0.8535 - val_accuracy: 0.5953\n",
      "Epoch 182/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8423 - accuracy: 0.6057 - val_loss: 0.8534 - val_accuracy: 0.5960\n",
      "Epoch 183/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8422 - accuracy: 0.6061 - val_loss: 0.8537 - val_accuracy: 0.5927\n",
      "Epoch 184/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8421 - accuracy: 0.6064 - val_loss: 0.8533 - val_accuracy: 0.5960\n",
      "Epoch 185/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8420 - accuracy: 0.6056 - val_loss: 0.8533 - val_accuracy: 0.5950\n",
      "Epoch 186/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8418 - accuracy: 0.6056 - val_loss: 0.8536 - val_accuracy: 0.5957\n",
      "Epoch 187/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8418 - accuracy: 0.6055 - val_loss: 0.8533 - val_accuracy: 0.5943\n",
      "Epoch 188/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8416 - accuracy: 0.6056 - val_loss: 0.8530 - val_accuracy: 0.5967\n",
      "Epoch 189/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8416 - accuracy: 0.6064 - val_loss: 0.8532 - val_accuracy: 0.5947\n",
      "Epoch 190/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8415 - accuracy: 0.6061 - val_loss: 0.8530 - val_accuracy: 0.5967\n",
      "Epoch 191/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8414 - accuracy: 0.6061 - val_loss: 0.8530 - val_accuracy: 0.5963\n",
      "Epoch 192/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8412 - accuracy: 0.6066 - val_loss: 0.8530 - val_accuracy: 0.5953\n",
      "Epoch 193/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8412 - accuracy: 0.6068 - val_loss: 0.8529 - val_accuracy: 0.5957\n",
      "Epoch 194/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8410 - accuracy: 0.6058 - val_loss: 0.8531 - val_accuracy: 0.5920\n",
      "Epoch 195/1200\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.8409 - accuracy: 0.6064 - val_loss: 0.8526 - val_accuracy: 0.5970\n",
      "Epoch 196/1200\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.8408 - accuracy: 0.6071 - val_loss: 0.8530 - val_accuracy: 0.5930\n",
      "Epoch 197/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.8408 - accuracy: 0.6066 - val_loss: 0.8528 - val_accuracy: 0.5937\n",
      "Epoch 198/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8406 - accuracy: 0.6063 - val_loss: 0.8527 - val_accuracy: 0.5943\n",
      "Epoch 199/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8406 - accuracy: 0.6066 - val_loss: 0.8526 - val_accuracy: 0.5953\n",
      "Epoch 200/1200\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.8404 - accuracy: 0.6070 - val_loss: 0.8523 - val_accuracy: 0.5977\n",
      "Epoch 201/1200\n",
      "14000/14000 [==============================] - 1s 77us/step - loss: 0.8403 - accuracy: 0.6066 - val_loss: 0.8525 - val_accuracy: 0.5943\n",
      "Epoch 202/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8402 - accuracy: 0.6071 - val_loss: 0.8523 - val_accuracy: 0.5980\n",
      "Epoch 203/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8401 - accuracy: 0.6066 - val_loss: 0.8526 - val_accuracy: 0.5950\n",
      "Epoch 204/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8400 - accuracy: 0.6071 - val_loss: 0.8525 - val_accuracy: 0.5937\n",
      "Epoch 205/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8399 - accuracy: 0.6065 - val_loss: 0.8527 - val_accuracy: 0.5940\n",
      "Epoch 206/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8398 - accuracy: 0.6069 - val_loss: 0.8519 - val_accuracy: 0.5983\n",
      "Epoch 207/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8397 - accuracy: 0.6068 - val_loss: 0.8520 - val_accuracy: 0.5983\n",
      "Epoch 208/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8396 - accuracy: 0.6071 - val_loss: 0.8523 - val_accuracy: 0.5947\n",
      "Epoch 209/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8396 - accuracy: 0.6071 - val_loss: 0.8518 - val_accuracy: 0.5983\n",
      "Epoch 210/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8395 - accuracy: 0.6069 - val_loss: 0.8519 - val_accuracy: 0.5963\n",
      "Epoch 211/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8393 - accuracy: 0.6061 - val_loss: 0.8520 - val_accuracy: 0.5963\n",
      "Epoch 212/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8391 - accuracy: 0.6079 - val_loss: 0.8516 - val_accuracy: 0.5967\n",
      "Epoch 213/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8391 - accuracy: 0.6069 - val_loss: 0.8515 - val_accuracy: 0.5983\n",
      "Epoch 214/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8391 - accuracy: 0.6074 - val_loss: 0.8517 - val_accuracy: 0.5960\n",
      "Epoch 215/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8390 - accuracy: 0.6074 - val_loss: 0.8514 - val_accuracy: 0.5977\n",
      "Epoch 216/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8389 - accuracy: 0.6079 - val_loss: 0.8514 - val_accuracy: 0.5980\n",
      "Epoch 217/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8388 - accuracy: 0.6079 - val_loss: 0.8515 - val_accuracy: 0.5980\n",
      "Epoch 218/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8387 - accuracy: 0.6080 - val_loss: 0.8516 - val_accuracy: 0.5957\n",
      "Epoch 219/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8386 - accuracy: 0.6074 - val_loss: 0.8515 - val_accuracy: 0.5967\n",
      "Epoch 220/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8384 - accuracy: 0.6066 - val_loss: 0.8515 - val_accuracy: 0.5963\n",
      "Epoch 221/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8384 - accuracy: 0.6077 - val_loss: 0.8516 - val_accuracy: 0.5950\n",
      "Epoch 222/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8383 - accuracy: 0.6080 - val_loss: 0.8512 - val_accuracy: 0.5963\n",
      "Epoch 223/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8383 - accuracy: 0.6083 - val_loss: 0.8512 - val_accuracy: 0.5950\n",
      "Epoch 224/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8381 - accuracy: 0.6076 - val_loss: 0.8510 - val_accuracy: 0.5973\n",
      "Epoch 225/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8380 - accuracy: 0.6094 - val_loss: 0.8510 - val_accuracy: 0.5987\n",
      "Epoch 226/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8379 - accuracy: 0.6079 - val_loss: 0.8511 - val_accuracy: 0.5953\n",
      "Epoch 227/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8379 - accuracy: 0.6084 - val_loss: 0.8510 - val_accuracy: 0.5960\n",
      "Epoch 228/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8377 - accuracy: 0.6081 - val_loss: 0.8508 - val_accuracy: 0.5953\n",
      "Epoch 229/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8377 - accuracy: 0.6086 - val_loss: 0.8510 - val_accuracy: 0.5953\n",
      "Epoch 230/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.8375 - accuracy: 0.6084 - val_loss: 0.8510 - val_accuracy: 0.5947\n",
      "Epoch 231/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8374 - accuracy: 0.6093 - val_loss: 0.8512 - val_accuracy: 0.5950\n",
      "Epoch 232/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8374 - accuracy: 0.6086 - val_loss: 0.8507 - val_accuracy: 0.5960\n",
      "Epoch 233/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.8373 - accuracy: 0.6081 - val_loss: 0.8507 - val_accuracy: 0.5957\n",
      "Epoch 234/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8372 - accuracy: 0.6078 - val_loss: 0.8507 - val_accuracy: 0.5963\n",
      "Epoch 235/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8371 - accuracy: 0.6088 - val_loss: 0.8506 - val_accuracy: 0.5957\n",
      "Epoch 236/1200\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.8370 - accuracy: 0.6086 - val_loss: 0.8505 - val_accuracy: 0.5980\n",
      "Epoch 237/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8369 - accuracy: 0.6084 - val_loss: 0.8506 - val_accuracy: 0.5960\n",
      "Epoch 238/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8368 - accuracy: 0.6079 - val_loss: 0.8504 - val_accuracy: 0.5973\n",
      "Epoch 239/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8368 - accuracy: 0.6084 - val_loss: 0.8505 - val_accuracy: 0.5957\n",
      "Epoch 240/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8366 - accuracy: 0.6090 - val_loss: 0.8502 - val_accuracy: 0.5967\n",
      "Epoch 241/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.8365 - accuracy: 0.6092 - val_loss: 0.8501 - val_accuracy: 0.5967\n",
      "Epoch 242/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8366 - accuracy: 0.6089 - val_loss: 0.8502 - val_accuracy: 0.5987\n",
      "Epoch 243/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8364 - accuracy: 0.6091 - val_loss: 0.8502 - val_accuracy: 0.5973\n",
      "Epoch 244/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8363 - accuracy: 0.6087 - val_loss: 0.8503 - val_accuracy: 0.5950\n",
      "Epoch 245/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8362 - accuracy: 0.6097 - val_loss: 0.8500 - val_accuracy: 0.5953\n",
      "Epoch 246/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8361 - accuracy: 0.6091 - val_loss: 0.8500 - val_accuracy: 0.5980\n",
      "Epoch 247/1200\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.8361 - accuracy: 0.6093 - val_loss: 0.8503 - val_accuracy: 0.5977\n",
      "Epoch 248/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.8360 - accuracy: 0.6095 - val_loss: 0.8501 - val_accuracy: 0.5967\n",
      "Epoch 249/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.8359 - accuracy: 0.6090 - val_loss: 0.8501 - val_accuracy: 0.5977\n",
      "Epoch 250/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.8358 - accuracy: 0.6097 - val_loss: 0.8499 - val_accuracy: 0.5977\n",
      "Epoch 251/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8357 - accuracy: 0.6097 - val_loss: 0.8498 - val_accuracy: 0.5983\n",
      "Epoch 252/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8356 - accuracy: 0.6092 - val_loss: 0.8496 - val_accuracy: 0.5970\n",
      "Epoch 253/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8356 - accuracy: 0.6091 - val_loss: 0.8500 - val_accuracy: 0.5973\n",
      "Epoch 254/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8355 - accuracy: 0.6085 - val_loss: 0.8496 - val_accuracy: 0.5980\n",
      "Epoch 255/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8354 - accuracy: 0.6095 - val_loss: 0.8495 - val_accuracy: 0.5973\n",
      "Epoch 256/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8353 - accuracy: 0.6096 - val_loss: 0.8498 - val_accuracy: 0.5973\n",
      "Epoch 257/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8352 - accuracy: 0.6094 - val_loss: 0.8495 - val_accuracy: 0.5983\n",
      "Epoch 258/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8351 - accuracy: 0.6101 - val_loss: 0.8497 - val_accuracy: 0.5977\n",
      "Epoch 259/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8351 - accuracy: 0.6104 - val_loss: 0.8496 - val_accuracy: 0.5980\n",
      "Epoch 260/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8350 - accuracy: 0.6099 - val_loss: 0.8497 - val_accuracy: 0.5987\n",
      "Epoch 261/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8349 - accuracy: 0.6095 - val_loss: 0.8495 - val_accuracy: 0.5983\n",
      "Epoch 262/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8348 - accuracy: 0.6100 - val_loss: 0.8493 - val_accuracy: 0.5990\n",
      "Epoch 263/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8347 - accuracy: 0.6109 - val_loss: 0.8493 - val_accuracy: 0.5990\n",
      "Epoch 264/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8346 - accuracy: 0.6106 - val_loss: 0.8493 - val_accuracy: 0.5997\n",
      "Epoch 265/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8346 - accuracy: 0.6099 - val_loss: 0.8493 - val_accuracy: 0.5987\n",
      "Epoch 266/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8344 - accuracy: 0.6111 - val_loss: 0.8496 - val_accuracy: 0.5977\n",
      "Epoch 267/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8344 - accuracy: 0.6097 - val_loss: 0.8494 - val_accuracy: 0.5967\n",
      "Epoch 268/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8343 - accuracy: 0.6106 - val_loss: 0.8491 - val_accuracy: 0.5997\n",
      "Epoch 269/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8343 - accuracy: 0.6095 - val_loss: 0.8490 - val_accuracy: 0.5987\n",
      "Epoch 270/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8341 - accuracy: 0.6109 - val_loss: 0.8491 - val_accuracy: 0.5983\n",
      "Epoch 271/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8341 - accuracy: 0.6098 - val_loss: 0.8491 - val_accuracy: 0.5983\n",
      "Epoch 272/1200\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.8340 - accuracy: 0.6111 - val_loss: 0.8488 - val_accuracy: 0.5977\n",
      "Epoch 273/1200\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.8339 - accuracy: 0.6112 - val_loss: 0.8489 - val_accuracy: 0.5993\n",
      "Epoch 274/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8338 - accuracy: 0.6113 - val_loss: 0.8487 - val_accuracy: 0.5980\n",
      "Epoch 275/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8338 - accuracy: 0.6120 - val_loss: 0.8489 - val_accuracy: 0.5987\n",
      "Epoch 276/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8337 - accuracy: 0.6105 - val_loss: 0.8486 - val_accuracy: 0.5983\n",
      "Epoch 277/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8336 - accuracy: 0.6114 - val_loss: 0.8486 - val_accuracy: 0.5977\n",
      "Epoch 278/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8335 - accuracy: 0.6113 - val_loss: 0.8486 - val_accuracy: 0.5977\n",
      "Epoch 279/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8335 - accuracy: 0.6104 - val_loss: 0.8488 - val_accuracy: 0.6003\n",
      "Epoch 280/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8333 - accuracy: 0.6109 - val_loss: 0.8490 - val_accuracy: 0.6003\n",
      "Epoch 281/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8333 - accuracy: 0.6114 - val_loss: 0.8486 - val_accuracy: 0.6000\n",
      "Epoch 282/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8333 - accuracy: 0.6114 - val_loss: 0.8486 - val_accuracy: 0.5980\n",
      "Epoch 283/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8331 - accuracy: 0.6122 - val_loss: 0.8485 - val_accuracy: 0.5993\n",
      "Epoch 284/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8331 - accuracy: 0.6116 - val_loss: 0.8484 - val_accuracy: 0.5993\n",
      "Epoch 285/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8330 - accuracy: 0.6119 - val_loss: 0.8484 - val_accuracy: 0.5993\n",
      "Epoch 286/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.8329 - accuracy: 0.6121 - val_loss: 0.8483 - val_accuracy: 0.5993\n",
      "Epoch 287/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8329 - accuracy: 0.6116 - val_loss: 0.8486 - val_accuracy: 0.5993\n",
      "Epoch 288/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8327 - accuracy: 0.6113 - val_loss: 0.8483 - val_accuracy: 0.5993\n",
      "Epoch 289/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8327 - accuracy: 0.6111 - val_loss: 0.8481 - val_accuracy: 0.5983\n",
      "Epoch 290/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8326 - accuracy: 0.6129 - val_loss: 0.8481 - val_accuracy: 0.5977\n",
      "Epoch 291/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8326 - accuracy: 0.6128 - val_loss: 0.8482 - val_accuracy: 0.6000\n",
      "Epoch 292/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8325 - accuracy: 0.6118 - val_loss: 0.8482 - val_accuracy: 0.5990\n",
      "Epoch 293/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8324 - accuracy: 0.6123 - val_loss: 0.8482 - val_accuracy: 0.5997\n",
      "Epoch 294/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8323 - accuracy: 0.6123 - val_loss: 0.8481 - val_accuracy: 0.5987\n",
      "Epoch 295/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8322 - accuracy: 0.6126 - val_loss: 0.8479 - val_accuracy: 0.5987\n",
      "Epoch 296/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8322 - accuracy: 0.6121 - val_loss: 0.8480 - val_accuracy: 0.5983\n",
      "Epoch 297/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8321 - accuracy: 0.6129 - val_loss: 0.8478 - val_accuracy: 0.5997\n",
      "Epoch 298/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8319 - accuracy: 0.6123 - val_loss: 0.8488 - val_accuracy: 0.6027\n",
      "Epoch 299/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8320 - accuracy: 0.6123 - val_loss: 0.8485 - val_accuracy: 0.6023\n",
      "Epoch 300/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8319 - accuracy: 0.6126 - val_loss: 0.8478 - val_accuracy: 0.5990\n",
      "Epoch 301/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8318 - accuracy: 0.6129 - val_loss: 0.8481 - val_accuracy: 0.6007\n",
      "Epoch 302/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8317 - accuracy: 0.6125 - val_loss: 0.8477 - val_accuracy: 0.5993\n",
      "Epoch 303/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8317 - accuracy: 0.6131 - val_loss: 0.8477 - val_accuracy: 0.5983\n",
      "Epoch 304/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.8316 - accuracy: 0.6122 - val_loss: 0.8479 - val_accuracy: 0.5993\n",
      "Epoch 305/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8315 - accuracy: 0.6139 - val_loss: 0.8478 - val_accuracy: 0.5993\n",
      "Epoch 306/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8314 - accuracy: 0.6135 - val_loss: 0.8476 - val_accuracy: 0.6023\n",
      "Epoch 307/1200\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.8313 - accuracy: 0.6136 - val_loss: 0.8479 - val_accuracy: 0.6000\n",
      "Epoch 308/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.8313 - accuracy: 0.6125 - val_loss: 0.8478 - val_accuracy: 0.6000\n",
      "Epoch 309/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8312 - accuracy: 0.6131 - val_loss: 0.8477 - val_accuracy: 0.6003\n",
      "Epoch 310/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8311 - accuracy: 0.6137 - val_loss: 0.8477 - val_accuracy: 0.6007\n",
      "Epoch 311/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8310 - accuracy: 0.6131 - val_loss: 0.8474 - val_accuracy: 0.6030\n",
      "Epoch 312/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8310 - accuracy: 0.6141 - val_loss: 0.8477 - val_accuracy: 0.6000\n",
      "Epoch 313/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8309 - accuracy: 0.6135 - val_loss: 0.8475 - val_accuracy: 0.5990\n",
      "Epoch 314/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8308 - accuracy: 0.6131 - val_loss: 0.8474 - val_accuracy: 0.6017\n",
      "Epoch 315/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8308 - accuracy: 0.6131 - val_loss: 0.8473 - val_accuracy: 0.6030\n",
      "Epoch 316/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8307 - accuracy: 0.6130 - val_loss: 0.8475 - val_accuracy: 0.6000\n",
      "Epoch 317/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8306 - accuracy: 0.6144 - val_loss: 0.8472 - val_accuracy: 0.6020\n",
      "Epoch 318/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8306 - accuracy: 0.6139 - val_loss: 0.8473 - val_accuracy: 0.6013\n",
      "Epoch 319/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8305 - accuracy: 0.6138 - val_loss: 0.8476 - val_accuracy: 0.6017\n",
      "Epoch 320/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8304 - accuracy: 0.6131 - val_loss: 0.8474 - val_accuracy: 0.6010\n",
      "Epoch 321/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8303 - accuracy: 0.6142 - val_loss: 0.8475 - val_accuracy: 0.6013\n",
      "Epoch 322/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.8302 - accuracy: 0.6141 - val_loss: 0.8471 - val_accuracy: 0.6017\n",
      "Epoch 323/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8302 - accuracy: 0.6139 - val_loss: 0.8473 - val_accuracy: 0.6013\n",
      "Epoch 324/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8301 - accuracy: 0.6147 - val_loss: 0.8472 - val_accuracy: 0.6013\n",
      "Epoch 325/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8301 - accuracy: 0.6136 - val_loss: 0.8472 - val_accuracy: 0.6007\n",
      "Epoch 326/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8299 - accuracy: 0.6149 - val_loss: 0.8470 - val_accuracy: 0.6030\n",
      "Epoch 327/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8298 - accuracy: 0.6144 - val_loss: 0.8474 - val_accuracy: 0.6013\n",
      "Epoch 328/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8298 - accuracy: 0.6145 - val_loss: 0.8470 - val_accuracy: 0.6030\n",
      "Epoch 329/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8297 - accuracy: 0.6141 - val_loss: 0.8468 - val_accuracy: 0.6027\n",
      "Epoch 330/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.8297 - accuracy: 0.6146 - val_loss: 0.8468 - val_accuracy: 0.6013\n",
      "Epoch 331/1200\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.8297 - accuracy: 0.6131 - val_loss: 0.8469 - val_accuracy: 0.6027\n",
      "Epoch 332/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8295 - accuracy: 0.6139 - val_loss: 0.8469 - val_accuracy: 0.6020\n",
      "Epoch 333/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8294 - accuracy: 0.6152 - val_loss: 0.8467 - val_accuracy: 0.6027\n",
      "Epoch 334/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8293 - accuracy: 0.6154 - val_loss: 0.8471 - val_accuracy: 0.6030\n",
      "Epoch 335/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.8294 - accuracy: 0.6144 - val_loss: 0.8467 - val_accuracy: 0.6040\n",
      "Epoch 336/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8292 - accuracy: 0.6149 - val_loss: 0.8467 - val_accuracy: 0.6007\n",
      "Epoch 337/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8292 - accuracy: 0.6139 - val_loss: 0.8470 - val_accuracy: 0.6013\n",
      "Epoch 338/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8291 - accuracy: 0.6144 - val_loss: 0.8465 - val_accuracy: 0.6023\n",
      "Epoch 339/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8290 - accuracy: 0.6151 - val_loss: 0.8466 - val_accuracy: 0.6033\n",
      "Epoch 340/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8290 - accuracy: 0.6154 - val_loss: 0.8468 - val_accuracy: 0.6020\n",
      "Epoch 341/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8289 - accuracy: 0.6139 - val_loss: 0.8465 - val_accuracy: 0.6020\n",
      "Epoch 342/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8288 - accuracy: 0.6151 - val_loss: 0.8466 - val_accuracy: 0.6030\n",
      "Epoch 343/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8287 - accuracy: 0.6149 - val_loss: 0.8466 - val_accuracy: 0.6033\n",
      "Epoch 344/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8287 - accuracy: 0.6145 - val_loss: 0.8465 - val_accuracy: 0.6033\n",
      "Epoch 345/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8286 - accuracy: 0.6147 - val_loss: 0.8468 - val_accuracy: 0.6023\n",
      "Epoch 346/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8286 - accuracy: 0.6159 - val_loss: 0.8463 - val_accuracy: 0.6030\n",
      "Epoch 347/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8284 - accuracy: 0.6160 - val_loss: 0.8464 - val_accuracy: 0.6013\n",
      "Epoch 348/1200\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.8284 - accuracy: 0.6149 - val_loss: 0.8465 - val_accuracy: 0.6033\n",
      "Epoch 349/1200\n",
      "14000/14000 [==============================] - 4s 278us/step - loss: 0.8283 - accuracy: 0.6156 - val_loss: 0.8464 - val_accuracy: 0.6033\n",
      "Epoch 350/1200\n",
      "14000/14000 [==============================] - 2s 130us/step - loss: 0.8283 - accuracy: 0.6151 - val_loss: 0.8465 - val_accuracy: 0.6033\n",
      "Epoch 351/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.8282 - accuracy: 0.6151 - val_loss: 0.8462 - val_accuracy: 0.6003\n",
      "Epoch 352/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8282 - accuracy: 0.6157 - val_loss: 0.8462 - val_accuracy: 0.6010\n",
      "Epoch 353/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8281 - accuracy: 0.6165 - val_loss: 0.8462 - val_accuracy: 0.6030\n",
      "Epoch 354/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.8280 - accuracy: 0.6149 - val_loss: 0.8462 - val_accuracy: 0.6037\n",
      "Epoch 355/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8279 - accuracy: 0.6149 - val_loss: 0.8462 - val_accuracy: 0.6020\n",
      "Epoch 356/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8279 - accuracy: 0.6154 - val_loss: 0.8463 - val_accuracy: 0.6030\n",
      "Epoch 357/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8278 - accuracy: 0.6161 - val_loss: 0.8467 - val_accuracy: 0.6023\n",
      "Epoch 358/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8278 - accuracy: 0.6157 - val_loss: 0.8465 - val_accuracy: 0.6027\n",
      "Epoch 359/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.8276 - accuracy: 0.6160 - val_loss: 0.8469 - val_accuracy: 0.6013\n",
      "Epoch 360/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8276 - accuracy: 0.6158 - val_loss: 0.8466 - val_accuracy: 0.6020\n",
      "Epoch 361/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8275 - accuracy: 0.6165 - val_loss: 0.8463 - val_accuracy: 0.6020\n",
      "Epoch 362/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8275 - accuracy: 0.6151 - val_loss: 0.8461 - val_accuracy: 0.6027\n",
      "Epoch 363/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8274 - accuracy: 0.6165 - val_loss: 0.8462 - val_accuracy: 0.6020\n",
      "Epoch 364/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8273 - accuracy: 0.6154 - val_loss: 0.8466 - val_accuracy: 0.6010\n",
      "Epoch 365/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8271 - accuracy: 0.6160 - val_loss: 0.8458 - val_accuracy: 0.6027\n",
      "Epoch 366/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8272 - accuracy: 0.6164 - val_loss: 0.8460 - val_accuracy: 0.6027\n",
      "Epoch 367/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8271 - accuracy: 0.6149 - val_loss: 0.8458 - val_accuracy: 0.6017\n",
      "Epoch 368/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8270 - accuracy: 0.6168 - val_loss: 0.8462 - val_accuracy: 0.6017\n",
      "Epoch 369/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8268 - accuracy: 0.6154 - val_loss: 0.8458 - val_accuracy: 0.6023\n",
      "Epoch 370/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8269 - accuracy: 0.6148 - val_loss: 0.8461 - val_accuracy: 0.6010\n",
      "Epoch 371/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8268 - accuracy: 0.6169 - val_loss: 0.8459 - val_accuracy: 0.6033\n",
      "Epoch 372/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8268 - accuracy: 0.6166 - val_loss: 0.8458 - val_accuracy: 0.6023\n",
      "Epoch 373/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8266 - accuracy: 0.6165 - val_loss: 0.8456 - val_accuracy: 0.6023\n",
      "Epoch 374/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8266 - accuracy: 0.6162 - val_loss: 0.8456 - val_accuracy: 0.6013\n",
      "Epoch 375/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.8266 - accuracy: 0.6161 - val_loss: 0.8461 - val_accuracy: 0.6007\n",
      "Epoch 376/1200\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.8265 - accuracy: 0.6165 - val_loss: 0.8455 - val_accuracy: 0.6023\n",
      "Epoch 377/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8264 - accuracy: 0.6171 - val_loss: 0.8461 - val_accuracy: 0.6000\n",
      "Epoch 378/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8264 - accuracy: 0.6167 - val_loss: 0.8457 - val_accuracy: 0.6000\n",
      "Epoch 379/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8263 - accuracy: 0.6164 - val_loss: 0.8456 - val_accuracy: 0.6010\n",
      "Epoch 380/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8262 - accuracy: 0.6165 - val_loss: 0.8462 - val_accuracy: 0.6013\n",
      "Epoch 381/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8261 - accuracy: 0.6172 - val_loss: 0.8457 - val_accuracy: 0.6017\n",
      "Epoch 382/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8261 - accuracy: 0.6166 - val_loss: 0.8456 - val_accuracy: 0.6023\n",
      "Epoch 383/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.8260 - accuracy: 0.6153 - val_loss: 0.8458 - val_accuracy: 0.6027\n",
      "Epoch 384/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.8260 - accuracy: 0.6161 - val_loss: 0.8453 - val_accuracy: 0.6013\n",
      "Epoch 385/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.8258 - accuracy: 0.6166 - val_loss: 0.8461 - val_accuracy: 0.6033\n",
      "Epoch 386/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.8258 - accuracy: 0.6171 - val_loss: 0.8454 - val_accuracy: 0.6013\n",
      "Epoch 387/1200\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.8258 - accuracy: 0.6163 - val_loss: 0.8454 - val_accuracy: 0.6017\n",
      "Epoch 388/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.8256 - accuracy: 0.6163 - val_loss: 0.8457 - val_accuracy: 0.6007\n",
      "Epoch 389/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.8255 - accuracy: 0.6173 - val_loss: 0.8452 - val_accuracy: 0.6013\n",
      "Epoch 390/1200\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.8256 - accuracy: 0.6167 - val_loss: 0.8455 - val_accuracy: 0.6027\n",
      "Epoch 391/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8255 - accuracy: 0.6166 - val_loss: 0.8453 - val_accuracy: 0.6010\n",
      "Epoch 392/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.8254 - accuracy: 0.6170 - val_loss: 0.8453 - val_accuracy: 0.6000\n",
      "Epoch 393/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8254 - accuracy: 0.6172 - val_loss: 0.8452 - val_accuracy: 0.6010\n",
      "Epoch 394/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8253 - accuracy: 0.6168 - val_loss: 0.8455 - val_accuracy: 0.6003\n",
      "Epoch 395/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8252 - accuracy: 0.6175 - val_loss: 0.8451 - val_accuracy: 0.6013\n",
      "Epoch 396/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8251 - accuracy: 0.6190 - val_loss: 0.8458 - val_accuracy: 0.6030\n",
      "Epoch 397/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8252 - accuracy: 0.6166 - val_loss: 0.8451 - val_accuracy: 0.6003\n",
      "Epoch 398/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8250 - accuracy: 0.6164 - val_loss: 0.8455 - val_accuracy: 0.6017\n",
      "Epoch 399/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8249 - accuracy: 0.6166 - val_loss: 0.8450 - val_accuracy: 0.6007\n",
      "Epoch 400/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8249 - accuracy: 0.6174 - val_loss: 0.8449 - val_accuracy: 0.6007\n",
      "Epoch 401/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8247 - accuracy: 0.6194 - val_loss: 0.8449 - val_accuracy: 0.6010\n",
      "Epoch 402/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8246 - accuracy: 0.6181 - val_loss: 0.8453 - val_accuracy: 0.6023\n",
      "Epoch 403/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8247 - accuracy: 0.6178 - val_loss: 0.8449 - val_accuracy: 0.6017\n",
      "Epoch 404/1200\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.8247 - accuracy: 0.6174 - val_loss: 0.8451 - val_accuracy: 0.6020\n",
      "Epoch 405/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8246 - accuracy: 0.6174 - val_loss: 0.8451 - val_accuracy: 0.6007\n",
      "Epoch 406/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8244 - accuracy: 0.6177 - val_loss: 0.8450 - val_accuracy: 0.6010\n",
      "Epoch 407/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8245 - accuracy: 0.6183 - val_loss: 0.8450 - val_accuracy: 0.6013\n",
      "Epoch 408/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8243 - accuracy: 0.6181 - val_loss: 0.8449 - val_accuracy: 0.6023\n",
      "Epoch 409/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8243 - accuracy: 0.6172 - val_loss: 0.8448 - val_accuracy: 0.6017\n",
      "Epoch 410/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8242 - accuracy: 0.6167 - val_loss: 0.8447 - val_accuracy: 0.6017\n",
      "Epoch 411/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8241 - accuracy: 0.6199 - val_loss: 0.8449 - val_accuracy: 0.6030\n",
      "Epoch 412/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8242 - accuracy: 0.6163 - val_loss: 0.8448 - val_accuracy: 0.6030\n",
      "Epoch 413/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8241 - accuracy: 0.6171 - val_loss: 0.8447 - val_accuracy: 0.6017\n",
      "Epoch 414/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8240 - accuracy: 0.6186 - val_loss: 0.8447 - val_accuracy: 0.6000\n",
      "Epoch 415/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8239 - accuracy: 0.6178 - val_loss: 0.8448 - val_accuracy: 0.6027\n",
      "Epoch 416/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8238 - accuracy: 0.6176 - val_loss: 0.8449 - val_accuracy: 0.6013\n",
      "Epoch 417/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8237 - accuracy: 0.6189 - val_loss: 0.8446 - val_accuracy: 0.5983\n",
      "Epoch 418/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8237 - accuracy: 0.6190 - val_loss: 0.8447 - val_accuracy: 0.6017\n",
      "Epoch 419/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8237 - accuracy: 0.6180 - val_loss: 0.8447 - val_accuracy: 0.5990\n",
      "Epoch 420/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8236 - accuracy: 0.6187 - val_loss: 0.8447 - val_accuracy: 0.5990\n",
      "Epoch 421/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8235 - accuracy: 0.6184 - val_loss: 0.8444 - val_accuracy: 0.6017\n",
      "Epoch 422/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8235 - accuracy: 0.6191 - val_loss: 0.8447 - val_accuracy: 0.6037\n",
      "Epoch 423/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8234 - accuracy: 0.6190 - val_loss: 0.8446 - val_accuracy: 0.6017\n",
      "Epoch 424/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8233 - accuracy: 0.6189 - val_loss: 0.8444 - val_accuracy: 0.6013\n",
      "Epoch 425/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8233 - accuracy: 0.6185 - val_loss: 0.8444 - val_accuracy: 0.6013\n",
      "Epoch 426/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8231 - accuracy: 0.6191 - val_loss: 0.8445 - val_accuracy: 0.5987\n",
      "Epoch 427/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8231 - accuracy: 0.6189 - val_loss: 0.8443 - val_accuracy: 0.6000\n",
      "Epoch 428/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8230 - accuracy: 0.6195 - val_loss: 0.8447 - val_accuracy: 0.6023\n",
      "Epoch 429/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8230 - accuracy: 0.6193 - val_loss: 0.8444 - val_accuracy: 0.6017\n",
      "Epoch 430/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8229 - accuracy: 0.6188 - val_loss: 0.8443 - val_accuracy: 0.5987\n",
      "Epoch 431/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8229 - accuracy: 0.6192 - val_loss: 0.8443 - val_accuracy: 0.6020\n",
      "Epoch 432/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8227 - accuracy: 0.6190 - val_loss: 0.8447 - val_accuracy: 0.6013\n",
      "Epoch 433/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.8227 - accuracy: 0.6208 - val_loss: 0.8446 - val_accuracy: 0.6020\n",
      "Epoch 434/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8227 - accuracy: 0.6186 - val_loss: 0.8443 - val_accuracy: 0.6007\n",
      "Epoch 435/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8226 - accuracy: 0.6189 - val_loss: 0.8443 - val_accuracy: 0.6030\n",
      "Epoch 436/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8224 - accuracy: 0.6196 - val_loss: 0.8444 - val_accuracy: 0.6040\n",
      "Epoch 437/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8224 - accuracy: 0.6188 - val_loss: 0.8446 - val_accuracy: 0.6027\n",
      "Epoch 438/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8224 - accuracy: 0.6194 - val_loss: 0.8441 - val_accuracy: 0.6020\n",
      "Epoch 439/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8223 - accuracy: 0.6194 - val_loss: 0.8442 - val_accuracy: 0.6003\n",
      "Epoch 440/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8223 - accuracy: 0.6196 - val_loss: 0.8443 - val_accuracy: 0.6017\n",
      "Epoch 441/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8222 - accuracy: 0.6190 - val_loss: 0.8441 - val_accuracy: 0.6023\n",
      "Epoch 442/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8222 - accuracy: 0.6186 - val_loss: 0.8440 - val_accuracy: 0.6020\n",
      "Epoch 443/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8219 - accuracy: 0.6178 - val_loss: 0.8443 - val_accuracy: 0.5983\n",
      "Epoch 444/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8221 - accuracy: 0.6194 - val_loss: 0.8440 - val_accuracy: 0.6020\n",
      "Epoch 445/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8219 - accuracy: 0.6204 - val_loss: 0.8441 - val_accuracy: 0.6020\n",
      "Epoch 446/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8218 - accuracy: 0.6191 - val_loss: 0.8439 - val_accuracy: 0.6027\n",
      "Epoch 447/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8218 - accuracy: 0.6201 - val_loss: 0.8440 - val_accuracy: 0.6033\n",
      "Epoch 448/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8217 - accuracy: 0.6197 - val_loss: 0.8439 - val_accuracy: 0.6023\n",
      "Epoch 449/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8216 - accuracy: 0.6192 - val_loss: 0.8443 - val_accuracy: 0.6010\n",
      "Epoch 450/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8216 - accuracy: 0.6200 - val_loss: 0.8439 - val_accuracy: 0.6017\n",
      "Epoch 451/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8215 - accuracy: 0.6191 - val_loss: 0.8444 - val_accuracy: 0.6023\n",
      "Epoch 452/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8215 - accuracy: 0.6195 - val_loss: 0.8439 - val_accuracy: 0.6020\n",
      "Epoch 453/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8213 - accuracy: 0.6199 - val_loss: 0.8442 - val_accuracy: 0.6023\n",
      "Epoch 454/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8211 - accuracy: 0.6191 - val_loss: 0.8441 - val_accuracy: 0.6017\n",
      "Epoch 455/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8213 - accuracy: 0.6206 - val_loss: 0.8439 - val_accuracy: 0.6040\n",
      "Epoch 456/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8212 - accuracy: 0.6202 - val_loss: 0.8440 - val_accuracy: 0.6030\n",
      "Epoch 457/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8211 - accuracy: 0.6199 - val_loss: 0.8440 - val_accuracy: 0.6027\n",
      "Epoch 458/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8210 - accuracy: 0.6200 - val_loss: 0.8439 - val_accuracy: 0.6027\n",
      "Epoch 459/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8210 - accuracy: 0.6193 - val_loss: 0.8440 - val_accuracy: 0.6027\n",
      "Epoch 460/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8209 - accuracy: 0.6209 - val_loss: 0.8438 - val_accuracy: 0.6027\n",
      "Epoch 461/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8208 - accuracy: 0.6201 - val_loss: 0.8437 - val_accuracy: 0.5990\n",
      "Epoch 462/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8208 - accuracy: 0.6202 - val_loss: 0.8439 - val_accuracy: 0.6043\n",
      "Epoch 463/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8207 - accuracy: 0.6198 - val_loss: 0.8442 - val_accuracy: 0.6037\n",
      "Epoch 464/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8207 - accuracy: 0.6189 - val_loss: 0.8438 - val_accuracy: 0.6030\n",
      "Epoch 465/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8205 - accuracy: 0.6209 - val_loss: 0.8436 - val_accuracy: 0.6027\n",
      "Epoch 466/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8205 - accuracy: 0.6217 - val_loss: 0.8439 - val_accuracy: 0.6023\n",
      "Epoch 467/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8204 - accuracy: 0.6198 - val_loss: 0.8446 - val_accuracy: 0.6037\n",
      "Epoch 468/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8204 - accuracy: 0.6193 - val_loss: 0.8437 - val_accuracy: 0.6030\n",
      "Epoch 469/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8202 - accuracy: 0.6213 - val_loss: 0.8437 - val_accuracy: 0.6023\n",
      "Epoch 470/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8201 - accuracy: 0.6212 - val_loss: 0.8436 - val_accuracy: 0.5983\n",
      "Epoch 471/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8202 - accuracy: 0.6209 - val_loss: 0.8438 - val_accuracy: 0.6027\n",
      "Epoch 472/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8202 - accuracy: 0.6210 - val_loss: 0.8437 - val_accuracy: 0.6027\n",
      "Epoch 473/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8200 - accuracy: 0.6202 - val_loss: 0.8437 - val_accuracy: 0.6027\n",
      "Epoch 474/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8199 - accuracy: 0.6195 - val_loss: 0.8436 - val_accuracy: 0.6023\n",
      "Epoch 475/1200\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.8199 - accuracy: 0.6204 - val_loss: 0.8442 - val_accuracy: 0.6037\n",
      "Epoch 476/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8198 - accuracy: 0.6210 - val_loss: 0.8436 - val_accuracy: 0.6030\n",
      "Epoch 477/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8198 - accuracy: 0.6214 - val_loss: 0.8437 - val_accuracy: 0.6040\n",
      "Epoch 478/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8197 - accuracy: 0.6211 - val_loss: 0.8434 - val_accuracy: 0.6007\n",
      "Epoch 479/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8197 - accuracy: 0.6209 - val_loss: 0.8434 - val_accuracy: 0.6033\n",
      "Epoch 480/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8195 - accuracy: 0.6215 - val_loss: 0.8434 - val_accuracy: 0.6037\n",
      "Epoch 481/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8195 - accuracy: 0.6211 - val_loss: 0.8439 - val_accuracy: 0.6037\n",
      "Epoch 482/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8195 - accuracy: 0.6212 - val_loss: 0.8434 - val_accuracy: 0.6023\n",
      "Epoch 483/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8193 - accuracy: 0.6188 - val_loss: 0.8433 - val_accuracy: 0.6030\n",
      "Epoch 484/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8193 - accuracy: 0.6199 - val_loss: 0.8434 - val_accuracy: 0.6033\n",
      "Epoch 485/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8193 - accuracy: 0.6209 - val_loss: 0.8435 - val_accuracy: 0.6040\n",
      "Epoch 486/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8191 - accuracy: 0.6219 - val_loss: 0.8435 - val_accuracy: 0.6050\n",
      "Epoch 487/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8191 - accuracy: 0.6195 - val_loss: 0.8435 - val_accuracy: 0.6030\n",
      "Epoch 488/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8190 - accuracy: 0.6206 - val_loss: 0.8434 - val_accuracy: 0.6033\n",
      "Epoch 489/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8189 - accuracy: 0.6209 - val_loss: 0.8432 - val_accuracy: 0.6007\n",
      "Epoch 490/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8189 - accuracy: 0.6212 - val_loss: 0.8434 - val_accuracy: 0.6033\n",
      "Epoch 491/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8188 - accuracy: 0.6225 - val_loss: 0.8437 - val_accuracy: 0.6047\n",
      "Epoch 492/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8189 - accuracy: 0.6206 - val_loss: 0.8433 - val_accuracy: 0.6030\n",
      "Epoch 493/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8188 - accuracy: 0.6209 - val_loss: 0.8432 - val_accuracy: 0.6017\n",
      "Epoch 494/1200\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.8186 - accuracy: 0.6206 - val_loss: 0.8436 - val_accuracy: 0.6013\n",
      "Epoch 495/1200\n",
      "14000/14000 [==============================] - 1s 73us/step - loss: 0.8186 - accuracy: 0.6209 - val_loss: 0.8436 - val_accuracy: 0.6047\n",
      "Epoch 496/1200\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.8184 - accuracy: 0.6214 - val_loss: 0.8437 - val_accuracy: 0.6030\n",
      "Epoch 497/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8185 - accuracy: 0.6206 - val_loss: 0.8431 - val_accuracy: 0.6037\n",
      "Epoch 498/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8183 - accuracy: 0.6209 - val_loss: 0.8430 - val_accuracy: 0.6003\n",
      "Epoch 499/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8184 - accuracy: 0.6211 - val_loss: 0.8431 - val_accuracy: 0.6027\n",
      "Epoch 500/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8182 - accuracy: 0.6206 - val_loss: 0.8431 - val_accuracy: 0.6030\n",
      "Epoch 501/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8182 - accuracy: 0.6225 - val_loss: 0.8432 - val_accuracy: 0.6030\n",
      "Epoch 502/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8181 - accuracy: 0.6213 - val_loss: 0.8432 - val_accuracy: 0.6043\n",
      "Epoch 503/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8179 - accuracy: 0.6212 - val_loss: 0.8437 - val_accuracy: 0.6027\n",
      "Epoch 504/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8180 - accuracy: 0.6206 - val_loss: 0.8434 - val_accuracy: 0.6040\n",
      "Epoch 505/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8179 - accuracy: 0.6211 - val_loss: 0.8431 - val_accuracy: 0.6043\n",
      "Epoch 506/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8178 - accuracy: 0.6217 - val_loss: 0.8429 - val_accuracy: 0.6040\n",
      "Epoch 507/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8177 - accuracy: 0.6229 - val_loss: 0.8436 - val_accuracy: 0.6033\n",
      "Epoch 508/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8178 - accuracy: 0.6208 - val_loss: 0.8432 - val_accuracy: 0.6027\n",
      "Epoch 509/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8176 - accuracy: 0.6210 - val_loss: 0.8429 - val_accuracy: 0.6013\n",
      "Epoch 510/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8175 - accuracy: 0.6204 - val_loss: 0.8430 - val_accuracy: 0.6033\n",
      "Epoch 511/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8173 - accuracy: 0.6226 - val_loss: 0.8429 - val_accuracy: 0.6013\n",
      "Epoch 512/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8175 - accuracy: 0.6213 - val_loss: 0.8431 - val_accuracy: 0.6030\n",
      "Epoch 513/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8174 - accuracy: 0.6216 - val_loss: 0.8431 - val_accuracy: 0.6037\n",
      "Epoch 514/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8173 - accuracy: 0.6226 - val_loss: 0.8431 - val_accuracy: 0.6027\n",
      "Epoch 515/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8172 - accuracy: 0.6220 - val_loss: 0.8432 - val_accuracy: 0.6027\n",
      "Epoch 516/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8171 - accuracy: 0.6230 - val_loss: 0.8430 - val_accuracy: 0.6023\n",
      "Epoch 517/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8171 - accuracy: 0.6211 - val_loss: 0.8430 - val_accuracy: 0.6040\n",
      "Epoch 518/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8170 - accuracy: 0.6219 - val_loss: 0.8428 - val_accuracy: 0.6040\n",
      "Epoch 519/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8169 - accuracy: 0.6231 - val_loss: 0.8434 - val_accuracy: 0.6047\n",
      "Epoch 520/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8168 - accuracy: 0.6225 - val_loss: 0.8427 - val_accuracy: 0.6027\n",
      "Epoch 521/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8167 - accuracy: 0.6226 - val_loss: 0.8428 - val_accuracy: 0.5987\n",
      "Epoch 522/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8165 - accuracy: 0.6212 - val_loss: 0.8441 - val_accuracy: 0.6030\n",
      "Epoch 523/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8168 - accuracy: 0.6221 - val_loss: 0.8428 - val_accuracy: 0.6030\n",
      "Epoch 524/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8166 - accuracy: 0.6234 - val_loss: 0.8428 - val_accuracy: 0.6027\n",
      "Epoch 525/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8166 - accuracy: 0.6219 - val_loss: 0.8428 - val_accuracy: 0.6030\n",
      "Epoch 526/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8165 - accuracy: 0.6228 - val_loss: 0.8427 - val_accuracy: 0.6017\n",
      "Epoch 527/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8164 - accuracy: 0.6239 - val_loss: 0.8432 - val_accuracy: 0.6027\n",
      "Epoch 528/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8163 - accuracy: 0.6217 - val_loss: 0.8427 - val_accuracy: 0.5997\n",
      "Epoch 529/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8163 - accuracy: 0.6229 - val_loss: 0.8427 - val_accuracy: 0.6027\n",
      "Epoch 530/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8163 - accuracy: 0.6214 - val_loss: 0.8427 - val_accuracy: 0.6030\n",
      "Epoch 531/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8161 - accuracy: 0.6214 - val_loss: 0.8428 - val_accuracy: 0.6010\n",
      "Epoch 532/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8161 - accuracy: 0.6229 - val_loss: 0.8426 - val_accuracy: 0.5990\n",
      "Epoch 533/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8160 - accuracy: 0.6230 - val_loss: 0.8428 - val_accuracy: 0.6023\n",
      "Epoch 534/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8159 - accuracy: 0.6225 - val_loss: 0.8435 - val_accuracy: 0.6037\n",
      "Epoch 535/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8159 - accuracy: 0.6235 - val_loss: 0.8429 - val_accuracy: 0.6010\n",
      "Epoch 536/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8159 - accuracy: 0.6239 - val_loss: 0.8427 - val_accuracy: 0.6007\n",
      "Epoch 537/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8156 - accuracy: 0.6239 - val_loss: 0.8434 - val_accuracy: 0.6037\n",
      "Epoch 538/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8158 - accuracy: 0.6233 - val_loss: 0.8428 - val_accuracy: 0.6010\n",
      "Epoch 539/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8155 - accuracy: 0.6239 - val_loss: 0.8434 - val_accuracy: 0.6030\n",
      "Epoch 540/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8156 - accuracy: 0.6226 - val_loss: 0.8436 - val_accuracy: 0.6020\n",
      "Epoch 541/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8155 - accuracy: 0.6226 - val_loss: 0.8424 - val_accuracy: 0.6013\n",
      "Epoch 542/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.8154 - accuracy: 0.6239 - val_loss: 0.8426 - val_accuracy: 0.6027\n",
      "Epoch 543/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8153 - accuracy: 0.6234 - val_loss: 0.8425 - val_accuracy: 0.6040\n",
      "Epoch 544/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8153 - accuracy: 0.6239 - val_loss: 0.8426 - val_accuracy: 0.6003\n",
      "Epoch 545/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8152 - accuracy: 0.6230 - val_loss: 0.8427 - val_accuracy: 0.6027\n",
      "Epoch 546/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8151 - accuracy: 0.6249 - val_loss: 0.8428 - val_accuracy: 0.6013\n",
      "Epoch 547/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8150 - accuracy: 0.6238 - val_loss: 0.8427 - val_accuracy: 0.6020\n",
      "Epoch 548/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8149 - accuracy: 0.6246 - val_loss: 0.8429 - val_accuracy: 0.6050\n",
      "Epoch 549/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8149 - accuracy: 0.6236 - val_loss: 0.8424 - val_accuracy: 0.6007\n",
      "Epoch 550/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8149 - accuracy: 0.6239 - val_loss: 0.8424 - val_accuracy: 0.6027\n",
      "Epoch 551/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8146 - accuracy: 0.6229 - val_loss: 0.8425 - val_accuracy: 0.5987\n",
      "Epoch 552/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8147 - accuracy: 0.6241 - val_loss: 0.8424 - val_accuracy: 0.6027\n",
      "Epoch 553/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8146 - accuracy: 0.6230 - val_loss: 0.8424 - val_accuracy: 0.5977\n",
      "Epoch 554/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8146 - accuracy: 0.6240 - val_loss: 0.8422 - val_accuracy: 0.6033\n",
      "Epoch 555/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8144 - accuracy: 0.6239 - val_loss: 0.8424 - val_accuracy: 0.6023\n",
      "Epoch 556/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8144 - accuracy: 0.6228 - val_loss: 0.8425 - val_accuracy: 0.6010\n",
      "Epoch 557/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8144 - accuracy: 0.6239 - val_loss: 0.8427 - val_accuracy: 0.6023\n",
      "Epoch 558/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8141 - accuracy: 0.6253 - val_loss: 0.8433 - val_accuracy: 0.6023\n",
      "Epoch 559/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8140 - accuracy: 0.6254 - val_loss: 0.8429 - val_accuracy: 0.5990\n",
      "Epoch 560/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8142 - accuracy: 0.6244 - val_loss: 0.8422 - val_accuracy: 0.6007\n",
      "Epoch 561/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8141 - accuracy: 0.6243 - val_loss: 0.8422 - val_accuracy: 0.6023\n",
      "Epoch 562/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8140 - accuracy: 0.6245 - val_loss: 0.8424 - val_accuracy: 0.6007\n",
      "Epoch 563/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8139 - accuracy: 0.6253 - val_loss: 0.8423 - val_accuracy: 0.5980\n",
      "Epoch 564/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8139 - accuracy: 0.6251 - val_loss: 0.8423 - val_accuracy: 0.6007\n",
      "Epoch 565/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8138 - accuracy: 0.6246 - val_loss: 0.8422 - val_accuracy: 0.5993\n",
      "Epoch 566/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8137 - accuracy: 0.6254 - val_loss: 0.8423 - val_accuracy: 0.6010\n",
      "Epoch 567/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8136 - accuracy: 0.6246 - val_loss: 0.8422 - val_accuracy: 0.6000\n",
      "Epoch 568/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8137 - accuracy: 0.6247 - val_loss: 0.8423 - val_accuracy: 0.6017\n",
      "Epoch 569/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8135 - accuracy: 0.6242 - val_loss: 0.8423 - val_accuracy: 0.6047\n",
      "Epoch 570/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8135 - accuracy: 0.6245 - val_loss: 0.8428 - val_accuracy: 0.6017\n",
      "Epoch 571/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8134 - accuracy: 0.6245 - val_loss: 0.8430 - val_accuracy: 0.6013\n",
      "Epoch 572/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8133 - accuracy: 0.6257 - val_loss: 0.8421 - val_accuracy: 0.5993\n",
      "Epoch 573/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8132 - accuracy: 0.6256 - val_loss: 0.8421 - val_accuracy: 0.6017\n",
      "Epoch 574/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8132 - accuracy: 0.6254 - val_loss: 0.8421 - val_accuracy: 0.6003\n",
      "Epoch 575/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8132 - accuracy: 0.6254 - val_loss: 0.8423 - val_accuracy: 0.6033\n",
      "Epoch 576/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8129 - accuracy: 0.6246 - val_loss: 0.8421 - val_accuracy: 0.6040\n",
      "Epoch 577/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8129 - accuracy: 0.6242 - val_loss: 0.8421 - val_accuracy: 0.5997\n",
      "Epoch 578/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8129 - accuracy: 0.6248 - val_loss: 0.8422 - val_accuracy: 0.5987\n",
      "Epoch 579/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8128 - accuracy: 0.6264 - val_loss: 0.8424 - val_accuracy: 0.6040\n",
      "Epoch 580/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8128 - accuracy: 0.6269 - val_loss: 0.8423 - val_accuracy: 0.6003\n",
      "Epoch 581/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8127 - accuracy: 0.6265 - val_loss: 0.8421 - val_accuracy: 0.6040\n",
      "Epoch 582/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8126 - accuracy: 0.6254 - val_loss: 0.8421 - val_accuracy: 0.5993\n",
      "Epoch 583/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8126 - accuracy: 0.6264 - val_loss: 0.8420 - val_accuracy: 0.5997\n",
      "Epoch 584/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8125 - accuracy: 0.6258 - val_loss: 0.8421 - val_accuracy: 0.6003\n",
      "Epoch 585/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8124 - accuracy: 0.6261 - val_loss: 0.8421 - val_accuracy: 0.5993\n",
      "Epoch 586/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8122 - accuracy: 0.6254 - val_loss: 0.8427 - val_accuracy: 0.6020\n",
      "Epoch 587/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8122 - accuracy: 0.6261 - val_loss: 0.8422 - val_accuracy: 0.6007\n",
      "Epoch 588/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8122 - accuracy: 0.6259 - val_loss: 0.8420 - val_accuracy: 0.5980\n",
      "Epoch 589/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8121 - accuracy: 0.6266 - val_loss: 0.8419 - val_accuracy: 0.6020\n",
      "Epoch 590/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8121 - accuracy: 0.6256 - val_loss: 0.8421 - val_accuracy: 0.6043\n",
      "Epoch 591/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8118 - accuracy: 0.6271 - val_loss: 0.8425 - val_accuracy: 0.6027\n",
      "Epoch 592/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8119 - accuracy: 0.6244 - val_loss: 0.8423 - val_accuracy: 0.6010\n",
      "Epoch 593/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.8117 - accuracy: 0.6259 - val_loss: 0.8422 - val_accuracy: 0.5987\n",
      "Epoch 594/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8117 - accuracy: 0.6279 - val_loss: 0.8420 - val_accuracy: 0.5973\n",
      "Epoch 595/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8116 - accuracy: 0.6270 - val_loss: 0.8427 - val_accuracy: 0.5990\n",
      "Epoch 596/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8115 - accuracy: 0.6265 - val_loss: 0.8418 - val_accuracy: 0.5997\n",
      "Epoch 597/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8115 - accuracy: 0.6276 - val_loss: 0.8419 - val_accuracy: 0.5997\n",
      "Epoch 598/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8115 - accuracy: 0.6275 - val_loss: 0.8419 - val_accuracy: 0.5983\n",
      "Epoch 599/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.8113 - accuracy: 0.6266 - val_loss: 0.8418 - val_accuracy: 0.6013\n",
      "Epoch 600/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8112 - accuracy: 0.6272 - val_loss: 0.8423 - val_accuracy: 0.6017\n",
      "Epoch 601/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8112 - accuracy: 0.6273 - val_loss: 0.8418 - val_accuracy: 0.6020\n",
      "Epoch 602/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.8109 - accuracy: 0.6263 - val_loss: 0.8421 - val_accuracy: 0.5983\n",
      "Epoch 603/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8112 - accuracy: 0.6264 - val_loss: 0.8419 - val_accuracy: 0.6030\n",
      "Epoch 604/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8109 - accuracy: 0.6267 - val_loss: 0.8419 - val_accuracy: 0.6037\n",
      "Epoch 605/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8109 - accuracy: 0.6252 - val_loss: 0.8421 - val_accuracy: 0.6010\n",
      "Epoch 606/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8109 - accuracy: 0.6281 - val_loss: 0.8422 - val_accuracy: 0.6007\n",
      "Epoch 607/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.8108 - accuracy: 0.6276 - val_loss: 0.8420 - val_accuracy: 0.6010\n",
      "Epoch 608/1200\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.8107 - accuracy: 0.6279 - val_loss: 0.8420 - val_accuracy: 0.6003\n",
      "Epoch 609/1200\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.8106 - accuracy: 0.6276 - val_loss: 0.8420 - val_accuracy: 0.6010\n",
      "Epoch 610/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8105 - accuracy: 0.6274 - val_loss: 0.8417 - val_accuracy: 0.6023\n",
      "Epoch 611/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8101 - accuracy: 0.6283 - val_loss: 0.8435 - val_accuracy: 0.5957\n",
      "Epoch 612/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8106 - accuracy: 0.6271 - val_loss: 0.8419 - val_accuracy: 0.6030\n",
      "Epoch 613/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8103 - accuracy: 0.6266 - val_loss: 0.8418 - val_accuracy: 0.5967\n",
      "Epoch 614/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8102 - accuracy: 0.6274 - val_loss: 0.8421 - val_accuracy: 0.6000\n",
      "Epoch 615/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8102 - accuracy: 0.6281 - val_loss: 0.8422 - val_accuracy: 0.6007\n",
      "Epoch 616/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8099 - accuracy: 0.6288 - val_loss: 0.8418 - val_accuracy: 0.6020\n",
      "Epoch 617/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8100 - accuracy: 0.6291 - val_loss: 0.8419 - val_accuracy: 0.6017\n",
      "Epoch 618/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8099 - accuracy: 0.6281 - val_loss: 0.8420 - val_accuracy: 0.6020\n",
      "Epoch 619/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8098 - accuracy: 0.6283 - val_loss: 0.8415 - val_accuracy: 0.6010\n",
      "Epoch 620/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8097 - accuracy: 0.6281 - val_loss: 0.8418 - val_accuracy: 0.6017\n",
      "Epoch 621/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8097 - accuracy: 0.6281 - val_loss: 0.8422 - val_accuracy: 0.6033\n",
      "Epoch 622/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8097 - accuracy: 0.6281 - val_loss: 0.8418 - val_accuracy: 0.6037\n",
      "Epoch 623/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8096 - accuracy: 0.6283 - val_loss: 0.8416 - val_accuracy: 0.5980\n",
      "Epoch 624/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8096 - accuracy: 0.6294 - val_loss: 0.8415 - val_accuracy: 0.6007\n",
      "Epoch 625/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8094 - accuracy: 0.6279 - val_loss: 0.8416 - val_accuracy: 0.6013\n",
      "Epoch 626/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8093 - accuracy: 0.6280 - val_loss: 0.8418 - val_accuracy: 0.6020\n",
      "Epoch 627/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8092 - accuracy: 0.6291 - val_loss: 0.8418 - val_accuracy: 0.6023\n",
      "Epoch 628/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8091 - accuracy: 0.6286 - val_loss: 0.8415 - val_accuracy: 0.5990\n",
      "Epoch 629/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8090 - accuracy: 0.6283 - val_loss: 0.8415 - val_accuracy: 0.5997\n",
      "Epoch 630/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8090 - accuracy: 0.6292 - val_loss: 0.8416 - val_accuracy: 0.5980\n",
      "Epoch 631/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.8090 - accuracy: 0.6306 - val_loss: 0.8417 - val_accuracy: 0.6023\n",
      "Epoch 632/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.8089 - accuracy: 0.6286 - val_loss: 0.8415 - val_accuracy: 0.6003\n",
      "Epoch 633/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8090 - accuracy: 0.6290 - val_loss: 0.8417 - val_accuracy: 0.6010\n",
      "Epoch 634/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.8088 - accuracy: 0.6295 - val_loss: 0.8416 - val_accuracy: 0.6020\n",
      "Epoch 635/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8086 - accuracy: 0.6294 - val_loss: 0.8416 - val_accuracy: 0.5993\n",
      "Epoch 636/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8086 - accuracy: 0.6287 - val_loss: 0.8415 - val_accuracy: 0.5987\n",
      "Epoch 637/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8085 - accuracy: 0.6287 - val_loss: 0.8415 - val_accuracy: 0.6030\n",
      "Epoch 638/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8084 - accuracy: 0.6302 - val_loss: 0.8418 - val_accuracy: 0.6013\n",
      "Epoch 639/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8083 - accuracy: 0.6297 - val_loss: 0.8418 - val_accuracy: 0.6007\n",
      "Epoch 640/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8084 - accuracy: 0.6309 - val_loss: 0.8420 - val_accuracy: 0.6003\n",
      "Epoch 641/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8082 - accuracy: 0.6294 - val_loss: 0.8419 - val_accuracy: 0.6003\n",
      "Epoch 642/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8080 - accuracy: 0.6296 - val_loss: 0.8418 - val_accuracy: 0.6010\n",
      "Epoch 643/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8076 - accuracy: 0.6294 - val_loss: 0.8420 - val_accuracy: 0.6007\n",
      "Epoch 644/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8080 - accuracy: 0.6306 - val_loss: 0.8420 - val_accuracy: 0.6003\n",
      "Epoch 645/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8078 - accuracy: 0.6302 - val_loss: 0.8413 - val_accuracy: 0.5987\n",
      "Epoch 646/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8079 - accuracy: 0.6286 - val_loss: 0.8413 - val_accuracy: 0.5997\n",
      "Epoch 647/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8075 - accuracy: 0.6300 - val_loss: 0.8426 - val_accuracy: 0.5980\n",
      "Epoch 648/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8076 - accuracy: 0.6293 - val_loss: 0.8414 - val_accuracy: 0.5980\n",
      "Epoch 649/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8076 - accuracy: 0.6296 - val_loss: 0.8414 - val_accuracy: 0.6010\n",
      "Epoch 650/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8076 - accuracy: 0.6305 - val_loss: 0.8415 - val_accuracy: 0.6013\n",
      "Epoch 651/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8074 - accuracy: 0.6298 - val_loss: 0.8415 - val_accuracy: 0.5977\n",
      "Epoch 652/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8073 - accuracy: 0.6292 - val_loss: 0.8416 - val_accuracy: 0.6000\n",
      "Epoch 653/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8073 - accuracy: 0.6300 - val_loss: 0.8414 - val_accuracy: 0.6033\n",
      "Epoch 654/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8071 - accuracy: 0.6305 - val_loss: 0.8416 - val_accuracy: 0.5987\n",
      "Epoch 655/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8071 - accuracy: 0.6299 - val_loss: 0.8413 - val_accuracy: 0.6010\n",
      "Epoch 656/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8070 - accuracy: 0.6308 - val_loss: 0.8413 - val_accuracy: 0.6007\n",
      "Epoch 657/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8070 - accuracy: 0.6304 - val_loss: 0.8412 - val_accuracy: 0.6007\n",
      "Epoch 658/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8069 - accuracy: 0.6294 - val_loss: 0.8412 - val_accuracy: 0.5993\n",
      "Epoch 659/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8068 - accuracy: 0.6316 - val_loss: 0.8413 - val_accuracy: 0.6027\n",
      "Epoch 660/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8067 - accuracy: 0.6303 - val_loss: 0.8412 - val_accuracy: 0.5990\n",
      "Epoch 661/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8066 - accuracy: 0.6324 - val_loss: 0.8413 - val_accuracy: 0.5993\n",
      "Epoch 662/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8066 - accuracy: 0.6295 - val_loss: 0.8411 - val_accuracy: 0.6000\n",
      "Epoch 663/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8065 - accuracy: 0.6293 - val_loss: 0.8413 - val_accuracy: 0.5987\n",
      "Epoch 664/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8064 - accuracy: 0.6313 - val_loss: 0.8413 - val_accuracy: 0.5990\n",
      "Epoch 665/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8064 - accuracy: 0.6309 - val_loss: 0.8413 - val_accuracy: 0.5983\n",
      "Epoch 666/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8063 - accuracy: 0.6314 - val_loss: 0.8412 - val_accuracy: 0.6013\n",
      "Epoch 667/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8061 - accuracy: 0.6304 - val_loss: 0.8418 - val_accuracy: 0.6013\n",
      "Epoch 668/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8061 - accuracy: 0.6306 - val_loss: 0.8418 - val_accuracy: 0.6017\n",
      "Epoch 669/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8060 - accuracy: 0.6325 - val_loss: 0.8411 - val_accuracy: 0.5993\n",
      "Epoch 670/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8059 - accuracy: 0.6315 - val_loss: 0.8414 - val_accuracy: 0.6027\n",
      "Epoch 671/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8058 - accuracy: 0.6319 - val_loss: 0.8414 - val_accuracy: 0.6020\n",
      "Epoch 672/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8057 - accuracy: 0.6317 - val_loss: 0.8412 - val_accuracy: 0.6030\n",
      "Epoch 673/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8056 - accuracy: 0.6318 - val_loss: 0.8412 - val_accuracy: 0.6000\n",
      "Epoch 674/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8057 - accuracy: 0.6311 - val_loss: 0.8412 - val_accuracy: 0.6017\n",
      "Epoch 675/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8054 - accuracy: 0.6313 - val_loss: 0.8411 - val_accuracy: 0.6040\n",
      "Epoch 676/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8054 - accuracy: 0.6317 - val_loss: 0.8412 - val_accuracy: 0.5993\n",
      "Epoch 677/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8053 - accuracy: 0.6326 - val_loss: 0.8411 - val_accuracy: 0.6000\n",
      "Epoch 678/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8052 - accuracy: 0.6313 - val_loss: 0.8416 - val_accuracy: 0.6017\n",
      "Epoch 679/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8052 - accuracy: 0.6313 - val_loss: 0.8411 - val_accuracy: 0.5993\n",
      "Epoch 680/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8050 - accuracy: 0.6310 - val_loss: 0.8418 - val_accuracy: 0.5990\n",
      "Epoch 681/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8050 - accuracy: 0.6330 - val_loss: 0.8413 - val_accuracy: 0.5983\n",
      "Epoch 682/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8050 - accuracy: 0.6325 - val_loss: 0.8413 - val_accuracy: 0.6017\n",
      "Epoch 683/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8048 - accuracy: 0.6318 - val_loss: 0.8413 - val_accuracy: 0.6020\n",
      "Epoch 684/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8047 - accuracy: 0.6313 - val_loss: 0.8411 - val_accuracy: 0.5993\n",
      "Epoch 685/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8046 - accuracy: 0.6321 - val_loss: 0.8416 - val_accuracy: 0.5990\n",
      "Epoch 686/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8044 - accuracy: 0.6333 - val_loss: 0.8411 - val_accuracy: 0.6020\n",
      "Epoch 687/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8044 - accuracy: 0.6322 - val_loss: 0.8412 - val_accuracy: 0.5997\n",
      "Epoch 688/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8043 - accuracy: 0.6331 - val_loss: 0.8411 - val_accuracy: 0.6020\n",
      "Epoch 689/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8045 - accuracy: 0.6324 - val_loss: 0.8410 - val_accuracy: 0.6017\n",
      "Epoch 690/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8042 - accuracy: 0.6311 - val_loss: 0.8412 - val_accuracy: 0.6027\n",
      "Epoch 691/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8041 - accuracy: 0.6315 - val_loss: 0.8411 - val_accuracy: 0.5993\n",
      "Epoch 692/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8041 - accuracy: 0.6339 - val_loss: 0.8409 - val_accuracy: 0.5993\n",
      "Epoch 693/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8039 - accuracy: 0.6321 - val_loss: 0.8410 - val_accuracy: 0.6003\n",
      "Epoch 694/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8039 - accuracy: 0.6333 - val_loss: 0.8413 - val_accuracy: 0.5993\n",
      "Epoch 695/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8037 - accuracy: 0.6343 - val_loss: 0.8410 - val_accuracy: 0.6030\n",
      "Epoch 696/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8037 - accuracy: 0.6332 - val_loss: 0.8411 - val_accuracy: 0.5990\n",
      "Epoch 697/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8038 - accuracy: 0.6333 - val_loss: 0.8411 - val_accuracy: 0.5987\n",
      "Epoch 698/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8037 - accuracy: 0.6328 - val_loss: 0.8410 - val_accuracy: 0.5980\n",
      "Epoch 699/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8035 - accuracy: 0.6322 - val_loss: 0.8415 - val_accuracy: 0.5997\n",
      "Epoch 700/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8034 - accuracy: 0.6346 - val_loss: 0.8409 - val_accuracy: 0.6003\n",
      "Epoch 701/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8034 - accuracy: 0.6344 - val_loss: 0.8409 - val_accuracy: 0.6007\n",
      "Epoch 702/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8033 - accuracy: 0.6338 - val_loss: 0.8417 - val_accuracy: 0.5997\n",
      "Epoch 703/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8031 - accuracy: 0.6333 - val_loss: 0.8418 - val_accuracy: 0.5983\n",
      "Epoch 704/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8031 - accuracy: 0.6331 - val_loss: 0.8410 - val_accuracy: 0.5997\n",
      "Epoch 705/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8031 - accuracy: 0.6332 - val_loss: 0.8409 - val_accuracy: 0.6000\n",
      "Epoch 706/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8029 - accuracy: 0.6333 - val_loss: 0.8412 - val_accuracy: 0.5993\n",
      "Epoch 707/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.8028 - accuracy: 0.6334 - val_loss: 0.8410 - val_accuracy: 0.5997\n",
      "Epoch 708/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8028 - accuracy: 0.6338 - val_loss: 0.8410 - val_accuracy: 0.6007\n",
      "Epoch 709/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8027 - accuracy: 0.6333 - val_loss: 0.8412 - val_accuracy: 0.6007\n",
      "Epoch 710/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.8026 - accuracy: 0.6340 - val_loss: 0.8410 - val_accuracy: 0.5993\n",
      "Epoch 711/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8025 - accuracy: 0.6338 - val_loss: 0.8411 - val_accuracy: 0.5983\n",
      "Epoch 712/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8024 - accuracy: 0.6324 - val_loss: 0.8413 - val_accuracy: 0.5987\n",
      "Epoch 713/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8023 - accuracy: 0.6344 - val_loss: 0.8408 - val_accuracy: 0.6017\n",
      "Epoch 714/1200\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.8020 - accuracy: 0.6342 - val_loss: 0.8416 - val_accuracy: 0.5997\n",
      "Epoch 715/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8021 - accuracy: 0.6348 - val_loss: 0.8410 - val_accuracy: 0.5990\n",
      "Epoch 716/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8021 - accuracy: 0.6345 - val_loss: 0.8412 - val_accuracy: 0.5993\n",
      "Epoch 717/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8020 - accuracy: 0.6334 - val_loss: 0.8409 - val_accuracy: 0.6000\n",
      "Epoch 718/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8019 - accuracy: 0.6343 - val_loss: 0.8410 - val_accuracy: 0.5990\n",
      "Epoch 719/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8015 - accuracy: 0.6341 - val_loss: 0.8411 - val_accuracy: 0.5980\n",
      "Epoch 720/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8018 - accuracy: 0.6338 - val_loss: 0.8409 - val_accuracy: 0.6003\n",
      "Epoch 721/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8016 - accuracy: 0.6359 - val_loss: 0.8411 - val_accuracy: 0.6000\n",
      "Epoch 722/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8015 - accuracy: 0.6359 - val_loss: 0.8409 - val_accuracy: 0.6023\n",
      "Epoch 723/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8015 - accuracy: 0.6354 - val_loss: 0.8416 - val_accuracy: 0.5980\n",
      "Epoch 724/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8014 - accuracy: 0.6340 - val_loss: 0.8410 - val_accuracy: 0.5993\n",
      "Epoch 725/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8014 - accuracy: 0.6334 - val_loss: 0.8413 - val_accuracy: 0.5980\n",
      "Epoch 726/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.8012 - accuracy: 0.6336 - val_loss: 0.8415 - val_accuracy: 0.5977\n",
      "Epoch 727/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.8012 - accuracy: 0.6359 - val_loss: 0.8411 - val_accuracy: 0.5997\n",
      "Epoch 728/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8011 - accuracy: 0.6352 - val_loss: 0.8409 - val_accuracy: 0.6013\n",
      "Epoch 729/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8009 - accuracy: 0.6346 - val_loss: 0.8412 - val_accuracy: 0.5960\n",
      "Epoch 730/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8009 - accuracy: 0.6357 - val_loss: 0.8414 - val_accuracy: 0.5980\n",
      "Epoch 731/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.8007 - accuracy: 0.6361 - val_loss: 0.8411 - val_accuracy: 0.5973\n",
      "Epoch 732/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8006 - accuracy: 0.6349 - val_loss: 0.8410 - val_accuracy: 0.6000\n",
      "Epoch 733/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.8006 - accuracy: 0.6339 - val_loss: 0.8413 - val_accuracy: 0.5973\n",
      "Epoch 734/1200\n",
      "14000/14000 [==============================] - 3s 247us/step - loss: 0.8002 - accuracy: 0.6346 - val_loss: 0.8413 - val_accuracy: 0.6000\n",
      "Epoch 735/1200\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.8005 - accuracy: 0.6355 - val_loss: 0.8409 - val_accuracy: 0.5993\n",
      "Epoch 736/1200\n",
      "14000/14000 [==============================] - 1s 77us/step - loss: 0.8002 - accuracy: 0.6358 - val_loss: 0.8411 - val_accuracy: 0.5987\n",
      "Epoch 737/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8003 - accuracy: 0.6356 - val_loss: 0.8409 - val_accuracy: 0.6027\n",
      "Epoch 738/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.8001 - accuracy: 0.6356 - val_loss: 0.8409 - val_accuracy: 0.6013\n",
      "Epoch 739/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.8000 - accuracy: 0.6356 - val_loss: 0.8409 - val_accuracy: 0.5997\n",
      "Epoch 740/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7997 - accuracy: 0.6356 - val_loss: 0.8412 - val_accuracy: 0.6007\n",
      "Epoch 741/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7999 - accuracy: 0.6372 - val_loss: 0.8413 - val_accuracy: 0.5983\n",
      "Epoch 742/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7998 - accuracy: 0.6356 - val_loss: 0.8411 - val_accuracy: 0.5957\n",
      "Epoch 743/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7998 - accuracy: 0.6364 - val_loss: 0.8409 - val_accuracy: 0.6033\n",
      "Epoch 744/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7996 - accuracy: 0.6366 - val_loss: 0.8412 - val_accuracy: 0.6017\n",
      "Epoch 745/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7995 - accuracy: 0.6354 - val_loss: 0.8413 - val_accuracy: 0.5997\n",
      "Epoch 746/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7995 - accuracy: 0.6353 - val_loss: 0.8411 - val_accuracy: 0.5977\n",
      "Epoch 747/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7994 - accuracy: 0.6365 - val_loss: 0.8409 - val_accuracy: 0.6007\n",
      "Epoch 748/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7992 - accuracy: 0.6371 - val_loss: 0.8413 - val_accuracy: 0.5960\n",
      "Epoch 749/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7991 - accuracy: 0.6354 - val_loss: 0.8415 - val_accuracy: 0.5973\n",
      "Epoch 750/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7990 - accuracy: 0.6360 - val_loss: 0.8410 - val_accuracy: 0.6017\n",
      "Epoch 751/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7990 - accuracy: 0.6362 - val_loss: 0.8411 - val_accuracy: 0.6020\n",
      "Epoch 752/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7988 - accuracy: 0.6363 - val_loss: 0.8412 - val_accuracy: 0.5973\n",
      "Epoch 753/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7987 - accuracy: 0.6362 - val_loss: 0.8410 - val_accuracy: 0.5977\n",
      "Epoch 754/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7986 - accuracy: 0.6372 - val_loss: 0.8414 - val_accuracy: 0.5993\n",
      "Epoch 755/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7986 - accuracy: 0.6374 - val_loss: 0.8413 - val_accuracy: 0.6007\n",
      "Epoch 756/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7984 - accuracy: 0.6362 - val_loss: 0.8411 - val_accuracy: 0.6000\n",
      "Epoch 757/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7984 - accuracy: 0.6373 - val_loss: 0.8417 - val_accuracy: 0.5977\n",
      "Epoch 758/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7981 - accuracy: 0.6377 - val_loss: 0.8418 - val_accuracy: 0.5980\n",
      "Epoch 759/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7981 - accuracy: 0.6371 - val_loss: 0.8414 - val_accuracy: 0.6010\n",
      "Epoch 760/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7982 - accuracy: 0.6399 - val_loss: 0.8414 - val_accuracy: 0.5960\n",
      "Epoch 761/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7980 - accuracy: 0.6360 - val_loss: 0.8412 - val_accuracy: 0.5977\n",
      "Epoch 762/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7980 - accuracy: 0.6380 - val_loss: 0.8411 - val_accuracy: 0.5977\n",
      "Epoch 763/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7979 - accuracy: 0.6379 - val_loss: 0.8418 - val_accuracy: 0.5983\n",
      "Epoch 764/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7976 - accuracy: 0.6369 - val_loss: 0.8412 - val_accuracy: 0.5977\n",
      "Epoch 765/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7976 - accuracy: 0.6371 - val_loss: 0.8409 - val_accuracy: 0.6010\n",
      "Epoch 766/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7976 - accuracy: 0.6374 - val_loss: 0.8411 - val_accuracy: 0.6017\n",
      "Epoch 767/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7973 - accuracy: 0.6385 - val_loss: 0.8416 - val_accuracy: 0.5987\n",
      "Epoch 768/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7973 - accuracy: 0.6369 - val_loss: 0.8418 - val_accuracy: 0.5963\n",
      "Epoch 769/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7970 - accuracy: 0.6399 - val_loss: 0.8410 - val_accuracy: 0.5983\n",
      "Epoch 770/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7970 - accuracy: 0.6366 - val_loss: 0.8412 - val_accuracy: 0.5977\n",
      "Epoch 771/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7969 - accuracy: 0.6379 - val_loss: 0.8411 - val_accuracy: 0.5983\n",
      "Epoch 772/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7970 - accuracy: 0.6390 - val_loss: 0.8412 - val_accuracy: 0.5993\n",
      "Epoch 773/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7968 - accuracy: 0.6392 - val_loss: 0.8413 - val_accuracy: 0.5990\n",
      "Epoch 774/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7968 - accuracy: 0.6389 - val_loss: 0.8412 - val_accuracy: 0.6027\n",
      "Epoch 775/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7966 - accuracy: 0.6385 - val_loss: 0.8414 - val_accuracy: 0.5977\n",
      "Epoch 776/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7966 - accuracy: 0.6369 - val_loss: 0.8414 - val_accuracy: 0.5983\n",
      "Epoch 777/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7965 - accuracy: 0.6379 - val_loss: 0.8411 - val_accuracy: 0.5960\n",
      "Epoch 778/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7963 - accuracy: 0.6379 - val_loss: 0.8411 - val_accuracy: 0.5997\n",
      "Epoch 779/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7963 - accuracy: 0.6384 - val_loss: 0.8414 - val_accuracy: 0.6013\n",
      "Epoch 780/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7962 - accuracy: 0.6377 - val_loss: 0.8414 - val_accuracy: 0.6013\n",
      "Epoch 781/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7962 - accuracy: 0.6386 - val_loss: 0.8414 - val_accuracy: 0.6013\n",
      "Epoch 782/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7960 - accuracy: 0.6380 - val_loss: 0.8412 - val_accuracy: 0.5973\n",
      "Epoch 783/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7958 - accuracy: 0.6389 - val_loss: 0.8413 - val_accuracy: 0.5990\n",
      "Epoch 784/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7956 - accuracy: 0.6396 - val_loss: 0.8413 - val_accuracy: 0.5980\n",
      "Epoch 785/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7955 - accuracy: 0.6392 - val_loss: 0.8418 - val_accuracy: 0.5983\n",
      "Epoch 786/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7956 - accuracy: 0.6396 - val_loss: 0.8412 - val_accuracy: 0.6007\n",
      "Epoch 787/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7955 - accuracy: 0.6390 - val_loss: 0.8413 - val_accuracy: 0.5977\n",
      "Epoch 788/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7953 - accuracy: 0.6398 - val_loss: 0.8417 - val_accuracy: 0.5987\n",
      "Epoch 789/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7951 - accuracy: 0.6385 - val_loss: 0.8414 - val_accuracy: 0.6010\n",
      "Epoch 790/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7951 - accuracy: 0.6373 - val_loss: 0.8414 - val_accuracy: 0.5983\n",
      "Epoch 791/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7951 - accuracy: 0.6382 - val_loss: 0.8415 - val_accuracy: 0.5997\n",
      "Epoch 792/1200\n",
      "14000/14000 [==============================] - 2s 146us/step - loss: 0.7950 - accuracy: 0.6394 - val_loss: 0.8414 - val_accuracy: 0.6000\n",
      "Epoch 793/1200\n",
      "14000/14000 [==============================] - 2s 129us/step - loss: 0.7948 - accuracy: 0.6399 - val_loss: 0.8413 - val_accuracy: 0.5977\n",
      "Epoch 794/1200\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.7947 - accuracy: 0.6402 - val_loss: 0.8418 - val_accuracy: 0.5980\n",
      "Epoch 795/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7946 - accuracy: 0.6401 - val_loss: 0.8417 - val_accuracy: 0.5983\n",
      "Epoch 796/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7946 - accuracy: 0.6402 - val_loss: 0.8412 - val_accuracy: 0.5977\n",
      "Epoch 797/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7945 - accuracy: 0.6397 - val_loss: 0.8412 - val_accuracy: 0.6007\n",
      "Epoch 798/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7943 - accuracy: 0.6400 - val_loss: 0.8413 - val_accuracy: 0.6000\n",
      "Epoch 799/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7940 - accuracy: 0.6399 - val_loss: 0.8419 - val_accuracy: 0.5977\n",
      "Epoch 800/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7940 - accuracy: 0.6387 - val_loss: 0.8418 - val_accuracy: 0.5967\n",
      "Epoch 801/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7941 - accuracy: 0.6404 - val_loss: 0.8414 - val_accuracy: 0.5990\n",
      "Epoch 802/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7939 - accuracy: 0.6406 - val_loss: 0.8416 - val_accuracy: 0.5973\n",
      "Epoch 803/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7938 - accuracy: 0.6396 - val_loss: 0.8413 - val_accuracy: 0.6000\n",
      "Epoch 804/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7937 - accuracy: 0.6404 - val_loss: 0.8413 - val_accuracy: 0.5977\n",
      "Epoch 805/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7936 - accuracy: 0.6403 - val_loss: 0.8414 - val_accuracy: 0.6003\n",
      "Epoch 806/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7934 - accuracy: 0.6411 - val_loss: 0.8418 - val_accuracy: 0.6017\n",
      "Epoch 807/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7932 - accuracy: 0.6404 - val_loss: 0.8420 - val_accuracy: 0.5990\n",
      "Epoch 808/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7931 - accuracy: 0.6392 - val_loss: 0.8414 - val_accuracy: 0.5977\n",
      "Epoch 809/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7931 - accuracy: 0.6399 - val_loss: 0.8416 - val_accuracy: 0.5987\n",
      "Epoch 810/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7929 - accuracy: 0.6406 - val_loss: 0.8418 - val_accuracy: 0.6013\n",
      "Epoch 811/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7931 - accuracy: 0.6409 - val_loss: 0.8415 - val_accuracy: 0.5993\n",
      "Epoch 812/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7929 - accuracy: 0.6415 - val_loss: 0.8414 - val_accuracy: 0.5993\n",
      "Epoch 813/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7926 - accuracy: 0.6413 - val_loss: 0.8414 - val_accuracy: 0.5983\n",
      "Epoch 814/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7926 - accuracy: 0.6401 - val_loss: 0.8414 - val_accuracy: 0.5987\n",
      "Epoch 815/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7924 - accuracy: 0.6418 - val_loss: 0.8425 - val_accuracy: 0.5980\n",
      "Epoch 816/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7924 - accuracy: 0.6416 - val_loss: 0.8421 - val_accuracy: 0.5990\n",
      "Epoch 817/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7922 - accuracy: 0.6406 - val_loss: 0.8424 - val_accuracy: 0.5970\n",
      "Epoch 818/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7922 - accuracy: 0.6421 - val_loss: 0.8422 - val_accuracy: 0.5977\n",
      "Epoch 819/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7921 - accuracy: 0.6404 - val_loss: 0.8421 - val_accuracy: 0.6007\n",
      "Epoch 820/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7920 - accuracy: 0.6401 - val_loss: 0.8415 - val_accuracy: 0.5983\n",
      "Epoch 821/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7917 - accuracy: 0.6416 - val_loss: 0.8416 - val_accuracy: 0.5983\n",
      "Epoch 822/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7915 - accuracy: 0.6405 - val_loss: 0.8431 - val_accuracy: 0.6080\n",
      "Epoch 823/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7917 - accuracy: 0.6419 - val_loss: 0.8417 - val_accuracy: 0.5973\n",
      "Epoch 824/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7917 - accuracy: 0.6411 - val_loss: 0.8416 - val_accuracy: 0.5983\n",
      "Epoch 825/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7914 - accuracy: 0.6406 - val_loss: 0.8414 - val_accuracy: 0.5980\n",
      "Epoch 826/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7912 - accuracy: 0.6421 - val_loss: 0.8416 - val_accuracy: 0.5983\n",
      "Epoch 827/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7912 - accuracy: 0.6436 - val_loss: 0.8420 - val_accuracy: 0.6003\n",
      "Epoch 828/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7909 - accuracy: 0.6437 - val_loss: 0.8425 - val_accuracy: 0.6010\n",
      "Epoch 829/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7911 - accuracy: 0.6412 - val_loss: 0.8416 - val_accuracy: 0.5990\n",
      "Epoch 830/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7908 - accuracy: 0.6424 - val_loss: 0.8416 - val_accuracy: 0.5987\n",
      "Epoch 831/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7908 - accuracy: 0.6421 - val_loss: 0.8420 - val_accuracy: 0.5973\n",
      "Epoch 832/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7905 - accuracy: 0.6424 - val_loss: 0.8424 - val_accuracy: 0.6000\n",
      "Epoch 833/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7908 - accuracy: 0.6418 - val_loss: 0.8420 - val_accuracy: 0.5957\n",
      "Epoch 834/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7905 - accuracy: 0.6416 - val_loss: 0.8418 - val_accuracy: 0.5963\n",
      "Epoch 835/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7902 - accuracy: 0.6433 - val_loss: 0.8425 - val_accuracy: 0.6000\n",
      "Epoch 836/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7903 - accuracy: 0.6431 - val_loss: 0.8417 - val_accuracy: 0.5973\n",
      "Epoch 837/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7901 - accuracy: 0.6434 - val_loss: 0.8417 - val_accuracy: 0.5980\n",
      "Epoch 838/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7900 - accuracy: 0.6418 - val_loss: 0.8419 - val_accuracy: 0.5970\n",
      "Epoch 839/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7900 - accuracy: 0.6416 - val_loss: 0.8418 - val_accuracy: 0.5977\n",
      "Epoch 840/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7897 - accuracy: 0.6426 - val_loss: 0.8426 - val_accuracy: 0.5963\n",
      "Epoch 841/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7897 - accuracy: 0.6426 - val_loss: 0.8421 - val_accuracy: 0.5977\n",
      "Epoch 842/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7894 - accuracy: 0.6439 - val_loss: 0.8418 - val_accuracy: 0.5980\n",
      "Epoch 843/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7894 - accuracy: 0.6445 - val_loss: 0.8422 - val_accuracy: 0.5990\n",
      "Epoch 844/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7891 - accuracy: 0.6430 - val_loss: 0.8422 - val_accuracy: 0.5970\n",
      "Epoch 845/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7890 - accuracy: 0.6439 - val_loss: 0.8430 - val_accuracy: 0.6007\n",
      "Epoch 846/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7890 - accuracy: 0.6421 - val_loss: 0.8420 - val_accuracy: 0.5977\n",
      "Epoch 847/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7889 - accuracy: 0.6434 - val_loss: 0.8422 - val_accuracy: 0.5967\n",
      "Epoch 848/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7889 - accuracy: 0.6437 - val_loss: 0.8423 - val_accuracy: 0.5987\n",
      "Epoch 849/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7887 - accuracy: 0.6439 - val_loss: 0.8420 - val_accuracy: 0.5990\n",
      "Epoch 850/1200\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.7885 - accuracy: 0.6439 - val_loss: 0.8421 - val_accuracy: 0.5963\n",
      "Epoch 851/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7884 - accuracy: 0.6439 - val_loss: 0.8434 - val_accuracy: 0.5970\n",
      "Epoch 852/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7883 - accuracy: 0.6437 - val_loss: 0.8428 - val_accuracy: 0.5987\n",
      "Epoch 853/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7881 - accuracy: 0.6434 - val_loss: 0.8421 - val_accuracy: 0.5970\n",
      "Epoch 854/1200\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.7880 - accuracy: 0.6447 - val_loss: 0.8422 - val_accuracy: 0.5973\n",
      "Epoch 855/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7881 - accuracy: 0.6451 - val_loss: 0.8424 - val_accuracy: 0.5977\n",
      "Epoch 856/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7879 - accuracy: 0.6439 - val_loss: 0.8422 - val_accuracy: 0.5973\n",
      "Epoch 857/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7876 - accuracy: 0.6435 - val_loss: 0.8424 - val_accuracy: 0.5980\n",
      "Epoch 858/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7876 - accuracy: 0.6440 - val_loss: 0.8428 - val_accuracy: 0.5990\n",
      "Epoch 859/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7876 - accuracy: 0.6453 - val_loss: 0.8424 - val_accuracy: 0.5967\n",
      "Epoch 860/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7873 - accuracy: 0.6444 - val_loss: 0.8421 - val_accuracy: 0.5970\n",
      "Epoch 861/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7873 - accuracy: 0.6437 - val_loss: 0.8427 - val_accuracy: 0.5957\n",
      "Epoch 862/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7871 - accuracy: 0.6437 - val_loss: 0.8423 - val_accuracy: 0.5967\n",
      "Epoch 863/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7869 - accuracy: 0.6440 - val_loss: 0.8424 - val_accuracy: 0.5953\n",
      "Epoch 864/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7869 - accuracy: 0.6441 - val_loss: 0.8425 - val_accuracy: 0.5963\n",
      "Epoch 865/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7867 - accuracy: 0.6436 - val_loss: 0.8430 - val_accuracy: 0.5953\n",
      "Epoch 866/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7865 - accuracy: 0.6443 - val_loss: 0.8433 - val_accuracy: 0.5973\n",
      "Epoch 867/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7864 - accuracy: 0.6458 - val_loss: 0.8424 - val_accuracy: 0.5970\n",
      "Epoch 868/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7862 - accuracy: 0.6447 - val_loss: 0.8446 - val_accuracy: 0.5970\n",
      "Epoch 869/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7862 - accuracy: 0.6460 - val_loss: 0.8430 - val_accuracy: 0.5983\n",
      "Epoch 870/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7861 - accuracy: 0.6456 - val_loss: 0.8425 - val_accuracy: 0.5960\n",
      "Epoch 871/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.7859 - accuracy: 0.6439 - val_loss: 0.8434 - val_accuracy: 0.5970\n",
      "Epoch 872/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7857 - accuracy: 0.6447 - val_loss: 0.8429 - val_accuracy: 0.5950\n",
      "Epoch 873/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7857 - accuracy: 0.6459 - val_loss: 0.8431 - val_accuracy: 0.5993\n",
      "Epoch 874/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7856 - accuracy: 0.6464 - val_loss: 0.8431 - val_accuracy: 0.5973\n",
      "Epoch 875/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7852 - accuracy: 0.6454 - val_loss: 0.8439 - val_accuracy: 0.5943\n",
      "Epoch 876/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7854 - accuracy: 0.6460 - val_loss: 0.8429 - val_accuracy: 0.5957\n",
      "Epoch 877/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7852 - accuracy: 0.6476 - val_loss: 0.8429 - val_accuracy: 0.5963\n",
      "Epoch 878/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7847 - accuracy: 0.6453 - val_loss: 0.8427 - val_accuracy: 0.5957\n",
      "Epoch 879/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7848 - accuracy: 0.6460 - val_loss: 0.8434 - val_accuracy: 0.5973\n",
      "Epoch 880/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7848 - accuracy: 0.6455 - val_loss: 0.8427 - val_accuracy: 0.5950\n",
      "Epoch 881/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7845 - accuracy: 0.6453 - val_loss: 0.8431 - val_accuracy: 0.5963\n",
      "Epoch 882/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.7844 - accuracy: 0.6454 - val_loss: 0.8428 - val_accuracy: 0.5940\n",
      "Epoch 883/1200\n",
      "14000/14000 [==============================] - 1s 75us/step - loss: 0.7844 - accuracy: 0.6462 - val_loss: 0.8433 - val_accuracy: 0.5953\n",
      "Epoch 884/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7841 - accuracy: 0.6453 - val_loss: 0.8433 - val_accuracy: 0.5983\n",
      "Epoch 885/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7843 - accuracy: 0.6454 - val_loss: 0.8431 - val_accuracy: 0.5973\n",
      "Epoch 886/1200\n",
      "14000/14000 [==============================] - 1s 78us/step - loss: 0.7840 - accuracy: 0.6478 - val_loss: 0.8431 - val_accuracy: 0.5973\n",
      "Epoch 887/1200\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.7837 - accuracy: 0.64 - 1s 78us/step - loss: 0.7837 - accuracy: 0.6471 - val_loss: 0.8431 - val_accuracy: 0.5957\n",
      "Epoch 888/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.7838 - accuracy: 0.6463 - val_loss: 0.8432 - val_accuracy: 0.5960\n",
      "Epoch 889/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7835 - accuracy: 0.6471 - val_loss: 0.8427 - val_accuracy: 0.5980\n",
      "Epoch 890/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.7832 - accuracy: 0.6459 - val_loss: 0.8439 - val_accuracy: 0.5957\n",
      "Epoch 891/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7833 - accuracy: 0.6468 - val_loss: 0.8434 - val_accuracy: 0.5980\n",
      "Epoch 892/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7830 - accuracy: 0.6464 - val_loss: 0.8431 - val_accuracy: 0.5953\n",
      "Epoch 893/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7827 - accuracy: 0.6471 - val_loss: 0.8430 - val_accuracy: 0.5963\n",
      "Epoch 894/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7829 - accuracy: 0.6471 - val_loss: 0.8438 - val_accuracy: 0.5973\n",
      "Epoch 895/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7828 - accuracy: 0.6480 - val_loss: 0.8434 - val_accuracy: 0.5963\n",
      "Epoch 896/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.7826 - accuracy: 0.6454 - val_loss: 0.8432 - val_accuracy: 0.5963\n",
      "Epoch 897/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7824 - accuracy: 0.6461 - val_loss: 0.8436 - val_accuracy: 0.5970\n",
      "Epoch 898/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7822 - accuracy: 0.6476 - val_loss: 0.8436 - val_accuracy: 0.5950\n",
      "Epoch 899/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.7822 - accuracy: 0.6480 - val_loss: 0.8431 - val_accuracy: 0.5953\n",
      "Epoch 900/1200\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.7820 - accuracy: 0.6471 - val_loss: 0.8436 - val_accuracy: 0.5980\n",
      "Epoch 901/1200\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.7821 - accuracy: 0.6471 - val_loss: 0.8433 - val_accuracy: 0.5970\n",
      "Epoch 902/1200\n",
      "14000/14000 [==============================] - 1s 75us/step - loss: 0.7818 - accuracy: 0.6465 - val_loss: 0.8436 - val_accuracy: 0.5980\n",
      "Epoch 903/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7816 - accuracy: 0.6491 - val_loss: 0.8433 - val_accuracy: 0.5960\n",
      "Epoch 904/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7813 - accuracy: 0.6484 - val_loss: 0.8437 - val_accuracy: 0.5983\n",
      "Epoch 905/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.7815 - accuracy: 0.6475 - val_loss: 0.8432 - val_accuracy: 0.5957\n",
      "Epoch 906/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7814 - accuracy: 0.6501 - val_loss: 0.8435 - val_accuracy: 0.5977\n",
      "Epoch 907/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7812 - accuracy: 0.6489 - val_loss: 0.8441 - val_accuracy: 0.5963\n",
      "Epoch 908/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7808 - accuracy: 0.6483 - val_loss: 0.8442 - val_accuracy: 0.5953\n",
      "Epoch 909/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7808 - accuracy: 0.6496 - val_loss: 0.8443 - val_accuracy: 0.5977\n",
      "Epoch 910/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7805 - accuracy: 0.6498 - val_loss: 0.8442 - val_accuracy: 0.5943\n",
      "Epoch 911/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7804 - accuracy: 0.6493 - val_loss: 0.8441 - val_accuracy: 0.5983\n",
      "Epoch 912/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7804 - accuracy: 0.6478 - val_loss: 0.8443 - val_accuracy: 0.5973\n",
      "Epoch 913/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7803 - accuracy: 0.6501 - val_loss: 0.8442 - val_accuracy: 0.5947\n",
      "Epoch 914/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7800 - accuracy: 0.6491 - val_loss: 0.8453 - val_accuracy: 0.5957\n",
      "Epoch 915/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7800 - accuracy: 0.6493 - val_loss: 0.8449 - val_accuracy: 0.5970\n",
      "Epoch 916/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7800 - accuracy: 0.6493 - val_loss: 0.8439 - val_accuracy: 0.5970\n",
      "Epoch 917/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7797 - accuracy: 0.6501 - val_loss: 0.8439 - val_accuracy: 0.5973\n",
      "Epoch 918/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7795 - accuracy: 0.6487 - val_loss: 0.8440 - val_accuracy: 0.5983\n",
      "Epoch 919/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7795 - accuracy: 0.6491 - val_loss: 0.8439 - val_accuracy: 0.5983\n",
      "Epoch 920/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7791 - accuracy: 0.6500 - val_loss: 0.8451 - val_accuracy: 0.5957\n",
      "Epoch 921/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7790 - accuracy: 0.6488 - val_loss: 0.8443 - val_accuracy: 0.5970\n",
      "Epoch 922/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7789 - accuracy: 0.6489 - val_loss: 0.8440 - val_accuracy: 0.5980\n",
      "Epoch 923/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.7784 - accuracy: 0.6506 - val_loss: 0.8439 - val_accuracy: 0.5967\n",
      "Epoch 924/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7787 - accuracy: 0.6509 - val_loss: 0.8440 - val_accuracy: 0.5973\n",
      "Epoch 925/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7785 - accuracy: 0.6499 - val_loss: 0.8440 - val_accuracy: 0.5963\n",
      "Epoch 926/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7782 - accuracy: 0.6534 - val_loss: 0.8442 - val_accuracy: 0.5977\n",
      "Epoch 927/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7781 - accuracy: 0.6495 - val_loss: 0.8441 - val_accuracy: 0.5953\n",
      "Epoch 928/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7780 - accuracy: 0.6496 - val_loss: 0.8442 - val_accuracy: 0.5983\n",
      "Epoch 929/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7779 - accuracy: 0.6505 - val_loss: 0.8444 - val_accuracy: 0.5967\n",
      "Epoch 930/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7775 - accuracy: 0.6492 - val_loss: 0.8443 - val_accuracy: 0.5990\n",
      "Epoch 931/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7774 - accuracy: 0.6506 - val_loss: 0.8446 - val_accuracy: 0.5980\n",
      "Epoch 932/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.7773 - accuracy: 0.6528 - val_loss: 0.8449 - val_accuracy: 0.5983\n",
      "Epoch 933/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7772 - accuracy: 0.6521 - val_loss: 0.8451 - val_accuracy: 0.5977\n",
      "Epoch 934/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7771 - accuracy: 0.6516 - val_loss: 0.8446 - val_accuracy: 0.5963\n",
      "Epoch 935/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7767 - accuracy: 0.6494 - val_loss: 0.8445 - val_accuracy: 0.5957\n",
      "Epoch 936/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7767 - accuracy: 0.6509 - val_loss: 0.8447 - val_accuracy: 0.5943\n",
      "Epoch 937/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7765 - accuracy: 0.6504 - val_loss: 0.8455 - val_accuracy: 0.5970\n",
      "Epoch 938/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7765 - accuracy: 0.6505 - val_loss: 0.8458 - val_accuracy: 0.5953\n",
      "Epoch 939/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7764 - accuracy: 0.6514 - val_loss: 0.8446 - val_accuracy: 0.5980\n",
      "Epoch 940/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7760 - accuracy: 0.6536 - val_loss: 0.8465 - val_accuracy: 0.5980\n",
      "Epoch 941/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7761 - accuracy: 0.6508 - val_loss: 0.8462 - val_accuracy: 0.5967\n",
      "Epoch 942/1200\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.7755 - accuracy: 0.6529 - val_loss: 0.8464 - val_accuracy: 0.5980\n",
      "Epoch 943/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7759 - accuracy: 0.6512 - val_loss: 0.8449 - val_accuracy: 0.5970\n",
      "Epoch 944/1200\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.7756 - accuracy: 0.6537 - val_loss: 0.8452 - val_accuracy: 0.5957\n",
      "Epoch 945/1200\n",
      "14000/14000 [==============================] - 1s 76us/step - loss: 0.7754 - accuracy: 0.6514 - val_loss: 0.8451 - val_accuracy: 0.5963\n",
      "Epoch 946/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7752 - accuracy: 0.6541 - val_loss: 0.8454 - val_accuracy: 0.5930\n",
      "Epoch 947/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7749 - accuracy: 0.6534 - val_loss: 0.8456 - val_accuracy: 0.5957\n",
      "Epoch 948/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.7750 - accuracy: 0.6521 - val_loss: 0.8452 - val_accuracy: 0.5963\n",
      "Epoch 949/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.7747 - accuracy: 0.6534 - val_loss: 0.8458 - val_accuracy: 0.5980\n",
      "Epoch 950/1200\n",
      "14000/14000 [==============================] - 1s 76us/step - loss: 0.7743 - accuracy: 0.6529 - val_loss: 0.8460 - val_accuracy: 0.5977\n",
      "Epoch 951/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7743 - accuracy: 0.6531 - val_loss: 0.8457 - val_accuracy: 0.5983\n",
      "Epoch 952/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7745 - accuracy: 0.6514 - val_loss: 0.8453 - val_accuracy: 0.5967\n",
      "Epoch 953/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7739 - accuracy: 0.6541 - val_loss: 0.8456 - val_accuracy: 0.5973\n",
      "Epoch 954/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7739 - accuracy: 0.6520 - val_loss: 0.8453 - val_accuracy: 0.5953\n",
      "Epoch 955/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7737 - accuracy: 0.6531 - val_loss: 0.8454 - val_accuracy: 0.5947\n",
      "Epoch 956/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7731 - accuracy: 0.6536 - val_loss: 0.8461 - val_accuracy: 0.5960\n",
      "Epoch 957/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7727 - accuracy: 0.6537 - val_loss: 0.8459 - val_accuracy: 0.5997\n",
      "Epoch 958/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7732 - accuracy: 0.6541 - val_loss: 0.8455 - val_accuracy: 0.5957\n",
      "Epoch 959/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.7729 - accuracy: 0.6554 - val_loss: 0.8464 - val_accuracy: 0.6000\n",
      "Epoch 960/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7730 - accuracy: 0.6539 - val_loss: 0.8456 - val_accuracy: 0.5963\n",
      "Epoch 961/1200\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.7727 - accuracy: 0.6544 - val_loss: 0.8466 - val_accuracy: 0.5977\n",
      "Epoch 962/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7726 - accuracy: 0.6535 - val_loss: 0.8457 - val_accuracy: 0.5963\n",
      "Epoch 963/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7724 - accuracy: 0.6549 - val_loss: 0.8459 - val_accuracy: 0.5953\n",
      "Epoch 964/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7721 - accuracy: 0.6529 - val_loss: 0.8463 - val_accuracy: 0.5990\n",
      "Epoch 965/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7720 - accuracy: 0.6529 - val_loss: 0.8468 - val_accuracy: 0.5973\n",
      "Epoch 966/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7719 - accuracy: 0.6539 - val_loss: 0.8466 - val_accuracy: 0.5990\n",
      "Epoch 967/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7719 - accuracy: 0.6551 - val_loss: 0.8465 - val_accuracy: 0.5963\n",
      "Epoch 968/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7715 - accuracy: 0.6539 - val_loss: 0.8472 - val_accuracy: 0.5973\n",
      "Epoch 969/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7711 - accuracy: 0.6546 - val_loss: 0.8470 - val_accuracy: 0.5957\n",
      "Epoch 970/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7713 - accuracy: 0.6556 - val_loss: 0.8462 - val_accuracy: 0.5947\n",
      "Epoch 971/1200\n",
      "14000/14000 [==============================] - 1s 79us/step - loss: 0.7710 - accuracy: 0.6547 - val_loss: 0.8463 - val_accuracy: 0.5950\n",
      "Epoch 972/1200\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.7717 - accuracy: 0.65 - 1s 78us/step - loss: 0.7709 - accuracy: 0.6549 - val_loss: 0.8464 - val_accuracy: 0.5950\n",
      "Epoch 973/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.7708 - accuracy: 0.6538 - val_loss: 0.8470 - val_accuracy: 0.5967\n",
      "Epoch 974/1200\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.7705 - accuracy: 0.6546 - val_loss: 0.8466 - val_accuracy: 0.5943\n",
      "Epoch 975/1200\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.7706 - accuracy: 0.6554 - val_loss: 0.8484 - val_accuracy: 0.5973\n",
      "Epoch 976/1200\n",
      "14000/14000 [==============================] - 1s 79us/step - loss: 0.7701 - accuracy: 0.6567 - val_loss: 0.8484 - val_accuracy: 0.5970\n",
      "Epoch 977/1200\n",
      "14000/14000 [==============================] - 1s 73us/step - loss: 0.7701 - accuracy: 0.6538 - val_loss: 0.8494 - val_accuracy: 0.5967\n",
      "Epoch 978/1200\n",
      "14000/14000 [==============================] - 1s 77us/step - loss: 0.7696 - accuracy: 0.6546 - val_loss: 0.8486 - val_accuracy: 0.5980\n",
      "Epoch 979/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.7693 - accuracy: 0.6546 - val_loss: 0.8493 - val_accuracy: 0.5967\n",
      "Epoch 980/1200\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.7697 - accuracy: 0.6554 - val_loss: 0.8476 - val_accuracy: 0.5957\n",
      "Epoch 981/1200\n",
      "14000/14000 [==============================] - 1s 78us/step - loss: 0.7693 - accuracy: 0.6551 - val_loss: 0.8481 - val_accuracy: 0.5973\n",
      "Epoch 982/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7689 - accuracy: 0.6544 - val_loss: 0.8470 - val_accuracy: 0.5953\n",
      "Epoch 983/1200\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.7690 - accuracy: 0.6553 - val_loss: 0.8483 - val_accuracy: 0.5977\n",
      "Epoch 984/1200\n",
      "14000/14000 [==============================] - 1s 79us/step - loss: 0.7687 - accuracy: 0.6561 - val_loss: 0.8485 - val_accuracy: 0.5953\n",
      "Epoch 985/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7682 - accuracy: 0.6560 - val_loss: 0.8476 - val_accuracy: 0.5943\n",
      "Epoch 986/1200\n",
      "14000/14000 [==============================] - 1s 73us/step - loss: 0.7685 - accuracy: 0.6565 - val_loss: 0.8473 - val_accuracy: 0.5943\n",
      "Epoch 987/1200\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.7683 - accuracy: 0.6562 - val_loss: 0.8474 - val_accuracy: 0.5923\n",
      "Epoch 988/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.7682 - accuracy: 0.6572 - val_loss: 0.8472 - val_accuracy: 0.5940\n",
      "Epoch 989/1200\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.7678 - accuracy: 0.6576 - val_loss: 0.8475 - val_accuracy: 0.5980\n",
      "Epoch 990/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7676 - accuracy: 0.6593 - val_loss: 0.8479 - val_accuracy: 0.5967\n",
      "Epoch 991/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7676 - accuracy: 0.6565 - val_loss: 0.8479 - val_accuracy: 0.5940\n",
      "Epoch 992/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7674 - accuracy: 0.6572 - val_loss: 0.8485 - val_accuracy: 0.5970\n",
      "Epoch 993/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7672 - accuracy: 0.6578 - val_loss: 0.8483 - val_accuracy: 0.5987\n",
      "Epoch 994/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7667 - accuracy: 0.6588 - val_loss: 0.8476 - val_accuracy: 0.5933\n",
      "Epoch 995/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7666 - accuracy: 0.6577 - val_loss: 0.8484 - val_accuracy: 0.5920\n",
      "Epoch 996/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7664 - accuracy: 0.6562 - val_loss: 0.8483 - val_accuracy: 0.5977\n",
      "Epoch 997/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7664 - accuracy: 0.6583 - val_loss: 0.8488 - val_accuracy: 0.5963\n",
      "Epoch 998/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7661 - accuracy: 0.6579 - val_loss: 0.8484 - val_accuracy: 0.5943\n",
      "Epoch 999/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7659 - accuracy: 0.6561 - val_loss: 0.8504 - val_accuracy: 0.5937\n",
      "Epoch 1000/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7657 - accuracy: 0.6571 - val_loss: 0.8485 - val_accuracy: 0.5953\n",
      "Epoch 1001/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7656 - accuracy: 0.6582 - val_loss: 0.8481 - val_accuracy: 0.5947\n",
      "Epoch 1002/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7654 - accuracy: 0.6571 - val_loss: 0.8482 - val_accuracy: 0.5940\n",
      "Epoch 1003/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7651 - accuracy: 0.6602 - val_loss: 0.8489 - val_accuracy: 0.5967\n",
      "Epoch 1004/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7649 - accuracy: 0.6593 - val_loss: 0.8487 - val_accuracy: 0.5963\n",
      "Epoch 1005/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7647 - accuracy: 0.6586 - val_loss: 0.8508 - val_accuracy: 0.5963\n",
      "Epoch 1006/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7648 - accuracy: 0.6594 - val_loss: 0.8487 - val_accuracy: 0.5940\n",
      "Epoch 1007/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7644 - accuracy: 0.6589 - val_loss: 0.8500 - val_accuracy: 0.5943\n",
      "Epoch 1008/1200\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.7638 - accuracy: 0.6602 - val_loss: 0.8497 - val_accuracy: 0.5977\n",
      "Epoch 1009/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7640 - accuracy: 0.6584 - val_loss: 0.8492 - val_accuracy: 0.5923\n",
      "Epoch 1010/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7639 - accuracy: 0.6591 - val_loss: 0.8490 - val_accuracy: 0.5940\n",
      "Epoch 1011/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7636 - accuracy: 0.6597 - val_loss: 0.8491 - val_accuracy: 0.5940\n",
      "Epoch 1012/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7635 - accuracy: 0.6578 - val_loss: 0.8492 - val_accuracy: 0.5937\n",
      "Epoch 1013/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7634 - accuracy: 0.6598 - val_loss: 0.8499 - val_accuracy: 0.5947\n",
      "Epoch 1014/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7628 - accuracy: 0.6581 - val_loss: 0.8495 - val_accuracy: 0.5950\n",
      "Epoch 1015/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7629 - accuracy: 0.6584 - val_loss: 0.8502 - val_accuracy: 0.5953\n",
      "Epoch 1016/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7625 - accuracy: 0.6597 - val_loss: 0.8513 - val_accuracy: 0.5953\n",
      "Epoch 1017/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7622 - accuracy: 0.6592 - val_loss: 0.8496 - val_accuracy: 0.5977\n",
      "Epoch 1018/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7619 - accuracy: 0.6601 - val_loss: 0.8500 - val_accuracy: 0.5963\n",
      "Epoch 1019/1200\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.7620 - accuracy: 0.6606 - val_loss: 0.8502 - val_accuracy: 0.5953\n",
      "Epoch 1020/1200\n",
      "14000/14000 [==============================] - 1s 78us/step - loss: 0.7621 - accuracy: 0.6601 - val_loss: 0.8500 - val_accuracy: 0.5947\n",
      "Epoch 1021/1200\n",
      "14000/14000 [==============================] - 1s 78us/step - loss: 0.7616 - accuracy: 0.6599 - val_loss: 0.8503 - val_accuracy: 0.5930\n",
      "Epoch 1022/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7617 - accuracy: 0.6609 - val_loss: 0.8500 - val_accuracy: 0.5950\n",
      "Epoch 1023/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7610 - accuracy: 0.6602 - val_loss: 0.8503 - val_accuracy: 0.5950\n",
      "Epoch 1024/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7611 - accuracy: 0.6595 - val_loss: 0.8515 - val_accuracy: 0.5947\n",
      "Epoch 1025/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7608 - accuracy: 0.6606 - val_loss: 0.8526 - val_accuracy: 0.5967\n",
      "Epoch 1026/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7608 - accuracy: 0.6612 - val_loss: 0.8507 - val_accuracy: 0.5930\n",
      "Epoch 1027/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7602 - accuracy: 0.6616 - val_loss: 0.8506 - val_accuracy: 0.5973\n",
      "Epoch 1028/1200\n",
      "14000/14000 [==============================] - 1s 73us/step - loss: 0.7600 - accuracy: 0.6610 - val_loss: 0.8516 - val_accuracy: 0.5957\n",
      "Epoch 1029/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7600 - accuracy: 0.6613 - val_loss: 0.8523 - val_accuracy: 0.5950\n",
      "Epoch 1030/1200\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.7599 - accuracy: 0.6630 - val_loss: 0.8509 - val_accuracy: 0.5953\n",
      "Epoch 1031/1200\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.7594 - accuracy: 0.6606 - val_loss: 0.8553 - val_accuracy: 0.5937\n",
      "Epoch 1032/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7594 - accuracy: 0.6615 - val_loss: 0.8516 - val_accuracy: 0.5953\n",
      "Epoch 1033/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7592 - accuracy: 0.6614 - val_loss: 0.8515 - val_accuracy: 0.5940\n",
      "Epoch 1034/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7587 - accuracy: 0.6606 - val_loss: 0.8517 - val_accuracy: 0.5940\n",
      "Epoch 1035/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7589 - accuracy: 0.6648 - val_loss: 0.8521 - val_accuracy: 0.5960\n",
      "Epoch 1036/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7584 - accuracy: 0.6623 - val_loss: 0.8514 - val_accuracy: 0.5940\n",
      "Epoch 1037/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7577 - accuracy: 0.6643 - val_loss: 0.8523 - val_accuracy: 0.5937\n",
      "Epoch 1038/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7581 - accuracy: 0.6619 - val_loss: 0.8520 - val_accuracy: 0.5970\n",
      "Epoch 1039/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7576 - accuracy: 0.6631 - val_loss: 0.8526 - val_accuracy: 0.5953\n",
      "Epoch 1040/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7581 - accuracy: 0.6616 - val_loss: 0.8519 - val_accuracy: 0.5943\n",
      "Epoch 1041/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7574 - accuracy: 0.6639 - val_loss: 0.8519 - val_accuracy: 0.5947\n",
      "Epoch 1042/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7572 - accuracy: 0.6619 - val_loss: 0.8524 - val_accuracy: 0.5933\n",
      "Epoch 1043/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7573 - accuracy: 0.6631 - val_loss: 0.8520 - val_accuracy: 0.5967\n",
      "Epoch 1044/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7568 - accuracy: 0.6617 - val_loss: 0.8522 - val_accuracy: 0.5950\n",
      "Epoch 1045/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7565 - accuracy: 0.6645 - val_loss: 0.8521 - val_accuracy: 0.5943\n",
      "Epoch 1046/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7562 - accuracy: 0.6649 - val_loss: 0.8526 - val_accuracy: 0.5930\n",
      "Epoch 1047/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7563 - accuracy: 0.6635 - val_loss: 0.8526 - val_accuracy: 0.5917\n",
      "Epoch 1048/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7563 - accuracy: 0.6636 - val_loss: 0.8524 - val_accuracy: 0.5937\n",
      "Epoch 1049/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7560 - accuracy: 0.6619 - val_loss: 0.8539 - val_accuracy: 0.5940\n",
      "Epoch 1050/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7557 - accuracy: 0.6625 - val_loss: 0.8524 - val_accuracy: 0.5957\n",
      "Epoch 1051/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7552 - accuracy: 0.6654 - val_loss: 0.8526 - val_accuracy: 0.5937\n",
      "Epoch 1052/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7552 - accuracy: 0.6669 - val_loss: 0.8529 - val_accuracy: 0.5940\n",
      "Epoch 1053/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7549 - accuracy: 0.6629 - val_loss: 0.8533 - val_accuracy: 0.5947\n",
      "Epoch 1054/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7546 - accuracy: 0.6645 - val_loss: 0.8527 - val_accuracy: 0.5957\n",
      "Epoch 1055/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7548 - accuracy: 0.6629 - val_loss: 0.8533 - val_accuracy: 0.5953\n",
      "Epoch 1056/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7542 - accuracy: 0.6654 - val_loss: 0.8586 - val_accuracy: 0.5927\n",
      "Epoch 1057/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7540 - accuracy: 0.6649 - val_loss: 0.8536 - val_accuracy: 0.5960\n",
      "Epoch 1058/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.7537 - accuracy: 0.6656 - val_loss: 0.8572 - val_accuracy: 0.5903\n",
      "Epoch 1059/1200\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.7537 - accuracy: 0.6636 - val_loss: 0.8540 - val_accuracy: 0.5940\n",
      "Epoch 1060/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7533 - accuracy: 0.6664 - val_loss: 0.8541 - val_accuracy: 0.5947\n",
      "Epoch 1061/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.7530 - accuracy: 0.6659 - val_loss: 0.8548 - val_accuracy: 0.5923\n",
      "Epoch 1062/1200\n",
      "14000/14000 [==============================] - 1s 75us/step - loss: 0.7525 - accuracy: 0.6641 - val_loss: 0.8561 - val_accuracy: 0.5973\n",
      "Epoch 1063/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7525 - accuracy: 0.6670 - val_loss: 0.8546 - val_accuracy: 0.5940\n",
      "Epoch 1064/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7525 - accuracy: 0.6661 - val_loss: 0.8546 - val_accuracy: 0.5933\n",
      "Epoch 1065/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7524 - accuracy: 0.6668 - val_loss: 0.8540 - val_accuracy: 0.5947\n",
      "Epoch 1066/1200\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.7516 - accuracy: 0.6657 - val_loss: 0.8562 - val_accuracy: 0.5960\n",
      "Epoch 1067/1200\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.7518 - accuracy: 0.6654 - val_loss: 0.8555 - val_accuracy: 0.5960\n",
      "Epoch 1068/1200\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.7513 - accuracy: 0.6642 - val_loss: 0.8549 - val_accuracy: 0.5937\n",
      "Epoch 1069/1200\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.7508 - accuracy: 0.6666 - val_loss: 0.8580 - val_accuracy: 0.5953\n",
      "Epoch 1070/1200\n",
      "14000/14000 [==============================] - 2s 147us/step - loss: 0.7509 - accuracy: 0.6670 - val_loss: 0.8565 - val_accuracy: 0.5923\n",
      "Epoch 1071/1200\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.7509 - accuracy: 0.6656 - val_loss: 0.8548 - val_accuracy: 0.5943\n",
      "Epoch 1072/1200\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.7503 - accuracy: 0.6685 - val_loss: 0.8564 - val_accuracy: 0.5910\n",
      "Epoch 1073/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7502 - accuracy: 0.6671 - val_loss: 0.8579 - val_accuracy: 0.5927\n",
      "Epoch 1074/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7498 - accuracy: 0.6674 - val_loss: 0.8567 - val_accuracy: 0.5947\n",
      "Epoch 1075/1200\n",
      "14000/14000 [==============================] - 1s 50us/step - loss: 0.7497 - accuracy: 0.6676 - val_loss: 0.8567 - val_accuracy: 0.5937\n",
      "Epoch 1076/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7496 - accuracy: 0.6684 - val_loss: 0.8586 - val_accuracy: 0.5940\n",
      "Epoch 1077/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7493 - accuracy: 0.6673 - val_loss: 0.8562 - val_accuracy: 0.5937\n",
      "Epoch 1078/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7489 - accuracy: 0.6674 - val_loss: 0.8568 - val_accuracy: 0.5947\n",
      "Epoch 1079/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7487 - accuracy: 0.6695 - val_loss: 0.8560 - val_accuracy: 0.5947\n",
      "Epoch 1080/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.7489 - accuracy: 0.6662 - val_loss: 0.8564 - val_accuracy: 0.5943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1081/1200\n",
      "14000/14000 [==============================] - 4s 265us/step - loss: 0.7483 - accuracy: 0.6686 - val_loss: 0.8577 - val_accuracy: 0.5907\n",
      "Epoch 1082/1200\n",
      "14000/14000 [==============================] - 3s 189us/step - loss: 0.7480 - accuracy: 0.6665 - val_loss: 0.8574 - val_accuracy: 0.5930\n",
      "Epoch 1083/1200\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.7478 - accuracy: 0.6696 - val_loss: 0.8573 - val_accuracy: 0.5957\n",
      "Epoch 1084/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7476 - accuracy: 0.6692 - val_loss: 0.8567 - val_accuracy: 0.5920\n",
      "Epoch 1085/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7470 - accuracy: 0.6674 - val_loss: 0.8567 - val_accuracy: 0.5970\n",
      "Epoch 1086/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7471 - accuracy: 0.6688 - val_loss: 0.8575 - val_accuracy: 0.5927\n",
      "Epoch 1087/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7469 - accuracy: 0.6686 - val_loss: 0.8573 - val_accuracy: 0.5940\n",
      "Epoch 1088/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7466 - accuracy: 0.6676 - val_loss: 0.8580 - val_accuracy: 0.5947\n",
      "Epoch 1089/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7465 - accuracy: 0.6684 - val_loss: 0.8656 - val_accuracy: 0.5930\n",
      "Epoch 1090/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7461 - accuracy: 0.6695 - val_loss: 0.8579 - val_accuracy: 0.5930\n",
      "Epoch 1091/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7457 - accuracy: 0.6711 - val_loss: 0.8592 - val_accuracy: 0.5953\n",
      "Epoch 1092/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7452 - accuracy: 0.6689 - val_loss: 0.8600 - val_accuracy: 0.5890\n",
      "Epoch 1093/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7451 - accuracy: 0.6691 - val_loss: 0.8603 - val_accuracy: 0.5927\n",
      "Epoch 1094/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7453 - accuracy: 0.6686 - val_loss: 0.8576 - val_accuracy: 0.5940\n",
      "Epoch 1095/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7448 - accuracy: 0.6690 - val_loss: 0.8604 - val_accuracy: 0.5917\n",
      "Epoch 1096/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7449 - accuracy: 0.6692 - val_loss: 0.8614 - val_accuracy: 0.5917\n",
      "Epoch 1097/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7440 - accuracy: 0.6685 - val_loss: 0.8592 - val_accuracy: 0.5910\n",
      "Epoch 1098/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7439 - accuracy: 0.6666 - val_loss: 0.8692 - val_accuracy: 0.5870\n",
      "Epoch 1099/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7438 - accuracy: 0.6717 - val_loss: 0.8586 - val_accuracy: 0.5940\n",
      "Epoch 1100/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7435 - accuracy: 0.6728 - val_loss: 0.8601 - val_accuracy: 0.5907\n",
      "Epoch 1101/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7434 - accuracy: 0.6699 - val_loss: 0.8594 - val_accuracy: 0.5957\n",
      "Epoch 1102/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7427 - accuracy: 0.6706 - val_loss: 0.8607 - val_accuracy: 0.5980\n",
      "Epoch 1103/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7432 - accuracy: 0.6716 - val_loss: 0.8592 - val_accuracy: 0.5927\n",
      "Epoch 1104/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7427 - accuracy: 0.6704 - val_loss: 0.8601 - val_accuracy: 0.5960\n",
      "Epoch 1105/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7418 - accuracy: 0.6735 - val_loss: 0.8601 - val_accuracy: 0.5933\n",
      "Epoch 1106/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7424 - accuracy: 0.6727 - val_loss: 0.8599 - val_accuracy: 0.5940\n",
      "Epoch 1107/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7418 - accuracy: 0.6692 - val_loss: 0.8618 - val_accuracy: 0.5953\n",
      "Epoch 1108/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7413 - accuracy: 0.6706 - val_loss: 0.8614 - val_accuracy: 0.5907\n",
      "Epoch 1109/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7415 - accuracy: 0.6729 - val_loss: 0.8608 - val_accuracy: 0.5907\n",
      "Epoch 1110/1200\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.7403 - accuracy: 0.6719 - val_loss: 0.8630 - val_accuracy: 0.5973\n",
      "Epoch 1111/1200\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.7406 - accuracy: 0.6692 - val_loss: 0.8668 - val_accuracy: 0.5860\n",
      "Epoch 1112/1200\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.7406 - accuracy: 0.6723 - val_loss: 0.8612 - val_accuracy: 0.5900\n",
      "Epoch 1113/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7398 - accuracy: 0.6706 - val_loss: 0.8618 - val_accuracy: 0.5930\n",
      "Epoch 1114/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7397 - accuracy: 0.6723 - val_loss: 0.8637 - val_accuracy: 0.5890\n",
      "Epoch 1115/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7392 - accuracy: 0.6721 - val_loss: 0.8611 - val_accuracy: 0.5897\n",
      "Epoch 1116/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7393 - accuracy: 0.6738 - val_loss: 0.8616 - val_accuracy: 0.5923\n",
      "Epoch 1117/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7392 - accuracy: 0.6713 - val_loss: 0.8619 - val_accuracy: 0.5950\n",
      "Epoch 1118/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7390 - accuracy: 0.6733 - val_loss: 0.8625 - val_accuracy: 0.5917\n",
      "Epoch 1119/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7385 - accuracy: 0.6750 - val_loss: 0.8702 - val_accuracy: 0.5903\n",
      "Epoch 1120/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7385 - accuracy: 0.6719 - val_loss: 0.8622 - val_accuracy: 0.5890\n",
      "Epoch 1121/1200\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.7377 - accuracy: 0.6726 - val_loss: 0.8648 - val_accuracy: 0.5880\n",
      "Epoch 1122/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.7378 - accuracy: 0.6714 - val_loss: 0.8622 - val_accuracy: 0.5897\n",
      "Epoch 1123/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7373 - accuracy: 0.6742 - val_loss: 0.8634 - val_accuracy: 0.5920\n",
      "Epoch 1124/1200\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.7367 - accuracy: 0.6750 - val_loss: 0.8627 - val_accuracy: 0.5913\n",
      "Epoch 1125/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7367 - accuracy: 0.6750 - val_loss: 0.8638 - val_accuracy: 0.5883\n",
      "Epoch 1126/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7365 - accuracy: 0.6751 - val_loss: 0.8632 - val_accuracy: 0.5893\n",
      "Epoch 1127/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7360 - accuracy: 0.6754 - val_loss: 0.8626 - val_accuracy: 0.5940\n",
      "Epoch 1128/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7356 - accuracy: 0.6737 - val_loss: 0.8644 - val_accuracy: 0.5900\n",
      "Epoch 1129/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7356 - accuracy: 0.6747 - val_loss: 0.8634 - val_accuracy: 0.5927\n",
      "Epoch 1130/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7355 - accuracy: 0.6764 - val_loss: 0.8651 - val_accuracy: 0.5960\n",
      "Epoch 1131/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7352 - accuracy: 0.6775 - val_loss: 0.8640 - val_accuracy: 0.5913\n",
      "Epoch 1132/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7350 - accuracy: 0.6759 - val_loss: 0.8644 - val_accuracy: 0.5893\n",
      "Epoch 1133/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7341 - accuracy: 0.6745 - val_loss: 0.8713 - val_accuracy: 0.5910\n",
      "Epoch 1134/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7346 - accuracy: 0.6737 - val_loss: 0.8640 - val_accuracy: 0.5913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1135/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7341 - accuracy: 0.6759 - val_loss: 0.8651 - val_accuracy: 0.5917\n",
      "Epoch 1136/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7340 - accuracy: 0.6748 - val_loss: 0.8656 - val_accuracy: 0.5900\n",
      "Epoch 1137/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7334 - accuracy: 0.6771 - val_loss: 0.8653 - val_accuracy: 0.5880\n",
      "Epoch 1138/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7329 - accuracy: 0.6764 - val_loss: 0.8656 - val_accuracy: 0.5910\n",
      "Epoch 1139/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.7329 - accuracy: 0.6781 - val_loss: 0.8661 - val_accuracy: 0.5907\n",
      "Epoch 1140/1200\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.7328 - accuracy: 0.6776 - val_loss: 0.8656 - val_accuracy: 0.5913\n",
      "Epoch 1141/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7320 - accuracy: 0.6764 - val_loss: 0.8656 - val_accuracy: 0.5900\n",
      "Epoch 1142/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7314 - accuracy: 0.6768 - val_loss: 0.8654 - val_accuracy: 0.5890\n",
      "Epoch 1143/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7320 - accuracy: 0.6747 - val_loss: 0.8656 - val_accuracy: 0.5883\n",
      "Epoch 1144/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7315 - accuracy: 0.6772 - val_loss: 0.8744 - val_accuracy: 0.5837\n",
      "Epoch 1145/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7309 - accuracy: 0.6775 - val_loss: 0.8679 - val_accuracy: 0.5893\n",
      "Epoch 1146/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7310 - accuracy: 0.6774 - val_loss: 0.8665 - val_accuracy: 0.5913\n",
      "Epoch 1147/1200\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7307 - accuracy: 0.6781 - val_loss: 0.8752 - val_accuracy: 0.5890\n",
      "Epoch 1148/1200\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.7304 - accuracy: 0.6779 - val_loss: 0.8676 - val_accuracy: 0.5893\n",
      "Epoch 1149/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7303 - accuracy: 0.6784 - val_loss: 0.8705 - val_accuracy: 0.5897\n",
      "Epoch 1150/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7295 - accuracy: 0.6756 - val_loss: 0.8679 - val_accuracy: 0.5910\n",
      "Epoch 1151/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7294 - accuracy: 0.6795 - val_loss: 0.8680 - val_accuracy: 0.5863\n",
      "Epoch 1152/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7294 - accuracy: 0.6789 - val_loss: 0.8686 - val_accuracy: 0.5890\n",
      "Epoch 1153/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7284 - accuracy: 0.6761 - val_loss: 0.8680 - val_accuracy: 0.5890\n",
      "Epoch 1154/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7279 - accuracy: 0.6814 - val_loss: 0.8777 - val_accuracy: 0.5927\n",
      "Epoch 1155/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7286 - accuracy: 0.6786 - val_loss: 0.8684 - val_accuracy: 0.5897\n",
      "Epoch 1156/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7277 - accuracy: 0.6789 - val_loss: 0.8682 - val_accuracy: 0.5920\n",
      "Epoch 1157/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7276 - accuracy: 0.6780 - val_loss: 0.8699 - val_accuracy: 0.5970\n",
      "Epoch 1158/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7279 - accuracy: 0.6789 - val_loss: 0.8690 - val_accuracy: 0.5930\n",
      "Epoch 1159/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7271 - accuracy: 0.6784 - val_loss: 0.8706 - val_accuracy: 0.5903\n",
      "Epoch 1160/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7261 - accuracy: 0.6814 - val_loss: 0.8690 - val_accuracy: 0.5903\n",
      "Epoch 1161/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7265 - accuracy: 0.6785 - val_loss: 0.8700 - val_accuracy: 0.5907\n",
      "Epoch 1162/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7252 - accuracy: 0.6818 - val_loss: 0.8717 - val_accuracy: 0.5910\n",
      "Epoch 1163/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7253 - accuracy: 0.6801 - val_loss: 0.8720 - val_accuracy: 0.5883\n",
      "Epoch 1164/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7261 - accuracy: 0.6804 - val_loss: 0.8732 - val_accuracy: 0.5930\n",
      "Epoch 1165/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7248 - accuracy: 0.6809 - val_loss: 0.8707 - val_accuracy: 0.5857\n",
      "Epoch 1166/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7245 - accuracy: 0.6794 - val_loss: 0.8721 - val_accuracy: 0.5910\n",
      "Epoch 1167/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7249 - accuracy: 0.6817 - val_loss: 0.8725 - val_accuracy: 0.5840\n",
      "Epoch 1168/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7245 - accuracy: 0.6814 - val_loss: 0.8705 - val_accuracy: 0.5890\n",
      "Epoch 1169/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7236 - accuracy: 0.6825 - val_loss: 0.8719 - val_accuracy: 0.5877\n",
      "Epoch 1170/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7226 - accuracy: 0.6810 - val_loss: 0.8769 - val_accuracy: 0.5860\n",
      "Epoch 1171/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7229 - accuracy: 0.6834 - val_loss: 0.8715 - val_accuracy: 0.5900\n",
      "Epoch 1172/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7222 - accuracy: 0.6818 - val_loss: 0.8716 - val_accuracy: 0.5880\n",
      "Epoch 1173/1200\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.7225 - accuracy: 0.6835 - val_loss: 0.8722 - val_accuracy: 0.5847\n",
      "Epoch 1174/1200\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.7225 - accuracy: 0.6814 - val_loss: 0.8721 - val_accuracy: 0.5900\n",
      "Epoch 1175/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7229 - accuracy: 0.6815 - val_loss: 0.8729 - val_accuracy: 0.5860\n",
      "Epoch 1176/1200\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.7207 - accuracy: 0.6836 - val_loss: 0.8780 - val_accuracy: 0.5850\n",
      "Epoch 1177/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7215 - accuracy: 0.6826 - val_loss: 0.8781 - val_accuracy: 0.5910\n",
      "Epoch 1178/1200\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.7209 - accuracy: 0.6842 - val_loss: 0.8731 - val_accuracy: 0.5880\n",
      "Epoch 1179/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7200 - accuracy: 0.6851 - val_loss: 0.8744 - val_accuracy: 0.5940\n",
      "Epoch 1180/1200\n",
      "14000/14000 [==============================] - 1s 56us/step - loss: 0.7203 - accuracy: 0.6819 - val_loss: 0.8745 - val_accuracy: 0.5863\n",
      "Epoch 1181/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7195 - accuracy: 0.6829 - val_loss: 0.8756 - val_accuracy: 0.5953\n",
      "Epoch 1182/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7193 - accuracy: 0.6843 - val_loss: 0.8827 - val_accuracy: 0.5847\n",
      "Epoch 1183/1200\n",
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7190 - accuracy: 0.6840 - val_loss: 0.8770 - val_accuracy: 0.5897\n",
      "Epoch 1184/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7182 - accuracy: 0.6854 - val_loss: 0.8767 - val_accuracy: 0.5840\n",
      "Epoch 1185/1200\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.7178 - accuracy: 0.6872 - val_loss: 0.8748 - val_accuracy: 0.5880\n",
      "Epoch 1186/1200\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.7186 - accuracy: 0.6842 - val_loss: 0.8766 - val_accuracy: 0.5867\n",
      "Epoch 1187/1200\n",
      "14000/14000 [==============================] - 1s 54us/step - loss: 0.7183 - accuracy: 0.6859 - val_loss: 0.8762 - val_accuracy: 0.5933\n",
      "Epoch 1188/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 55us/step - loss: 0.7179 - accuracy: 0.6841 - val_loss: 0.8750 - val_accuracy: 0.5903\n",
      "Epoch 1189/1200\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.7172 - accuracy: 0.6861 - val_loss: 0.8757 - val_accuracy: 0.5887\n",
      "Epoch 1190/1200\n",
      "14000/14000 [==============================] - 3s 193us/step - loss: 0.7172 - accuracy: 0.6836 - val_loss: 0.8762 - val_accuracy: 0.5940\n",
      "Epoch 1191/1200\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.7163 - accuracy: 0.6879 - val_loss: 0.8801 - val_accuracy: 0.5867\n",
      "Epoch 1192/1200\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.7155 - accuracy: 0.6867 - val_loss: 0.8758 - val_accuracy: 0.5903\n",
      "Epoch 1193/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7158 - accuracy: 0.6863 - val_loss: 0.8785 - val_accuracy: 0.5900\n",
      "Epoch 1194/1200\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.7153 - accuracy: 0.6866 - val_loss: 0.8904 - val_accuracy: 0.5823\n",
      "Epoch 1195/1200\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.7153 - accuracy: 0.6848 - val_loss: 0.8781 - val_accuracy: 0.5860\n",
      "Epoch 1196/1200\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.7146 - accuracy: 0.6879 - val_loss: 0.8782 - val_accuracy: 0.5840\n",
      "Epoch 1197/1200\n",
      "14000/14000 [==============================] - 1s 77us/step - loss: 0.7137 - accuracy: 0.6882 - val_loss: 0.8795 - val_accuracy: 0.5870\n",
      "Epoch 1198/1200\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.7144 - accuracy: 0.6864 - val_loss: 0.8790 - val_accuracy: 0.5903\n",
      "Epoch 1199/1200\n",
      "14000/14000 [==============================] - 1s 107us/step - loss: 0.7131 - accuracy: 0.6881 - val_loss: 0.8783 - val_accuracy: 0.5873\n",
      "Epoch 1200/1200\n",
      "14000/14000 [==============================] - 2s 173us/step - loss: 0.7127 - accuracy: 0.6858 - val_loss: 0.8815 - val_accuracy: 0.5883\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "analysis = model.fit(X_train, y_train, batch_size=batch_size,epochs=1200,verbose=1,validation_data=(X_valid, y_valid))\n",
    "trainTime = (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.367565580209096  minutes\n"
     ]
    }
   ],
   "source": [
    "print(trainTime/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7690514006614685\n",
      "Test accuracy: 0.6389999985694885\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])      # this is the categorical_crossentropy\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(np.round(y_pred),axis=1) # Choose the prediction with the highest probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_pred_one_hot = to_categorical(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score =  0.6100863922483809\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-Score = \", f1_score(y_test, y_pred_one_hot, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABsgAAAJOCAYAAAAam4IxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNXdx/HvScKObInWBVkULQgCQgQVXEFEH/cFRXBBkYrWqrVatyrVqlWrBTceqYpbFCk+uBV3bdWqlaCABRdcAFFUdgh7kt/zx29uZjKZSUISCJDP+/Wa18zc5dxz97nnN+ecYGYCAAAAAAAAAAAA6oqM2s4AAAAAAAAAAAAAsCURIAMAAAAAAAAAAECdQoAMAAAAAAAAAAAAdQoBMgAAAAAAAAAAANQpBMgAAAAAAAAAAABQpxAgAwAAAAAAAAAAQJ1CgAwAAADAFhVCyAwhFIQQ2tTktLUphNAhhGCbId3+IYS5Cd+/CCEcXJlpq7Csh0II11Z1fgAAAADYlmTVdgYAAAAAbN1CCAUJXxtLWi+pKPb9V2aWtynpmVmRpKY1PW1dYGa/rIl0QgjDJQ01s8MS0h5eE2kDAAAAwLaAABkAAACAcplZSYAqVkNpuJm9kW76EEKWmRVuibwBFeF4BAAAAJAKTSwCAAAAqJYQwp9CCM+EEJ4OIaySNDSEcGAI4cMQwvIQwsIQwj0hhHqx6bNCCBZCaBf7/mRs/MshhFUhhA9CCO03ddrY+KNDCF+GEFaEEO4NIfw7hHBumnxXJo+/CiF8FUJYFkK4J2HezBDCX0MIS0IIX0saWM72uT6EMCFp2P0hhLtjn4eHED6Lrc/Xsdpd6dJaEEI4LPa5cQjhiVjeZknqmWK538TSnRVCOD42fF9J90k6ONZ85eKEbTsqYf4LY+u+JITwXAhhl8psm03ZzlF+QghvhBCWhhB+DCFclbCcP8S2ycoQQn4IYddUzVmGEN6L9nNse74TW85SSdeHEPYKIbwdW5fFse3WPGH+trF1XBQbPyaE0DCW504J0+0SQlgTQshOt74AAAAAtg0EyAAAAADUhJMkPSWpuaRnJBVKulRSjqQ+8gDSr8qZ/0xJf5DUStJ8STdv6rQhhJ0kTZR0ZWy530rqVU46lcnjMfLA037ywF//2PCRkgZI6hZbxqBylvOUpGNDCE1i+cySdFpsuCT9JOl/JDWTdIGke0MIXctJL3KTpN0l7RHL5zlJ47+MrVdzSbdIeiqE8Asz+1TSryW9a2ZNzSwnOeEQwoBY+qdK2k3SD5KSm9JMt22Spd3OsSDVG5JelLSLpL0l/TM235Wx5Q+U1ELScEnrytsgCQ6S9JmkHSXdLilI+lNsGfvIt9kfYnnIkvQPSV9JaiffphPNbJ38eBqakO6Zkl41syWVzAcAAACArRQBMgAAAAA14T0ze9HMis1srZlNNbP/mFmhmX0jaZykQ8uZf5KZ5ZvZRnkgpnsVpj1W0nQzez427q+SFqdLpJJ5vM3MVpjZXHngJlrWIEl/NbMFsWDJn8tZzjeS/ivphNigIyUtN7P82PgXzewbc29JelPSweWsf2SQpD+Z2TIzmyevFZa43IlmtjC2T56SNFdSbiXSlaQhkh4ys+mxQNHVkg4NIbROmCbdtimlgu18vKTvzGyMma03s5Vm9lFs3HBJ15rZnNg6TDezpZXM/3wzG2tmRbHj8Usze9PMNpjZz/JjI8rDgfLg3e/NbHVs+n/Hxj0m6cwQQoh9P0vSE5XMAwAAAICtGAEyAAAAADXhu8QvIYSOIYR/xJrMWymvjVSmplKCHxM+r5HUNN2E5Uy7a2I+zMwkLUiXSCXzWKllSZpXTn4lry02OPb5TCXUxgohHBtC+E+sicHl8ppp5W2ryC7l5SGEcG4IYUasmcDlkjpWMl3J168kPTNbKWmZvDZZpFL7rILtvLu85lYqu0v6upL5TZZ8PO4cQpgYQvg+lodHk/Iw18yKkhOJBcoKJfUNIXSR1EZe2wwAAADANo4AGQAAAICaYEnfH5TXmupgZs0k3SBv5m5zWiippIZTrNbPbuknr1YeF8oDK5E2FUz/jKT+sRpYJyjWvGIIoZGkSZJuk/QLM2sh6bVK5uPHdHkIIewhaay8KcjsWLqfJ6SbvL+S/SCpbUJ6O0hqKen7SuQrWXnb+TtJe6aZL9241bE8NU4YtnPSNMnrd7uk9ZL2jeXh3KQ8tA0hZKbJx+PyZhbPkje9uD7NdAAAAAC2IQTIAAAAAGwOO0haIWl1CKGTyu9/rKa8JKlHCOG4WL9Sl8r7oNoceZwo6bIQwm4hhGxJvy9vYjP7SdJ7ksZL+sLM5sRGNZBUX9IiSUUhhGMl9duEPFwbQmgRQmgj71cs0lQeJFokjxUOl9cgi/wkqXUIoV6atJ+WdH4IoWsIoYE8gPeumaWtkVeO8rbzC5LahBB+HUKoH0JoFkKI+o17SNKfQgh7Btc9hNBKHhj8Ud7vWWYIYYQSgnnl5GG1pBUhhN0l/S5h3AeSlki6NYTQOITQKITQJ2H8E/K+0M6UB8sAAAAAbAcIkAEAAADYHK6QdI6kVfIaRM9s7gXGglCnS7pbHvDYU9In8ppDNZ3HsfK+wj6VNFVeC6wiT0nqH3uP8rxc0uWSJktaKg/EvFTJPNwor8k2V9LLSgjemNlMSfdI+ig2TUdJ/0mY93VJcyT9FEJIbCoxmv8VeVOIk2Pzt5H3S1YVabezma2Q98l2iqSfJX2peN9gd0p6Tr6dV8r7LmsYazrzAknXyvuY65C0bqncKKmXPFD3gqRnE/JQKO+/rpO8Ntl8+X6Ixs+V7+cNZvb+Jq47AAAAgK1U8GcLAAAAANi+xJrM+0HSqWb2bm3nB9uuEMLjkr4xs1G1nRcAAAAANSOrtjMAAAAAADUlhDBQ3mTeOknXSCqU16ICqiTWn9sJkvat7bwAAAAAqDnVamIxhDAwhPBFCOGrEMLVKca3CSG8HUL4JIQwM4RwTMK4a2LzfRFCOKo6+QAAAACAmL6SvpE3vTdQ0olmlq6JRaBcIYTbJM2QdKuZza/t/AAAAACoOVVuYjHWXMmX8vbiF8jb3R9sZrMTphkn6RMzGxtC2EfSFDNrF/v8tLwN+F0lvSFpbzMrqtbaAAAAAAAAAAAAABWoTg2yXpK+MrNvzGyDpAnyZicSmaRmsc/N5e3/KzbdBDNbb2bfSvoqlh4AAAAAAAAAAACwWVWnD7LdJH2X8H2BpN5J04yS9FoI4RJJTST1T5j3w6R5d0u1kBDCCEkjJKlJkyY9O3bsWI0sAwAAAAAAAAAAYFs0bdq0xWa2Y02kVZ0AWUgxLLm9xsGSHjWzu0IIB0p6IoTQpZLz+kCzcZLGSVJubq7l5+dXI8sAAAAAAAAAAADYFoUQ5tVUWtUJkC2QtHvC99aKN6EYOV/eMbbM7IMQQkNJOZWcFwAAAAAAAAAAAKhx1emDbKqkvUII7UMI9SWdIemFpGnmS+onSSGETpIaSloUm+6MEEKDEEJ7SXtJ+qgaeQEAAAAAAAAAAAAqpco1yMysMITwa0mvSsqU9IiZzQoh3CQp38xekHSFpL+FEC6XN6F4rpmZpFkhhImSZksqlHSxmRVVd2UAAAAAAAAAAACAigSPV20b6IMMAAAAAAAAAIDtx8aNG7VgwQKtW7eutrOCrUjDhg3VunVr1atXr9TwEMI0M8utiWVUpw8yAAAAAAAAAACAKluwYIF22GEHtWvXTiGE2s4OtgJmpiVLlmjBggVq3779ZltOdfogAwAAAAAAAAAAqLJ169YpOzub4BhKhBCUnZ292WsVEiADAAAAAAAAAAC1huAYkm2JY4IAGQAAAAAAAAAAAOoUAmQAAAAAAAAAAKBOWrJkibp3767u3btr55131m677VbyfcOGDZVKY9iwYfriiy/Kneb+++9XXl5eTWQZNSSrtjMAAAAAAAAAAABQGXl50nXXSfPnS23aSLfcIg0ZUvX0srOzNX36dEnSqFGj1LRpU/3ud78rNY2ZycyUkZG6ztH48eMrXM7FF19c9UzWksLCQmVlbb9hJGqQAQAAAAAAAACArV5enjRihDRvnmTm7yNG+PCa9tVXX6lLly668MIL1aNHDy1cuFAjRoxQbm6uOnfurJtuuqlk2r59+2r69OkqLCxUixYtdPXVV6tbt2468MAD9fPPP0uSrr/+eo0ePbpk+quvvlq9evXSL3/5S73//vuSpNWrV+uUU05Rt27dNHjwYOXm5pYE7xLdeOON2n///UvyZ2aSpC+//FJHHHGEunXrph49emju3LmSpFtvvVX77ruvunXrpuuuu65UniXpxx9/VIcOHSRJDz30kM444wwde+yxOvroo7Vy5UodccQR6tGjh7p27aqXXnqpJB/jx49X165d1a1bNw0bNkzLly/XHnvsocLCQknS8uXL1b59exUVFdXYfqlJBMgAAAAAAAAAAMBW77rrpDVrSg9bs8aHbw6zZ8/W+eefr08++US77bab/vznPys/P18zZszQ66+/rtmzZ5eZZ8WKFTr00EM1Y8YMHXjggXrkkUdSpm1m+uijj3TnnXeWBNvuvfde7bzzzpoxY4auvvpqffLJJynnvfTSSzV16lR9+umnWrFihV555RVJ0uDBg3X55ZdrxowZev/997XTTjvpxRdf1Msvv6yPPvpIM2bM0BVXXFHhen/wwQd64okn9Prrr6tRo0Z6/vnn9fHHH+uNN97Q5ZdfLkmaMWOGbr/9dv3zn//UjBkzdNddd6lFixbq06dPSX6eeuopDRo0SJmZmRVv7FpAgAwAAAAAAAAAAGz15s/ftOHVteeee2r//fcv+f7000+rR48e6tGjhz777LOUAbJGjRrp6KOPliT17NmzpBZXspNPPrnMNO+9957OOOMMSVK3bt3UuXPnlPO++eab6tWrl7p166Z//etfmjVrlpYtW6bFixfruOOOkyQ1bNhQjRs31htvvKHzzjtPjRo1kiS1atWqwvUeMGCAWrZsKckDeb///e/VtWtXDRgwQN99950WL16st956S6effnpJetH78OHDS5qcHD9+vIYNG1bh8moLATIAAAAAAAAAALDVa9Nm04ZXV5MmTUo+z5kzR2PGjNFbb72lmTNnauDAgVq3bl2ZeerXr1/yOTMzs6S5wWQNGjQoM03UVGJ51qxZo1//+teaPHmyZs6cqfPOO68kHyGEMtObWcrhWVlZKi4ulqQy65G43o8//rhWrFihjz/+WNOnT1dOTo7WrVuXNt1DDz1UX375pd5++23Vq1dPHTt2rHCdagsBMgAAAAAAAAAAsNW75RapcePSwxo39uGb28qVK7XDDjuoWbNmWrhwoV599dUaX0bfvn01ceJESdKnn36asoba2rVrlZGRoZycHK1atUrPPvusJKlly5bKycnRiy++KMmDXmvWrNGAAQP08MMPa+3atZKkpUuXSpLatWunadOmSZImTZqUNk8rVqzQTjvtpKysLL3++uv6/vvvJUn9+/fXhAkTStKL3iVp6NChGjJkyFZde0wiQAYAAAAAAAAAALYBQ4ZI48ZJbdtKIfj7uHE+fHPr0aOH9tlnH3Xp0kUXXHCB+vTpU+PLuOSSS/T999+ra9euuuuuu9SlSxc1b9681DTZ2dk655xz1KVLF5100knq3bt3ybi8vDzddddd6tq1q/r27atFixbp2GOP1cCBA5Wbm6vu3bvrr3/9qyTpyiuv1JgxY3TQQQdp2bJlafN01lln6f3331dubq7+/ve/a6+99pIkde3aVVdddZUOOeQQde/eXVdeeWXJPEOGDNGKFSt0+umn1+TmqXGhMlX2tha5ubmWn59f29kAAAAAAAAAAAA14LPPPlOnTp1qOxtbhcLCQhUWFqphw4aaM2eOBgwYoDlz5igrK6u2s7ZJJkyYoFdffbWkL7KqSnVshBCmmVlutRKO2ba2KgAAAAAAAAAAwHaooKBA/fr1U2FhocxMDz744DYXHBs5cqTeeOMNvfLKK7WdlQptW1sWAAAAAAAAAABgO9SiRYuSfsG2VWPHjq3tLFQafZABAAAAAAAAAACgTiFABgAAAAAAAAAAgDqFABkAAAAAAAAAAADqFAJkAAAAAAAAAAAAqFMIkAEAAAAAAAAAgDrpsMMO06uvvlpq2OjRo3XRRReVO1/Tpk0lST/88INOPfXUtGnn5+eXm87o0aO1Zs2aku/HHHOMli9fXpmso5oIkAEAAAAAAAAAgDpp8ODBmjBhQqlhEyZM0ODBgys1/6677qpJkyZVefnJAbIpU6aoRYsWVU5vSzMzFRcX13Y2qoQAGQAAAAAAAAAAqJNOPfVUvfTSS1q/fr0kae7cufrhhx/Ut29fFRQUqF+/furRo4f23XdfPf/882Xmnzt3rrp06SJJWrt2rc444wx17dpVp59+utauXVsy3ciRI5Wbm6vOnTvrxhtvlCTdc889+uGHH3T44Yfr8MMPlyS1a9dOixcvliTdfffd6tKli7p06aLRo0eXLK9Tp0664IIL1LlzZw0YMKDUciIvvviievfurf3220/9+/fXTz/9JEkqKCjQsGHDtO+++6pr16569tlnJUmvvPKKevTooW7duqlfv36SpFGjRukvf/lLSZpdunTR3LlzS/Jw0UUXqUePHvruu+9Srp8kTZ06VQcddJC6deumXr16adWqVTr44IM1ffr0kmn69OmjmTNnbtJ+qwlZ1Zk5hDBQ0hhJmZIeMrM/J43/q6TDY18bS9rJzFrExhVJ+jQ2br6ZHV+dvAAAAAAAAAAAgG3XZZdJCXGTGtG9uxSLLaWUnZ2tXr166ZVXXtEJJ5ygCRMm6PTTT1cIQQ0bNtTkyZPVrFkzLV68WAcccICOP/54hRBSpjV27Fg1btxYM2fO1MyZM9WjR4+ScbfccotatWqloqIi9evXTzNnztRvfvMb3X333Xr77beVk5NTKq1p06Zp/Pjx+s9//iMzU+/evXXooYeqZcuWmjNnjp5++mn97W9/06BBg/Tss89q6NChpebv27evPvzwQ4UQ9NBDD+mOO+7QXXfdpZtvvlnNmzfXp596eGbZsmVatGiRLrjgAr3zzjtq3769li5dWuF2/eKLLzR+/Hg98MADadevY8eOOv300/XMM89o//3318qVK9WoUSMNHz5cjz76qEaPHq0vv/xS69evV9euXStcZk2rcg2yEEKmpPslHS1pH0mDQwj7JE5jZpebWXcz6y7pXkn/lzB6bTSO4BgAAAAAAAAAAKgNic0sJjavaGa69tpr1bVrV/Xv31/ff/99SU2sVN55552SQFXXrl1LBX0mTpyoHj16aL/99tOsWbM0e/bscvP03nvv6aSTTlKTJk3UtGlTnXzyyXr33XclSe3bt1f37t0lST179tTcuXPLzL9gwQIdddRR2nfffXXnnXdq1qxZkqQ33nhDF198ccl0LVu21IcffqhDDjlE7du3lyS1atWq3LxJUtu2bXXAAQeUu35ffPGFdtllF+2///6SpGbNmikrK0unnXaaXnrpJW3cuFGPPPKIzj333AqXtzlUpwZZL0lfmdk3khRCmCDpBEnp9upgSTemGQcAAAAAAAAAAOqw8mp6bU4nnniifvvb3+rjjz/W2rVrS2p+5eXladGiRZo2bZrq1aundu3aad26deWmlap22bfffqu//OUvmjp1qlq2bKlzzz23wnTMLO24Bg0alHzOzMxM2cTiJZdcot/+9rc6/vjj9c9//lOjRo0qSTc5j6mGSVJWVlap/sUS89ykSZMK1y9duo0bN9aRRx6p559/XhMnTlR+fn7add2cqtMH2W6Svkv4viA2rIwQQltJ7SW9lTC4YQghP4TwYQjhxHQLCSGMiE2Xv2jRompkFwAAAAAAAAAAoLSmTZvqsMMO03nnnVdSe0ySVqxYoZ122kn16tXT22+/rXnz5pWbziGHHKK8vDxJ0n//+9+SfrVWrlypJk2aqHnz5vrpp5/08ssvl8yzww47aNWqVSnTeu6557RmzRqtXr1akydP1sEHH1zpdVqxYoV2281DNo899ljJ8AEDBui+++4r+b5s2TIdeOCB+te//qVvv/1WkkqaWGzXrp0+/vhjSdLHH39cMj5ZuvXr2LGjfvjhB02dOlWStGrVKhUWFkqShg8frt/85jfaf//9K1VjbXOoToAsVSOb6UKaZ0iaZGZFCcPamFmupDMljQ4h7JlqRjMbZ2a5Zpa74447ViO7AAAAAAAAAAAAZQ0ePFgzZszQGWecUTJsyJAhys/PV25urvLy8tSxY8dy0xg5cqQKCgrUtWtX3XHHHerVq5ckqVu3btpvv/3UuXNnnXfeeerTp0/JPCNGjNDRRx+tww8/vFRaPXr00LnnnqtevXqpd+/eGj58uPbbb79Kr8+oUaN02mmn6eCDDy7Vv9n111+vZcuWqUuXLurWrZvefvtt7bjjjho3bpxOPvlkdevWTaeffrok6ZRTTtHSpUvVvXt3jR07VnvvvXfKZaVbv/r16+uZZ57RJZdcom7duunII48sqYXWs2dPNWvWTMOGDav0OtW0UF41vXJnDOFASaPM7KjY92skycxuSzHtJ5IuNrP306T1qKSXzGxSecvMzc212qpqBwAAAAAAAAAAatZnn32mTp061XY2sIX98MMPOuyww/T5558rIyN1Xa5Ux0YIYVqs8lW1VacG2VRJe4UQ2ocQ6strib2QPFEI4ZeSWkr6IGFYyxBCg9jnHEl9lL7vMgAAAAAAAAAAAGwHHn/8cfXu3Vu33HJL2uDYlpBV1RnNrDCE8GtJr0rKlPSImc0KIdwkKd/MomDZYEkTrHRVtU6SHgwhFMuDdH82MwJkAAAAAAAAAAAA27Gzzz5bZ599dm1no+oBMkkysymSpiQNuyHp+6gU870vad/qLBsAAAAAAAAAAGz7zEwhhNrOBrYiVe0ebFPUXt01AAAAAAAAAABQpzVs2FBLlizZIgERbBvMTEuWLFHDhg0363KqVYMMAAAAAAAAAACgqlq3bq0FCxZo0aJFtZ0VbEUaNmyo1q1bb9ZlECADAAAAAAAAAAC1ol69emrfvn1tZwN1EE0sAgAAAAAAAAAAoE4hQAYAAAAAAAAAAIA6hQAZAAAAAAAAAAAA6hQCZAAAAAAAAAAAAKhTCJABAAAAAAAAAACgTiFABgAAAAAAAAAAgDqFABkAAAAAAAAAAADqFAJkAAAAAAAAAAAAqFMIkAEAAAAAAAAAAKBOIUAGAAAAAAAAAACAOoUAGQAAAAAAAAAAAOoUAmQAAAAAAAAAAACoUwiQAQAAAAAAAAAAoE4hQAYAAAAAAAAAAIA6hQAZAAAAAAAAAAAA6hQCZAAAAAAAAAAAAKhTCJABAAAAAAAAAACgTiFABgAAAAAAAAAAgDqFABkAAAAAAAAAAADqlGoFyEIIA0MIX4QQvgohXJ1i/F9DCNNjry9DCMsTxp0TQpgTe51TnXwAAAAAAAAAAAAAlZVV1RlDCJmS7pd0pKQFkqaGEF4ws9nRNGZ2ecL0l0jaL/a5laQbJeVKMknTYvMuq2p+AAAAAAAAAAAAgMqoTg2yXpK+MrNvzGyDpAmSTihn+sGSno59PkrS62a2NBYUe13SwGrkBQAAAAAAAAAAAKiU6gTIdpP0XcL3BbFhZYQQ2kpqL+mtKsw7IoSQH0LIX7RoUTWyCwAAAAAAAAAAAFQvQBZSDLM0054haZKZFW3qvGY2zsxyzSx3xx13rEI2AQAAAAAAAAAAgLjqBMgWSNo94XtrST+kmfYMxZtX3NR5AQAAAAAAAAAAgBpTnQDZVEl7hRDahxDqy4NgLyRPFEL4paSWkj5IGPyqpAEhhJYhhJaSBsSGAQAAAAAAAAAAAJtVVlVnNLPCEMKv5YGtTEmPmNmsEMJNkvLNLAqWDZY0wcwsYd6lIYSb5UE2SbrJzJZWNS8AAAAAAAAAAABAZYWEuNVWLzc31/Lz82s7GwAAAAAAAAAAANjCQgjTzCy3JtKqThOLAAAAAAAAAAAAwDaHABkAAAAAAAAAAADqFAJkAAAAAAAAAAAAqFMIkAEAAAAAAAAAAKBOIUAGAAAAAAAAAACAOoUAGQAAAAAAAAAAAOoUAmQAAAAAAAAAAADY4vLypHbtpIwMKSfHXxkZPuyii+Lj2rXzaWsSATIAAAAAAAAAAABsFolBsMRAV16eNGKENG+eZCYtWeIvMx82dmx83Lx5Pq2U06qm8kWADAAAAAAAAAAAoI5KF8CqaJ6cHCmEsq+cnHjtrxCkoUNLB7qGDo0PX7Om8vn0aVvvXqWVTIEAGQAAAAAAAAAAwFaoKsGrTUkzJ0c677yyNbXy8soPgg0d6rW9UlmyJF77q+ZlZtVUSsHMaiqtzS43N9fy8/NrOxsAAAAAAAAAAACbVdQEYWItqxA8kNW2rXTLLdKQIaWnv+46af58qVWsIcIlS+LzSFKTJtLGjdKGDVtuPWpWrszyQ02kRA0yAAAAAAAAAACAWpKultill5ZtgjAKdCU2VRiC1KBB6aYMo/68EueRpNWrt+XgWM0iQAYAAAAAAAAAAFBFyU0RJvfBlZVV+j0jo2xzhan66ErXhGEqBL02HQEyAAAAAAAAAACw3UnuaysKYiUGqJKDWcnBq5yc1P1+RWmn6o8ruQ+uoqLS79tQz1e1IoTS76VZcU0thwAZAAAAAAAAAADYKqRrbjDV+CjolWraqP+uipocTA5mJQevliwp3ZRhcq0vVF5mpr+nDny57GzpiSd8PxQXS08+6f2theDv0vwa2+oEyAAAAAAAAAAAQI2rKNiVavrEoNa8edJZZ0n9+8dra511VtmgV3LThNF0yf13oeZkxKJLbdt6EMvMX08+6UGuSHZ2fHxhYTzwFU2bGPx68klp8WJpyJD4/EOGSHPn+jxz50rS4qU1tQ7BtqG6fLm5uZafn1/b2QAAAAAAAAAAoE7Ky5Ouu84DUiHEa1xlZ0tjxsSDGxddJP3v/6ZuTrBJE39fvXrL5BmVk7xfMjI8MNW2rXTLLaUDV7UlhDDNzHJrIi1qkAEAAAAAAAAAsJ2oTBOEeXnx/riS+9lKnr9p0/RNCyY3VZhYg2sE1gZcAAAgAElEQVTs2PR9ba1eTXBsc4v2W1QzK6qtJcWbOkyu/VVQ4K/oe1GRv8+du3UEx2oaNcgAAAAAAAAAAKhlUc2s+fOlNm0qV2MneZ4OHaS33kofmMLWKaqplZ0trVolbdhQenzjxtI550hTpqQ+Pqpy7GyrqEEGAAAAAAAAAMAWVl6fWqnGRcNCkLKy/L1dO29+MLEGV4MG8ZpZyf1pNW1athZXcm2uaJ433yQ4trXJzpZGjizb11ZUSyuxptbixdL69WX75ho3TnrggdJ9cZXXT9f2GhyradQgAwAAAAAAAADUSalq3kiph116qTcjmKxBAw9+0WTgtiHqT0uK96WWmelBquS+tvLy0u93yfvsathQWrrUj5Vjjklfyws1oyZrkBEgAwAAAAAAAABs8yrTzFw0zbx5XjtnGyoeRzWEIF14odfCwrZtq2liMYQwMITwRQjhqxDC1WmmGRRCmB1CmBVCeCpheFEIYXrs9UJ18gEAAAAAAAAA2DqU1wxhZaZN1SxhTo6/0jVtmJOTuonCjIzS6UTTSATHtrQGDSo3XUYsatG2rTdNmJ0dH9ekiX9PbKowuTnCVMOeeILgGMqqcg2yEEKmpC8lHSlpgaSpkgab2eyEafaSNFHSEWa2LISwk5n9HBtXYGZNN2WZ1CADAAAAAAAAgOqrTG2rxGmTm5nLyPD+jqLgRWITc489Jq1Zs/nXAbUj2vepmipMrJWXPF1is4WVPfaAZFtFE4shhAMljTKzo2Lfr5EkM7stYZo7JH1pZg+lmJ8AGQAAAAAAAABUQbogQ2WbGRwxonQQKwTpiCOkr77yeVu1ktato1+tbV3Tpr4PGzcuuy+jZgf79CkbAE3uW4sgFrYWW0sTi7tJ+i7h+4LYsER7S9o7hPDvEMKHIYSBCeMahhDyY8NPTLeQEMKI2HT5ixYtqkZ2AQAAAAAAAKDmbUqTgunmDSHeHGD0ysyMNy/YtGnpcamaEyxvePK8yTW8zKQ334zPu2QJwbHatKnNEWZmln6PmhpctcprcRUUpG92cMgQafFi3+/Rq6DAhxUXS3PnEhzD9qk6AbKQYlhydbQsSXtJOkzSYEkPhRBaxMa1iUX5zpQ0OoSwZ6qFmNk4M8s1s9wdd9yxGtkFAAAAAAAAsD0qrx+r5KBV8vCLLqr8dDk5qYNX551XcVAqejVtWjrYVV6fWMXF/k6watuSGNwqrz+t7Oz0fWitW+fHQ6pxiYGsoiJ/Lyws/Z4qqDVkiA8n6AW4zd3E4v9K+tDMHo19f1PS1WY2NSmtRyW9ZGaTylsmTSwCAAAAAAAA25bkJv+OOUaaMiXejJ/kAaDMTC/sT+zXKLHZt8Qm32j+D1tCgwbS+vVlhzduLI0bV/kmLQHUnK2licWpkvYKIbQPIdSXdIakF5KmeU7S4ZIUQsiRN7n4TQihZQihQcLwPpJmVyMvAAAAAAAAwFarJprgy8jw2ko5ORXXfkqVRrraT9HwrKyyw5Kb/GvaNP24dK/kJv/Gji3djF8UACsq8veoBtbQoaX7RFq92r/T/B8qUpnmCaMaXVHtrOxsf1WmFlcUHJOolQVsy6pcg0ySQgjHSBotKVPSI2Z2SwjhJkn5ZvZCCCFIukvSQElFkm4xswkhhIMkPSipWB6kG21mD1e0PGqQAQAAAAAA1G2bu7ZGReknjo9qPy1dGq8ZNXFi2RpPiUGeysjI8ML2tm2lDh2kt94q2/QeUNeE4OdBdnbZ2oOJ50x55yw1vIBtX03WIKtWgGxLI0AGAAAAAACwbdiUQFNlC63z8qQRI6Q1a1KPT2yCL0pTKhvQWrIkXtgezSdRIwkoT3a2NGZM/DxNDhYnBq3KC1glKu86QGALQCoEyAAAAAAAALDFbGqw65hjpMceKxvIatDAm+grr0ZV1A9VYgALwKZJrL1Y3rmUnS0NGuR9ws2bFz//kvuDIzAFYGuxtfRBBgAAAAAAgK1Iqn6uomGJfUyl6qsquZ+rpk3T9yE1dKi0ww7l9zGVqpbX+vUVNzcY9UNFcAzbshA2fdqo3yuz+Cu576tofLrh0augQFq82D8XF5cel/havFh64AHvO8tMKiws/U6fWgC2Z9QgAwAAAAAAqGFRjarEGhlRTQwp9bjk/qsS0QQgUDlRbalNaUIzag6wSZPU0zRo4MFdqXQzg3l50qWXxs/Z5CYIU6HZQACoHppYBAAAAAAAdV5y/zeS9z2V7nPU9N+UKWXnSR4XfU8MWEWF6NnZpfvaAVCx5CBVYn9xyeds4vmV2ARgZc7bigJOm6NvPADAlkOADAAAAAAA1KpUfU6lK6ROrmVRnsr2mwPAVTZwG02XXJMxMeiU6rxr3FgaNy5eY4rgEQCgNtEHGQAAAAAAdUSqPqWi4Tk58T6gMjPjfUtddFHlx1X0iuatqE+qsWPL9lGVOG1lgmOSF+5H0xIcQ21p0iRe4ylZRqw0LTPT37Oz/ZU4rG1baeTIsn1EVdRvVGK/U1Ga0TLSzV9UFO9LqqAgfV9T0XRRn1JDhvjn4mKfN+qv6oknSi8jCo5JpeehbyoAwLaOGmQAAAAAgDqhvBpPyU12RbUiNmWe5Ob4kpsTi/qmkSpfmwqoC6J+2DZFcl9PqZrbTK4NldikX3SeS9SIAgBgW0ITiwAAAACALaammtRKbmYvsYA7eVxiM3tR4XnbtmWDUInK69+mcWP6iwKqI2qeb1ObvQxBuvBC6YEH6PsJAABUH00sAgAAAEAdk66Zvc01fzR9qqb0RozwZvqi9HJy4k32ZWSkb6ovuZm9JUvizfAlj0tsZi+qWRI145eu5tXq1aWDYFEaZgTHULckNw8YNQkYNfuX2HRfouSmAxObAIya5ysuLr+ZwORxTzzhwTGp4ub5aL4PAABsSdQgAwAAAIAK1GQNquR0pMo1C7Zxo7RhQzytevWkZs3KNhWW3HRfVWt9AKgZ2dnSoEHeNOe8eaXPxeRxibUlE68z1KwCAABwNLEIAAAAYKuxtRTcpup/JrFvqFSF0+U1yZcuWAVg65OqSc6ollR0Pq9bl/5cTzUuuXlP+qsCAACofQTIAAAAAGxSYCpd8Ki8QuPEwFK0jMTvyfMmigJK2dnpp5HKr1mRHLxKFtWMys6WVq0qXbsKwJaRKpgUvSeez9H5mlwzKtnWEnAHAADA1okAGQAAALAFRQW2FTWNVZnC4Ly89E3gtW1b+QBUOk2bSgUF1HgCtieJweDka0J2tjRmjF9jkq8vlR1XEYJWAAAA2FoQIAMAAMB2o6q1oJL7b0oOUAFAOhU1rZkchNqU6aPAk1T6enXMMdLEiVULUAEAAABwBMgAAABQa8prqk9K3cxW1A9MRU1wAag76tWT6tePB5bS1aSsTHCpouB5cj9SBKUAAACAbRMBMgAAgDosuZms5JoMUun+oxILlQGgspKbCZVS19ZM7rcuXQCKZvoAAAAAVFdNBsgyaiIRAACA7UFentSunRcKt2vn3ys7X06OFxiH4DUVQvA0Lrqo9LiaeA0dWjrgtXq1fzfz9+jzvHnS2LEEx4CaFELp96po0iReqzIxnWh4CB6UevJJf7Vt6+MzM/09Ozve5F80X+L37Gyfz8xfURqJ6UbjynsVFfn73LkeyBoyxD+beeAsmq6gQFq82IdF06YSzV/RdAAAAACwJVCDDAAAbFabWmOgvGayEpvaSmx6K11TWlEBNLWpgC2jQQNp/frazkXl+ocaMqTs9Sbx2pKqyVCa5wMAAACA2kUTiwAAoFZEhcmJQahUfUxVtk+pqMZDVHBdv760YcPmyTuwPYqawKvMORdNm6o/uFRN6KU6xxMDTRU1q1dRcDzV9SQ5HxUF1mmyDwAAAADqFgJkAABAUukC5uT+YKR4QXZ5EgvNEwu/AZSVXPsosS+4xHFS2fHp0ommTReYqmytJYJFAAAAAIDtHQEyAABqQXlNcW1K832bErwCUFZUcym5tmJy0AkAAAAAAGxfajJAllETiQAAUF15eVK7dl7YnZXl7+3a+fBU02VkSDk5UtOmPm3yq2nT9OOq+ho61Gt3mPn72LFlv1emb6vVqwmOYduWEfsFmZnp79nZ/gqh9Oe2baWRI/29onFt20pPPunnU0WvggJp8WL/XFwcH754McExAAAAAABQOdUKkIUQBoYQvgghfBVCuDrNNINCCLNDCLNCCE8lDD8nhDAn9jqnOvkAANS8xEBUcqAqOUiVk+MF3BkZ1Q8+Sd6kmOTfhw5NH6RasiR9oIkgFLZnUYAqXQBKigevovdNCUBV9Coq8vfCwnhgavFiD1Ylfp47V3rgAX+vaNzcuQS3thX5+dKnn9Z2LoDyrV0r/fBDbedi27UNNTQDYDtXXCy9+KI3Bb89SXedLe/6u3ix9Pjj/mexRG+/7a0olKew0LfjZ59tWj4rm7fy5nn2WalPH+mcc6SPP6768muKmW+vKVPST/Pjj+WPT+Xnn307A9i2VDlAFkLIlHS/pKMl7SNpcAhhn6Rp9pJ0jaQ+ZtZZ0mWx4a0k3Sipt6Rekm4MIbSsal4AYFtXXu2pVOOqE4iqam2pxEBVcpAqqjVFYQq2dck1o0LYtPmiINSTT/rnxLQ2R4AqXQAqMXgVvROAqj0ffCCdcoq0bFlt56T6Cgul446TTjgh/meGqrr3Xu+jbXMrKpJeeMEDJjVt+fLNU2BXWCj99FPlpq3L997ly6XZs1Pv29NP999PY8Zs+jbauFH66iv/XFQU/wNPeVav9vxUxeLF0oQJfp1OZUvv488/l3bcUerXT3r0UWnaNM9DeUHHwkIvTJQ8gL6lg+grVkgvv1z1wltJWrPG00lUXCxNniwtXVr9PNakKVOkk08um99Eib8bUo2T/Lh96aWy1/Mff4z/vl+wQFq/vmbyvbWJCu5nzNg6r6WFhX4t+v771OM//1yaObP6y3nxRb8fjx3r97SCgvLPp6Ii6bnnPBiQyvz5fh2trB9/lB57zO/VgwdLw4eXvrfecYd0/PHSrbf6teWkk+LXm2Rr1vg2mTRJevddHzZt2qZdkxYv9mbzk9fv/POlgw7a9GPFTPrvfz3NoiJp4ULpggukHXaQ/vCH0ulddZXUurWfly++KN1/v69LcbFvo9139yDTsGHx+ZYtk844Q7r8cv/tYObLeOcd6aGHPM0TT/R74vHH+zYuLpb++Efp8MP9Wj9mTDyws3atdPTR0sCB0m23+TaVpBtvlDp1Kvsn1C+/9On33DM+LvHac8890qmn+vZ84YWyvyGLi6Xnn69cSyxVtWaNdNNN0tdf+/fRo6XLLvNj6b33yk5fVOTjjj3Wj4fKmD9f6tDBy0qwZSxdKm3YUNu5wHbBzKr0knSgpFcTvl8j6Zqkae6QNDzFvIMlPZjw/UFJgytaZs+ePQ0AatuTT5plZ8cfOZs08VfNFHvz4sUr8dWgQfxz8rnWpEn8XAwhPjw722zkSLO2bX14dnbp+Vq0MHv88dq+kmBLKy42W7jQrKio9PDvvjObMMHsgw/MZswwmzu37DTFxWbvv2/23//653vvNcvLM9uwoeLlbtxo1rmzH3sjR9bc+pRnxgyza681e+stz++iRWZ//KPZjz9WPc2NG82WLTP7xz/i59Lf/1719L79Nn5+f/KJD/vpJ7PXXvM8r1ljtnx55dNbtcrshhvMXn7Z54+sWWN24okVb/+CAk8jMb0ZM8zy8309P/us7Dw//mi2665mPXqYrV3rw4qLzSZONDv6aLNZs0pPv2aN2dKl/nnx4vg8ydauNevf37fPv//tw777zvfh0qVmCxaYvf22WWGhr9uxx/r+iUybZrbbbma7727Wr5/ZZZeZTZ/ux/BDD5mNHWt21VVmf/6zp/PUU2ZTpphNmmT229+a3X67T/enP5kddZR///JLs/vuMzvuOLPLL/d8LF3qaQ8f7utm5ut8ww1mn3/uaf/rX2arV5v95S9mf/iDjxswwNP6/HOzRx/1ZT30kNlFF/n2/N3vzK67zmznnT3PkU8/NbvlFrOrr/a8HXqoWWam79uMDLM+fcxGjDD7/e/9Gi+Z7bGHvx90kNkxx5j94hdmH31kdtttPq5hQ7NDDjE7/niz3Fyznj19f7Zo4fONH2924YX++bDDyu7Tn382e+EFv2506GC2yy6+rxKtXOnXjFNO8XwMHuzXGzM/xu+8M748yey008xmz/bjaNYs3x477mj2xBOl0y0u9m3y3HO+/YuLzSZPNvuf/zG76y6zFSt82Cuv+PZ97TW/ti1c6MP+/nfP/4IFfjxGVq8269LFrFUrP46ifHXubJaT48flxx+bjRrlx0thoc83fLhZVpbvg/r1/d67aFE83Y8/9v17zTWlj9c33jC74w6z778vvX4bN5rdfLPZsGHxc2XJktLn+D//6ft12jQ/5ySz66+3lL74wo/BOXNKD7/9drO99vJtve++nscFC3zcmjW+PySz1q19eZXxzTdmL77o+yCV99/3fF9+ua//qlU+T7QtIy+9ZHbEEWZnnWV2003x82HOHLMddvB8nXqqb4/iYr+uRtexjz7y410ya9rUbO+9/f34483+9jeznXby5R9+uE/zxz/6cXzDDX4OSL4fe/f2z8ceG783Fhf79ho/3mzcOJ/n3nt9/NSpfp5eeqnZ6NF+XZ8zx4/LU0/17f2f//i6XHihD7/vPr8GV6Sw0LdJ8r1hwwY/5wcO9LTLs3y55ynyzDPxY/y440rf/4uK/PfB739v9vTTpe8tiYqL/dhM9O23ZkOG+DXltNP8vDLz/fPDD2XTmD3bz8toOjOzN98s/cy5995+nXrgAR8/b56fp02b+vGd7IsvzJ591tNOlfdnnvH9P2BAfH9LZhdf7Ncrya+VK1fGrxE//2z28MNm3bv7+I4d/V5YUOD75rnn/PdHCD5u0iTfFrfeavarX/lxcd99ZvPn+33nmGP8t1XfvvH1bNbM33NzfZ7zz/drfWamX5OOOsrHn3mmp/3ww2aPPGL26qt+HcrIKP0sccklvm4NG5r93//5eqxbV/r69Pjjft1r0MDvPQ0bxp9DzjvP76GvvRZP85VX4tv45ps9rSee8Hvrbbf59ejMM/16dNBBpa/xY8b4/atBA79vSX6eXXyxn4eJ2yDxdfnlvq/79PH7guTX0/nzzc4+Oz7d//6vn6/Jz1P77GN28sm+jSTPq+THaJcu/vm++3y97rnHv0fDd9/dj+covccei2+7dev8WhM9a917r697tB7ffmt24IFm++3n1/VJk3zcSy/F0xg3zoe1bBnfR5EPPzRr397svfdSn2uprFlT+jfvTz+ZHXCAL+OEE8zefdeP0eOP9/OqUSM//4880u9rxcX+Gyla38mTK16mWfz3puTL2FQffOC/lxKvA2a+Lsn3h2QzZ/pvkNmzy4776iu/FmzK7+rKKCz03zB5eb4/jznGf5dU1sqV6e+TZn68vPyyH2OpFBT4NaFr18odF5HE3zybasGCyj3/YcuQlG9WtbhW8qvqM0qnSnoo4ftZku5Lmua5WJDs35I+lDQwNvx3kq5PmO4Pkn6XZjkjJOVLym/Tps1m2aAAti1PPukF31K8YCSxcJwXL16b7xU9dGZnxx+ko1d0HrZt6+dpqvM2BH9PDGBF0z/+uBcCSl5wk5yGmRf4PPlkvOB/U7z7rheCSf7AWljohV2JBXWpbNjgD5/Rg8n8+f6Q8eGHXsC7cKEPX7nSH97+/ncvoEks/C4o8OX//e++Dp9/Hi8oN/MH7Dvv9IeaZ57xwsyK8hUpLPQ8VfRjPT/fCyaOOsrs3HM9L9FDyfjx/vAZFdpOnuzfDz7YCx2St/X8+b4OK1fGh61f7+uw667+8L9okRdit2njr/79/eH/3//2B78ZM3w7PvmkL2/GDE/z55/985AhXuj27be+Ld980/O3dKk/PN98s6/PlVeaPf+8BzC+/97zOmmSF7g++aQX6u66qz/cS17Y+P33nubNN/tDcfJx3rixF9r17OmFGu3a+fCWLb1wL5pujz38OPj+e1/ekUd6Qcq0ab5Niou9gFAy239/P94feMALQHbZxR+Co0Lb3Xf3h/dLLvGCj+ef9wDDtdea7bmnByISHxBXrvTtNWuWFzK9+abvgyVLfHtHeRw1yuycc/zzzjuXfWCPCjqfe87s6699u7z6qqezaJGfa1HAZocdzHr18kLyPfbw7TN1qm/7Rx7xQof77vO8LV/uhQu33+4FLVdc4fvr0ku9UObww33bN2liNnSoP1hHhbnnnOPrkJPjAZbXXvM83Xuvn8MjRvgx1ru3Fw4ecogXvETr3Lev5332bLNu3Xy79+7t73ff7QVJu+zihcBXXWV2441eiNO4sdmgQZ5e8vWtfn3P+9FHe2HXiSf6/oqmO/hgz39WVvx62K6db/+zz/bttO++vr5nn+2Fbx06xI+V1av93HjggXhed97Zr4mPPebTSl6Q07Klfz7ooHj+zj3X7IwzvCB3jz28wOCsszytqKAv8VWvXuprfPJ6RwGm6NWund8HEl8heOHX9Ollp5fiy4+mbd8+/bIPOST+vVkzX/9HH/V1S857165+fjzxhL/37Fl6H7Rv78fuI494Ojvt5EGOaHz//n6+7befFxwOHOjn/f/8jxfI9u4dvz4MGBBPY/p0LzifPj1+bQjBCy532MGP0SOP9P2z777x9e/QwQtFc3LMmjf3IFbz5j7uyCP9XLvhhnj+El977unvWVm+/vXqlZ6uVSu/zkmevuTnUHTuR6/oHpvqeDj7bL+H9e/v6/Pqq34f+vxzvycdcICf47vtVvpPJ8OG+bEbQvzak5vr+Tv2WA8I/v73vg6NG/v4nj39Oj1yZOk8DB3q+/Puuz2NaNzRR3sBauvW8WX++tfx3yTRNu7Wzd8POMDvddnZvl+jglHJrFMnD1J8/bXfB6PfLvXr++fGjf14GDkyfk266qr4OXj44X5uRvsheu25p9kFF3jeovMoM9OPh8GD/X703Xd+vc/M9H2RfL716mV2//1+DF58sae7++7x+1dGRvwcb9nSC8wl385HHhlPp0sXHx9dgy65xAMe558fX2Z0riZeHxs2jAebb73Vt3GXLvEg4Wmn+TkaHWPJv/969Yrvk2hft2nj26B58/g2jF4NGsSHtW7twagNG/yPGE884flt2dL32QknxPdvz55+jyku9vtfx46l16W42INQPXt6GitX+u+caP4QPOC1caPZL3/pvxOuv97H3X9//P54222lf/sedJBfA9q08SBDdE+++WbfpxMn+r30mGN8OzdqFA8+3XST5yVa93vv9d8748b59TtaRr16vr4HHuifO3f2a9idd/p9J7rXXXqp38OaNvXzf599/L74q1/576e8vNLn6W67ef47d/Z5omtXhw7+uvJK/w1x2WVlr//16vn6HXZY/Php396PkUaN4tf2xH07aFD8uhW9dtopnqfoGT7x/L3nHv9dvmqVHwvt2vk5+Itf+LIfeyw+T/R7Pvkcysryc+eZZ/x378CB8WvDAQd4Xl97zc+XzEwPkET3ndxcD44MG+ZpvP66Xwei+0B0Pu+yi18nCwvjweToehyt1957+zkegp8XI0f6vu7fPz7Ngw/6sXr33Z63pk3j59Hy5T79G294cOfUU+Pb6uuv/R6UeF+U/Ldjhw5+fZL8vH/1Vf8dnRhcWbEifn7us4+PKy7246NNG9/+rVv77xoz/y3ar5+v41FH+X499FC/v5xwgv/JRvKg4YEHxrfX4MHx62dmZvzPCxs2+D49/vj4M0XLln7udu3q97KNG/1YvuaaeLnPccf5eZCR4edvsrff9mvURx/F90v37r5ddtnFt91RR/k+2WsvX8eCAv9jwK9+5cP23ju+7bKyfP0aNvRrrZnfp/faywP8zzzj+yA/34OS0Z8NbrjBz7eePUtv94ULPXAY/VEm+c8aK1fG/5TSpo3vt+nT/Rol+faZNav0M9nKlX79eP99z7Pkz15m/vtn0KD48SD5MZb8Z5uvvvJ9nZ1tdvrp/mc4M39Gmzix7HaO0n73Xd+Hyb8nDjmkdB4XLoz/1o3MnOn3uXr1/JowbpxfOy+7zK9xOTn+R4soiHv44aWDe99952lG1+h69Xxfz5jh4+fN83P/nHM8neefjz+z3nSTzxMFgyP//KdfGxJ99pk/s82b57+P9tknfi9MVw4xebIfT/Pmmf3mN37c3nSTX1+rY84c/42U/GeidBYu9N9vycHWyJQpfu35+GN/Fq3NoN+6dVVf/tYSIDstRYDs3qRpXpI0WVI9Se0lLZDUQtKVKQJkV1S0TGqQAdum5ILxqNA7uSZW9GBA0IsXr01/ZWeXPrdSnXObeo5G3n237L/5qrKcROvXly7s//nneCGC5EGJFSv8Yfiqq/yHZs+epdf5qaf8wSP5h9+qVV6APmRI/CFg+XJ/EGrf3gt+Gjf2NCV/WBk3zn90zp3rBfonneS1GY49Nv4vznr14g+vya8OHcoWODdu7AVSDz8cL9RLHj92rD/spaqF2revF9QMGeLbo3nz+MNulOeLL44XLDRv7t8Tt2tBgRcAHnywT9OokT80RgXsWVnxh8GMDH8gi/6F2rVr/J+jfft6QUmHDqULPJo29X+AjxkTf4CLHmSjQosBA3zb9uq1abVt023rxFezZmULRxIfBCXP19ln+8PMtdfGC3OiAr5TTvHA24sv+sPguHG+7/fayx9if/Urf0C+4474sXDAAV5rJCpgil5duvi+atTIj9uogPfww/14jranFC/Qk/wcGjjQg2jNm5euORlCvHC3YUMvgE+3bRo39vWvX98f9AYP9ntqCP557719H4we7Q/B99wTL/iMjoHoX86NG8ePreheHRWuX3qpH9fJy4/G168fP8aiV6NGvm7Nm8f32ahRpQvjOnWK/7O5ffvUwZbu3eO/E3JzvUC6bVtfr8mTvcCpQYP4vtEEdsUAACAASURBVMrO9sLWFSviAYRWrXz9DzooXqgVBY533dW39xVXeMHA5MkeBI3+jd2xoxdwRfv+4Ye9wDoEfwi+5hovzPzgg3ghUeI/0aPr3IknekFICJ5e4r/L27f3a9/nn8evHdF+a97cz+Hon9xnn+1B2Wi9MjJ8naKaZ2b+T9l77/UCpW+/9X+/Fhb6+8sv+7/333vPr/UbN/r1cv78+L9xX3/dj5WohsInn3hB1/XX++dJk+KFbVlZfr+46y7fduPH+/n/r3/5dT8q1H7hBQ8Gzp7ty5o/Px6w/8c/vKDk8899naJteOON/sC/cWPpPxgk++orL4hOrO1TWOjzffutb79Royr+k8XXX/t279TJC4M++8wLeKNzRfLv48Z5Idm773oBYYcOfmz27+/HxBVXlK7VMnduPJ2DDvLCtURTp/o19f33/R4RBarGjvXjK/E1bpwXcpx5phcEjRvnhQzvvRcPRF52mRfU5OX5+X7bbb4/PvjAP99/v99boutzVpbvt3Tee8+P5Ysv9mBPdNzm5HjB2vvv+30oKtiKjsvMTJ/3mWe8sFLyYRdd5IV+l15a+trWsaPfwx98MP5MsOeePn2Uzwsu8ALE1q29wHvjRr9W5+b6/Ged5e/77++FhhMmeFqJf4zo1MkLz+rX92NsyhS/DjRv7tflt9/29S4o8GN+jz18fyfuh6uv9sK+Vq38XB461I+F66/3e0xyYHLoUD8XVq3yY/2mmzzfUcC0TRvfNj16xAsrly+PX4c6dPDjrajIgzPZ2T7vn/7k3484woOz335bdv/NmOGFuRs3eh7/8Q9ft0MP9fvE/Pll5yku9mtm4nV37Fg/R+fP9/39l7/4th061M/P4mI/7n/xC/999M47ntZ33/m1YfJk/+0XHVNR4CeqGRfdN4YO9d9knTv7vrrhBk8v+qNGdFw895wfK5Jvz332id9Lo3tOly4e1OnTx8dFtQ7/7/88vwMG+LG6ww5+H8jM9PXesMG37V57+bkW3TdPOMHzHtVOivLdrp0fz9G2PPnk+DF8wQV+XGVkxPd3o0Z+Pk2Z4veTE0/068ewYfH9H9mwwbdH9Dvp2Wd9P0b3kChQL3l+33nHA9yDBnmaxx/v5/tpp/mxklwouWaNb6dDDvHj4oILPHj229/6cXfxxX7ORdfPjz7yc+CGG/xe8dFHfs8082v+66/77+rPP48fS3PmeJrXX+/Xux13jNeELM+GDf4bp3lzr1Fz6KF+L5w1y2tgvvWWX7eT1+e++/xPM6tW+fUguu+fdJIHn3v08EL0dDV0Fi/2433QIL++RYXy/fr5+623+nZ6/HE/r6J7Z1FR6T+Smfn9qWFDP76SWytYv97P61Q1YZYv930S1R6M/Oc/vn3//W/fftF1d889yy9wjoK1kybFh738cvy4kfzek6igIF6zN/F6FgXji4ritcMOO8y/R4Feye87kauvjv+2kXya6E+CUryGXDTuxBP9HGrSJB6wHTMm/mfC2bPj51M0z+9+588/GRn+LDB9uh830XUhOVBk5sdA9Ju7c2ff7ocd5s+ga9bEn4FatChbU3GfffwesmGD/96S/I9iTz3lvy933NHP9X79/ByNfqub+Tlx/vm+jvfd58foFVf4Mdeihd9ro9+1rVr5/v5/9u48Pqrq/v/4+0MIYAARAlYLJKC4gkIxdam41lpEq7YutUZFq6WIWrsXiH7b4i91bS20KqWKSx23n/76Fa1LtdVaa0UC1pWyyBKiIAiyhi3J+f3xueNMwiRkmWSyvJ6Pxzwy99xz7z137uTOuedzz7kVFR6Mj5/b4vWKE07wdd5+u09feKF/Vi++6NdivXtXP6+MGePlKSz07fbr5/sc368f/MCPa/x8XVWVCAZ26uT1w7/8xeu+8Z6HP/yhf08efdT/Z7OyEqNOTJ/u0336JI5RfFtdu/p56uSTE2nHH+/lOuAAD+Zs3py4saJLF//tfeYZ/x3s1Mnrl9dd5++Te8FnZyd6qsZ/k4cM8WO7apWXp2tX/5y++MXqv0X77uvn1iFDEvXvq6/24/300/57NnWqf+cPOSRx/dapUyKodtZZfs750pf8psZUVq3yukz//j6Swpo1fn668cZEb+5zzknkX7zY63jXX1/9/FlWljjP7btvYnu//71vf+7cRL09/urf378z8fPge+/5tcPOnf7/NWuWp2/dWv28VlLi550pU/x79dBDfkNCeblfX8SXi3931q5NlLWqyr8XvXp5MDGE2gOJmzf7ue6nP/VzVVxrCZDVZ4jF6ZIuTZr+m6QvMsQi0D4kN47n5qYe6owXr/b2Sh7WL95ImzzEk5Q6WLR1q1fEkwNKU6cm7nSqqarKh7R68cVEhTQEr5Ds2OHz//lPb0TZd19vpF2wwBsPUw1VsH69z5s/3ysVTz1VveHktde8fBUVXtaVK73SNW1aYv8efdQr5IWF3pDx7rs+/wc/8Avwu+5KNICksmOH79PMmV4JO/BAv8N39WqvPHbr5ut49VXfXvyOzvhQTccc4xW1//7XL1569/YL3b339kbaX/7SL9yPP97LHG8MLyryyn+nTn4huXBhYp+SAxbxBjzJGxZ79fL5l1/uDYgTJ/q+3nqrNyw++aRXAm++2SvnP/2pV5LnzfPGlgkTEt+VIUO88jxvnjfixGLVLz5OPNErq7/+ta/3/vsTAYYePbwBPH4nppSo1Hbq5PPuuCMR2Bo1yi8MRo9OXATm5/u643ff7dzpx2ryZK+w//Sn/h2I3wk/aZJXUCsrvdFu4EBvVDn/fP87dap/xy+5JLGNIUN8/ysqfL3f/a5/R5Jt2uQXRvGLprlz/XjMmePBiFjMK+e/+pVXoBcs8H0rKvIK9sMP+3F+5ZXEcEzbt3ujyEMPeQPd2Wf7Nlas8DsBa1a0Fy70C4mvf93/vxriz3/272q8oefTT71RZdo0v/AOwS9u4oGxESO8/PEgblWVfwfmzvX3Dz/s85ctq76d7du9Ufavf00MxfTcc/79i79uvNGPwcMP+7ngySe9Qe6MMxJ3fK5b5/8HffsmzgHxgGi8IaFz58TQXZMn+4X0Y4/58bvySh+K68AD/XNfutQbnOPlnT/fP5OHHvJjUlXl/xs//rE3vs2Z49tdtar6hVt8mLfKSr8T8pxzvAEv3uvylVcSy91yi1/4vvyyv6qq/Nw0b15iffGgTtyrr3pj269+VX0oq8WLE40KycvWLF8qVVXVtxEfujL+PlXA5p13/LuyZIk3qMcbm+LDEX7yiX/m+fn+ec2a5Y17yWWpqPDPND5kzsaNibu9X3nFG6a3bfPvyrZtfoxqBlxawooV3kA4c2Z617txo//P1hUQa04LFlT/DV6+3BsYJk70/934UHwN9fbbvp7mvGN3/fq6f5NrWrfOz+3xgFBdkocj/cc/vF7wxBPV8+zY4d/LrVt3/V5u3Oj/DzWP66ZNfrxr3iG9cqWnx8/n//xn9Txbt9a/1/Udd3jQ4w9/8PNn/P+4PkP8NVZlpdc/bryx7mPy0Ud+3qyq8rpczWGldu5M/K8nq3nTUXPYXWA6hNTDd61cWXtdN1lFhdcBL7jA60kLF9Y+9NaLL3pAeMwY72Ea3/cdOxINp716+Xf5wQf9/PrCC4lz65o1Xo8cNMh/5+LpH3/s9Y1rrvFGyYKC2svwu98l6mS9evm54pJLvD5Q87u4eLFfP1x2mW9r0yZvxP7qV73+WjNQsjtVVX5eSl4uPoz0tm2+Hzfd1Pjz07Zt9f9/SoctW+r/Gfztb4nhDRvj3Xe9Xn3JJQ0fiSJu82YPeGRne5C1oet5//1dA5/pMm9e7T2skpWV+Xc1uexVVb4/hx3m1za17dfy5f59vuqqRHCjuNjnVVR4vTE+ukZ8FIXu3avXx1ev9mDwD37g9bz470N5eSIw0b+/16HmzUs0+Hfu7HXoeM/Aww/3oOE++3gw/tVX/ffoqacS24rXm+ImTfLla/vOxXvqxK+T/+d//DONBxXvvNOv0UaN8vrwbbf5b1LNzzI+TKnk16qjRyeGaf7oIz//HHZYoveq5J9pCH4t07evXwPHAwelpf77NWiQ3xwQv2khHjCXPKiXne312n79PNCUbN48z3f99T79/PM+feutPj17tp8vBw70csVvWpN8fc89l7hOnzx513PMzp1+TJLbTgYO9OBO586Jm8TGjEkMcxi/WWP27MTvcEWFb/vkk/33/R//8OuZ7GwPXkl+PAYP9vpUCP77NGSIb+vAAz0QGYKfb196ya9NDjnEj8OGDR7giveAiwc+49+97t39murmm/3aY8AAX/eHH/r3JlXPOckD/5L/hnzjG4n61G9+k7imj/e0f+kl/81KHpLyvvsS7RNZWd6+kLz+eODwnns8IJ+dnWh/+t73Et/BP/3J0265xdtKzLz+Eb9mz872toR//cuvx2fOTKx71Ci/hooH2CZN8mOYleX/+/HemcOG+f/x4YcnyjBqVOIz/Oc/E8d76lQvV/wmlu7d/Ro5fiNXp07+vf74Yw9UTprkQddjjvH/lQ8+SAQe4wHy+O9AawmQdZa0JOoZ1kXSW5KG1sgzWtL90fu+klZIypXUR9JSSb2j11JJfXa3TQJkQPOrq0dI8tCGvHhl+pUciM3J8Qrl+ef7xWz8h7lrV28sXr7cf5iLiz1Pfr5XdL74Ra9cxZ8vc/31Xon4yld8fcXF3sA6ZYpXBuLDZHz96/4691yvbD32mFeeJQ9W3XmnV3b++EevfMWHrjniCL/L54wzEnfnSV5RO+44r9Sefbbnqdm7pH//6oG5+D7Ghzmr+fn07ev7OGBA4g78VJ/haaf5BXu8YjNo0K7DcZ1ySvWhvHr29PXX7PWZvD8/+pHv09FHe+PD8OHVh4MaMcIrR/37J8b6T26Ui1/4nHBC6ov0BQv8uO+/f/UeQ3vs4fsVi/ly8YuHrl29cho3caIH0rZs8Urho4/6Os8+2yun6VJe7o0yNe8gDcEr/88+641AqVRWeqNzckPkc895oKu83AMa8UBN3IMPJu7AP+AA/y698EL9GzpKSrwhpyF27vQLxKYOHdGeVFY2bXz7dFq+vPp37OOP/Xu0c6cf71TP1gIAoC1atMjrPbU94zGd3n7brxVq9rRJJd57FpmXrmOxbl3zB6YbI/mmjuYSv6757389WFDbNsvK/Lrs9NPrv+740MC33FI9/YYb/Ca6EBLDqceDDQcfvOtNeeny4ouJ68xrrvG09et3/0yw1av9unLmzNTBuMceS6y3sNB7XsbzPflkYl7yDWEheMAm3g5y002+zOGHe9Au/pzgeJAqPnR+svPO8+vuG27w6/n996/9exzv8fmPf3hApFMnDxT17l37TSUbN3og6dNP/Tp39WoPSE2Y4O0SZ5zRuPPzmjXeZiF58CqVqVMTn9uMGfVbb3wUhq98xW/OyMvb9XmjW7ZUH7GmqsoDllu2+O/NSy8lhvDNzk7dC/SllzzYs3mzf37f+laip+TPf+7rjPfmX7UqcSPj+PF+rCZO9GvteIBK8p58H37owTHJb7AJwW9Y22sv/25s2pS4Kbdnz0SwLrldJL5PM2f6d2LwYG+/OesszxsfUv3II3364ou9/ScerJw5MxHci9/EGx95Jd5jf/Zsbz/bd9/EkPVnnunH6bbbPE9RUWLf4u1G06d7e1337v6/uHGjf7/33NMDzukMkFkIQY1lZmMk/VZSlqSZIYRiM5sSFXCWmZmkX0eBskpJxSGER6Jlvy1pcrSq4hDCvbvbXkFBQSgpKWl0eQFIsZh07bXS2rWZLgnaik6dpKqq1PPMfH5lpZSTI+3YIfXtK61a5fP33FPKz5eWLpU2b5a+8Q1p+nTPP22a1KWL9Omn0ty50lFHSQccIHXrJg0aJK1ZI/XpI518sm//jTekf/1LWrRIWrjQX+vXS9dcI735pvTyy76trl2lxYulbdukwYN928n22Uc66STP9+GHvt4NGxLzTz5Z2rTJ15+cfsgh0umnS//+t7Rxo6ft2CEtWyZt3+7T55/v25szJ7HcnntKQ4dKxx4r/eUvnn/IEN/XY47xZW+7zcs6cKDv3wcfSIcdJl1xhbT//r7N5cul7GzPt2mTl+Ggg6SLLpJ69vT9WLhQKi/3ci9dKu3c6WXo0kXabz/P1727v+/cWZo1S3r8cV/3+edLp54qzZwpDR8uHXigH4shQ7ycn34q3XyzdMQR/jmsWydNmODH9Mwzpb//XTr8cF/f/ff7Og8/3Lf95pvSl77k6znwQC/3kUf68fyf/5H69fPjePzxic/t7belX/xC+v3vpc9/PvX3b/VqqVcvackS6fvfl666yvdh9WopL8/z7NwpPfmkdMIJvh0AAAAAQPObMUMaOVIqKKhf/rfekoqKvN2qV6+685aX+/X1mDF+jdsctm2Txo71bVxyibd/pEMI0te+5ut74gm/Zo7buVMaMMDbLf7zn123+cAD/tmcdZZPL13q1+ZDh0q9e3uZb7pJ+tnPdt3uxx/7df8rr3g7w7PPervE7mzZIn3rW9JTT0mTJ0vFxY3f96b48ENp3329DaqmDRuk/v19/1et8nap3fnkE+nKK6XrrvM2kMZ6+mk/nmee6W0Pdbn6aumee3wfunf3dq8ZM6T77vNj/eqr0h//KN16q7eXJLdh7Nzp7S2LFvnx7drV210GDZLuuksaP146+GBvc5k1y5fZvNnTv/Y16Zvf9O3Vp11kzRpp1Cjp0kul2bN9v/bbT1qwwNuU77zTv6PLlnk57r/f222+8x3fr/ff97ac739f+slPpLvv9v+j++6rvp133vF2o27dfH3Dh0srV0orVvj2X3vN25H+7//1/CtWSD/4gbcr9utnc0MI9Ty71K1JAbKWRoAMqB2Br7Yv/iNfVeU/KDt2JAIc3bp5+o4d/qPx9a9LPXp40GLIEOnEE73SWVnplcTu3T0g0KWL9NJL/oP1hS9Iv/mNlJUlnXKK/7itWuWVo/nzvaK0dav03ntelrw8D8y8/LJ03HHSGWd4UGPdOv9Ry831AE52dmIfQvAf9QULvDJ3+ulezh07/Id7yJD0VSqTt1fz/dat/kN98MFeWZkzxwNJ+fn+mSSXoaJCKimR/vtfz3/00Yn17diRyFdzueTlZ8/2z+WMMzztnXd8nUcdJR16aPXlkstZn/1qCc2xvZbeBwAAAAAA2oK6rpdLSrxN55BDGrbOBx7wG3TPPrv2PJWVHpQ76aSG3UBaUeFBl9NOk/bYo2Hlaim//rUHAW+5pWW3G4L0q195+9eIEXXnLSmRvvhFP/bvveftcHvu6e1nV1whTZ2aWGd92lNC8BvLv/lN6Ze/9PbCW27xoFQ69svMb4b+8pc9yHX55R5YPOwwaeJEb4dOdv75iWDWBx9Il13mbW2rV3vg74orquevqpI+9zlf57XXSrff7umXXio98oi3ycW3W5MZATKgXYrF/G6Z0lI/wW3b5ndqoPXp0cPvNDnkEP8RKi31gFJxsVRYWD3vsmXe0yk/33vt9OhB4AAAAAAAAADoKEJIjKzzwAM+as4vf+nz7r/feyo21Ekn+U3iP/6xdN550uuv+83a6TR/vt9QnuoG9WS33ebBub339hvyb7rJex0mr6Omc8/1oO3f/uYjOkn+2Ywd6+9XrPBelTWlM0DWOR0rAbB7NYNfkvf2MvMTS030BKtb9+7eq2rdutoDUw1VXu7rTNVduy6XXVb3/EGDGl0kAAAAAAAAAG2cmQ+dGA8ufeMbiQDZEUc0bp0jRkh/+IP0v//rj9UYOTI9ZU1WszdjbTf9H3mk//3SlzzP6NEeIMvN9UdtpDJ2rLftHndcIi0eKDvssNTBsXRrYDMw0D7FYh7E6NTJx6nt2zf1+3jPn8a8LrrIh5gLwYNf8QBYG+rE2WjxgFNu7q5jQ+fmSg8+6J/Dgw96Lysz/xtPT/XavNm74FZVeQ+tpgbHJH+GVkODYwAAAAAAAACwO1lZibbHww7zR5Hk5KTuXVUfI0Z4D7KHHvK20eTHoLS0kSOlvfaSvvpVnx4+3J9NdvzxtQfVvvY1H8YxudwDBvijZcaNa/4ySwyxiA6IZ3WlX3P05gIAAAAAAACA9uqRR6SlS6VJkxq3/FtvJZ599uabu38OWnPbssWfUxcPAi5c6M9Z22ef9G6HIRbRrtUMYHXq5L2EcnN9eu1aj7ZXVtY+PCEaL/nzrvkMtPi8/HyCYAAAAAAAAADQWBdc0LTlDznEe1+NGJH54Ji068hhBx6YmXI0BAEyZNzuenRVVfnf5PmVlf6X4Fjj5OZKU6cS4AIAAAAAAACAtqhLF2n6dGno0EyXpO0iQIYWwbCGzS/emy4vT/rVrwh+AQAAAAAAAEB79u1vZ7oEbRsBMqQNQbD06NbNx2pdv57neQEAAAAAAAAA0BwIkCGlWEwqKpKWL+c5X+nWubM/y2vHDmnAAOmmmwiAAQAAAAAAAADQkjplugBoXWIxqUcP6aKLPDgmdYzgWKfoPyE311+SlJVVPc1Mys+XHnzQP5Pk16ZN0oQJifWYJdY7fLgHwiZN8nw7d0rbt/tyK1YQHAMAAAAAAAAAoKXRgwwdcmjE3Fxp6tSmB6c2bZL++lfvbbdokXTVVR4I69VLeu01acgQadCgtBQZAAAAAAAAAACkCQGyDi4Wky69VKqoyHRJEjp1kqqqvLdWcbGnFRVJpaVSnz4+vW5d5p7PVVkpLV0qPf209ItfSBs2SP37S3/7m3TiiYl8p5zSsuUCAAAAAAAAAAD1Q4CsA4vFpIsvbh1DKO6uR1e6g2CVlT7UYZcuiWERU9mxQ9q2TXrsMWn2bKl3b+nRRz1YJ0lf+YoH74491p8tBgAAAAAAAAAAWj+a9DuoWEz69rdbNjiWrmENm2L7dun3v5emTJE2bvQA2ZAh0gEHSAce6D3UPvhAWrjQh0xcuTKx7F57SevXSyecIF1/vT9brKAg8bwxAAAAAAAAAADQNhAg66C++13vHZVurSEIJvm+lZZKAwZI3bpJn3wiTZ8u3XGHtGqVNGaMdNxxPlTjokUeEHv2WV9u7709YDZ6tDR4sJSdLR11lA+fWFHh0wAAAAAAAAAAoO0iQNYBXX+9tGVL/fL27Cnddpt00EE+HOOKFd7r6te/lq6+OpFvwwZp1ixp8WIPSrWEykrpxRc9+LV4sfTaa1K/ftKyZdLrr/v87t2lgQO9V9jOnR70+tGPUj8frLJSKi/3fa4NwTEAAAAAAAAAANo+C63hAVT1VFBQEEpKSjJdjDava9fG9R7bZx/p3nu9F9bTT3tPsWuukW6+WSouljZv9nxm0sSJPoxhzedyLVwoLVniQatVq3x64UIPYO23n/TNb0rHHON5d+6UNm3yYQ+Tvfmm9Pjj0sMPS0uXJrZ52GHSp596kOzUU33oxHnzfJjEeIDv0EMbvt8AAAAAAAAAACDzzGxuCKEgLesiQNaxzJjhwyvW5k9/8qEH4wG0jz6SXn7Zn881ZozUq5cHrs47T3rySR+KcNEi6eyzpUmTpIMP9h5ad98tfelL/pyzN9+U/vxnaetWD2DVlJPjQxl+8IG0bZt0xRXS/PmJXmDDhkl5eZ53zRppzhwpK0s6/nhpwgR/Flhu7q6BNAAAAAAAAAAA0H4QIEOj5eb6c7dqm/fJJ/VbT0WF9yS78UZp/Hjp5z/3XlxxjzwiXXmltH69D8l41llS377S0KHe0+vDD71H2oEHSp//vC+7ZYv0k59Id90l7b+/dP75Uo8eHqCLB9a6dJHOOUe67DKpd+8mfRQAAAAAAAAAAKANIUCGRksOYtX04INSYWH6tlVRIZWWSnvu6cGx+vr4Y8+flZW+sgAAAAAAAAAAgLYtnQGyzrvPgvaiuLj2ebm56Q2OSf78sf32a/hyn/tcessBAAAAAAAAAACQrFOmC4CWEYtJv/hF6nk5OdLUqS1aHAAAAAAAAAAAgIxpUoDMzEab2QIzW2xmE1PMv9TM1pjZf6LXFUnzKpPSZzWlHNi9yZN9yMOasrKkGTPS33sMAAAAAAAAAACgtWr0EItmliXpDklfkVQmaY6ZzQohvF8j66MhhKtTrGJrCGFEY7ePhiktTZ1eVUVwDAAAAAAAAAAAdCxN6UF2pKTFIYQlIYQdkh6RdFZ6ioV069MndXpeXsuWAwAAAAAAAAAAINOaEiDrL2lF0nRZlFbTOWb2tpk9bmYDk9K7mVmJmb1uZmfXthEzGxflK1mzZk0TituxHXbYrmk5OVJxccuXBQAAAAAAAAAAIJOaEiCzFGmhxvRTkgaFEA6X9KKk+5Pm5YUQCiRdKOm3ZrZ/qo2EEGaEEApCCAX9+vVrQnE7tiVLpOzsxHRuLs8eAwAAAAAAAAAAHVNTAmRlkpJ7hA2Q9FFyhhDC2hDC9mjyj5KOSJr3UfR3iaSXJX2hCWVBHe65R1qxQtq5M5G2dWvmygMAAAAAAAAAAJBJTQmQzZF0gJkNNrMuki6QNCs5g5ntmzR5pqT5UXpvM+save8r6VhJ7zehLKhDUdGuaeXlqdMBAAAAAAAAAADau86NXTCEUGFmV0t6XlKWpJkhhPfMbIqkkhDCLEnfM7MzJVVIWifp0mjxQyT9wcyq5EG6m0IIBMiayccfp04vLW3ZcgAAAAAAAAAAALQGFkLNx4a1XgUFBaGkpCTTxWhzunf3HmM15edLy5a1eHEAAAAAAAAAAAAazMzmhhAK0rGupgyxiDYgFpO2bds1PSdHKi5u+fIAAAAAAAAAAABkGgGydiwWk77zHamqqnp6bq40Y4ZUWJiZcgEAAAAAAAAAAGQSAbJ2rKhI2rp11/QePQiOAQAAAAAAAACAjosAWTtWWtqwdAAAAAAAAAAAgI6AAFk7lpfXsHQAAAAAAAAAAICOgABZO3baabum5eRIxcUtXxYAAAAAAAAAAIDWggBZOxWLSffdPVkHuAAAIABJREFUVz3NTBo7luePAQAAAAAAAACAjo0AWTtVVCRt21Y9LQTpmWcyUx4AAAAAAAAAAIDWggBZO1Va2rB0AAAAAAAAAACAjoIAWTuVl9ewdAAAAAAAAAAAgI6CAFk7VVzszxxLlpPj6QAAAAAAAAAAAB0ZAbJ2qrzcnzkWl5srzZghFRZmrkwAAAAAAAAAAACtAQGydigWk665pnra1q2ZKQsAAAAAAAAAAEBrQ4CsHSoqkrZvr55WXu7pAAAAAAAAAAAAHR0BsnaotLRh6QAAAAAAAAAAAB0JAbJ2KC+vYekAAAAAAAAAAAAdCQGydqi4WDKrnpaT4+kAAAAAAAAAAAAdHQGydiYWkyZNkkJIBMny86UZM6TCwsyWDQAAAAAAAAAAoDXonOkCIH1iMWncOKm83KdDSPQcIzgGAAAAAAAAAADg6EHWjhQVJYJjceXlng4AAAAAAAAAAABHgKwdKS1tWDoAAAAAAAAAAEBHRICsHcnLa1g6AAAAAAAAAABAR9SkAJmZjTazBWa22Mwmpph/qZmtMbP/RK8rkuaNNbNF0WtsU8oBN2bMrmnxZ5ABAAAAAAAAAADAdW7sgmaWJekOSV+RVCZpjpnNCiG8XyProyGEq2ss20fSzyUVSAqS5kbLftrY8nR0sZh0//3V08yksWOlwsLMlAkAAAAAAAAAAKA1akoPsiMlLQ4hLAkh7JD0iKSz6rnsVyW9EEJYFwXFXpA0ugll6fCKiqTy8uppIUjPPJOZ8gAAAAAAAAAAALRWTQmQ9Ze0Imm6LEqr6Rwze9vMHjezgQ1cVmY2zsxKzKxkzZo1TShu+xWLScuXp55XWtqyZQEAAAAAAAAAAGjtmhIgsxRpocb0U5IGhRAOl/SipPgggPVZ1hNDmBFCKAghFPTr16/RhW2vYjFp3Lja5+fltVxZAAAAAAAAAAAA2oKmBMjKJA1Mmh4g6aPkDCGEtSGE7dHkHyUdUd9lMyEWkwYN8md3de7sf/v29VenTj4vFst0KatLNbRiXE6OVFzcsuUBAAAAAAAAAABo7ZoSIJsj6QAzG2xmXSRdIGlWcgYz2zdp8kxJ86P3z0s61cx6m1lvSadGaRkzYYJ08cWJoQorK/3v2rX+CsHnXXSRB86SX1lZ/jcTAbTahlaUpBkzpMLClisLAAAAAAAAAABAW9DoAFkIoULS1fLA1nxJj4UQ3jOzKWZ2ZpTte2b2npm9Jel7ki6Nll0n6QZ5kG2OpClRWkZMmCDddZcHwRqjqsr/JgfQWiJYNmFC7fPy8wmOAQAAAAAAAAAApGKhsVGhDCgoKAglJSVpWVcsJl17rfcOa049ekjTp6c3WLW7sptJf/oTATIAAAAAAAAAANB+mNncEEJBOtbVlCEW26RYzJ8pdtFFzR8ck6TNmxO9yvr2bXyvsuTno+2u7CEQHAMAAAAAAAAAAKhNhwqQxWLSuHEtExhLZe3ahgfLZs6UunXz5ep63liy/PymlRMAAAAAAAAAAKA961BDLPbtm7ngWEtheEUAAAAAAAAAANAeMcRiI0yY0PDgWJ8+HnDKzZVycpqnXOlkJo0fT3AMAAAAAAAAAACgLh0iQBaLSdOn1y9vbq50333S8cdL69ZJF14o3XOPNHSozx8/Xqqs9Od8xV8PPpj5YQ1zc73n2J13ZrYcAAAAAAAAAAAArV27D5DFYtLYsR7IqkufPh7o+uQTz//ii9J110lPPCGdfba0YoX02GPSXXdJnWp8aoWF0rJliWBZbm6z7c4uzKQrr/Ry03MMAAAAAAAAAABg99p1gGzCBOnii73HV11mzvThF5MDTNnZ0g03eGDs8celBQuk887b/TYLCz1Y1RLBsvx8eo0BAAAAAAAAAAA0VLsNkMWHVdxdz7EBA6RLLql9ft++0jnnSHvu2fAy1AyWde/e8HXUlJvr6wrBe63RawwAAAAAAAAAAKBh2m2ArKho98ExSbr/fikrq/nLU1gobd5c/XllZvVbNjkoxlCKAAAAAAAAAAAATdM50wVoDrGYtHz57vNdf7108snNX55khYUEuAAAAAAAAAAAADKp3QXIJkzwoRXrcuONUo8e0pVXtkyZAAAAAAAAAAAA0Hq0qwDZ7p47ZiaNHy9NnNiy5QIAAAAAAAAAAEDr0a4CZLt77tif/sTwhgAAAAAAAAAAAB1dp0wXIJ1KS2ufl59PcAwAAAAAAAAAAADtLECWl5c63UwqLm7ZsgAAAAAAAAAAAKB1alcBsuJiqUuX6mnx547RewwAAAAAAAAAAABSOwuQ1ZSb688du/POTJcEAAAAAAAAAAAArUW7CZDFYtJ3viPt2JFI27o1c+UBAAAAAAAAAABA69RuAmRFRbsGxMrLPR0AAAAAAAAAAACIazcBstLShqUDAAAAAAAAAACgY2o3AbKBA1On5+W1bDkAAAAAAAAAAADQujUpQGZmo81sgZktNrOJdeQ718yCmRVE04PMbKuZ/Sd6TW9KOSTpkkt2TcvJkYqLm7pmAAAAAAAAAAAAtCedG7ugmWVJukPSVySVSZpjZrNCCO/XyNdT0vckza6xig9CCCMau/1ksZg0bZq/79RJqqqS8vM9OFZYmI4tAAAAAAAAAAAAoL1oSg+yIyUtDiEsCSHskPSIpLNS5LtB0i2StjVhW7WKxaRx46SNG326qirRc4zgGAAAAAAAAAAAAGpqSoCsv6QVSdNlUdpnzOwLkgaGEJ5OsfxgM3vTzP5hZsfVthEzG2dmJWZWsmbNml3mFxVJ5eXV08rLPR0AAAAAAAAAAACoqSkBMkuRFj6badZJ0u2SfpQi30pJeSGEL0j6oaSHzGzPVBsJIcwIIRSEEAr69eu3y/zS0tSFqy0dAAAAAAAAAAAAHVtTAmRlkgYmTQ+Q9FHSdE9JwyS9bGbLJB0taZaZFYQQtocQ1kpSCGGupA8kHdiYQuTlNSwdAAAAAAAAAAAAHVtTAmRzJB1gZoPNrIukCyTNis8MIWwIIfQNIQwKIQyS9LqkM0MIJWbWz8yyJMnM9pN0gKQljSlEcbGUnV09Lf4MMgAAAAAAAAAAAKCmRgfIQggVkq6W9Lyk+ZIeCyG8Z2ZTzOzM3Sx+vKS3zewtSY9LGh9CWNeYchQWSieeKFk04GN+vjRjhqcDAAAAAAAAAAAANVkIYfe5WomCgoJQUlKyS/pJJ0nbtkn//ncGCgUAAAAAAAAAAIBmZ2ZzQwgF6VhXU4ZYbBVCkN59Vxo6NNMlAQAAAAAAAAAAQFvQ5gNkv/mN9Mkn0j33SIMGSbFYpksEAAAAAAAAAACA1qxNB8hiMWny5MT08uXSuHEEyQAAAAAAAAAAAFC7Nh0gKyqSduyonlZe7ukAAAAAAAAAAABAKm06QFZa2rB0AAAAAAAAAAAAoE0HyD7/+dTpeXktWw4AAAAAAAAAAAC0HW06QHbOObum5eRIxcUtXxYAAAAAAAAAAAC0DW06QHbggf53wADJTMrPl2bMkAoLM1suAAAAAAAAAAAAtF6dM12Apli3zv8uWSJlZ2e2LAAAAAAAAAAAAGgb2nQPsnXrpJ49CY4BAAAAAAAAAACg/tp0gGztWqlPn0yXAgAAAAAAAAAAAG1Jmw6QrVsn5eZmuhQAAAAAAAAAAABoS9p8gIweZAAAAAAAAAAAAGiINh0gY4hFAAAAAAAAAAAANFSbDpDRgwwAAAAAAAAAAAAN1WYDZFVVPIMMAAAAAAAAAAAADddmA2SbNnmQjB5kAAAAAAAAAAAAaIg2GyCbOdP//uhH0qBBUiyW0eIAAAAAAAAAAACgjWiTAbJYTJo0KTG9fLk0bhxBMgAAAAAAAAAAAOxemwyQFRVJ27dXTysv93QAAAAAAAAAAACgLm0yQFZa2rB0AAAAAAAAAAAAIK5NBsjy8hqWDgAAAAAAAAAAAMQ1KUBmZqPNbIGZLTaziXXkO9fMgpkVJKVNipZbYGZfbch2i4ul7OzqaTk5ng4AAAAAAAAAAADUpdEBMjPLknSHpNMkHSrpW2Z2aIp8PSV9T9LspLRDJV0gaaik0ZLujNZXL4WF0pe/LJn5Kz9fmjHD0wEAAAAAAAAAAIC6NKUH2ZGSFocQloQQdkh6RNJZKfLdIOkWSduS0s6S9EgIYXsIYamkxdH66m3vvX1IxaoqadkygmMAAAAAAAAAAACon85NWLa/pBVJ02WSjkrOYGZfkDQwhPC0mf24xrKv11i2f6qNmNk4SeOiye1m9m71+Y0rPAAk6Svpk0wXAkC7w7kFQHPg3AKgOXBuAdAcOLcAaA4HpWtFTQmQpQpNhc9mmnWSdLukSxu6bLXEEGZImhGtsySEUJAqHwA0FucWAM2BcwuA5sC5BUBz4NwCoDlwbgHQHMysJF3rakqArEzSwKTpAZI+SpruKWmYpJfNu3ntI2mWmZ1Zj2UBAAAAAAAAAACAZtGUZ5DNkXSAmQ02sy6SLpA0Kz4zhLAhhNA3hDAohDBIPqTimSGEkijfBWbW1cwGSzpA0htNKAsAAAAAAAAAAABQL43uQRZCqDCzqyU9LylL0swQwntmNkVSSQhhVh3Lvmdmj0l6X1KFpKtCCJX12OyMxpYXAOrAuQVAc+DcAqA5cG4B0Bw4twBoDpxbADSHtJ1bLISUj/4CAAAAAAAAAAAA2qWmDLEIAAAAAAAAAAAAtDkEyAAAAAAAAAAAANChtIkAmZmNNrMFZrbYzCZmujwA2g4zG2hmL5nZfDN7z8yujdL7mNkLZrYo+ts7Sjczmxadb942s5GZ3QMArZmZZZnZm2b2dDQ92MxmR+eWR82sS5TeNZpeHM0flMlyA2i9zGwvM3vczP4b1V+Ood4CoKnM7AfR9dC7ZvawmXWj3gKgocxsppmtNrN3k9IaXE8xs7FR/kVmNjYT+wKg9ajl3HJrdE30tpn92cz2Spo3KTq3LDCzryalNziO1OoDZGaWJekOSadJOlTSt8zs0MyWCkAbUiHpRyGEQyQdLemq6BwyUdLfQggHSPpbNC35ueaA6DVO0l0tX2QAbci1kuYnTd8s6fbo3PKppMuj9MslfRpCGCLp9igfAKQyVdJzIYSDJQ2Xn2OotwBoNDPrL+l7kgpCCMMkZUm6QNRbADTcfZJG10hrUD3FzPpI+rmkoyQdKenn8aAagA7rPu16bnlB0rAQwuGSFkqaJElRu+4FkoZGy9wZ3bzcqDhSqw+QyU+Ui0MIS0IIOyQ9IumsDJcJQBsRQlgZQpgXvd8kb2TqLz+P3B9lu1/S2dH7syQ9ENzrkvYys31buNgA2gAzGyDpdEl3R9Mm6WRJj0dZap5b4uecxyV9OcoPAJ8xsz0lHS/pHkkKIewIIawX9RYATddZ0h5m1llSjqSVot4CoIFCCK9IWlcjuaH1lK9KeiGEsC6E8Km8EbxmwziADiTVuSWE8NcQQkU0+bqkAdH7syQ9EkLYHkJYKmmxPIbUqDhSWwiQ9Ze0Imm6LEoDgAaJhgb5gqTZkj4XQlgpeRBN0t5RNs45AOrrt5J+Kqkqms6VtD6pApd8/vjs3BLN3xDlB4Bk+0laI+neaPjWu82su6i3AGiCEMKHkm6TVCoPjG2QNFfUWwCkR0PrKdRfADTUtyU9G71P67mlLQTIUt2lFFq8FADaNDPrIekJSd8PIWysK2uKNM45AKoxszMkrQ4hzE1OTpE11GMeAMR1ljRS0l0hhC9I2qLEMEWpcG4BsFvR0GVnSRos6fOSusuHH6qJeguAdKrtXMI5BkC9mVmR/BE6sXhSimyNPre0hQBZmaSBSdMDJH2UobIAaIPMLFseHIuFEP5flPxxfAii6O/qKJ1zDoD6OFbSmWa2TN5t/2R5j7K9oqGLpOrnj8/OLdH8Xtp1aBIAKJNUFkKYHU0/Lg+YUW8B0BSnSFoaQlgTQtgp6f9J+pKotwBIj4bWU6i/AKgXMxsr6QxJhSGEeLArreeWthAgmyPpADMbbGZd5A9gm5XhMgFoI6Kx8u+RND+E8JukWbMkjY3ej5X0ZFL6JeaOlrQhPlQAAMSFECaFEAaEEAbJ6yZ/DyEUSnpJ0rlRtprnlvg559woP3dJAqgmhLBK0gozOyhK+rKk90W9BUDTlEo62sxyouuj+LmFeguAdGhoPeV5SaeaWe+oh+upURoAfMbMRkv6maQzQwjlSbNmSbrAzLqa2WBJB0h6Q42MI1lbqOOY2Rj5XdlZkmaGEIozXCQAbYSZjZL0T0nvKPGcoMny55A9JilPfsF4XghhXXTB+Hv5A2LLJV0WQihp8YIDaDPM7ERJPw4hnGFm+8l7lPWR9Kaki0II282sm6Q/yZ+DuE7SBSGEJZkqM4DWy8xGSLpbUhdJSyRdJr+xkXoLgEYzs19K+qZ8iKI3JV0hfy4H9RYA9WZmD0s6UVJfSR9L+rmk/1UD6ylm9m1524wkFYcQ7m3J/QDQutRybpkkqauktVG210MI46P8RfLnklXIH6fzbJTe4DhSmwiQAQAAAAAAAAAAAOnSFoZYBAAAAAAAAAAAANKGABkAAAAAAAAAAAA6FAJkAAAAAAAAAAAA6FAIkAEAAAAAAAAAAKBDIUAGAAAAAAAAAACADoUAGQAAAAAAAAAAADoUAmQAAAAAAAAAAADoUAiQAQAAAAAAAAAAoEMhQAYAAAAAAAAAAIAOhQAZAAAAAAAAAAAAOhQCZAAAAAAAAAAAAOhQCJABAAAAAAAAAACgQyFABgAAAAAAAAAAgA6FABkAAAAAAAAAAAA6FAJkAAAAAAAAAAAA6FAIkAEAAAAAAAAAAKBDIUAGAAAAAAAAAACADoUAGQAAAAAAAAAAADoUAmQAAAAA2gwzyzKzzWaWl868mWRmQ8wsNMN6TzGzZUnTC8zsuPrkbcS27jazyY1dvo71/h8zuy/d6wUAAACAzpkuAAAAAID2y8w2J03mSNouqTKa/m4IIdaQ9YUQKiX1SHfejiCEcFA61mNmV0i6KIRwYtK6r0jHugEAAACgpRAgAwAAANBsQgifBaiiHkpXhBBerC2/mXUOIVS0RNkAAAAAAB0XQywCAAAAyJhoCL1HzexhM9sk6SIzO8bMXjez9Wa20symmVl2lL+zmQUzGxRNPxjNf9bMNpnZv81scEPzRvNPM7OFZrbBzH5nZv8ys0trKXd9yvhdM1tsZp+a2bSkZbPM7HYzW2tmH0gaXcfnc52ZPVIj7Q4z+030/gozmx/tzwdR767a1lVmZidG73PM7E9R2d6TdESK7S6J1vuemZ0ZpR8m6feSjouGr/wk6bP9RdLy46N9X2tm/2tm+9bns9kdMzs7Ks96M/u7mR2UNG+ymX1kZhvN7L9J+3q0mc2L0j82s1vruz0AAAAA7RcBMgAAAACZ9nVJD0nqJelRSRWSrpXUV9Kx8gDSd+tY/kJJ10vqI6lU0g0NzWtme0t6TNJPou0ulXRkHeupTxnHyANPX5AH/k6J0q+UdKqk4dE2zq9jOw9JOsPMukfl7CzpvChdkj6WdLqkPSV9R9LvzOzwOtYXN0XSQEn7ReUcW2P+wmi/ekkqlvSQmX0uhPCOpKsl/TOE0COE0Lfmis3s1Gj950rqL+kjSTWH0qzts6mVmR0i6UFJ10jqJ+lFSU+ZWbaZDZV//iNDCHtKOk1+fCXpd5JujdKHSHp8d9sCAAAA0P4RIAMAAACQaa+GEJ4KIVSFELaGEOaEEGaHECpCCEskzZB0Qh3LPx5CKAkh7JQHYkY0Iu8Zkv4TQngymne7pE9qW0k9y3hjCGFDCGGZpJeTtnW+pNtDCGUhhLWSbqpjO0skvSvprCjpK5LWhxBKovlPhRCWBPd3SX+TdFwd+x93vqT/E0L4NISwXN4rLHm7j4UQVkbH5CFJyyQV1GO9klQo6e4Qwn9CCNskTZR0gpkNSMpT22dTlwskzQoh/D06RjfJA4NHyQOW3SQNjYbpXBp9dpK0U9IBZpYbQtgUQphdz/0AAAAA0I4RIAMAAACQaSuSJ8zsYDP7i5mtMrON8t5Iu/RUSrIq6X25pB61Zawj7+eTyxFCCJLKaltJPctYr21JWl5HeSXvLfat6P2FSuqNZWZnmNlsM1tnZuvlPdPq+qzi9q2rDGZ2qZm9FQ1luF7SwfVcr+T799n6QggbJX0q700W15BjVtt6q+THqH8IYYGkH8mPw2rzITv3ibJeJulQSQvM7A0zG1PP/QAAAADQjhEgAwAAAJBpocb0H+S9poZEw+L9jyRr5jKslPRZDyczM1UP6NTUlDKulA9vGJe3m/yPSjol6oF1lqLhFc1sD/lwgTdK+lwIYS9Jf61nOVbVVgYz20/SXfKhIHOj9f43ab01j1dNH0nKT1pfT0m9JX1Yj3I1ZL2d5MfsQ0kKITwYQjhW0mBJWfLPRSGEBSGECyTtLenXkp4ws25NLAsAAACANo4AGQAAAIDWpqekDZK2RM+dquv5Y+nytKSRZva16Dlf18qfc9UcZXxM0vfNrL+Z5Ur6WV2ZQwgfS3pV0r2SFoQQFkWzukrqImmNpEozO0PSlxtQhslmtpeZ5cmfKxbXQx4EWyOPFV4h70EW97GkAWaWXcu6H5Z0uZkdbmZd5YGqf4YQau2R14Ayn2lmJ0bb/omkTZJmm9khZnZStL2t0atSvgMXm1nfqMfZhmjfqppYFgAAAABtHAEyAAAAAK3NjySNlQc//iDvQdWsoiDUNyX9RtJaSftLelPS9mYo413yZ4W9I2mOvBfY7jwk6ZTob7zM6yX9QNKfJa2TdK480FcfP5f3ZFsm6VlJDySt921J0yS9EeU5WFLyc7tekLRI0sdmljxUYnz55+RDHf45Wj5P/lyyJgkhvCf/zO+SB+9GSzozeh5ZV0m3yJ8bt0reY+26aNExkuab2SZJt0n6ZghhR1PLAwAAAKBtMx9aHwAAAAAQZ2ZZ8iH9zg0h/DPT5QEAAAAApBc9yAAAAABAkpmNNrNe0TB910uqkPeiAgAAAAC0M/UKkJnZTDNbbWbv1jLfzGyamS02s7fNbGTSvLFmtih6jU1KP8LM3omWmRY9BBsAAAAAMmWUpCXyYfpGSzo7hFDbEIsAAAAAgDasXkMsmtnxkjZLeiCEMCzF/DGSrpGP7X6UpKkhhKPMrI+kEkkF8gchz5V0RAjhUzN7Q/7g69clPSNpWgjh2fTsFgAAAAAAAAAAAJBavXqQhRBekT/0uTZnyYNnIYTwuqS9zGxfSV+V9EIIYV0I4VP5w5xHR/P2DCH8O3iE7gFJZzdpTwAAAAAAAAAAAIB66Jym9fSXtCJpuixKqyu9LEX6LsxsnKRxktS9e/cjDj744DQVOXPWrZOWL5eqqhJpnTpJ+flSnz6ZKxcAAAAAAAAAAEBrNXfu3E9CCP3Ssa50BchSPT8sNCJ918QQZkiaIUkFBQWhpKSksWVsNQYNqh4ck3y6qkpqB7sHAAAAAAAAAACQdma2PF3rqtcQi/VQJmlg0vQASR/tJn1AivQOobS0YekAAAAAAAAAAABIn3QFyGZJusTc0ZI2hBBWSnpe0qlm1tvMeks6VdLz0bxNZna0mZmkSyQ9maaytHp5eQ1LBwAAAAAAAAAAQPrUK0BmZg9L+rekg8yszMwuN7PxZjY+yvKMpCWSFkv6o6QJkhRCWCfpBklzoteUKE2SrpR0d7TMB5KeTc8utX7FxVJOzq7pY8a0fFkAAAAAAAAAAAA6Ggsh5aO/WqX28gwySZowQZo+XUr++PfYQ/rjH6XCwsyVCwAAAAAAAACA9mbnzp0qKyvTtm3bMl0U1EO3bt00YMAAZWdnV0s3s7khhIJ0bKNzOlaChnvmmerBMUnaulUqKiJABgAAAAAAAABAOpWVlalnz54aNGiQ/MlPaK1CCFq7dq3Kyso0ePDgZttOup5BhgYqLW1YOgAAAAAAAAAAaJxt27YpNzeX4FgbYGbKzc1t9t5+BMgyJC8vdfrAgS1bDgAAAAAAAAAAOgKCY21HSxwrAmQZUlws5eTsmr5hgxSLtXx5AAAAAAAAAAAAOgoCZBlSWCjNmCHl5lZP37BBGjeOIBkAAAAAAAAAAJkSi0mDBkmdOvnfprbZr127ViNGjNCIESO0zz77qH///p9N79ixo17ruOyyy7RgwYI689xxxx2KpSnAMGrUKP3nP/9Jy7pao86ZLkBHVlgoFRVJa9dWTy8v9/TCwsyUCwAAAAAAAACAjioW844s5eU+vXy5T0uNb7fPzc39LNj0i1/8Qj169NCPf/zjanlCCAohqFOn1H2b7r333t1u56qrrmpcATsgepBlWGlpw9IBAAAAAAAAAEDzKSpKBMfi4h1b0m3x4sUaNmyYxo8fr5EjR2rlypUaN26cCgoKNHToUE2ZMuWzvPEeXRUVFdprr700ceJEDR8+XMccc4xWr14tSbruuuv029/+9rP8EydO1JFHHqmDDjpIr732miRpy5YtOuecczR8+HB961vfUkFBwW57ij344IM67LDDNGzYME2ePFmSVFFRoYsvvviz9GnTpkmSbr/9dh166KEaPny4LrroorR/ZulCD7IMy8vz6HOqdAAAAAAAAAAA0LJaumPL+++/r3vvvVfTp0+XJN10003q06ePKioqdNJJJ+ncc8/VoYceWm2ZDRs26IQTTtBNN92kH/7wh5o5c6YmTpy4y7pDCHrjjTc0a9YsTZkyRc8995x+97vfaZ999tETTzyht956SyNHjqyzfGVlZbruuutUUlKiXr166ZRTTtHTTz+tfv366ZNPPtE777wjSVq/fr0k6ZZbbtHy5cvVpUuXz9JaI3qQZVhxsZSTs2v6mDEtXxYAAAAAAAAAADq62jqwNFfHlv33319f/OIXP5t++OGHNXLkSI0cOVLz58/X+++/v8sye+yxh0477TRJ0hFHHKFly5alXPc3vvGNXfK8+uqruuCCCyRJw4cP19ChQ+ss3+zZs3XyySerb9++ys7O1oUXXqgk65bnAAAgAElEQVRXXnlFQ4YM0YIFC3Tttdfq+eefV69evSRJQ4cO1UUXXaRYLKbs7OwGfRYtiQBZhhUWSmPHSmbV0++/v+kP/QMAAAAAAAAAAA2TqmNLTo6nN4fu3bt/9n7RokWaOnWq/v73v+vtt9/W6NGjtW3btl2W6dKly2fvs7KyVFFRkXLdXbt23SVPCKFB5astf25urt5++22NGjVK06ZN03e/+11J0vPPP6/x48frjTfeUEFBgSorKxu0vZZCgKwVeOYZqeb3q7nGMwUAAAAAAAAAALUrLJRmzJDy871zS36+TxcWNv+2N27cqJ49e2rPPffUypUr9fzzz6d9G6NGjdJjjz0mSXrnnXdS9lBLdvTRR+ull17S2rVrVVFRoUceeUQnnHCC1qxZoxCCzjvvPP3yl7/UvHnzVFlZqbKyMp188sm69dZbtWbNGpXXfKBbK8EzyFqBlh7PFAAAAAAAAAAA1K6wsGUCYjWNHDlShx56qIYNG6b99ttPxx57bNq3cc011+iSSy7R4YcfrpEjR2rYsGGfDY+YyoABAzRlyhSdeOKJCiHoa1/7mk4//XTNmzdPl19+uUIIMjPdfPPNqqio0IUXXqhNmzapqqpKP/vZz9SzZ8+070M6WEO70mVSQUFBKCkpyXQx0m7QIGn58l3T8/OlWoYNBQAAAAAAAAAA9TR//nwdcsghmS5Gq1BRUaGKigp169ZNixYt0qmnnqpFixapc+fW1acq1TEzs7khhIJ0rL917W0HVVwsjRvnwyommzw5M+UB8P/Zu+/wKMu0/ePnnYQAoZMA0ougFFGEiLgKWNaCq4DovoqjIu8qgvqK67J215pV9+equGtDV1cRl7VhxbKyNAtKQAhNikAAQQhBSkgg7f79cc2YECYNkknh+zmOOZJ52twTJZnnOZ/rugEAAAAAAACgdsrIyNBZZ52l3Nxcee/1/PPPV7twLBKOvHdcDYXKNMePl9LTC5anpFTNeAAAAAAAAAAAQO3UtGlTLViwoKqHUeWiqnoAKJCVdeDz556TpkypmrEAAAAAAAAAAADUVgRk1cRddx3cYjEvjzaLAAAAAAAAAAAAFY2ArJrYsKF8ywEAAAAAAAAAAHBoCMiqiQ4dwi93jjaLAAAAAAAAAAAAFYmArJpISpLi4g5e7r107bWEZAAAAAAAAAAA1FSnn366Pv300wOWPfnkk7r++utL3K9hw4aSpM2bN+uSSy4p9tjJycklHufJJ59UZqF5ns4//3zt3LmzLEMv0X333afHHnvssI9TFQjIqolAQJo0SYqOPnhdVpbNUQYAAAAAAAAAAGqekSNHaurUqQcsmzp1qkaOHFmm/du0aaO33nrrkF+/aEA2ffp0NW3a9JCPVxvEVPUAUCAQkK68Mvw65iIDAAAAAAAAAODw3XyztGhRxR6zTx/pySeLX3/JJZfo7rvv1v79+1W3bl2tX79emzdv1mmnnaaMjAwNGzZMP//8s3JycvTQQw9p2LBhB+y/fv16XXDBBVq6dKmysrI0evRoLV++XD169FBWVtYv240bN07z589XVlaWLrnkEt1///166qmntHnzZp1xxhlKSEjQzJkz1alTJyUnJyshIUGPP/64XnrpJUnSNddco5tvvlnr16/XkCFDdNppp+mrr75S27Zt9d5776l+/frFvsdFixZp7NixyszM1NFHH62XXnpJzZo101NPPaXnnntOMTEx6tmzp6ZOnarZs2dr/PjxkiTnnObMmaNGjRodxn+B8itTBZlz7jzn3Ern3Brn3O1h1nd0zs1wzqU452Y559oFl5/hnFtU6LHPOTc8uO6fzrl1hdb1qdi3VjMVNxdZccsBAAAAAAAAAED1Fh8fr/79++uTTz6RZNVjl156qZxzqlevnqZNm6aFCxdq5syZ+sMf/iDvfbHHevbZZxUXF6eUlBTdddddWrBgwS/rkpKSlJycrJSUFM2ePVspKSm66aab1KZNG82cOVMzZ8484FgLFizQyy+/rG+++Ubz5s3TCy+8oO+++06StHr1at1www1atmyZmjZtqrfffrvE93jVVVfp0UcfVUpKinr37q37779fkvTII4/ou+++U0pKip577jlJ0mOPPaann35aixYt0ty5c0sM3ipLqRVkzrloSU9LOlvSJknznXPve++XF9rsMUmveu9fcc6dKelhSVd672dK6hM8TnNJayR9Vmi/P3rvD70msBZKSpLGjJEKVTpKkgYMqJrxAAAAAAAAAABQm5RU6VWZQm0Whw0bpqlTp/5SteW915133qk5c+YoKipKP/74o7Zu3aqjjjoq7HHmzJmjm266SZJ0/PHH6/jjj/9l3RtvvKFJkyYpNzdXW7Zs0fLlyw9YX9QXX3yhiy66SA0aNJAkjRgxQnPnztXQoUPVuXNn9eljtU39+vXT+vXriz3Orl27tHPnTg0ePFiSNGrUKP32t7/9ZYyBQEDDhw/X8OHDJUmnnnqqbrnlFgUCAY0YMULt2rUry4+wQpWlgqy/pDXe+7Xe+2xJUyUNK7JNT0kzgt/PDLNeki6R9LH3PjPMOgQFAtKoUZJzBy5/5x1pypSqGRMAAAAAAAAAADg8w4cP14wZM7Rw4UJlZWWpb9++kqQpU6YoLS1NCxYs0KJFi9SqVSvt27evxGO5oiGCpHXr1umxxx7TjBkzlJKSot/85jelHqekSrW6dev+8n10dLRyc3NLPFZxPvroI91www1asGCB+vXrp9zcXN1+++168cUXlZWVpQEDBuj7778/pGMfjrIEZG0lbSz0fFNwWWGLJV0c/P4iSY2cc/FFtrlM0r+KLEsKtmV8wjlXV2E458Y455Kdc8lpaWllGG7NN326VPT/yZwc6a67qmY8AAAAAAAAAADg8DRs2FCnn366/vd//1cjR478ZfmuXbvUsmVL1alTRzNnzlRqamqJxxk0aJCmBCtqli5dqpSUFEnS7t271aBBAzVp0kRbt27Vxx9//Ms+jRo10p49e8Ie691331VmZqb27t2radOmaeDAgeV+b02aNFGzZs00d+5cSdLkyZM1ePBg5efna+PGjTrjjDP0l7/8RTt37lRGRoZ++OEH9e7dW7fddpsSExOrJCArtcWipINjSKlopDhB0t+dc1dLmiPpR0m/RInOudaSekv6tNA+d0j6SVKspEmSbpP0wEEv5P2k4HolJiYWH2XWIhs2hF9eyr8JAAAAAAAAAABQjY0cOVIjRozQ1KlTf1kWCAR04YUXKjExUX369FH37t1LPMa4ceM0evRoHX/88erTp4/69+8vSTrhhBN04oknqlevXurSpYtOPfXUX/YZM2aMhgwZotatWx8wD1nfvn119dVX/3KMa665RieeeGKJ7RSL88orr2js2LHKzMxUly5d9PLLLysvL09XXHGFdu3aJe+9fv/736tp06a65557NHPmTEVHR6tnz54aMmRIuV/vcLmSyuckyTl3iqT7vPfnBp/fIUne+4eL2b6hpO+99+0KLRsvqZf3fkwx+5wuaYL3/oKSxpKYmOiTk5NLHG9t0KlT+DCsaVPp558jPhwAAAAAAAAAAGq0FStWqEePHlU9DJRDuP9mzrkF3vvEijh+WVoszpfUzTnX2TkXK2uV+H6RASU450LHukPSS0WOMVJF2isGq8rkrFHmcElLyz/82ikpSYqLO3j5nj3MQwYAAAAAAAAAAHC4Sg3IvPe5km6UtUdcIekN7/0y59wDzrmhwc1Ol7TSObdKUitJSaH9nXOdJLWXNLvIoac455ZIWiIpQdJDh/VOapFAQJo0SYovMotbXp50zTWEZAAAAAAAAAAAAIej1BaL1cmR0mIxpLhWix07SofQ/hMAAAAAAAAAgCPSihUr1L17d1lTO1R33nt9//33Vd5iEVVkw4bwy8OFZgAAAAAAAAAAILx69eopPT1dNalo6EjlvVd6errq1atXqa8TU6lHx2Hp0CF8GNakSeTHAgAAAAAAAABATdWuXTtt2rRJaWlpVT0UlEG9evXUrl27Sn0NArJqLClJGj1aysk5cPmePTYPWSBQNeMCAAAAAAAAAKAmqVOnjjp37lzVw0A1QovFaiwQkBo3Pnh5fr50552RHw8AAAAAAAAAAEBtQEBWze3YEX55cfOTAQAAAAAAAAAAoGQEZNVchw7hlzdoENlxAAAAAAAAAAAA1BYEZNVcUpIUF3fw8v37pYyMyI8HAAAAAAAAAACgpiMgq+YCAWnUKMm5A5fn5kq33FI1YwIAAAAAAAAAAKjJCMhqgOnTJe8PXv7qq5EfCwAAAAAAAAAAQE1HQFYDbNgQfvn+/dLq1ZEdCwAAAAAAAAAAQE1HQFYDdOhQ/LoJEyI3DgAAAAAAAAAAgNqAgKwGSEqS4uLCr/vgA2ny5MiOBwAAAAAAAAAAoCYjIKsBAgFp0iQpOvrgdd5TRQYAAAAAAAAAAFAeBGQ1RCAg5eeHX7dtW2THAgAAAAAAAAAAUJMRkNUgJc1FtmlT5MYBAAAAAAAAAABQkxGQ1SBJSVKdOuHX3XRTZMcCAAAAAAAAAABQUxGQ1SCBgNS4cfh1778v5eREdjwAAAAAAAAAAAA1EQFZDbNjR/jleXnSH/8Y2bEAAAAAAAAAAADURARkNUxJ85D97W/SlCmRGwsAAAAAAAAAAEBNREBWwyQlSXFx4dfl50u33hrZ8QAAAAAAAAAAANQ0MVU9AJRPIGBfr7gi/PrNmyM3FgAAAAAAAAAAgJqoTBVkzrnznHMrnXNrnHO3h1nf0Tk3wzmX4pyb5ZxrV2hdnnNuUfDxfqHlnZ1z3zjnVjvn/u2ci62Yt1T7BQJSx47Fry9unjIAAAAAAAAAAACUISBzzkVLelrSEEk9JY10zvUsstljkl713h8v6QFJDxdal+W97xN8DC20/FFJT3jvu0n6WdLvDuN9HHGSkqQ6dcKvGzcusmMBAAAAAAAAAACoScpSQdZf0hrv/VrvfbakqZKGFdmmp6QZwe9nhll/AOeck3SmpLeCi16RNLysg4ZVkTVuHH7d229LOTmRHQ8AAAAAAAAAAEBNUZaArK2kjYWebwouK2yxpIuD318kqZFzLj74vJ5zLtk5N885FwrB4iXt9N7nlnBMSZJzbkxw/+S0tLQyDPfIUVwrxbw86c03IzsWAAAAAAAAAACAmqIsAZkLs8wXeT5B0mDn3HeSBkv6UVIo/OrgvU+UdLmkJ51zR5fxmLbQ+0ne+0TvfWKLFi3KMNwjR4cO4ZdHRUl//avkw/5EAQAAAAAAAAAAjmxlCcg2SWpf6Hk7SZsLb+C93+y9H+G9P1HSXcFlu0Lrgl/XSpol6URJ2yU1dc7FFHdMlK64ecickxYulGbMOHgdAAAAAAAAAADAka4sAdl8Sd2cc52dc7GSLpP0fuENnHMJzrnQse6Q9FJweTPnXN3QNpJOlbTce+9lc5VdEtxnlKT3DvfNHGmKm4csL0+Kjpb+/OfIjwkAAAAAAAAAAKC6KzUgC84TdqOkTyWtkPSG936Zc+4B59zQ4GanS1rpnFslqZWkpODyHpKSnXOLZYHYI9775cF1t0m6xTm3RjYn2T8q6D0dUUqah2zmTGnevMiOBwAAAAAAAAAAoLpzvgZNVJWYmOiTk5OrehjVSqdOUmpq8ev79pUWLIjYcAAAAAAAAAAAACqFc26B9z6xIo5VlhaLqMaSkqS4uOLXL1woLVkSufEAAAAAAAAAAABUdwRkNVwgIE2aVPI2zEUGAAAAAAAAAABQgICsFggEpI4di1//739LS5dGbjwAAAAAAAAAAADVGQFZLZGUJDlX/Pp7743cWAAAAAAAAAAAAKozArJaIhCQvA+/znvpnXdsPjIAAAAAAAAAAIAjHQFZLVJcm8WoKKlBA+lPf4rseAAAAAAAAAAAAKojArJaJClJios7eHl+vpSdLX30kTRvXuTHBQAAAAAAAAAAUJ0QkNUigYA0aZIUHX3wupwcqyS7/fbiWzECAAAAAAAAAAAcCQjIaplAwCrGwsnPl2bPlj7+OLJjAgAAAAAAAAAAqE4IyGqhDh2KX9eypXTbbVJeXuTGAwAAAAAAAAAAUJ0QkNVCSUmSc+HX5edLS5dKr70W2TEBAAAAAAAAAABUFwRktVAgUPw8Y9u3S4mJ0j33SFlZkR0XAAAAAAAAAABAdUBAVkt17Bh+uXPSOedIGzdKjz8e2TEBAAAAAAAAAABUBwRktVRxbRa9lx59VDrpJNtmw4bIjw0AAAAAAAAAAKAqEZDVUiW1WczLk5YskXJzpQkTIjsuAAAAAAAAAACAqkZAVosV12ZRkvbtk+LipDfflGbMiNyYAAAAAAAAAAAAqhoBWS2WlGQhWHF27ZI6d5ZuuknKyYncuAAAAAAAAAAAAKoSAVktFghIkyZJ0dHh1zsnDR8uLV8u/f3vkR0bAAAAAAAAAABAVSEgq+UCAemVVywMK8p76e23pfPOk+67T/rpp4gPDwAAAAAAAAAAIOIIyI4AgYCFYeFs2CCddZaUlSX9/veRHRcAAAAAAAAAAEBVICA7QnTsWPy6e++Vhg6Vpk6VPvwwcmMCAAAAAAAAAACoCgRkR4ikJCkuLvy6zExp5kzpuOOkceOk3bsjOzYAAAAAAAAAAIBIKlNA5pw7zzm30jm3xjl3e5j1HZ1zM5xzKc65Wc65dsHlfZxzXzvnlgXXXVpon38659Y55xYFH30q7m2hqEBAmjSp+PU7dki//a20ebN0+0H/hQEAAAAAAAAAAGqPUgMy51y0pKclDZHUU9JI51zPIps9JulV7/3xkh6Q9HBweaakq7z3vSSdJ+lJ51zTQvv90XvfJ/hYdJjvBaUIBEputfjSS9L48dKzz0qzZkVsWAAAAAAAAAAAABFVlgqy/pLWeO/Xeu+zJU2VNKzINj0lzQh+PzO03nu/ynu/Ovj9ZknbJLWoiIHj0CQlFb8uNVV68EGpa1dp9Ghpz57IjQsAAAAAAAAAACBSyhKQtZW0sdDzTcFlhS2WdHHw+4skNXLOxRfewDnXX1KspB8KLU4Ktl58wjlXN9yLO+fGOOeSnXPJaWlpZRguShIISPHx4dc5J737rvTKK9KGDdItt0R2bAAAAAAAAAAAAJFQloDMhVnmizyfIGmwc+47SYMl/Sgp95cDONda0mRJo733+cHFd0jqLukkSc0l3Rbuxb33k7z3id77xBYtKD6rCBMnWhhWlPfSqFHSunXSH/8ovfii9NFHkR8fAAAAAAAAAABAZSpLQLZJUvtCz9tJ2lx4A+/9Zu/9CO/9iZLuCi7bJUnOucaSPpJ0t/d+XqF9tnizX9LLslaOiIBAwMKwcPLypDFjpO7dpd69pWuukSjcAwAAAAAAAAAAtUlZArL5kro55zo752IlXSbp/cIbOOcSnHOhY90h6aXg8lhJ0yS96r1/s8g+rYNfnaThkpYezhtB+XTsWPy6zEzpvvukyZOln3+Wrr5ays8vfnsAAAAAAAAAAICapNSAzHufK+lGSZ9KWiHpDe/9MufcA865ocHNTpe00jm3SlIrSUnB5f8jaZCkq51zi4KPPsF1U5xzSyQtkZQg6aGKelMoXVKSFBdX/PrUVOmEE6THHpOmT7e2jAAAAAAAAAAAALWB88X12quGEhMTfXJyclUPo9aYMsXmHMvLO3idc1ZBdvnl0kUXWUj29ddSv36RHycAAAAAAAAAAIBzboH3PrEijhVTEQdBzRQI2Ncrrzx4TjLvLTyTpH/8Q+rTR7rsMmnhQqlRo8iOEwAAAAAAAAAAoCKVZQ4y1GKBwMHhWEhenjRmjPTJJ9Lrr0tr10o33BDZ8QEAAAAAAAAAAFQ0AjKoY8fi12VmSuPHSwMHSn/6k7VdnDQpcmMDAAAAAAAAAACoaARkUFKSFBdX/Pr0dJuv7O67pSFDrIps7tzIjQ8AAAAAAAAAAKAiEZBBgYBVhUVHF7/N+PG2/vXXpS5dpIsvllJTIzdGAAAAAAAAAACAikJABkkWkr3ySvHrQ1VkTZtK778v7d8vDR8u7d0buTECAAAAAAAAAABUBAIy/CIQkOLji18/apSFZMceK/3rX9LixdLo0ZL3kRsjAAAAAAAAAADA4SIgwwEmTix+XV6eNGaMhWTnny89/LD05pvSvfdGbnwAAAAAAAAAAACHi4AMByitiiwz0+Yjk6Rbb7UKsgcflJ55JjLjAwAAAAAAAAAAOFwEZDjIxIlSXFzx60PzkTknTZokXXCBdOON0ltvRW6MAAAAAAAAAAAAh4qADAcJBCz4io4ufptQFVlMjPTvf0u/+pXtN3NmZMYIAAAAAAAAAABwqAjIEFYgIL3ySvHrQ1VkklWbvf++1K2bNGyY9N13kRkjAAAAAAAAAADAoSAgQ7FKm49s1KiCkKx5c+mTT6RmzaRzzpGWLo3MGAEAAAAAAAAAAMqLgAwlmjix+HV5edKYMQUhWbt20owZUmysdOaZ0vLlkRkjAAAAAAAAAABAeRCQoUSlVZFlZhbMRyZJXbvaPGTR0RaSrVhR+WMEAAAAAAAAAAAoDwIylGriRJtnrDiF5yOTpGOOsZBMkgYNkhYurNzxAQAAAAAAAAAAlAcBGUoVCEiTJllVWHEKz0cmSd27S3PnWrB2xhnSF19U/jgBAAAAAAAAAADKgoAMZRIISK+8Uvz6vDzpyiul668vWNatmwVjRx0lnXOO9OmnlT9OAAAAAAAAAACA0hCQocxKm4/Me+m55w6sJGvf3irJjjlGuvBC6Y03Kn+cAAAAAAAAAAAAJSEgQ7mUNh+Z99L48Qcua9nS5iTr31+69FLpoYdsOwAAAAAAAAAAgKpAQIZyKct8ZOnpUkLCgZVkzZpJn39u+99zj3TVVdL+/ZU/XgAAAAAAAAAAgKJiqnoAqHkCAft65ZXFV4Klp0tjxhy4fb160uTJUvfuFpKtWydNmya1aFH5YwYAAAAAAAAAAAgpUwWZc+4859xK59wa59ztYdZ3dM7NcM6lOOdmOefaFVo3yjm3OvgYVWh5P+fckuAxn3LOuYp5S4iEQEAaO7bkbTIzD2636Jx09902F9mCBdLJJ0vLllXeOAEAAAAAAAAAAIoqNSBzzkVLelrSEEk9JY10zvUsstljkl713h8v6QFJDwf3bS7pXkknS+ov6V7nXLPgPs9KGiOpW/Bx3mG/G0TUM89I8fElbxOu3aIk/fa30pw5UlaWdMop0ttvV944AQAAAAAAAAAACitLBVl/SWu892u999mSpkoaVmSbnpJmBL+fWWj9uZL+473f4b3/WdJ/JJ3nnGstqbH3/mvvvZf0qqThh/leUAUmTpTi4kreJtRusWhIdtJJ0rffSj17SpdcYtVm2dmVN1YAAAAAAAAAAACpbAFZW0kbCz3fFFxW2GJJFwe/v0hSI+dcfAn7tg1+X9IxJUnOuTHOuWTnXHJaWloZhotICgSkSZNKryQL125Rktq3t0qym2+WnnpKOvVUaeXKyhkrAAAAAAAAAACAVLaALNzcYL7I8wmSBjvnvpM0WNKPknJL2Lcsx7SF3k/y3id67xNbtGhRhuEi0gIBafv2srVbvP76g5fHxkpPPGFtFteulfr0sbAsP79yxgsAAAAAAAAAAI5sZQnINklqX+h5O0mbC2/gvd/svR/hvT9R0l3BZbtK2HdT8Ptij4mapyztFp977uBWiyEjRkhLl0pnnmnVZmefLW3YUPHjBAAAAAAAAAAAR7ayBGTzJXVzznV2zsVKukzS+4U3cM4lOOdCx7pD0kvB7z+VdI5zrplzrpmkcyR96r3fImmPc26Ac85JukrSexXwflCFytJu0Xtp1KjiQ7LWraUPP7TjfPut1Lu39M47lTNeAAAAAAAAAABwZCo1IPPe50q6URZ2rZD0hvd+mXPuAefc0OBmp0ta6ZxbJamVpKTgvjskPSgL2eZLeiC4TJLGSXpR0hpJP0j6uKLeFKpOWdot5uVJV14Zvt2iJDknXXuttHixdOyx0sUXS9ddJ/38c+WMGQAAAAAAAAAAHFmc92Gn/qqWEhMTfXJyclUPA2UwZYqFYKX97xUfb60ZA4Hw6/fvl+68U3rySSkhwb5edpmFaAAAAAAAAAAA4MjhnFvgvU+siGOVpcUiUG6BgDR2bOlBVnp6ydVkdetKf/2rNH++1KGDdPnl0rnnSmvWVPyYAQAAAAAAAADAkYGADJXmmWekyZOl6OiSt/NeevbZ4kMySerbV5o3T/rb3+xrr17S7bdLe/ZU7JgBAAAAAAAAAEDtR0CGShUISK+8UraWiM8+a20Up0wJvz46WrrxRmnlSmnkSOnRR22OstdeK72VIwAAAAAAAAAAQAgBGSpdWdstStZyccyY4kMySWrdWvrnP6Wvv5batbMWjQMGSB99RFAGAAAAAAAAAABKR0CGiAi1W4yPL33bzExp/PjStxswwNotvvyytHWrdMEFUr9+0jvvSPn5hz9mAAAAAAAAAABQOxGQIWICAWn7dmncuNK3TU8vud1iSFSUdPXV0urVFpRlZEgXXyz17i29/rqUl1chQwcAAAAAAAAAALUIARki7plnLCQrreVierq1T7z++tKPWaeOBWUrVlgw5pwFcj16WDvG3NyKGDkAAAAAAAAAAKgNCMhQJcractF76dlnyxaSSVJ0tDRypJSSIr39ttSwoTR6tNS9O0EZAAAAAAAAAAAwBGSoMqGWi2WZl+zZZ60qrCxtFyVrvThihLRggfT++1KTJgVB2UsvSfv3H/74AQAAAAAAAABAzURAhio3caIUF1e2bdPTpSuuKHtQ5px04YVScnJBUPa730kdOkj33itt3nx4YwcAAAAAAAAAADUPARmqXCAgTZpUtkqykPLMTyYdGJT95z9S//7Sgw9K7dtLQ4ZIH39s7RwBAAAAAAAAAEDtR0CGaiHUbnHcuLLvU975ySQLyn79a+mDD6RVq6Q77oMU3IIAACAASURBVLD5ys4/XzruOOmFF6Q9e8o/fgAAAAAAAAAAUHMQkKFaeeYZC8mcK/s+zz5b9paLhXXtKj30kLRunTR5slSnjjRmjHTUUdJVV0n//a+Un1++YwIAAAAAAAAAgOqPgAzVzjPPWGBV3paLV1xhwVqnTuULy2Jjbd/vvpO+/NK+f+896ayzpM6dpXvukdasKffbAAAAAAAAAAAA1RQBGaqlUMvF114rX1AmSamp5ZufLMQ56Ve/kp5/XvrpJ+n116UePaSkJKlbN2ngQOnFF6Xdu8t3XAAAAAAAAAAAUL0QkKFaCwVl3lf+/GSF1a8vjRwpffKJtGGD9PDDNo5rr7UWjFdcIX32mZSdfWjHBwAAAAAAAAAAVYeADDXGoc5P5tyhzVEW0q6ddPvt0vLl0rx50tVXSx99JJ17rlW3XXSR9MIL0rZth3Z8AAAAAAAAAAAQWc57X9VjKLPExESfnJxc1cNAFZsyRRo/3uYdK6/4eGniRKtMOxz79kmffip9/LE9NmyQoqKsDePFF1to1q7d4b0GAAAAAAAAAAAo4Jxb4L1PrJBjEZChprr+eum556ydYnk1bGj7Hm5QJtnrp6RIb79tj+XLbfnJJ1tYdvHFUpcuh/86AAAAAAAAAAAcyQjIgKApU6S77pJSUw/9GBVVVRby/ffSO+9YWLZwoS3r00caMcLCsp49K+Z1AAAAAAAAAAA4khCQAWEcTkWZZPObPfNMxY5p3Tpp2jQLy776ypZ1725B2YgR0oknlm9ONQAAAAAAAAAAjlQEZEAxDmd+spCKrigL2by5ICybPVvKz5cSEqROnaTTTpPOPVcaNEiKi6vY1wUAAAAAAAAAoDaoyIAsqowveJ5zbqVzbo1z7vYw6zs452Y6575zzqU4584PLg845xYVeuQ75/oE180KHjO0rmVFvCEc2QIBaft26bXXLOg6FOnp0hVXWGVXQoKFbhWhTRvphhuk//5X2rpVevFFafhwqXFjq3wbMkRq3lw65xzp9del3NyKeV0AAAAAAAAAAHCgUivInHPRklZJOlvSJknzJY303i8vtM0kSd957591zvWUNN1736nIcXpLes973yX4fJakCd77MpeEUUGGQ3H99dKzzx7+cTp2lJKSKr6yTJKysqQ5c6RPP5U++EBas0Zq29bCst69pa5dpV69pC5dKv61AQAAAAAAAACoCSJdQdZf0hrv/VrvfbakqZKGFdnGS2oc/L6JpM1hjjNS0r8OdaDAoXrmmcOrKAtJTS2oLOvUqeIqyySpfn1rsfj449LKldI770gDBkjvvy/dcos0dKh09NE2Z9n//Z/0j39YpRwAAAAAAAAAACi/slSQXSLpPO/9NcHnV0o62Xt/Y6FtWkv6TFIzSQ0k/dp7v6DIcX6QNMx7vzT4fJakeEl5kt6W9JAPMxjn3BhJYySpQ4cO/VJTUw/tnQJBU6ZI110n7d17+Mdq2NDaI1ZGVVlIerpVlH39tfTWW9KSJdLu3RbUdekinXSSdPbZ0plnSk2aSA0aSLGxlTceAAAAAAAAAACqQqQryFyYZUWDrJGS/um9byfpfEmTnXO/HNs5d7KkzFA4FhTw3veWNDD4uDLci3vvJ3nvE733iS1atCjDcIGSBQJSRkbFVJVlZFTOfGWFxcdLJ58s3Xyz9MUX0s6d0sKF0v33S337SrNmSb/7ndS5s81h1qaN9Je/SF99ZUEaAAAAAAAAAAA4UFkqyE6RdJ/3/tzg8zskyXv/cKFtlsmqzDYGn6+VNMB7vy34/AlJad77PxfzGldLSixclRYOc5ChMkyZIo0fb5VaFSk+Xpo4sXKryyTJe2nZMmn2bCk7W/rkE+mzz2xddLS1ZTz+eOmii6QhQ2wZAAAAAAAAAAA1TUVWkJUlIIuRtErSWZJ+lDRf0uXe+2WFtvlY0r+99/90zvWQNENSW++9D1aSbZA0yHu/ttAxm3rvtzvn6sjmJvvce/9cSWMhIENlq8j2i4VFKiwLWb1aWrVKmjfPKskWLZJ27LAWjF27SllZUtu20uDB0umn23xnBGcAAAAAAAAAgOosogFZ8AXPl/SkpGhJL3nvk5xzD0hK9t6/75zrKekFSQ1l7Rdv9d5/Ftz3dEmPeO8HFDpeA0lzJNUJHvNzSbd47/NKGgcBGSJlyhTprrukypjyLtJhmSTl5EjvvSfNmCGtWyfFxdm8ZkuW2Pp27aTLLrOw7NRTpaZNIzc2AAAAAAAAAADKIuIBWXVBQIaqUJlhmVQ1gVlIerqFZi+/bF9zcmw+tdhYqV49aeBAa8/Yv7+1Z4yNjfwYAQAAAAAAAACQCMiqehg4glXWfGUhVRmWZWVJ33wjzZ1rLSbT06UvvrBKs9xcqyrr21fq08dCs+OOk3r0sGo0AAAAAAAAAAAq2pIl0s6dVswhEZBV9TAASZUflklVG5iFZGdLn38uvfuuzWW2ZIm0b5+tc046+mgLy0KPXr2kY46h2gwAAAAAAAAAjlSffiq1bm3FFuUxbZpNCXTSSXYdumtX6ccfpWuvlR5/XGrUiIAMqFYiEZZJ1SMwy821qrJly6SlSwseq1dLecFZBGNipGOPPTA0q1/fArX4ePulSIAGAAAAAAAAALVPSorUr59dB16wIPw2e/faNeb+/QuWpaZaQUZMjE0LtHmzNGGCdOmlFpx9/bXUrx8BGVCtRSIwi4qS8vOljh2lpKSqDc0kaf9+aeXKA0OzpUuldesO3rZRI+nss6XBg22us06d7BEVZV9jYiI8eAAAAAAAAADAYcvNlU45RQpFOQsW2NQ9e/fauiZNbPn//I/05pvShx/a9rm50iOPSH/7m03zE9r/7LOlzz6zKrK2bWmxWNXDAMplyhTpuuvsF0Blck7yvvoEZiEZGdL330s5ORbobd5sLRunT5c2bTp4+7g4u7vgxBOtBLdHD/sF2q6dvUcAAAAAAAAAgPT009IJJ0innVa149i3T7rqKruWu3ChhV7PP29FJMOGWbD14otS06Y2jc/SpdKgQdZ1LDbWrh3n5EjR0dIll0gvvCC99Zb0ySfSnXdKPXsWvBYBGVADTZki3XWXlYmGwqzKVF0DsxDvpa1b7Rff6tUWnOXkSIsXS998Y78kMzIKtm/aVGrQQGrTRurWzX55HnOMtXJs3txCtbi4qns/AAAAAAAAABApe/ZIzZpZODZrVmRec+tWuxZbp86Byx98UPrTn+z7qCjp73+Xxo2z0GzyZAu+hg6VPvhAOv10ae1aKTvbnp9/vr2HBg2kt9+WvvxS6t27+DEQkAG1RKSqywqrDvOYlVVGhgVlCxfa1/37LWBct07KzJR++qlg27p1LSxLSLBwsGVLu7Ng4ECpVSsr3W3e3LYDAAAAAAAAgKq0a5dd42zd+tD2/+QTacgQC6S2brXroofjv/+1+b5eftmq0ryX5s2TjjvOpsz59lur+jr2WOnGGy3kCgQKWioOHSrdc49d0x0wwI65YYM0dao0cqTUvr300EO2zdFHSy+9ZMcrzPvSu4gRkAG1TKSrywqrSYFZUdu3S+vXW1A2a5a0apXN++a9LVu//sCfZWys/XLOy7Oetbt22S/7U06xR2KihXCNG1uYBgAAAAAAAACV4dJLpSVLpOXLD23/O+6wObskC7WuvvrQx+K9dej67jsL2l57TfroI5sPrH596bzzLCCLirLrp9u22X5RUbZv06bWGax9+5JfJz/fQreTTjq4Cq2sCMiAI8CUKdajNT09sq8bFWW/qKpra8bySE+X5s+Xfv7ZwrA1a6QvvrBWjG3b2tcFC+yXd25uwX7O2Rxo7dpJMTH2R6BXLyvzbdbMfjb5+VaV1rat/dGIiqq69wkAAAAAAACg5sjJscKFPXuktLRDq/761a8snPrxR6lvX+ndd4vfNlSZtWWL9Prr1tVs/nzp66+l//s/ac4c6YILrIjjlVekTZtsv+uus/0+/tiKFebOlTp3ljZulI46SnriCevYdf31UosWh/azKC8CMuAIVFWBWUhNrjQrTWamlJxsd0g0bGi/4L/80u6EyMuzcC30RyGcOnWsFLpNG/tjlpNjfxC6dLFy4aOPtuexsVK9etbysbRSYQAAAAAAAAC109y5Be0Fp0+3VonlsXevVW1NmGDfP/+89M03Up8+B2/7xhvSDTdIv/udtWVcvNiuW6am2rXPpk3t+mibNtahKy9PmjZNysqSRo8u6HiWk2PXN6saARmAKg/MalOlWVns2WMTR6alWYAWE2OVaZs3210aP/5o36enW2C2dattF+5XbHy81KOHbXfUUVap1ratPZo2tYq1uDgL63btskeHDha0UakGAAAAAAAAVB8ZGdKOHXb9rqzuvtvaI3ov/elP0r33ln3fvDzb589/tsquE0+09oh16tg147ZtLfzKyrLnkyfb9cdNm6ToaHutJ56wKWf+8AfpH/+w9aNHS927l//9RxoBGYCDVHVgFrqT4EgJzMpi/36bB+2HH6SdO+353r3W1nH9emvr+NNP9sdp377Sj9e0qf2h3b3bKtY6drSS5s6d7Q9gTo79kevevaDtY0yM7UOwBgAAAAAAAFSsXbuk004ruMZXt27BulWrpJYt7ZqeJD33nN0sP3y4zcFVt27BjfEffVSwn/d2PXHXLrsGGArgFi+2yq6UFGuVePnl1g4xJsbaJZ5xhl17LKxBA2t/+OCD0vvvW3erCy+065SxsTWzyxUBGYBSTZliPWNTU6t6JLW7PWNF8N7+yG3aZJVqmZn2xywjQ2rc2B7r1klffWVtHxs3tmq11FRpw4YD508LJyFBOuYY+4N39NEFf/w6drQ/ko0b2x/nVq3sj2Nurv1hbtv20CfLBAAAAAAAAGoz76Xzz7e2hZL03nvS0KH2/YoV0vHH283s119vj2OPtWtt990n3XGHFRn88IMFVxMnWmDWoIF0zTXWrSqcY46RTj5ZOu88aeTIAwOun3+WPvvMgrXQDfUnnCA1a1apP4aIIyADUG6FA7NQtVdVIzg7fLm5Fpbl59vdIvv3S8uXW5WZ9xa2ffGF/VHNy5NWr7bleXkWtpUkKsrucklIsEejRgXtH0NfGzWyIK15c/u+cWP7umWLPU44we5Mad7c/nsDAAAAAAAAh2vnTquoGjw4cq/pvbUtjIuz59OmSSNGSI8/bmHX2WdLDz1k1+cmTLCb3c8/X/rXv6zj07p1UpMmdk1uwADp88+t/eG4cQe+Tq9e0u9/b9fTfvrJrrXFx9vN7j161Myqr4pEQAagQlR1W8aSEJ5Vvqwsa+24a5f9sf3pJwuzoqOtMi011ZalpUnbt1tFW1aWhW6hr5mZZXut6GjpzDMLQrK4OLuLxntb16lTwf+HrVpZ3+QWLfiDDwAAAAAAgINddZWFS0uXWqBUHt5LX39t158Kt0QMJzfXtp8wQXrhBbsm9vvf2/xfffvauiVLpBtvlF5+2W5iD3V7euwx6eabpbPOkmbPlq67TrrsMun556Wnn7YAbONGa5V47bV24/kPP0hjx1olGcIjIANQaapTa8bCoqLsDwxznFUvOTlWwfbzz9YecvdueyQkWNvGpUvtQ8GyZdL06XYHjWTbp6WVfOyYGGsHmZ9vx2vVyj4c7NwptWljVWy7dll5+gkn2GSiu3bZugYN7PuYGFveqpWFeQkJFsgBAAAAAACgZlq1yiqp8vOtHeHtt0uLFtkN2CecYNeDwtmwwW7IfuMN6eqrpSuvlP74R+nhh+1a1ZlnSldcYd2ZUlOl11+XZsywfdLSbPuoKJv3K+Stt6SLL7ZqsVNPtRaLZ55pXZz++lcL4DZskO65x65ptmsXiZ9Q7UZABiBiqmNrxnCoOKtZvJe2brUAbP9++6CQkGAfMjZulJKT7YNHTo79f7d9u22fkWETm27cKGVnW4n5ihUWypVFbKztHxUlde1qLSSjoizcy8iwMveuXaWGDa2aLibGxtqjh91VdNRR0vffWwDXvr2FbfPn23FPOIHwDQAAAAAAoKL9/LNdzwldmxw50ubtOv986YMP7HpMVpZt26SJVZcFAtKcOXaz/YYNVv21alXBDdYxMXbcevXsJuy2be1G78Jat7aKr40bpYsuskovyeYaW7jQ5gO7/PKCDkgbNtjxo6Ii97M5EhGQAahy1bk9Y1GEZ7Wb9wXtIJs0kTZtstaRTZtaiJaaagFbXJx9UNmzx5avWmUfhPLzLRBr2FDasUNau9Y+VIXK4QsrHBI7Z8fcu9eeN2kinXKKHX/HDjte584Wpu3bZ6/ZooU9GjaU+vSx6rcGDSz8a9zYgrasLPtQlpNj/75CY6tTJ3I/UwAAAAAAgMq2fLldDylaVeW99PHH0vr11pXo+eel4cOlSZOsCuvxx6V777WgrHdvm8/r0Uftus+HH1rlV37+gcccOFC68EJryxi6Ofv66+3ay7vv2hhmz7Ybofv0kbp0sZujuR5T/RCQAah2akqlWVGEZyhObq498vLsDqKFC6Uff7S+1vv32//raWnSaafZh65Zs6x/dbNmVpm2e7dNvrp/f0E12tatFp6VJjraXrewVq3sQ9/OnRb+de0qdetmX+PiLATcvt0+2HkvHX20BWuxsfaoW9cq4Vq0qJQfFwAAAAAAiKD0dLtJt1MnuybRsqXUs2dVj8qsXGkBVLNm0oIF0syZdk3lhhvsesXGjdaS8LXX7IbjBx+0ebzatrWqrWnTLCCT7BrJkCEWfIXceKP01FN2DXLzZnvvhdsqLltmr//rX9v6uLiCecry8uxm58aND7wJGjUHARmAGqMmVZoVRXiGyuC9lfIvXGjVahkZ1roxVNlWt64Fa3Fx9gEvM9PWrVpl7STj463ybfVq+xpOSSF127YWnDVoYFVq+/bZ8x49LITbuNFet3nzgjYD3bpZWJicLJ14YsEH7vXr7W6qhAQL57p2lbZtk7ZssYlqY2Mr5UcIAAAAAMARzXvp9NOtAuuLL2zahyZNpJQUO7cvat8+6fPP7Tx+zx47tz/vPFu3fbvdGDxoUPjWgIsX203xV14pXXqpBUwzZ1qLw5QUu5YxaJCUmGjXOGbNsuArdOOvc1aRVa+e3VgcUreuNHas9N//WjjWsKEFV97bjcH33GMVYjExdrPvxx9bqDZokAVfhFpHLgIyADVaTa02KywqyqqGOna00m5CNFSF9HQLyrKzLaRKSLBgKy/P/n1lZdm6/fstaFu40O7iysy0D50xMRaA7d5tk9nu2GGB1/btVqlW3n+bhf89169v/05iYuzDeWamja9bN7uDrEkTG9dPP9l2xx0nnXyy/buKi7PqvA0bbPtWrWxZgwb2NS7OjpuWZt/n5VnYeMwxNi/d/v22HAAAAACA6mbsWLthddKk8s9lvnixzX/Vq5d0ySW27Kij7Py4Th3rcvPBBxZGhWRlWQXW7NkHHusPf7Cg7NZbrcqqRw8LpvbutWPFxNgjObmgw86xx9o1hC1b7Ly/Xz871rx5BVNVNGxoc4CNGWPb9upl1yq8t2Pl5dm1h6OOsvefmWlBW9++Ft7t3GlTVjCPF4pDQAag1qoN4VlhVKGhJvG+4A4s7+0De0aG3ZHmvd0Ntnix/fvMy5M6dLC7z3bvttDr++/tQ2/bttKXX9qxsrOtqiwuzsKwdeusgm7nTvvA3aaNfYheu/bwx++cfYDOy7NqtubN7YN9Wpp9f+yx1qayTh2bqy4315ZlZ1sLh5Yt7U635s2l44+3wG3PHjte3bq2X3a2Vca1aWPvOTfXTjYaNz788QMAAAAAardFiyyUkqTrrpOeeaYgCMrPl1580c6Zr7rqwEqw3bulN9+UbrrJAiXJQqa+fS0wGzXKKqt+9zurJsvNteMMGmTVYUuW2DxeQ4fa+fmECRbQSTbX1k03SW+/bee9jRoVTDuRk2Ov8/DDds3uq6/s/HjECOmCCywkk6zDzaZNdr7ctWv5gz+gPCIekDnnzpM0UVK0pBe9948UWd9B0iuSmga3ud17P90510nSCkkrg5vO896PDe7TT9I/JdWXNF3SeF/KYAjIgCNXTW7VWByq0IACW7ZYwBYbax/2Gze2Pupr1lhl2969BZVvmZn2IT0hwcIp7+0D/dKltq5ePbv7bO9e+75FC/vdsWSJVdxJtiwqyuaFK6xuXatAK4t69Swwy8+3u+yaNSuocAs9GjSw1/nuOzu56NPHwrWWLe0RH2+vt26d9WPv0cPaXGZk2MlGhw52x15Oju3fqlXBXXaH004iO9teo3nzQz8GAAAAAFSUL7+UbrtNevddO9erLN5Ln35q55vduxcs37FDevVVC5gaNbLtZs+WXn7Zztsee6z4iqa0NOmtt+yGzOxsO8ZVV1mItGKFdNZZdq66bZv0l7/Y648aJf3971bZ1bevnZtu2iR98okdMyrKblI9+2wb20sv2bnjySfbz+n++6W777ZzzGuusfVduljbw7Fj7VpTmzbW0rB9e7umdvnlB477hx/sXLlXLzt3BWqKiAZkzrloSasknS1pk6T5kkZ675cX2maSpO+8988653pKmu697xQMyD703h8X5rjfShovaZ4sIHvKe/9xSWMhIAMQTm0MzyQCNKAy5OXZv6s6dez57t0WdK1fbwHVKadYGLV0qYVzTZrYtvv3F8wRt2+ftZ8ITfTbsKFV1e3ebSc9hYO8zEzbvndv23fJEjvx2bHjwHE5Z6+1c6eFhHXrWvVaSWJiDmx7UaeOvZemTe1Rv35BkLZxox27Xj17rFlj4eJvfmMnVLt323vo18/Cw7Q0Oznr2dNOlkIVvfv22bgyM227Dh3s0axZwTYlBXelrQcAAABQu6SnS+PGSXfcUVA5VZT3FvzMny/deaddAwknL89urPzmG5un+ze/sZaCpZ1j7Nlj140WLLDw68sv7YbFOXPsPLBDBwu15syxua2GDrVuQD/8YOd8mZkWLvXpY+eBq1dbJVhmpo1p796C+bZiYux8bPv2gtcv2iHp1lulRx6RnntOuvlm2zc+3m5ivP9+u1nyX/+S/vMf6dtv7frQqFEWuv3qV1RnAZEOyE6RdJ/3/tzg8zskyXv/cKFtnpe01nv/aHD7v3rvf1VcQOacay1ppve+e/D5SEmne++vK2ksBGQAyqu2hmeFEaQBNU92tp0wpadbGNamjd2xt2WLhU1RUXanX3q6nSzFxNiyn36yuw5D7S4Kt73IzbUTtF27rL3Fvn0FgWCbNnYX5r59Foy1b2/B3uTJ9ppxcbbNmjUFJ27NmtlxyiIuzvbLyrIArkMHe90ff7Tj5OdbCLdvn534HnecjXnzZnvfrVsXtOlcu9bey4UXFrTj7NPHKudC77FlS3tev74ds0MH+5lu3WqvX7++rW/WLHyr3owMO3br1pxcAgAAABVh2za7iS4UVn3wgXT00dLTT1sbwf797RwnVIW1c6fdyNe9uzRtmnTppfb5PCNDeuIJOxe66CI7b9i92+bUfuCBgi4godBp4EDp//0/OyeoW9fWf/mlvVZMjHUnefNNe62BA+3rlVdaALZz54HvYfRoqxiTLIgaO1a6+GK71vLnP9vyBg2s+qxvX7vJMTraQreLLrLqtxUrrJXht98WzOv16acWgLVpY+Ha2LEWokl2zhUba8cNd0Phrl12HhQfX+H/yYAaK9IB2SWSzvPeXxN8fqWkk733NxbaprWkzyQ1k9RA0q+99wuCAdkyWQXabkl3e+/nOucSJT3ivf91cP+Bkm7z3l8Q5vXHSBojSR06dOiXmpp6eO8YAIKOhPCsKOZEA1BUfr59jYqyE8SsrIIKtNTUgjkhJQufGjWyddu2SRs2FDxiYmx5Zqa1jIyKsiBu1y47aWzc2I4ze7adlMbEWIiVlWUh3Y4d1qv+2GPtGLNmWfDWtKkFbYeiVSt7/X37wq+vW9fmmuvUyV6rfn17j97be2jUqGA+u337rHXnmjU2GXbfvvbzWrnSTmZbtLDgrnlzC/pWrrST+VNOkQYMsPWZmXbCnJ1t1XpffWWVf6eeamMBAABA9ZWVJf3zn9YSr1Onqh5NgS1brNLp1FMPvVvDunXWXnDbNunBB8O3Yp8926qYRo2ygOk//5GGDbNQ64knbE6rCy+0VoQvvGChVagtfY8e0rJlVkmWm2vnD7NmWaeO0E2/3bpZ1VRiCZe8Bw60Sq+TT5batbMx/+lP4a/rxMfbDYN79th+990nDR5csP7LLy0M+81v7Ca9li3tfX34oZ27DBp04PG2bLHP/cw/DVS9SAdkv5V0bpGArL/3/v8KbXNL8Fh/DVaQ/UPScZLqSGrovU8Pzjn2rqReko6V9HCRgOxW7/2FJY2FCjIAkXIkhmeFUZUGINLy8g6s5tq5005A69Sx8Gz79oIQLi3Nqun27bNgaf16u+uyTRs7yd671066V660E+OGDQ98rbg4C7/WrrXAauNGu+ARqrDLz7eLHnv22MWCnBzbr317uzP1yy9Lfz916tjv0rLMaVenjp3g161rrx2q/MvLs2XHHmvvf88eCwz37bOLFqFKvcaN7f3v2WN33LZqZfs4Z+N3zo4/e7b9jDt2tOPGxlplYdeu9vNISbFWNfXqWVvQBg3sDtwuXezO3oSEgrta8/PtjtjUVDtWq1ZWsbd5s42xZcvw79V725fKPQAAUNPcd5+1v4uOtnaBDzxQ9kAqO1u6/Xb7jDZmTMF+3lso1apV8fumpNjnsDZtDlyek2PXLE491T7XDhxo5+/9+9tnulWr7PNikybWWnDXLmnxYgt6rr224PPfzJlW+eS9vbeuXaWTTrL28Bs32vHq17eKsIYND+wyUa+efd4Otav/9tuCVoPXXmufyZcutdcdMsRaKCYkSG3bWgB10kn2ebxtW2n4cPv6zjv2ubJzZ+mjj+xzb7Nm9hnz5JMP/pmnp0vTpxe0t2/SxMZyzDEFP3tuRgNql+rYYnGZrMpsY/D5wmdOkAAAHxJJREFUWkkDvPfbihxrlqQJkn4ULRYB1GBTpkh33VVQWVHKr9JajTANQG3mvQVudesWzF2XmmrBUYMGduK9f7+Fdtu2WZDVubMFSvn50rx5drdsWppdWOjWzY4xf75VlnlvgduGDXaRIzrafq+GvmZkWNCXkGAXBnbtsgsR27bZPHHR0RaMZWfbRY6GDS2kCgVzMTH2Gnl5dndvbKy9VnF/t6KjCy5qFBUTY3f8Nm5sFx+ys4v/uXXqZOszMux9HHWUtcYJzcUwcKCFdjt3WojXqpXt07y5BaLNmhW8Tmys/ezq17e/uXPn2rHPPtsuyOzZY9t16mT/TXbssJ9NTIy9RqdO9t9uzx77GYfCwdj/3969R8dRnnke/z3WXZYsYxkQlmVsDDPGZiAED2AuexII12SBnEkGg71xAtmwZzLA5rBkw05mkuVM5nL2MrlsMmcgBBIcYJhcFtgNCwwLExIIwcasMRCwDbblK9iyZVuWJUv97B9PFd0Wbaulbt2/n3P6tLq6urq6uru69P7qed/KmCdtZDGLS3d3DI6+d690003xmjOZ2H7usf16eqLLoHwDtXd1RWPTGWfEc6Sfo6efjgala67JfpYAACiVvXvjpKHTTx/pNRmc7u743dy/P36Hr7oq+zva2hoBSHNzjM2UWrNGWro0Qqurrz768jdvju7zPvQh6atfjRClP21tETItXBjHciefLH30o3G8cv/90he/KH3pS3Ey0Z49EQLNmhXrvWtXTKuvj+Dmr/5KevzxWO5VV0UXe7t2Sd/+dhwXnndeHBvmHgdOmhTHFI89FscsF1wQxzodHdFN35YtceKXJN1+u3TXXRF+pf+j51NXF5ft27PTpk+XPv956U/+JCrRrrsu1uG00yKUe/75mO+cc6RvfjPaQzZtiq4Hf/jDWJ9FiyL4W7UqukL8vd+LAMwsjpvKy2O+ffviuBAAijHcAVm5oovEixXB1kuSrnf313LmeVzSP7r7fWZ2qqSnJTVLmi6pzd17zewkSc9J+gN3bzOzlyTdLOlFSb+Q9B13/8XR1oWADMBYMtGr0I6Grh4BYOgcOhSNI1KEOj090YBy0knZQKe3N4KcHTuiIWTfvmj0Oe20aKBatSqujz8+W2n37rvR4JOGdHPmxMkR6fhvbW3xfFu3xhnHtbXRANPTE40wDQ3RANPVFdVsbW3RyDN3bix7w4aY1tgYQVJ3d/6TUJqaImBqbR36bXm0k2Dq66OBbPLkCO+qqmK7vPpqNKI1NUVXnOl2XrMmHtfSIn3kI/G43buj8ayuLrZNQ0O8Fw0NcZb0tm3xHOvXxxnZl14a1X1pePpP/xTr98d/HO9ve3s0sv3qV/H+LFoU3Xk2NETD4IED8R6XlWUrJg8e/ODfzc2xPg88EO/J9u3x/tx2m3TDDYefuZ3JZM8437s3XtOsWR88u9s9PptpY2c+7hGA9vREA+Rgu4kaKl1d8Rr6VqWORtu3x9gr11wz+rYjitfbG/valpaRXhOMFt3d0XXcSy/Fb+z55xf2uLffjgqdd96J3/Abb8zftV4u9wiNmpryh0zusb8sK4tQZO3a6KK6pyd+l4499vB5d+6M7vjuvDNCrnfeiddx4YXSl78sPflkjGGVBj5Ll0rXXx+/uZ/7XJy4VFMT/19KsW7TpsXvYG9v9sSmn/0s/jdPK4yWLYv5fvvbCHTq62P+2tqo8uroiMqqgwfjeCiTid/sN96I39xbb5W+8514zsrK7Ak1RzJpUozD1d4eJ5bu3RvTW1ri/+Kf/zyO13J7Eshk4jfn9tvj9/XXv47focmT43Fz58Zjli2LMOrAAemee+K4asGCODFr/fp4rrPPjt/2446L5T76aCzn9NMjBMv9rcg3DhYAjCbDGpAlT3ilpG9KKpP0A3f/hpndKWmFuz9qZvMl3S2pTpIrukt80sz+SNKdknok9Ur6mrs/lixzoaT7JNVIelzSzd7PyhCQARhPCNAKQ5gGABNPJhMNTWmDU2dnXLq7s404GzZE41V9fQRmGzZEg1x9fQQ0aaNYWvFVXx/L6+7OXtLuM90PD8LOPjue4/77owGwsjLCKrMIj8ziLPG9e6MxqqMjnrurKxoYL788zvbevDmCs5qaOMu6uTkaAV9+OZ5/2rRopOvoiAbC9vZoCNu7N9sA1tER85x1VgRfuZV78+ZFA+Rrr2WnVVXFGegbN8Y2KUZVVTSkTZ0a22Dlymg4TBvuenqy2y1dVym2WXV1zJdW/23aFI17c+fGb7t7dszD6up43M6dEc5K0WDX3ByNq+XlMW3Llni9afVeJhOXrq5oUK2tjTFOWltjmc3N8VytrbG+5eXxvp14YoSXabjZ3R3v4zHHZKsud+2SHnkktsEFF8T7cc898d5cfHGMNThjhrR4cTSUdnXFY7Zti5B0375Yh7lz44z7efNi2Z2dUenw/PPSRRdFI+z8+dGYfehQNL52d8fnoLMz1rG2NioQu7ujKnL+/GgAr66O9/rZZ6Oh9IIL4nU+9FA0Kre1SbfcEuPCTJoUr2vt2ux3p7o6Gk/nzs3fENrZGUGsFPfv3h3X+ebPZGL90vcSQ2vZMmn58qhGufTSmOYeYyPNmhWf0VJ69dX47Hzyk0PfaO6ePRGjujqet64u9q2pri7piSfiO7poUYQ6+darpyfCgd27o6q3pubw+w8dinDkhBMiTEmX8e678X2eNy+m9fbGiQ/HH3/483R3S6+/Hvv688+P8Zh27JA+/elsFU9zcyxvy5bYn5x1Vtzu7Iz9akVFtqo5k4nAyj1e+44dsZyXX459xs6d8XpvvTUet3JlfJebm2NbPPBABCA1NRE2PfdcbKeTToqTK5qa4rnTro7Xr4+qLCke09kZ+8crrojtvnBh7BvTk27S/f26dbEvLS+Paqympli3/ftjfVpbY9ubxT4s3Y+kamrid626OttlthQB3/PPx7rdcktUVh08GNvxppuiWuuhh6S//utstXtNjfTTn0o33xyvR4rt3LeL6ylToqL8Rz+Kx/7N30Rg1tsb2+fCC+P1l5fH5++tt2Ldzzkn3tvHH4/36JOfPLxSbe1a6Z//OfarNTUx/5YtsY0bG7MnvlRVxbZKu0js7JR++cv47M2fn/2dAwAUZtgDstGCgAzAREI3jgNHd48AgPEgDQXr67OD11dURCNje3s06KVjy0nRGLltWzQAzpmTDSnSsGb//miEq66OxtxJk7KNzzU12b+rq6MR7623osH3mmuigU+K39d7743Hp6FVWh0gRQN0Y2OETC++GNMmTYrXceBAPP/xx8ey9+yJ+2tqsoGQFMtbvDhe6/Ll0TDa03N4N5eHDkVDpFm2+6ny8mj43L07lj9nTixzy5aYloacnZ3RSLx+fRxf9efMM2Nbr14dty+5JMKhp56K5bz+ejxfX3PmRCP1/v3R2N23oba2Vvr4x6MheOvW0h7jpceMf/iH0Rh7990xraEhtm++E7PKyyOoPOaYWLe0CjV3jJlcJ50U72lvb1SeShEY7tkT96Xq67OX/fujinLatHivZsyI9UkrFNvaIoxobs4Gq6tWxfRzz8026E+dGuuXBifPPBPdkp11VjTMr1kT73dLSza8rqiI78aUKfnHP8y3/d0jEEnDh/r6+G7s3BkN9JMmRRXM1q3x/KecEvO3tMRnb9u22NZnnBGvde3aqII5/vh4bxoa4vOdNtp3dETXaNu3S9deG8FIOhbn7Nkxfc2a+K6femqsQ11dvHeLFsV7XFERIYkUVTUf/nC2a9xM5vAgJu1i9sEHY9yhpUulj33s8G7d0krVZ5+NUCGTkT71qXi9mUx2f9HZGeu6f39skz17Yv+xYEF0k7d5s3TlldlK1bq6OFavq4vnS7f1Cy9E1VBbW3y26uoioHn22Xie666Lz2drawQ/e/bEOhw8GIFObW1s8+7u+LuyMvZF6We+oSE+S4cORbhTUxOPTbv+nTIlPoPp/ZlMvK/HHRcVQ2n3vzU18X51dMS2HQ41NRHSNDbGyRcHDuSf7/bbo6L4oosilKmpiX1N+luwd298h8rKspVJN9wgfeYz8d196aV4/HvvRfd4q1fHNm5pyVagp/uTa6+N5a5cGaHb9OmxDWtrY/6Ghni/d+2KfdGCBfG+vvBCzN/eHvc3NUWoe8YZUQH11lvxHixYEJ/7TZviPZg9O/s69+3Lnmgyb172+/722/FdbWmJebZsifVuaYnvUl+5v68AgLGFgAwA8D4q0YpHlRoAAONTOu5JX2ljfVrFUV0dDe6ZTDSYVlVluwFLQ7q+1VHpmHSbN0dDdGNjNBLnNsQeOhQNyJs2ReNwb29USaRd46X3r1wZj5s6NRprOzpime3tEVR99KOx/LVro6F70aJsI/FFF8XyV6+OBt9LLonGdLMIUt54I5Zz4EAEDgsWxHN1dkbIt359vPbdu2O7lJVFGDljRjR4p681rYR46qkIusrKokFaisb1GTNizMQ0hNq3L3upqIiqwPb2CDjTYPCYY6KBfMqUqIRsa4v17uiI6rrGRmnFitgWPT2xnmnYOW1ahDq/+lW8/oqKqMTYti0a4Gtr49LTE8HA0bo+y6eyMtsVaq7zzov13bUrPiP/8i+xvmmFqhTP29CQrbyRIrBKx4/Mp7ExwrjVq2NZjY2x3h0d8RmeNy8+X889F+//vfdGZaoU22P9eukv/iICn3/4h2yF7NFMnhzjOT3ySLaKJ988n/1svE9f//qRx6msqMiOpTltWoQsM2fGej/zTGyPurr4POQLX08+Ob4bTU3x+Fdfjcddf30EHY89Fp+NGTNiWy5eHJ/9v/zL2BZTpsQ2Sz8fnZ3xebjssnjeRx6Jz3s6rlJ3d3wGr7oq1ueVV6IyqqwsvicnnBDVVQcOZAOc3/0uPk+TJ8cyJ0+OQLypKYK8M8+MEP2xx7KVrlu3xv0zZsT7+corcbu+PrZXbkWzewRB5eXZbv2ammI7VlXFdtqxIz4DZWUR1E+dGttn1qz4Pkmxzlu3xucz7QLRPZ4nXc6RpBXCFRXZcUDzjbcJAMBIIiADAAwYQVppEKYBAACMrLQZI+3uLncsvLTL1NxGffcIDY4UkuXrnq+2NpZx4EBc0jGVmpoOn+/gwbhvypQIhaqrI/wwizBsz54IW9KuRdPQq6oqgpnW1nies86KwGXDhgjKKiuz1VVpN6dSBGBp96C5urqy4UcmE49zj7DFLIKdrq7Du5ltaYn12rMnlpuOeZSGJJWVUUWVhp7t7dntnI5ZmHaXl3ZNl47HuH17BHoVFbGs3Oq9tHoofT+mTaN7TgAAUDgCMgDAkCJMKz26fwQAAAAAAACKU8qAjEJpAMAHLFkSZ5GmZ+Ae7bJ8eYQ+0tAP2j2WpWfIbtwY4zyYFXYpK4vr2bMjuAQAAAAAAABQPAIyAEBRliyJrmDcs93bEKaVzmCDtdzL9OmEawAAAAAAAEAuAjIAwLAhTBsZu3YNLlwjWAMAAAAAAMB4RUAGABiVBhKm5YZqjY0jvebjx0CDNbqDBAAAAAAAwFhBQAYAGDcGMnYaoVrpFTvO2vTpcZk0iZANAAAAAAAAQ4uADAAwoQ0kVCNMGxppsLZrV1zcGXMNAAAAAAAAQ4uADACAAg2mQo1wbfgx5hoAAAAAAAD6Q0AGAMAwGGy4RrA2fAYbrBG0AQAAAAAAjD0EZAAAjGLFVq2deGIsx2xkX8dEUkzQRrgGAAAAAAAwPAjIAAAYp5YskTZsiLAskyFYGwtKUcVGyAYAAAAAANA/AjIAAHAYgrWxja4iAQAAAAAA+kdABgAASqLYYM0sxlubPHmkXwkkqtkAAAAAAMD4RkAGAABGVBqsZTIx3tr+/Yy5Nl4UE7KVlcX17NmEbAAAAAAAoPQIyAAAwLhA15DjSyYT1xs3Dj5ko4INAAAAAAAcCQEZAACY0AYbrBG0jX6MxwYAAAAAAI6EgAwAAKAEig3ali+PMdgw+jAeGwAAAAAA4w8BGQAAwCiwZEmMwTbYCjZCttGtmJCNcA0AAAAAgNIjIAMAABgnShGyEbSNPlSwAQAAAABQegRkAAAAOEyxQRvjsY0+jMcGAAAAAMDhCgrIzOxyM3vTzNaZ2Vfy3D/LzJ4xs1VmttrMrkymX2JmK83s1eT6opzHPJss85XkclzpXhYAAABGSrHjsRGyjV5UswEAAAAAxot+AzIzK5P0XUlXSJov6Tozm99ntq9Ketjdz5S0WNL3kuk7Jf1rd/8DScsk3d/ncUvc/UPJ5d0iXgcAAADGkWJCNsK10Y3x2AAAAAAAo0EhFWRnS1rn7m+7e7ekhyRd3WcelzQl+btB0lZJcvdV7r41mf6apGozqyp+tQEAAID8SlHBxnhsoxMVbAAAAACAUikkIGuW1Jpze3MyLdfXJS01s82SfiHp5jzL+SNJq9y9K2favUn3in9ulv/8XjP7gpmtMLMV7733XgGrCwAAAJQG47GNP1SwAQAAAACkwgKyfP/Ke5/b10m6z91nSrpS0v1m9v6yzWyBpL+VdFPOY5YkXS9emFz+Tb4nd/e73H2huy889thjC1hdAAAAYHQotpqNCrbRZbDhWllZXM+eTcAGAAAAAKNFIQHZZkktObdnKulCMceNkh6WJHd/QVK1pOmSZGYzJf1c0mfcfX36AHffklzvk/SAoitHAAAAAAkq2MaHTCauN26keg0AAAAARotCArKXJJ1iZnPMrFLSYkmP9plnk6SLJcnMTlUEZO+Z2VRJ/1vSHe7+63RmMys3szRAq5D0CUlrin0xAAAAALIYj238KKZrSCrYAAAAAOCD+g3I3L1H0p9KekLSG5IedvfXzOxOM7sqme02Sf/WzP6fpAclfdbdPXncyZL+PBlr7BUzO05SlaQnzGy1pFckbZF0d6lfHAAAAIDSoJpt7BpsBRvBGgAAAIDxzCLHGhsWLlzoK1asGOnVAAAAADDMfvxj6dZbo5IKY0tjo/Stb0XICgAAAADFMLOV7r6wFMsqpItFAAAAABhRVLCNXYPtHpIKNgAAAABDiYAMAAAAwLhX7HhsjME2/AbbNWTuZfp0wjUAAAAA+RGQAQAAAEA/iqlgI1wbOVSvAQAAADgSAjIAAAAAGELFhmt0DTn8iqleo2oNAAAAGBsIyAAAAABglCq2a0hCtuE32Ko1gjUAAABgeBGQAQAAAMA4NtiQjWBteBGsAQAAAMOLgAwAAAAA8AGlql5j/LWhNZhgjVANAAAAICADAAAAAAwRxl8bnQZbrUa4BgAAgPGEgAwAAAAAMOoUW8FG9drQGEi4VlYW17NnE6oBAABg9CEgAwAAAACMO8VWrxGuFS+TieuNGwdWsUawBgAAgOFAQAYAAAAAQI7BhmsEa6Ux2GCN7h8BAAAwEARkAAAAAACUAMHayKL7RwAAAAwEARkAAAAAACOIYG34UaUGAAAAAjIAAAAAAMaggQZry5dLJ54YjzUb2XUfqwZSpUaoBgAAMLoRkAEAAAAAMAEsWSJt2BBhWSZDxdpwGUioRpgGAAAwfAjIAAAAAABAv6hYG3qFhml1dRGmTZrEOGoAAACDRUAGAAAAAABKbrAVawRr/evoiDDNvbBx1MrK4powDQAAIIuADAAAAAAAjBqDCdbo/vHoMpm4LiRMo7tHAAAwURCQAQAAAACAMY3uH0uvv+4eqUoDAABjHQEZAAAAAACYUKhSK95gqtII1gAAwGhCQAYAAAAAANAPqtRKo9BgjS4eAQDAUCMgAwAAAAAAKLGBVqlRoXa4/rp4rKuLEM1MKi+nKg0AAAxcQQGZmV1uZm+a2Toz+0qe+2eZ2TNmtsrMVpvZlTn33ZE87k0zu6zQZQIAAAAAAEwUhVSopVVpZhGmTZ480ms9cjo6IkSTpN7euC6ku0cq0wAAQKrfgMzMyiR9V9IVkuZLus7M5veZ7auSHnb3MyUtlvS95LHzk9sLJF0u6XtmVlbgMgEAAAAAAJBIq9IymQjT9u+nu8eB6q8yjbHSAACYOAqpIDtb0jp3f9vduyU9JOnqPvO4pCnJ3w2StiZ/Xy3pIXfvcvd3JK1LllfIMgEAAAAAAFCkgXT3SJgWGCsNAIDxr7yAeZoltebc3izpnD7zfF3Sk2Z2s6TJkj6W89jf9Hlsc/J3f8uUJJnZFyR9IbnZZWZrClhnABiI6ZJ2jvRKABh32LcAGArsWwAMhbz7FvejPmSaNKNZqqgcsrUaA9KKtKVLC5m7t0fa3CrtbBvq9QJGCY5bAAyF3y/VggoJyPKdL9T3EOk6Sfe5+38zs0WS7jez047y2HyVa3kPu9z9Lkl3SZKZrXD3hQWsMwAUjH0LgKHAvgXAUGDfAmAosG8BMBTYtwAYCma2olTLKiQg2yypJef2TGW7UEzdqBhjTO7+gplVK84QONpj+1smAAAAAAAAAAAAUHKFjEH2kqRTzGyOmVVKWizp0T7zbJJ0sSSZ2amSqiW9l8y32MyqzGyOpFMk/bbAZQIAAAAAAAAAAAAl128Fmbv3mNmfSnpCUpmkH7j7a2Z2p6QV7v6opNsk3W1mX1J0lfhZd3dJr5nZw5Jel9Qj6Yvu3itJ+ZZZwPreNfCXCAD9Yt8CYCiwbwEwFNi3ABgK7FsADAX2LQCGQsn2LeZHH3EVAAAAAAAAAAAAGFcK6WIRAAAAAAAAAAAAGDcIyAAAAAAAAAAAADChjImAzMwuN7M3zWydmX1lpNcHwNhhZi1m9oyZvWFmr5nZrcn0aWb2lJmtTa6PSaabmX072d+sNrMPj+wrADCamVmZma0ys/+V3J5jZi8m+5Z/NLPKZHpVcntdcv/skVxvAKOXmU01s5+Y2e+S45dFHLcAKJaZfSn5f2iNmT1oZtUctwAYKDP7gZm9a2ZrcqYN+DjFzJYl8681s2Uj8VoAjB5H2Lf8l+R/otVm9nMzm5pz3x3JvuVNM7ssZ/qAc6RRH5CZWZmk70q6QtJ8SdeZ2fyRXSsAY0iPpNvc/VRJ50r6YrIP+Yqkp939FElPJ7el2Neckly+IOnvh3+VAYwht0p6I+f230r6u2TfslvSjcn0GyXtdveTJf1dMh8A5PMtSf/H3edJOkOxj+G4BcCgmVmzpFskLXT30ySVSVosjlsADNx9ki7vM21AxylmNk3S1ySdI+lsSV9LQzUAE9Z9+uC+5SlJp7n76ZLeknSHJCXtuoslLUge873k5OVB5UijPiBT7CjXufvb7t4t6SFJV4/wOgEYI9x9m7u/nPy9T9HI1KzYj/wwme2Hkq5J/r5a0o88/EbSVDM7YZhXG8AYYGYzJX1c0veT2ybpIkk/SWbpu29J9zk/kXRxMj8AvM/Mpkj6V5LukSR373b3PeK4BUDxyiXVmFm5pFpJ28RxC4ABcvdfSmrrM3mgxymXSXrK3dvcfbeiEbxvwziACSTfvsXdn3T3nuTmbyTNTP6+WtJD7t7l7u9IWqfIkAaVI42FgKxZUmvO7c3JNAAYkKRrkDMlvSjpeHffJkWIJum4ZDb2OQAK9U1JX5aUSW43StqTcwCXu/94f9+S3N+ezA8AuU6S9J6ke5PuW79vZpPFcQuAIrj7Fkn/VdImRTDWLmmlOG4BUBoDPU7h+AXAQN0g6fHk75LuW8ZCQJbvLCUf9rUAMKaZWZ2kn0r69+6+92iz5pnGPgfAYczsE5LedfeVuZPzzOoF3AcAqXJJH5b09+5+pqQOZbspyod9C4B+JV2XXS1pjqQZkiYruh/qi+MWAKV0pH0J+xgABTOzP1MMofPjdFKe2Qa9bxkLAdlmSS05t2dK2jpC6wJgDDKzCkU49mN3/1kyeUfaBVFy/W4ynX0OgEKcL+kqM9ugKNu/SFFRNjXpukg6fP/x/r4lub9BH+yaBAA2S9rs7i8mt3+iCMw4bgFQjI9Jesfd33P3Q5J+Juk8cdwCoDQGepzC8QuAgpjZMkmfkLTE3dOwq6T7lrEQkL0k6RQzm2NmlYoB2B4d4XUCMEYkfeXfI+kNd//vOXc9KmlZ8vcySY/kTP+MhXMltaddBQBAyt3vcPeZ7j5bcWzyf919iaRnJH0qma3vviXd53wqmZ+zJAEcxt23S2o1s99PJl0s6XVx3AKgOJsknWtmtcn/R+m+heMWAKUw0OOUJyRdambHJBWulybTAOB9Zna5pP8o6Sp3P5Bz16OSFptZlZnNkXSKpN9qkDmSjYVjHDO7UnFWdpmkH7j7N0Z4lQCMEWZ2gaTnJL2q7DhB/0kxDtnDkmYp/mH8tLu3Jf8w/g/FALEHJH3O3VcM+4oDGDPM7COS/oO7f8LMTlJUlE2TtErSUnfvMrNqSfcrxkFsk7TY3d8eqXUGMHqZ2YckfV9SpaS3JX1OcWIjxy0ABs3M/rOkaxVdFK2S9HnFuBwctwAomJk9KOkjkqZL2iHpa5L+pwZ4nGJmNyjaZiTpG+5+73C+DgCjyxH2LXdIqpK0K5ntN+7+75L5/0wxLlmPYjidx5PpA86RxkRABgAAAAAAAAAAAJTKWOhiEQAAAAAAAAAAACgZAjIAAAAAAAAAAABMKARkAAAAAAAAAAAAmFAIyAAAAAAAAAAAADChEJABAAAAAAAAAABgQiEgAwAAAAAAAAAAwIRCQAYAAAAAAAAAAIAJ5f8DZAFQzGi4mFAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2160x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results(analysis,\"W2V_MLP_1200_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 64\n",
    "epochs      = 10\n",
    "learning_rate = 0.0003\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(16, kernel_size=(3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling1D((4),padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(8, kernel_size=(3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling1D((2 ),padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=learning_rate)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 300)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 300, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 300)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.expand_dims(X_valid, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 300, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "14000/14000 [==============================] - 5s 333us/step - loss: 0.9631 - accuracy: 0.5178 - val_loss: 0.8880 - val_accuracy: 0.5750\n",
      "Epoch 2/100\n",
      "14000/14000 [==============================] - 5s 335us/step - loss: 0.8907 - accuracy: 0.5699 - val_loss: 0.8701 - val_accuracy: 0.5817\n",
      "Epoch 3/100\n",
      "14000/14000 [==============================] - 5s 369us/step - loss: 0.8810 - accuracy: 0.5798 - val_loss: 0.8757 - val_accuracy: 0.5777\n",
      "Epoch 4/100\n",
      "14000/14000 [==============================] - 4s 301us/step - loss: 0.8740 - accuracy: 0.5836 - val_loss: 0.8611 - val_accuracy: 0.5947\n",
      "Epoch 5/100\n",
      "14000/14000 [==============================] - 4s 303us/step - loss: 0.8709 - accuracy: 0.5826 - val_loss: 0.8706 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "14000/14000 [==============================] - 4s 301us/step - loss: 0.8681 - accuracy: 0.5894 - val_loss: 0.8654 - val_accuracy: 0.5790\n",
      "Epoch 7/100\n",
      "14000/14000 [==============================] - 4s 303us/step - loss: 0.8659 - accuracy: 0.5851 - val_loss: 0.8540 - val_accuracy: 0.5897\n",
      "Epoch 8/100\n",
      "14000/14000 [==============================] - 4s 320us/step - loss: 0.8632 - accuracy: 0.5871 - val_loss: 0.8542 - val_accuracy: 0.5903\n",
      "Epoch 9/100\n",
      "14000/14000 [==============================] - 4s 300us/step - loss: 0.8612 - accuracy: 0.5899 - val_loss: 0.8547 - val_accuracy: 0.5913\n",
      "Epoch 10/100\n",
      "14000/14000 [==============================] - 4s 303us/step - loss: 0.8599 - accuracy: 0.5909 - val_loss: 0.8559 - val_accuracy: 0.5933\n",
      "Epoch 11/100\n",
      "14000/14000 [==============================] - 4s 307us/step - loss: 0.8588 - accuracy: 0.5980 - val_loss: 0.8517 - val_accuracy: 0.5917\n",
      "Epoch 12/100\n",
      "14000/14000 [==============================] - 5s 322us/step - loss: 0.8576 - accuracy: 0.5908 - val_loss: 0.8524 - val_accuracy: 0.5907\n",
      "Epoch 13/100\n",
      "14000/14000 [==============================] - 4s 310us/step - loss: 0.8557 - accuracy: 0.5961 - val_loss: 0.8530 - val_accuracy: 0.5907\n",
      "Epoch 14/100\n",
      "14000/14000 [==============================] - 4s 307us/step - loss: 0.8572 - accuracy: 0.5903 - val_loss: 0.8496 - val_accuracy: 0.5940\n",
      "Epoch 15/100\n",
      "14000/14000 [==============================] - 4s 310us/step - loss: 0.8544 - accuracy: 0.5945 - val_loss: 0.8482 - val_accuracy: 0.5950\n",
      "Epoch 16/100\n",
      "14000/14000 [==============================] - 5s 324us/step - loss: 0.8529 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5960\n",
      "Epoch 17/100\n",
      "14000/14000 [==============================] - 4s 309us/step - loss: 0.8524 - accuracy: 0.5952 - val_loss: 0.8475 - val_accuracy: 0.5963\n",
      "Epoch 18/100\n",
      "14000/14000 [==============================] - 4s 312us/step - loss: 0.8518 - accuracy: 0.5921 - val_loss: 0.8470 - val_accuracy: 0.5930\n",
      "Epoch 19/100\n",
      "14000/14000 [==============================] - 5s 321us/step - loss: 0.8509 - accuracy: 0.5913 - val_loss: 0.8501 - val_accuracy: 0.5943\n",
      "Epoch 20/100\n",
      "14000/14000 [==============================] - 10s 680us/step - loss: 0.8511 - accuracy: 0.5990 - val_loss: 0.8467 - val_accuracy: 0.5970\n",
      "Epoch 21/100\n",
      "14000/14000 [==============================] - 5s 335us/step - loss: 0.8487 - accuracy: 0.5961 - val_loss: 0.8487 - val_accuracy: 0.5953\n",
      "Epoch 22/100\n",
      "14000/14000 [==============================] - 4s 319us/step - loss: 0.8476 - accuracy: 0.5988 - val_loss: 0.8477 - val_accuracy: 0.5963\n",
      "Epoch 23/100\n",
      "14000/14000 [==============================] - 4s 314us/step - loss: 0.8496 - accuracy: 0.5949 - val_loss: 0.8479 - val_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "14000/14000 [==============================] - 5s 335us/step - loss: 0.8479 - accuracy: 0.5984 - val_loss: 0.8452 - val_accuracy: 0.5993\n",
      "Epoch 25/100\n",
      "14000/14000 [==============================] - 4s 316us/step - loss: 0.8459 - accuracy: 0.6014 - val_loss: 0.8463 - val_accuracy: 0.5980\n",
      "Epoch 26/100\n",
      "14000/14000 [==============================] - 4s 319us/step - loss: 0.8437 - accuracy: 0.6033 - val_loss: 0.8444 - val_accuracy: 0.6007\n",
      "Epoch 27/100\n",
      "14000/14000 [==============================] - 5s 326us/step - loss: 0.8465 - accuracy: 0.6010 - val_loss: 0.8506 - val_accuracy: 0.5930\n",
      "Epoch 28/100\n",
      "14000/14000 [==============================] - 4s 313us/step - loss: 0.8430 - accuracy: 0.6031 - val_loss: 0.8432 - val_accuracy: 0.6003\n",
      "Epoch 29/100\n",
      "14000/14000 [==============================] - 4s 314us/step - loss: 0.8466 - accuracy: 0.6005 - val_loss: 0.8471 - val_accuracy: 0.6013\n",
      "Epoch 30/100\n",
      "14000/14000 [==============================] - 4s 316us/step - loss: 0.8453 - accuracy: 0.6007 - val_loss: 0.8432 - val_accuracy: 0.5997\n",
      "Epoch 31/100\n",
      "14000/14000 [==============================] - 5s 323us/step - loss: 0.8433 - accuracy: 0.6021 - val_loss: 0.8491 - val_accuracy: 0.5943\n",
      "Epoch 32/100\n",
      "14000/14000 [==============================] - 4s 315us/step - loss: 0.8434 - accuracy: 0.6021 - val_loss: 0.8450 - val_accuracy: 0.5993\n",
      "Epoch 33/100\n",
      "14000/14000 [==============================] - 4s 312us/step - loss: 0.8440 - accuracy: 0.5979 - val_loss: 0.8429 - val_accuracy: 0.6033\n",
      "Epoch 34/100\n",
      "14000/14000 [==============================] - 5s 354us/step - loss: 0.8406 - accuracy: 0.6003 - val_loss: 0.8425 - val_accuracy: 0.6033\n",
      "Epoch 35/100\n",
      "14000/14000 [==============================] - 4s 314us/step - loss: 0.8398 - accuracy: 0.6017 - val_loss: 0.8449 - val_accuracy: 0.5997\n",
      "Epoch 36/100\n",
      "14000/14000 [==============================] - 5s 325us/step - loss: 0.8395 - accuracy: 0.6039 - val_loss: 0.8446 - val_accuracy: 0.5987\n",
      "Epoch 37/100\n",
      "14000/14000 [==============================] - 5s 322us/step - loss: 0.8412 - accuracy: 0.6016 - val_loss: 0.8437 - val_accuracy: 0.6050\n",
      "Epoch 38/100\n",
      "14000/14000 [==============================] - 4s 313us/step - loss: 0.8371 - accuracy: 0.6085 - val_loss: 0.8447 - val_accuracy: 0.5983\n",
      "Epoch 39/100\n",
      "14000/14000 [==============================] - 5s 357us/step - loss: 0.8389 - accuracy: 0.6003 - val_loss: 0.8446 - val_accuracy: 0.6010\n",
      "Epoch 40/100\n",
      "14000/14000 [==============================] - 6s 393us/step - loss: 0.8391 - accuracy: 0.6051 - val_loss: 0.8426 - val_accuracy: 0.6053\n",
      "Epoch 41/100\n",
      "14000/14000 [==============================] - 6s 405us/step - loss: 0.8385 - accuracy: 0.6022 - val_loss: 0.8429 - val_accuracy: 0.6050\n",
      "Epoch 42/100\n",
      "14000/14000 [==============================] - 4s 320us/step - loss: 0.8351 - accuracy: 0.6077 - val_loss: 0.8424 - val_accuracy: 0.6003\n",
      "Epoch 43/100\n",
      "14000/14000 [==============================] - 5s 332us/step - loss: 0.8346 - accuracy: 0.6068 - val_loss: 0.8425 - val_accuracy: 0.6017\n",
      "Epoch 44/100\n",
      "14000/14000 [==============================] - 5s 342us/step - loss: 0.8375 - accuracy: 0.6035 - val_loss: 0.8436 - val_accuracy: 0.6023\n",
      "Epoch 45/100\n",
      "14000/14000 [==============================] - 5s 325us/step - loss: 0.8358 - accuracy: 0.6068 - val_loss: 0.8415 - val_accuracy: 0.6020\n",
      "Epoch 46/100\n",
      "14000/14000 [==============================] - 5s 358us/step - loss: 0.8341 - accuracy: 0.6095 - val_loss: 0.8436 - val_accuracy: 0.6017\n",
      "Epoch 47/100\n",
      "14000/14000 [==============================] - 5s 330us/step - loss: 0.8322 - accuracy: 0.6128 - val_loss: 0.8411 - val_accuracy: 0.6047\n",
      "Epoch 48/100\n",
      "14000/14000 [==============================] - 4s 314us/step - loss: 0.8331 - accuracy: 0.6061 - val_loss: 0.8424 - val_accuracy: 0.6057\n",
      "Epoch 49/100\n",
      "14000/14000 [==============================] - 4s 315us/step - loss: 0.8309 - accuracy: 0.6082 - val_loss: 0.8437 - val_accuracy: 0.6060\n",
      "Epoch 50/100\n",
      "14000/14000 [==============================] - 4s 319us/step - loss: 0.8347 - accuracy: 0.6070 - val_loss: 0.8435 - val_accuracy: 0.6057\n",
      "Epoch 51/100\n",
      "14000/14000 [==============================] - 4s 314us/step - loss: 0.8324 - accuracy: 0.6053 - val_loss: 0.8418 - val_accuracy: 0.6040\n",
      "Epoch 52/100\n",
      "14000/14000 [==============================] - 4s 312us/step - loss: 0.8282 - accuracy: 0.6086 - val_loss: 0.8409 - val_accuracy: 0.6037\n",
      "Epoch 53/100\n",
      "14000/14000 [==============================] - 4s 314us/step - loss: 0.8317 - accuracy: 0.6092 - val_loss: 0.8412 - val_accuracy: 0.6033\n",
      "Epoch 54/100\n",
      "14000/14000 [==============================] - 5s 342us/step - loss: 0.8323 - accuracy: 0.6073 - val_loss: 0.8415 - val_accuracy: 0.6017\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 8s 557us/step - loss: 0.8305 - accuracy: 0.6098 - val_loss: 0.8429 - val_accuracy: 0.6010\n",
      "Epoch 56/100\n",
      "14000/14000 [==============================] - 4s 319us/step - loss: 0.8300 - accuracy: 0.6071 - val_loss: 0.8419 - val_accuracy: 0.6017\n",
      "Epoch 57/100\n",
      "14000/14000 [==============================] - 4s 302us/step - loss: 0.8284 - accuracy: 0.6082 - val_loss: 0.8440 - val_accuracy: 0.6020\n",
      "Epoch 58/100\n",
      "14000/14000 [==============================] - 5s 337us/step - loss: 0.8300 - accuracy: 0.6088 - val_loss: 0.8459 - val_accuracy: 0.5953\n",
      "Epoch 59/100\n",
      "14000/14000 [==============================] - 5s 357us/step - loss: 0.8300 - accuracy: 0.6138 - val_loss: 0.8425 - val_accuracy: 0.6007\n",
      "Epoch 60/100\n",
      "14000/14000 [==============================] - 4s 305us/step - loss: 0.8293 - accuracy: 0.6139 - val_loss: 0.8437 - val_accuracy: 0.5990\n",
      "Epoch 61/100\n",
      "14000/14000 [==============================] - 5s 330us/step - loss: 0.8244 - accuracy: 0.6138 - val_loss: 0.8403 - val_accuracy: 0.5983\n",
      "Epoch 62/100\n",
      "14000/14000 [==============================] - 4s 311us/step - loss: 0.8265 - accuracy: 0.6128 - val_loss: 0.8433 - val_accuracy: 0.6027\n",
      "Epoch 63/100\n",
      "14000/14000 [==============================] - 4s 305us/step - loss: 0.8247 - accuracy: 0.6148 - val_loss: 0.8438 - val_accuracy: 0.5997\n",
      "Epoch 64/100\n",
      "14000/14000 [==============================] - 4s 299us/step - loss: 0.8273 - accuracy: 0.6137 - val_loss: 0.8443 - val_accuracy: 0.6017\n",
      "Epoch 65/100\n",
      "14000/14000 [==============================] - 4s 299us/step - loss: 0.8244 - accuracy: 0.6137 - val_loss: 0.8425 - val_accuracy: 0.5993\n",
      "Epoch 66/100\n",
      "14000/14000 [==============================] - 4s 300us/step - loss: 0.8254 - accuracy: 0.6149 - val_loss: 0.8406 - val_accuracy: 0.6017\n",
      "Epoch 67/100\n",
      "14000/14000 [==============================] - 4s 320us/step - loss: 0.8235 - accuracy: 0.6184 - val_loss: 0.8429 - val_accuracy: 0.6020\n",
      "Epoch 68/100\n",
      "14000/14000 [==============================] - 4s 300us/step - loss: 0.8229 - accuracy: 0.6131 - val_loss: 0.8461 - val_accuracy: 0.5977\n",
      "Epoch 69/100\n",
      "14000/14000 [==============================] - 4s 309us/step - loss: 0.8202 - accuracy: 0.6177 - val_loss: 0.8452 - val_accuracy: 0.5947\n",
      "Epoch 70/100\n",
      "14000/14000 [==============================] - 4s 316us/step - loss: 0.8249 - accuracy: 0.6139 - val_loss: 0.8424 - val_accuracy: 0.5983\n",
      "Epoch 71/100\n",
      "14000/14000 [==============================] - 4s 302us/step - loss: 0.8187 - accuracy: 0.6233 - val_loss: 0.8456 - val_accuracy: 0.6003\n",
      "Epoch 72/100\n",
      "14000/14000 [==============================] - 5s 382us/step - loss: 0.8218 - accuracy: 0.6141 - val_loss: 0.8417 - val_accuracy: 0.6013\n",
      "Epoch 73/100\n",
      "14000/14000 [==============================] - 6s 462us/step - loss: 0.8196 - accuracy: 0.6155 - val_loss: 0.8460 - val_accuracy: 0.5927\n",
      "Epoch 74/100\n",
      "14000/14000 [==============================] - 5s 341us/step - loss: 0.8188 - accuracy: 0.6189 - val_loss: 0.8436 - val_accuracy: 0.6020\n",
      "Epoch 75/100\n",
      "14000/14000 [==============================] - 5s 348us/step - loss: 0.8191 - accuracy: 0.6184 - val_loss: 0.8448 - val_accuracy: 0.5970\n",
      "Epoch 76/100\n",
      "14000/14000 [==============================] - 5s 326us/step - loss: 0.8170 - accuracy: 0.6180 - val_loss: 0.8470 - val_accuracy: 0.5917\n",
      "Epoch 77/100\n",
      "14000/14000 [==============================] - 6s 435us/step - loss: 0.8178 - accuracy: 0.6168 - val_loss: 0.8435 - val_accuracy: 0.5963\n",
      "Epoch 78/100\n",
      "14000/14000 [==============================] - 5s 351us/step - loss: 0.8170 - accuracy: 0.6186 - val_loss: 0.8442 - val_accuracy: 0.5993\n",
      "Epoch 79/100\n",
      "14000/14000 [==============================] - 6s 398us/step - loss: 0.8170 - accuracy: 0.6200 - val_loss: 0.8439 - val_accuracy: 0.6017\n",
      "Epoch 80/100\n",
      "14000/14000 [==============================] - 5s 379us/step - loss: 0.8140 - accuracy: 0.6238 - val_loss: 0.8422 - val_accuracy: 0.5943\n",
      "Epoch 81/100\n",
      "14000/14000 [==============================] - 6s 393us/step - loss: 0.8145 - accuracy: 0.6204 - val_loss: 0.8423 - val_accuracy: 0.6030\n",
      "Epoch 82/100\n",
      "14000/14000 [==============================] - 5s 358us/step - loss: 0.8132 - accuracy: 0.6196 - val_loss: 0.8429 - val_accuracy: 0.5997\n",
      "Epoch 83/100\n",
      "14000/14000 [==============================] - 5s 375us/step - loss: 0.8129 - accuracy: 0.6228 - val_loss: 0.8438 - val_accuracy: 0.5943\n",
      "Epoch 84/100\n",
      "14000/14000 [==============================] - 5s 324us/step - loss: 0.8112 - accuracy: 0.6270 - val_loss: 0.8443 - val_accuracy: 0.5993\n",
      "Epoch 85/100\n",
      "14000/14000 [==============================] - 4s 308us/step - loss: 0.8136 - accuracy: 0.6249 - val_loss: 0.8448 - val_accuracy: 0.5953\n",
      "Epoch 86/100\n",
      "14000/14000 [==============================] - 4s 320us/step - loss: 0.8134 - accuracy: 0.6220 - val_loss: 0.8448 - val_accuracy: 0.5977\n",
      "Epoch 87/100\n",
      "14000/14000 [==============================] - 5s 362us/step - loss: 0.8102 - accuracy: 0.6278 - val_loss: 0.8435 - val_accuracy: 0.6063\n",
      "Epoch 88/100\n",
      "14000/14000 [==============================] - 4s 311us/step - loss: 0.8112 - accuracy: 0.6246 - val_loss: 0.8427 - val_accuracy: 0.5977\n",
      "Epoch 89/100\n",
      "14000/14000 [==============================] - 6s 420us/step - loss: 0.8085 - accuracy: 0.6274 - val_loss: 0.8452 - val_accuracy: 0.5940\n",
      "Epoch 90/100\n",
      "14000/14000 [==============================] - 5s 338us/step - loss: 0.8075 - accuracy: 0.6269 - val_loss: 0.8441 - val_accuracy: 0.5953\n",
      "Epoch 91/100\n",
      "14000/14000 [==============================] - 7s 487us/step - loss: 0.8108 - accuracy: 0.6255 - val_loss: 0.8443 - val_accuracy: 0.5937\n",
      "Epoch 92/100\n",
      "14000/14000 [==============================] - 5s 346us/step - loss: 0.8091 - accuracy: 0.6259 - val_loss: 0.8441 - val_accuracy: 0.5967\n",
      "Epoch 93/100\n",
      "14000/14000 [==============================] - 7s 519us/step - loss: 0.8078 - accuracy: 0.6291 - val_loss: 0.8430 - val_accuracy: 0.6047\n",
      "Epoch 94/100\n",
      "14000/14000 [==============================] - 5s 389us/step - loss: 0.8054 - accuracy: 0.6290 - val_loss: 0.8440 - val_accuracy: 0.5943\n",
      "Epoch 95/100\n",
      "14000/14000 [==============================] - 5s 342us/step - loss: 0.8069 - accuracy: 0.6251 - val_loss: 0.8433 - val_accuracy: 0.6000\n",
      "Epoch 96/100\n",
      "14000/14000 [==============================] - 5s 363us/step - loss: 0.8075 - accuracy: 0.6268 - val_loss: 0.8445 - val_accuracy: 0.6003\n",
      "Epoch 97/100\n",
      "14000/14000 [==============================] - 4s 270us/step - loss: 0.8049 - accuracy: 0.6247 - val_loss: 0.8481 - val_accuracy: 0.5870\n",
      "Epoch 98/100\n",
      "14000/14000 [==============================] - 4s 290us/step - loss: 0.8039 - accuracy: 0.6316 - val_loss: 0.8469 - val_accuracy: 0.5967\n",
      "Epoch 99/100\n",
      "14000/14000 [==============================] - 4s 261us/step - loss: 0.8034 - accuracy: 0.6298 - val_loss: 0.8447 - val_accuracy: 0.5980\n",
      "Epoch 100/100\n",
      "14000/14000 [==============================] - 4s 259us/step - loss: 0.8029 - accuracy: 0.6300 - val_loss: 0.8449 - val_accuracy: 0.5990\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "analysis = model.fit(X_train, y_train, batch_size=batch_size,epochs=100,verbose=1,validation_data=(X_valid, y_valid))\n",
    "trainTime = (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.014245581626891  minutes\n"
     ]
    }
   ],
   "source": [
    "print(trainTime/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7632112565040589\n",
      "Test accuracy: 0.6589999794960022\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])      # this is the categorical_crossentropy\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score =  0.5969507158631687\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(np.round(y_pred),axis=1) # Choose the prediction with the highest probability\n",
    "y_pred_one_hot = to_categorical(y_pred)\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred_one_hot, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results(analysis,\"W2V_CNN_100_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Gensim FastText model\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Training a Gensim FastText model\")\n",
    "model = FastText(sentences=tokenized_tweet, size = 200, window = 5) \n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "\n",
    "        vec += model[word].reshape((1, size))\n",
    "        count += 1.\n",
    "\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 200)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_arrays = np.zeros((len(tokenized_tweet), 200))\n",
    "\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    fasttext_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
    "    \n",
    "fasttext_df = pd.DataFrame(fasttext_arrays)\n",
    "fasttext_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(\n",
    "        fasttext_arrays, \n",
    "        sentiment,\n",
    "        train_size=0.85, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "# print(len(X_test))\n",
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        train_size=0.82352942, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 200)\n",
      "(3000, 200)\n",
      "(3000, 200)\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape))\n",
    "print((X_test.shape))\n",
    "print((X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.5816666666666667\n",
      "F1-Score =  0.5651131631800275\n",
      "[[723 118  59]\n",
      " [507 295 298]\n",
      " [109 164 727]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.SVC(kernel='linear',decision_function_shape='ovr', class_weight='balanced',random_state=0)\n",
    "lin_clf.fit(X_train, y_train)\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGDCAYAAAB0s1eWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xt8nHWZ9/HPlUPTJCWlkFI5tZCAq2ztKgRM7Yqs292lKsEVfIQKldpSaWmRChTqPnvQ3QW1UrQWy0LQpWDxUMWnrA1qcdHVNi6pQstBtFNtOWoDbWnTdJom1/PHPSGTycxkJplTJt/36zWv5r7nvmeuTBr65Xc0d0dEREREClNJvgsQERERkcQU1kREREQKmMKaiIiISAFTWBMREREpYAprIiIiIgVMYU1ERESkgCmsiYgUETM7zczczMryXYuIZIbCmoikxcz+YGadZnYw6nFS5Lm7zew5M+sxs6tSeK15ZvYbMztgZn80sx+Y2TFZ/yZyzMz+xcweiDo+OfJ9rzIzi7n2h2b22TivcbGZvaIQJjL6KKyJyFBc5O7joh4vRc4/CSwCfjXYC5jZe4Bbgcvd/RjgrcC3M1lkIQYbM5sC/AzY4O7X+cCVyf8TuDI2xAFXAt9w96M5KFNECojCmohkjLvf6e6PAodTuPxcYIu7/zpy72vufp+7HwAws0ozu93MdpnZfjP7uZlVRp5rMrOnzWyfmT1mZm/tfdFIy9/NZrYN6DCzMjM7ycy+a2Z7zOz3ZnZdvILMrDHSelUade7vI6+FmZ1nZm1m9nqkJXBlOp+PmdUTBLV17r4swWXfB44D3h113wTgA8DayPH7zezXkTqeN7N/SfKefzCzmVHHsa18jWa2OfJZPmlmF6TzPYlI9imsiUi+/BL4OzP7jJnNMLOKmOe/CJwDvIsgvCwDeszszcCDwPXARGAj8LCZjYm693Lg/cCxQA/wMEGr38nAXwPXm9nfxRbk7q1AB/DeqNOzgXWRr78MfNnda4B60msJrCMIav/h7v+Y6CJ374y87pyo0/8H+I27Pxk57og8f2zk+1xoZh9MoxYg6I4FfgD8G8FnfCPwXTObmO5riUj2KKyJyFB8P9ISs8/Mvj+UF3D3/wE+BJxNEBheNbOVZlZqZiXAx4FPuvuL7t7t7pvdPQx8BPiBu//Y3bsIQl0lQajrtcrdn48En3OBie7+WXc/4u47gXuAyxKU9iBB2CMyfu59kXMAXcAZZlbr7gcj4S5VU4Fq4FspXHsf8OHelkSCYHZf75Pu/pi7b3f3HnffFqnvPWnU0usKYKO7b4y81o+BNoLvWUQKhMKaiAzFB9392MgjpRadmAkJkwHcvcXdLyJo1bkYuAqYD9QCY4FQnJc6CdjVe+DuPcDzBK1mvZ6P+noKcFJUuNwHfBqYlKDUdcCHIi19HwJ+5e697zcPeDPwGzN73Mw+kMr3HrEB+Brwk8i4tYTc/efAHuBiM6sjCJy9rXuY2TvN7L8j3br7gWsIPrN0TSEIhdGfzV8CJw7htUQkSwpu8K2IFCd3H5fkuR7gUTP7CUEL1D0E497qCbovo70EvK33IDIQ/1TgxeiXjPr6eeD37n5minU+Y2a7gFn07wLF3X8HXB5p+fsQsN7Mjnf3jhRf+1OREPgTMzvf3V9Mcvlagha1PwN+5O5/jHpuHbAamOXuh83sSyQOax1AVdTxm6K+fh64392vTqV+EckPtayJSMaY2RgzGwsYUG5mYyPBJt61F5vZZWY2wQLnEXTltUbC29eAlZHJAaVmNj0SdL4NvN/M/trMyoEbgDCwOUFZ/wu8Hpl0UBl5ralmdm6Sb2UdcB1wPvCdqJqvMLOJkfr2RU53p/jx9FoM/IQgnCZq3YMgrM0EriaqCzTiGOC1SFA7jyBUJvIEcJmZlZtZA3Bp1HMPABeZ2d9FPpexZnaBmZ2S5vckIlmksCYimfQjoJNg/Njdka/PT3DtXoIg8jvgdYLgsMLdvxF5/kZgO/A48BrweaDE3Z8jGGv1FaAduIhgKZEj8d7E3bsj17wd+H3knmZgfJLv40HgAuAn7t4edf5C4GkzO0gw2eAydz8Mb3TzvnvAKw2sx4FPEITITWYWt0XM3f9AEECrCbpQoy0CPmtmB4B/IvlEh38kaKHcC3yG/i2FzxN0P3+aoNv1eeAm9G+DSEGxgUv8iIiIiEih0P89iYiIiBQwhTURERGRAqawJiIiIlLAFNZERERECpjCmoiIiEgBK5pFcWtra/20007LdxkiIiIig9q6dWu7u6e0D2/RhLXTTjuNtra2fJchIiIiMqjITikpUTeoiIiISAFTWBMREREpYAprIiIiIgVMYU1ERESkgCmsiYiIiBQwhTURERGRAqawJiIiIlLAFNZERETkDaEQLF0UZlJNJ6UlPUyq6WTpojChUL4rG70U1kREREap2GB2bFWYs9/Swdh7VrH5wFTCPobNB6ZS2byKxmkdtLQkvrdQQ128Oud+NMzHryj82nsprImIiBSRVENUSws0TuugsjkIZs/4WyjrPMAjR2dy29Fl1LOTMrqpZye3di1jw6GZzLm0g1Bo4L3JQt1wax9OsIpX520HruWhdZ0c/43M1p5V7l4Uj3POOcdFRERGs40b3WurDvry8i/4Duq8i1LfQZ0vL/+C11Yd9I0bg+t27Aiu20yjO7iDX89KX86/v3Ec73FL+Qqfe8XhAfdGPzbT6LVVB33HjuHXfi9zfTx7/UaSfz+9duxwv37hYT/hmENudHsV/evcQZ3X8qe4te+gzi/jG15Jh5dYt59wzCG/fuHhtL+PVAFtnmLGyXvIytRDYU1EREazeAEsUYi6fuFhX17+hX7Pn8ArvoO6pGFtB3U+vvzAgHvjhbql1x4eVu3JglW8UBgb9q7jDr+FW/vdkyiQbuRCr+VPvpx/TykUZoLCmoiIyCgTL4AlClEnHHNoQDAr4ah3UZr0/iOU+Vg6Ugp1k2o63qgtusUrXqtVvNpTbelbeu3huGEvXviMdy7dUJgp6YQ1jVkTEREpAuse6GFe111Jr5nftYZ193fTfrCCKezq91wt7exiStL7dzOZMGMH3BtrMrtpPzgWSG18W7za1zGbedwb9/VD1LGUlTR3zeFLd5Zzzls7mNv5VabT+sY17dQOqDPeudUs5mru6XdvtOm0Mr9rDXfeEU76PWeTwpqIiEgRiBfAooWoYxXXsf91GOOHBwSz2azjXuYlfY/m8oXUlA+8N9ZuJlM77jChEMy5tIMNh2Zya1fiSQvxao8XrABauJBGWqmkk1amc4QxlHd18AnvH/bihc9455KFwl69ITdfFNZERGTEGynLSGRT7bhwwhDVG3CqOMRTvI0F3E0z8/tds5jV3MPVbKFxwP0h6ricb/DlrkUc7irhLq5JWEeIOj5q3+BwJ/z5GYe56tBXB221OqZsYACMF6xC1DGHtWygiVv5hzfC32scPyDYxQuf8c4lCoXRolsK80FhTURERrRMLCNRDGFv9hUl3Fs+MERFB5zb+DT17OQ6vkIz8/sFs3p2spY5NLGBm7mNEHV0UcbXmMvZ/IqTeZHtvI0nmcbXmRs31LVwIefxv7zb/4etXW9jPPu5hsG7ZqFnQO3xglWiLst4wS5e+Ix3LtXu39pxh5Nek1WpDm4r9IcmGIiIFJ/BBqanMwMykVSXuyhEgy1VkcoMyFu41XdQ50co8x3U+SfK7vaa0gN+fFWwhEW81+y9dxm3vXHvo1zg49nX79pUJy2UWHdKs0ETzVhN53sMlgPZ5zewIjJr9EsDZo0Od3ZrKtBsUBERKVSDBbBeiULUNZEwcVzlIa+g029k6MtIZCLs5Uuidclq2OufigSRI5R5LX9MOHtzB3W+lNt9In/0Erp9Uk3HG7Mr3ZPPMO29dzx7vYRuH19+wG+yoS0HMqmmwzdudB9fftBvLFmRMFglCn+DrZ92OQ94FR1easH3OPeKw/7xjx72STWJA2khzQbNe8jK1ENhTUSk8A1n0dbolpKbIy0lycLADur8elZ6LX90I34oHCyMXM/KN8JIolCZavjMpGQhMzacGN0ptW6VlnQPeJ94S3wkClvxrk1n+Y2uLvfjjnN/S10QokpLBgarZMuG9P3duK1fS+Et5SsGbSHt/Xt5S/mKtO8dKoU1EREpOMNdtDVe60milpZUFzlNFEZSvT/dLtRMBbvhrqmWKHDFKrHUg168a9NZw2zjxuD0Qw8N/fveQZ032hYfP6Yv7EW3FCazY4f70mv7B8VU7x0KhTURkVEqH608qRpuwIjXSjPcRU6HEzAefTS9LtRUunWT/cyif7bpLEybzucea7gta9HBN3Zs3I0l/VutLr88aFkLhxP/HRrJ3daxFNZEREahdFp58hHq0vmHP16IihfM4gW4dLrehtN1d+7UjpRDUKrduqm24KU6cL+0pHtYASedoJfO+Laa8g6fcW7f37fXX3evrHRfuHDwv0f56LLMBoU1EZFRJp1/kPM1+3GwLrXemXljiT82KV5ASWfGYKqtTqneXzXM1q3htOCl8z26Dz3gpPP3Kt1QGPs/DDXlh3z2JYXZZZkNCmsiIqNMqi0gc684nLdupGQta7FdZfE24U4UUGLvHW6rU6r3pzNwP9MteOm0HvYaasBJJ+ilem3vdTeXjrzlUjJFYU1EZJRJtYtxfPmBtMcvZXtQfLwWpnjnkgWU6G62dDcajw0YmWhZi52JGi/YDed9cr35eDpBb7Bri2nc2XAorImIjDKpztobapDJRJdpon+kU13Q9Fne7MezZ9B/5Od+NL0B9T097m95i/uMhiBgpLp2W6Ixa/FmksZb6yxZC15v2DuBVxK24CUauF/oY7eGM+GhmCisiYjkUbyWqKtmH/a5Hx383FAH+afaspZO110mWkBiP4vxlYe9puyg31w2tEVbj63sHHB/bEBJt+7t24On1qzpqzmV++ONJUvU4pXqTNZ4YW+wteSSLWpbiIazlEgxUVgTEcmTRKvKj2ev30jyc8MZs5Nqa8X48tws+ZDos9hBnc+nbzuj0pL0F21NpUsu0dipTzGw1emf/9ndzP2VVwa//+aYVqv1692rODjo1kWpduum2/07Elui0lm7rZgprImI5EG8FplUx2Ol22KVynvHe83Bugh3UOfvtC0+vjz5avGDtYCk07qVrZaW2FB3fFWHl3PYb7+9/3V//ufu73nP4Pf3rqZ/xYf7WgonjD3k5Rz2iy9Mf4X9eN26qQa44f59ySe1rAUU1kRE8iBeS9Rw1wFLx8aN7sePPdhvX8gd1Pl861t0NdFm371h4jja32jtS2dWZSqfRaLvMVdjmLq73evr3c8/v+/cM88Eb/GVr6T2+R439qDfENMaenNZX2toKsuTfJI7vJIgAMZ266Y643WkjE+LR2PWAgprIiJ5EK/FIN4/vumukZWO665zH8NhP+GY/mHglrKBXbA3RIW6R7nAa9iX8lpesbMdY8fbpdN6ksvZgbfdFrzsb34THL/0kvtnPuP+4ovJ70u1xtrq9FuNolvwknUJ945Pm8TLbiNkfFo8mg0aUFgTEcmDeK0q8VqnhtJileryGWed1ddylM5m3+PLD/hNltpaXqnsm5nuuKRcrUr/8svuJ53k/qH3pzexI9XWoHR2NYhntHQRFssuBMOhsCYikgfZallLdfmMp54Kbr/zzuB4uHtxpjvebgd1fhnf8MoEOxCk08KUrVXph7oUSaoh6vhxh4bVajSaugiLYReC4VBYExEZhqEuApuNMWvpdBk9+aT7Bz8YtB65D38vzuhWtL6dBeLPdoxtbYu3A0G+Q8dwut/SaSkcTquRughHD4U1EUlbPjb2LkTDWQQ2G7NBh9PSkk7ASBbsotfyitdilqsZr8M1nM8y3e7J4bQaqYtwdFBYE5G05Gtj76HIdKiMfr1kMyUd/Ntc4jWlB7y2OvF7P/hgsO7Wjdb3D20woH9fvwH98c7toM5vKun/D3KqIeGEYzp8587+31s6ASPVIFMSZwB8qjsQ5Dt0DGc8WK67J0d7F+FooLAmIikbSd0umQ6Vsa+XrOuuN3jcxOeSvvc//mNwy8cuH7g+18c/mvzcuNIOP/H4/v8gJ2sd652R2bslUSWH/JqP992fTsAYzmzHkbLC/nAWYx1JvycyMiisiUjKhtJikI8u00z/Yxnv9RKFjlQH1ZdYEJjecvrQPouVK4OX/e1v+84lag1KZUZmup9ZKt1v8f6+DGc9tlwa7kxLdU9KJhVMWAMuBJ4DdgC3xHn+KmAP8ETkMT/quS8ATwPPAqsAS/ZeCmsiQ5PuP2CJWreuKetbeDUbAS7T3VDphI50l7CIXiQ1Hbt2BS99223J60xnPFi6AWOw7rd0Qm6qIShXMvF3SN2TkikFEdaAUiAE1AFjgCeBs2KuuQpYHefedwG/iLxGKbAFuCDZ+ymsiQxNOl1DiVpq+rbRuTVrAS7T60+lusxGovPZGkB/3nnuDQ19x/E+83R3QMh0wIgNgIlmiA41SGeLujKlkBRKWJsO/DDqeDmwPOaaRGFtOrAVqASqgDbgrcneT2FNZGiGOwg9UWhJFOCGOr4s05s/x3u9RCEoXotbtraMWrPGfe5c9yNH+s7dfLN7JQd9WWnyLYly2ZIVHQBLLPnEjEIKQerKlEJRKGHtUqA56vjK2GAWCWsvA9uA9cCpUc99EdgH7Af+fbD3U1gTGZrhLpyaq42nc9GylqjuXG8ZFa2nJ2hpmzLF/fpFg29JNJTgmgkjKQSpK1MKQaGEtQ/HCWtfibnmeKAi8vU1wE8iX58B/AAYF3lsAc6P8x4LIq1ubZMnT87SxylS3NLpGorXGhUvtGSj1en6hYf9liyPWYtuEYxebmIuzX4Tn+t3XTYH1f/ud+5XXd43gWMsh3zm+UPbdzOXFIJEUlcoYW3QbtCY60uB/ZGvbwL+Meq5fwKWJXs/tayJDN3DD7tX28EBa37FtorECwnxQksmWp1iZ5weV93p4yy7s0Gja4veN/P4cYe8piw3g+o3bnQ/dsxBv4H+Ezhuieo+Hk1bEokUq0IJa2XATuD0qAkGfx5zzYlRX/890Br5+iPApshrlAOPAhclez+FNZGhW7cu+K/BxRf2bxX54PsO91tGIl5IiBdahtvqlGjG6Yf4jldFjd3qDZXzbWgTGXrf5+YUuu5yMag+1VbORx/VQHmRka4gwlpQB+8DfhuZFfoPkXOfBZoiX99GsDzHk8B/A2+JnC8F/oNg2Y5ngJWDvZfCmkTT1knJxX4+1SWHfNKx/YPZAw8E/4X4+c/735fKzMThtDoNFlh6dxGYOC4IlcdWdnpN2UG/pWxoC+Wm03WX7UH16bSYjaQxYiIyUMGEtVw+FNak10jaOikfEn0+y0r7fz6vv+4+dqz7tdf2v7+5ObKdUkkQEp7lzX48e4a1tES0bKy6nygw/elP7u94h/tjjw3vs8xUYMrl/pMikl8KazJqaR2l5NL9fD78YfcTTnDv6up7jSVL3MvL3T9xVV9I6G3durkscYBL9eeQqf0se7diGs9eLyF+6+rttweXP/XU8D7TTAWmTC9PIiKFS2FNRi0NvE4u3c/nu98NTv/4x32v8eqrwYSEWLGhJTbAJWt1it1MPdXAku5WTLGL9FaXHPJTTyiclqhCneUpIpmnsCajlv6xSy7dz+epp9yryw/7+DFDG/uXSqtTbLdsOuPd4rVEpbtIb2z3bz7pfzZERg+FNRm1CqEbqZAnN6Tz+bwxHitm4P5Q973s6HD/0Y/c29v7zg13K6V8LtKbDerGFxk9FNZk1Mp3y1qhT25I9fM5ftyhjIeGtrbg9gcf7Ds33E3KU11KJFtbQ2WDZnmKjA4KazJqxLZijS8/6DfZ0AecD7eWQm8VSbWb7dypHRnvjjtyxL2y0v266/rODTbmLHoXgXiBJd5nnq1FenNJszxFip/CmowK8VqxHuUCr2Fv1jcVj2ckjDdKNVDWVmenhfL8893PPbfvOFm37A7qfCm3+yRediNxYIlticrGIr0iIpmmsCZFL1no2MiFfhztb2ydlGwZiR3U+WV8wyvpGPb4smx1wWZ6DNy3vuV+TOnAXQCiW62yNfbv5pvdy8rcDx0KjjP1mUW3RFXQ6TcyeNdoIbesiUjxSyeslSAyAq2+PczVXV9lOq0DnpvFI/wv5/EL+0vOGbOdt/Mkc/n6gGtbuJBGWjmdP7CdtxH2MWw+MJXK5lU0TuugpSW9mtoPVjCFXUmvmcxu2g+OTfk1W1qgcVoHlc2r2Hxg6pBqDIVg6aIwk2o6KS3pYcn8Ti75SBntly1hRs12KkvCzKjZTnjBElq3VTNrFtSOC7OLKUlfdzeTqR13OOXvBWD6dDh6FLZuDY5nX1HCveXXJL2nuXwhs68sTXpNfT2sXF3BK/ureHrHWP6zahFbaHzj+dms417mDft9RETyItVUV+gPtayNLum0yMS7NhuzA4ey+nyyFrOhjIEbMIav8vCQtmLKVpfu/v3uW7f2LbKbrXF+sV2jw1mkV0QkG1A3qBS7dLrp4l2bbHbgUCciDGVfx2SzRtMNTLGv+RvOHHJAyeVkiY0b3Y8fe9A/RWZnPw5nkV4RkWxTWJOiFN1qNJaOYbWsJRrDlGjl+1QmIuzY4X7c2MEDzqOPDn+Qf2+grOWPbnT7cdVBEMnU/pzu2VtCYvNm91tuce/p6Tu3YIF7BYf9hGOyO/tRsyxFpFAorEnRiW01uo47/BZuTSmIxGuhijc7MFnXaLyJCFfNPuxzP9q/G3PisUe8ioN+c0zAuTkq4KTaYlaSYNuleIFyLs1+E59LKZDGC7SJZCPcrF4dvP0f/hAcd3W5n3ii+0UXDf01RURGGoU1KSrxuuTSGXMW7/50Fk6NF47uZa6PZ6/fSP9uzBv4gh9T3uEf+kAk4Fi3Txjb4Us+0RdwUh3bVhWn9TDR9z2SlqvYujV4+3XrguNw2P3rX3f/6U9zWoaISF4prMmIF93lGW8phugQNdjCqe4Du/Su40sDWubiBZ544Wi4kxMGW1vselb6CbziY+J834kC5UhaCLary72qyn3Jkpy+rYhIQUknrGnpDik4sctVjGc/13DXgOtm8QitNBKmgulsYSwDl6B449pZ0LqtmvCCYLmK1baEVVzXb3mHdmoHLL2xmsVczT39lv2Idy7adFqZ37WGO+8IA3DwINx3X/AnJF4Wo3cpkUo62cy72MY0vs7cfjWuYzbzuHfAvbW0D3jNQl2uYtcuOGF8mK/dGSwlMmFsJwvnhQmFclqGiMjIkWqqK/SHWtaKQ6rbB2WiOy+Vle9TPZesxep//ic4vXZt8L7p7IfZ23q4jNt8B3UJP4uRsnl572d+U0lmNocXERmpUDeojFSpbsydqe68wVa+jxeO0g2PPT3up5ziXndK0K1rdHsVqc/c7N12aTx7E86CTTXs5XO5ipGwd6qISK6kE9bUDSp5F73C/l1rupnX1b/LM5vdeYOtfB+vezHeuVjRq/s/8ggc+GMHf/9C0K17hDF8hSVcSAs3soIQdQm7NwHq2clKbmAr51BR3hN3xf96drKWOTSxgZv4PCHq6KKMN/NbLin7PneVLuadVfF3K8iVZLtOwMDuYxERiUg11RX6Qy1rI1PskhzpLqmR6RaZVCYipLN+WbLWpB3U+eU84FV0uCVYpiO2ta7EupO2Tn2bS7ym9IBPHFd464hla+9UEZGRCHWDykiQ6pIa0d15qcz8zERdvV2jJTawyzKd8Jjqmmrjy1Nf5Ddbi9VmW7Y2hxcRGYnSCWvqBpW8idctlqjLM3rm5zlsTTrzc7iiu0a7e0pYv7GapqpNLC8Puiwns5vPczOzeOSNbswuyghRx/LyFTRVbWLt+mrq62HdAz0DunVjze9aA8Tv3ozW29UbO7M1n12b6cjW5vAiIsXOgnA38jU0NHhbW1u+y5A0TKrpZPOBqdSz841zIepopJUNNMUd27SFRpqqNtG6LQhDuRIKwZ13hFl3fzftB8dSO+4w72sqxRx+8HDfudlXlnLt0oo3aist6SHsYyijO+Frd1HGWAtzXGUnGw7NLKjvO5OWLgpT2byKW7uWJbxmefkKwguWsHJ1RQ4rExHJPTPb6u4NKV2rsCb5kijItHAhc1jLfJqZTzOT2c1uJtNcvpDm8oWsXV+4rUex4gXSWCHqmFGzna9/s4o5l3Ywv2sN87vWjOjvO55QKFg/r5gDqYhIqtIJa+oGlbxJ1C2WzmK3hW72FSVF372Zqvp6WLu+f5dyou5jERHpo5Y1yZvR0C2m1qSB4nUpx3Yfi4gUO3WDyogwWoJMSwtF3b0pIiLpUzeojAi93WIfGLuJGwaZVTmSFXv3poiIZJda1iTvPvWpoFvs2GO6ebVD3WIiIlL80mlZK8t2MSKDefJJeOtfVPDEE71nqvJZjoiISEFRN6jkVTgMmzfDX/1VvisREREpTAprkle//CUcPgwXXJDvSkRERAqTukElr97xDvh//09hTUREJBG1rElWhELBOmqTajopLelhUk0nSxeFCYX6X3fMMdDUBDU1+alTRESk0CmsybDFBrNjq8Kc/ZYOxt6zis0HphL2MWw+MJXK5lU0TuugpSW4r7MTbrsNdibeiUlERGTUU1iTYWlpCRa2rWwOgtkz/hbKOg/wyNGZ3HZ0GfXspIxu6tnJrV3L2HBoJnMu7SAUgi1b4NOfhmefzfd3ISIiUrg0Zk2GLBQKVuaP3oFgKStZwN1xdyQAmE4r87vWcOcdS6ieUEFJCbz73bmsWkREZGRRWJMhW317mKu7vtovmK1jNpt5V9L75netYcb9izjjbXDOORqvJiIikoy6QWXI1j3Qw7yuu/qda6eWKexKeE+IOlZxHftfh82/6OG3T8afeCAiIiIBhTUZsvaDFQOCWS3t7GJK3OtbuJBGWqniEE/xNo4whq1HBk48EBERkT4KazJktePCA4LZbNZxL/MGXBuijjmsZQNN3Mank048EBERkT4KazJks68o4d7ya/qdW8xq7uFqttDY7/xqFnM196Qw8SCctXpFRERGIoU1GbLFN1RwT/mifsGsnp2sZQ5NbOBmbiNEHV2U8QAfZR6iM0sVAAAgAElEQVT3Jn29+V1rWHd/d7bLFhERGVEU1mTI6uth7fpqmqo2cZOteCOYvZnfcknZ97mrdDHvrNpOZUmYVweZeAAwmd20Hxybo+pFRERGhqyGNTO70MyeM7MdZnZLnOevMrM9ZvZE5DE/6rnJZvYjM3vWzJ4xs9OyWasMzaxZsOXJau6pWMLZ5UEwm1GznapPzOFXz42jvaOKo90lTDxm4Pi2WLuZTO24wzmqXEREZGTIWlgzs1LgTmAWcBZwuZmdFefSb7n72yOP5qjza4EV7v5W4DzgT9mqVYanqwv2H65g5ZogmL2yv4qVqyuor++7Jt74tljN5QuZfWVplqsVEREZWbLZsnYesMPdd7r7EeCbwMWp3BgJdWXu/mMAdz/o7oeyV6oMx6FD8Nd/DRdckPiaeOPbom2hkebyhVy7tCI7RYqIiIxQ2QxrJwPPRx2/EDkX6xIz22Zm683s1Mi5NwP7zOx7ZvZrM1sRaanrx8wWmFmbmbXt2bMn89+BpOScc2DTJvq1pMWKHt+2vLxvfFuIOpaXr6CpahNr11cnfQ0REZHRKJthzeKc85jjh4HT3H0asAm4L3K+DHg3cCNwLlAHXDXgxdzvdvcGd2+YOHFipuqWNLjD66+ndu2sWdC6rZrwgiXMqOkb3xZesITWbdXMmpXdWkVEREaibIa1F4BTo45PAV6KvsDdX3X33oW17gHOibr315Eu1KPA94Gzs1irDNFvfwsTJsD69aldX18PK1dX8Mr+xOPbREREpE82w9rjwJlmdrqZjQEuAzZEX2BmJ0YdNgHPRt07wcx6m8veCzyTxVpliH76U+jpgWnT8l2JiIhIcSrL1gu7+1EzWwz8ECgFvubuT5vZZ4E2d98AXGdmTcBR4DUiXZ3u3m1mNwKPmpkBWwla3qTAPPYYvOlNcOaZ+a5ERESkOJl77DCykamhocHb2tryXcao4g6nnALnnw8PPpjvakREREYOM9vq7g2pXKsdDGTIduyAl16C97wn35WIiIgUL4U1GbJjj4UvfxnN4hQREcmirI1Zk+IUCsHq28Ose6CH9oMV1I4L8/vflLD4Bs3oFBERyQa1rEnKWlqgcVoHlc2r2HxgKmEfw+YDU6lsXkXjtA5aWvJdoYiISPHRBANJSSgUBLUNh2YyndYBz2+hkaaqTbRu0y4EIiIig9EEA8m41beHubrrq3GDGsB0WpnftYY77wjHfV5ERESGRmFNEgqFYOmiMJNqOrlrTTfzuu5Kev38rjWsu787R9WJiIiMDgprElfs+LQjVDCFXUnvmcxu2g+OzVGFIiIio4Nmg8oAoRDMubT/+LRa2tnFFOrZmfC+3UymdtxhoCpHlYqIiBQ/tazJAPHGp81mHfcyL+l9zeULmX1labbLExERGVXUsiYDrHugh80x49MWs5pGWrmIhxPOBm0uX0jr0opclSkiIjIqqGVNBmg/OHB8Wj07WcscmtjAcm4lRB1dlBGijuXlK2iq2sTa9Vq2Q0REJNMU1mSA2nFhdjFlwPlZPEIrjYSpYDpbGEuYGTXbCS9YQuu2am07JSIikgUKazLA7CtKuLf8mrjP1bOTldzAvPK1fPLaLl7ZX8XK1dpqSkREJFsU1mSAxTdUcE/5IrbQGPf53vFp12p8moiISNYprMkA9fWwdn01TVWbWF6+QuPTRERE8kizQSWuujq48hPV7H99CTO+s4j2g2OpHXeY2VeW0rpU3Z4iIiK5orAmcd19N6xeDS+8UMFXm3vParFbERGRXFM3qAwQDsPatdDUBCeckO9qRERERjeFNQH6b9peVdnDwfZO/HCYUCjflYmIiIxuCmsyYNP2sI/hKaby5h+tonFaBy0t+a5QRERk9DJ3z3cNGdHQ0OBtbW35LmPECYWCoBa9aXu0LTTSVLWJ1m2a/SkiIpIpZrbV3RtSuVYta6NcvE3bo02nlflda7jzjnCOKxMRERFQWBv11j3Qw7yYTdtjze9aw7r7u3NUkYiIiERTWBvl4m3aHmsyu2k/ODZHFYmIiEg0hbVRLtGm7dF2M5nacYdzVJGIiIhEU1gb5ZJt2t6ruXwhs68szVFFIiIiEk1hbZTTpu0iIiKFTWFtlOvdtP1vbBM3ok3bRURECo3CmjBrFvyktZr2y5Ywo2Y7lSVhZtRsJ7xgCa3bqpk1K98VioiIjF7ayF0AOO88OO/B6K5ObdouIiJSCNSyNsrt3QszZ0Jr/DVxRUREJM8U1kah6E3ba4/r4RePdrJ6pTZtFxERKUQKa0UsOpSVlvQwqaaTD76/i3e+LWrTdoJN2yd/X5u2i4iIFCKFtSLV0hJs0P5GKPMxPHjgfTy2sYOHO2dya9cy6tlJGd3Us5Nbu5ax4dBM5lzaoRY2ERGRAqKwVoRCIZhzaQcbDvUPZQ/TxCK0abuIiMhIorBWhFbfHubqroGhbB2zmce9Se/Vpu0iIiKFRUt3FKF1D/SwueuuAefbqdWm7SIiIiOMWtaKUPvBirihrJZ2bdouIiIywiisFaHaceG4oWw267iXeUnv1abtIiIihSXlsGZmlWb2Z9ksRjJj9hUl3Ft+zYDzi1nNPVytTdtFRERGkJTCmpldBDwBPBI5fruZbchmYTJ0i2+o4J7yRQNCWT07WcscPsB/adN2ERGRESLVlrV/Ac4D9gG4+xPAadkpSQYTb7HbpYv6diCor4e166tpqtrEzaX9Q9nPyv8aH1vJ7z+gTdtFRERGglTD2lF335/ui5vZhWb2nJntMLNb4jx/lZntMbMnIo/5Mc/XmNmLZrY63fcuVvEWu918YCqVzf13IJg1C1q3VfOtiUt4e0n/UPb4U1V89+EKXtlfxdHuEl7ZX8XK1RVqURMRESlAqS7d8ZSZzQZKzexM4Dpgc7IbzKwUuBP4G+AF4HEz2+Duz8Rc+i13X5zgZf4V+GmKNRa96MVuo9dQ692B4KKu79F06SZatwVdmZMmwYvtFdy4DG67DaAqb7WLiIjI0KTasrYE+HMgDKwD9gPXD3LPecAOd9/p7keAbwIXp1qYmZ0DTAJ+lOo9xS7RYre9Yncg+NnP4OhRmDkzl1WKiIhIJg0a1iItZJ9x939w93Mjj//r7oMtxnUy8HzU8QuRc7EuMbNtZrbezE6NvGcJcDtwU2rfxuiw7oEe5sVZ7DZa9A4EmzbB2LEwY0YuqhMREZFsGDSsuXs3cM4QXtvivVzM8cPAae4+DdgE3Bc5vwjY6O7Pk4SZLTCzNjNr27NnzxBKHFkSLXYbLXoHguefh7/8yyCwiYiIyMiU6pi1X0eW6vgO0NF70t2/l+SeF4BTo45PAV6KvsDdX406vAf4fOTr6cC7zWwRMA4YY2YH3f2WmPvvBu4GaGhoiA2CRad2XJhdB6ZQz86E1/TtQFDFd74DR47krj4RERHJvFTHrB0HvAq8F7go8vjAIPc8DpxpZqeb2RjgMqDf2mxmdmLUYRPwLIC7f9TdJ7v7acCNwNrYoDYaJVrsNlrsDgRjxmS7KhEREcmmlFrW3H1uui/s7kfNbDHwQ6AU+Jq7P21mnwXa3H0DcJ2ZNQFHgdeAq9J9n9Fk8Q0VNN63iIu6vhd3kkHvDgStSytYuhTa2+H++/NQqIiIiGSMuQ/ee2hmpwBfAWYQjDv7OfBJd38hu+WlrqGhwdva2vJdRta1tATLd3zs0BoWsobJ7GY3k2kuX0hz+ULWrq/mwgvh9NPh7LPhe8k6qkVERCQvzGyruzekcm2q3aBfJ+jCPIlgRufDkXOSY7NmwcbHqlnFEhoq+ha73XvFEr58T7ADwc6dsGuXluwQEREpBqmGtYnu/nV3Pxp5/CcwMYt1SRLPPw9dVPCDn/TtQPC7XRUsmhdsQfXmM3oYSyeP/7xvCyoREREZmVINa+1mdoWZlUYeVxBMOJA8eOwxqKqChkjjaUsLPLG5g/mHI1tQMYanmMqb1vffgkpERERGnlTHrE0GVhMsqeEEW0190t2TL/qVQ6NlzBrAtGnwpjfBj34UbEHVOG3gFlS9ttBIU1XfFlQiIiKSf+mMWUt1NuhugqU1JM/cYckSmBjphE59C6olrFxdkcNKRUREJBNSbVm7j6AlbV/keAJwu7t/PMv1pWw0taxFm1TTyeYDU5MulBuijhk123llvzZyFxERKQTZmA06rTeoAbj7XuAdQylOhueXvwxmevZKdwsqERERGVlSDWslkdY0AMzsOFLfqkoy6OqrYcGCvuPacWF2MSXpPX1bUImIiMhIk2pYux3YbGb/amb/SjDB4AvZK0viaW+H7dvhggv6zg1lCyoREREZOVIKa+6+FrgE+GPk8SF310ZGOfaznwV/Roe1xTdUcE/5IrbQGPee3i2orl2qyQUiIiIjUdKwZmZVZlYO4O7PAD8GyoG35KA2iRG7vhpAfT2sXV9NU9UmlpevIEQdXZQRoo7l5StoqtrE2vVatkNERGSkGqxl7RHgNAAzOwPYAtQB15rZ57JbmkCwjtrSRcHOBKu/0kNJuJNln+y/M8GsWdC6rZrwgiXMqOnbgiq8YAmt24ItqERERGRkGiysTXD330W+/hjwoLsvAWYB789qZUJLS7DgbWVzsDPBEcbwRPdUKpsH7kxQXw8rV1fwyv6+LahWrq5Qi5qIiMgIN1hYi16E7b0E3aC4+xGgJ1tFSdCiNufSYGeCW7uWUc9Oyuimnp3c2rWMDYdmMufSDu39KSIiUuQGC2vbzOyLZrYUOAP4EYCZHZv1yka51HcmCOe4MhEREcmlwcLa1UA7wbi1v3X3Q5HzZwFfzGJdo966B3qY13VX0mvmd61h3f3dOapIRERE8iHpwrbu3gn0m0hgZme7+2aCtdYkS7QzgYiIiEDqi+JGa854FTKAdiYQERERGFpYs4xXIQNoZwIRERGBoYW1z2S8ChlAOxOIiIgIDCGsufv3AcxMuxhkkXYmEBERERhay1qvH2WsilEoemeC0pIeJtV0snTRwJ0JtjypnQlERERGs6SzQc1sVaKnAK21NkQtLcGCt1d3fZXNXXcxhV3sOjCFe5uvofG+Raxd3xfE5s6Fc8+t4JX9vXdX5atsERERyYOkYQ2YC9wAxFt59fLMl1P8oncmiF7wtndngou6vkfTpZto3VZNTQ384hfwt3+bx4JFREQkrwYLa48DT0XWVevHzP4lKxUVudR3JlhCw7sqcIcLL8xxkSIiIlIwBgtrlwJxF/Jy99MzX07xW/dAD5tT2Jlgxv2LaH8damvhnHNyVJyIiIgUnMEmGIyL2mJKMiCdnQl++MOgC7RkONNAREREZEQbLAZ8v/cLM/tulmsZFdLZmeCTn4SPfSxHhYmIiEhBGiysRe9WUJfNQkaLdHYm+PSnNblARERktBssrHmCr2WIku1MEKKOy/kGX+5axJfvLI+79pqIiIiMLoOFtb8ws9fN7AAwLfL162Z2wMxez0WBxSZ6Z4Kb6NuZ4GvM5Wx+xcm8yHbeRpgxbD4wlcrmVTRO66ClJd+Vi4iISD6Ye3E0mDU0NHhbW1u+y0hZKATTzwkT7ujmYPdYxnonm5gZd0mPLTTSVBWsvabtpUREREY+M9vq7g2pXKt5hnlSXw//9G8V3PedKq67potPlqey9lq8tYlFRESkmKllrQBMqulk84Gp1LMz4TUh6phRs51X9mu7KRERkZFOLWsjQEdH0BV65Eh6a6+JiIjI6KKwliebN8MZZ0Bra3prr4mIiMjoorCWJy+9FPx50knprb0mIiIio4vCWp68+GLw58knJ197DYLZoM3lC7l2aUUOKxQREZFCoLCWJy++CBMmQGVl/7XXlpf3rb0Woo7l5StoqtrE2vVatkNERGQ0UljLk5deCrpAe82aBa3bqgkvWMKMmu1UloSZUbOd8IIltG6rZtas/NUqIiIi+aOlO/Jk0ybYvx8uuSTflYiIiEiupbN0R1m2i5H4Zs7MdwUiIiIyEqgbNA+6u+Gxx2DPnnxXIiIiIoVOYS0P/vhH+Ku/gvXr812JiIiIFLqshjUzu9DMnjOzHWZ2S5znrzKzPWb2ROQxP3L+7Wa2xcyeNrNtZvaRbNaZa9HLdoiIiIgkk7Uxa2ZWCtwJ/A3wAvC4mW1w92diLv2Wuy+OOXcImOPuvzOzk4CtZvZDd9+XrXpzSWFNREREUpXNlrXzgB3uvtPdjwDfBC5O5UZ3/627/y7y9UvAn4CJWas0xxTWREREJFXZDGsnA89HHb8QORfrkkhX53ozOzX2STM7DxgDhOI8t8DM2sysbc8IGq3/4otQWgonnJDvSkRERKTQZTOsWZxzsYu6PQyc5u7TgE3Aff1ewOxE4H5grrv3DHgx97vdvcHdGyZOHDkNb1ddBQ89BCWa3iEiIiKDyOY6ay8A0S1lpwAvRV/g7q9GHd4DfL73wMxqgB8A/9fdW7NYZ869+c3BQ0RERGQw2WzbeRw408xON7MxwGXAhugLIi1nvZqAZyPnxwAPAWvd/TtZrDEvNmyA7dvzXYWIiIiMBFkLa+5+FFgM/JAghH3b3Z82s8+aWVPksusiy3M8CVwHXBU5/3+A84Gropb1eHu2as21OXPg7rvzXYWIiIiMBFndbsrdNwIbY879U9TXy4Hlce57AHggm7XlS0dHsCeoZoKKiIhIKjTEPcdeiozaU1gTERGRVCis5VjvGmsnnZTfOkRERGRkUFjLMS2IKyIiIulQWMux978fNm+G00/PdyUiIiIyEmR1goEMdOyxMH16vqsQERGRkUItazn20EPBOmsiIiIiqVDLWo6tWAGVldDUNPi1IiIiImpZy7EXX9TkAhEREUmdwloO9fTAyy8rrImIiEjqFNZyqL0durq0xpqIiIikTmEth7TGmoiIiKRLEwxyaNo02L0bJkzIdyUiIiIyUiis5VBpKZx6ar6rEBERkZFE3aA59IMfwOc/n+8qREREZCRRWMuhhx6CL30p31WIiIjISKKwlkNaY01ERETSpbCWQy+9pGU7REREJD0KaxkUCsHSRWEm1XRSWtLDpJpO5n40zMevCM5t39bDTx/pZOmiMKFQvqsVERGRkUBhLUNaWqBxWgeVzavYfGAqYR/DbQeu5aF1nRz/jeDcEcbwq66pVDavonFaBy0t+a5aRERECp25e75ryIiGhgZva2vLy3uHQkFQ23BoJtNpDc5RRyOtbKDpjXPRttBIU9UmWrdVU1+f64pFREQkn8xsq7s3pHKtWtYyYPXtYa7u+mq/ULaaxVzNPXGDGsB0WpnftYY77wjnqkwREREZgdSylgGTajrZfGAq9ezsO8crbOZd/c7FClHHjJrtvLK/KhdlioiISIFQy1qOtR+sYAq7+p+jdsC5WJPZTfvBsdksTUREREY4hbUMqB0XZhdT+p+jfcC5WLuZTO24w9ksTUREREY4hbUMmH1FCfeWX9P/HOu4l3lJ72suX8jsK0uzWZqIiIiMcAprGbD4hgruKV/EFhr7zrGae7i637loW2ikuXwh1y6tyFWZIiIiMgIprGVAfT2sXV9NU9UmlpevIEQdk9nN57mZWTzCjQTnuigjRB3Ly1fQVLWJteu1bIeIiIgkp9mgGRQKwZ13hLnrzm7CjGVizWHe11SKOfzg4W7aD46ldtxhZl9ZyrVLKxTURERERql0ZoMqrGVYOAxjx8K//Rv8wz/kuxoREREpROmEtbJsFzPajBkD7e1QXp7vSkRERKQYKKxlmBkcf3y+qxAREZFioQkGGfb73wfdnzsTb1wgIiIikjKFtQx77jm49VZ45ZV8VyIiIiLFQGEtw/btC/6cMCG/dYiIiEhxUFjLsN6wduyx+a1DREREioPCWobt3Rv8qbAmIiIimaCwlmH790NFBVRW5rsSERERKQYKaxl2223w2mv5rkJERESKhcJahplBVVW+qxAREZFiobCWYbffDqtW5bsKERERKRYKaxn2rW9BS0u+qxAREZFiobCWYfv2aSaoiIiIZI7CWobt26cFcUVERCRzshrWzOxCM3vOzHaY2S1xnr/KzPaY2RORx/yo5z5mZr+LPD6WzTozxT1YZ00tayIiIpIpZdl6YTMrBe4E/gZ4AXjczDa4+zMxl37L3RfH3Hsc8M9AA+DA1si9e7NVbyZ0dgbrq6llTURERDIla2ENOA/Y4e47Aczsm8DFQGxYi+fvgB+7+2uRe38MXAg8mKVaM6KqCl5/PWhhExEREcmEbHaDngw8H3X8QuRcrEvMbJuZrTezU9O518wWmFmbmbXt2bMnU3UPm1m+KxAREZFikc2wFi+yxLY5PQyc5u7TgE3AfWnci7vf7e4N7t4wceLEYRWbCU8/DZdfDs8+m+9KREREpFhkM6y9AJwadXwK8FL0Be7+qruHI4f3AOekem8h+v3v4ZvfhIMH812JiIiIFItshrXHgTPN7HQzGwNcBmyIvsDMTow6bAJ626R+CPytmU0wswnA30bOFbR9+4I/NcFAREREMiVrEwzc/aiZLSYIWaXA19z9aTP7LNDm7huA68ysCTgKvAZcFbn3NTP7V4LAB/DZ3skGhWxvZK6qlu4QERGRTMnmbFDcfSOwMebcP0V9vRxYnuDerwFfy2Z9mdbbsjZ+fH7rEBERkeKhHQwyqKwMTjsNysvzXYmIiIgUC4W1DFq+PJhkICIiIpIpCmsiIiIiBUxhLYM+9Sn49KfzXYWIiIgUk6xOMBhtHnsMTo63R4OIiIjIEKllLYP27tUaayIiIpJZCmsZtG+f1lgTERGRzFJYy5CeHti/X2FNREREMkthLUM6O2HaNJgyJd+ViIiISDFRWEtBKARLF4WZVNNJaUkPk2o6WbooTCjUd011NTzxBMybl786RUREpPgorA2ipQUap3VQ2byKzQemEvYxbD4wlcrmVTRO66ClJd8VioiISDFTWEsiFII5l3aw4dBMbu1aRj07KaObenZya9cyNhyayZxLOwiF4Je/hHe+E558Mt9Vi4iISDFRWEti9e1hru76KtNpjfv8dFqZ37WGO+8I89JL8L//C+45LlJERESKmsJaEuse6GFe111Jr5nftYZ193ezb19wrNmgIiIikkkKa0m0H6xgCruSXjOZ3bQfHMvevcGxwpqIiIhkksJaErXjwuwi+Vocu5lM7bjD7NsHZlBTk6PiREREZFRQWEti9hUl3Ft+TdJrmssXMvvKUk48Ed77XijRJyoiIiIZZF4kI+IbGhq8ra0to68ZCgXLdmw4NDPuJIMtNNJUtYnWbdXU12f0rUVERKSImdlWd29I5Vq1AyVRXw9r11fTVLWJ5eUrCFFHF2WEqGN5+Qqaqjaxdr2CmoiIiGSPwtogZs2C1m3VhBcsYfq47YwlzPRx2wkvWELrtmpmzQqu+/CHYf78/NYqIiIixacs3wWMBPX1sHJ1BStX956pGnDNb34DZ56Z07JERERkFFDLWpq6uqC9feD5vXthwoTc1yMiIiLFTS1raZo5M1ii47HH+p/ft09rrImIiEjmqWUtTXV1sGNH/3NdXdDRobAmIiIimaewlqb6enjxRTh0qO/ckSPwwQ/C1Kn5q0tERESKk7pB03TGGcGfO3f2hbPqanjoofzVJCIiIsVLLWtp6g1rsV2hIiIiItmgsJamP/sz+Nzn4Kyz+s795CcwcSJkeAMFEREREXWDpuuYY+Dmm/ufe/XVYDmPysr81CQiIiLFSy1rQ/DKK/DEE33He/cGf2o2qIiIiGSawtoQ3HhjMPuz1759wZ8KayIiIpJpCmtDcMYZsHs3hMPB8b59UFYGVQN3oRIREREZFoW1ITjjDHCH3/8+OJ42DT7+8WBnAxEREZFMUlgbgt7lO0Kh4M/LLoP/+I/81SMiIiLFS2FtCGLXWuvpyV8tIiIiUtwU1obg+ONh3TpoagqOZ8yAiy/Ob00iIiJSnLTO2hCYweWX9x3v3QuTJ+evHhERESlealkboueeg+99L/h63z4t2yEiIiLZobA2RGvXwkc+Al1dQcuawpqIiIhkg8LaEJ1xBhw9GrSwHTmisCYiIiLZobA2RL0zQn/7W/jUp6CxMb/1iIiISHHSBIMh6g1rL78Mt9+e31pERESkeKllbYje9KZge6lnnoGOjmBHAxEREZFMy2pYM7MLzew5M9thZrckue5SM3Mza4gcl5vZfWa23cyeNbPl2axzKMzgZz+D886DcePgl7/Md0UiIiJSjLIW1sysFLgTmAWcBVxuZmfFue4Y4DogOu58GKhw97cB5wCfMLPTslXrUJ1zDpSXB19PmJDfWkRERKQ4ZbNl7Txgh7vvdPcjwDeBeOv8/yvwBeBw1DkHqs2sDKgEjgCvZ7HWIXnySVi2LPhas0FFREQkG7IZ1k4Gno86fiFy7g1m9g7gVHf/r5h71wMdwMvAbuCL7v5aFmtNWygEN30yzKsvdmL0MO3MTpYuCr+xubuIiIhIJmQzrFmcc28MwzezEuAO4IY4150HdAMnAacDN5hZ3YA3MFtgZm1m1rZnz57MVJ2ClhZonNbB2T9fxVNM5Qhj2HxgKpXNq2ic1kFLS85KERERkSKXzbD2AnBq1PEpwEtRx8cAU4HHzOwPQCOwITLJYDbwiLt3ufufgF8ADbFv4O53u3uDuzdMnDgxS99Gf6EQzLm0gw2HZvK57mXUs5MyuqlnJ7d2LWPDoZnMubRDLWwiIiKSEdkMa48DZ5rZ6WY2BrgM2ND7pLvvd/dadz/N3U8DWoEmd28j6Pp8rwWqCYLcb7JYa8pW3x7m6q6vMp3WuM9Pp5X5XWu4845wjisTERGRYpS1sObuR4HFwA+BZ4Fvu/vTZvZZM2sa5PY7gXHAUwSh7+vuvi1btaZj3QM9zOu6K+k187vWsO7+7hxVJCIiIsXMvEhWc21oaPC2trasv09pSQ9hH0MZicNYF2VUloQ52q01h0VERGQgM9vq7gOGeMWjNJGm2nFhdjEl6TW7mUztuMNJrxEREToo9EsAAAYjSURBVBFJhcJammZfUcK95dckvaa5fCGzryzNUUUiIiJSzBTW0rT4hgruKV/EFhrjPr+FRprLF3Lt0oocVyYiIiLFSGEtTfX1sHZ9NU1Vm1hevoIQdXRRRog6lpevoKlqE2vXV1Nfn+9KRUREpBgorA3BrFnQuq2a8IIlzKjZTmVJmBk12wkvWELrtmpmzcp3hSIiIlIsNBtUREREJMc0G1RERESkSCisiYiIiBQwhTURERGRAqawJiIiIlLAFNZERERECpjCmoiIiEgBU1gTERERKWAKayIiIiIFrGgWxTWzPcCuDL9sLdCe4deUzNDPprDp51O49LMpbPr5FK5M/2ymuPvEVC4smrCWDWbWlurqwpJb+tkUNv18Cpd+NoVNP5/Clc+fjbpBRURERAqYwpqIiIhIAVNYS+7ufBcgCelnU9j08ylc+tkUNv18ClfefjYasyYiIiJSwNSyJiIiIlLAFNbiMLMLzew5M9thZrfku57RzsxONbP/NrNnzexpM/tk5PxxZvZjM/td5M8J+a51tDKzUjP7tZn9V+T4dDP7ZeRn8y0zG5PvGkcrMzvWzNab2W8iv0PT9btTGMxsaeS/aU+Z2YNmNla/O/ljZl8zsz+Z2VNR5+L+rlhgVSQnbDOzs7NZm8JaDDMrBe4EZgFnAZeb2Vn5rWrUOwrc4O5vBRqBayM/k1uAR939TODRyLHkxyeBZ6OOPw/cEfnZ7AXm5aUqAfgy8Ii7vwX4C4Kfk3538szMTgauAxrcfSpQClyGfnfy6T+BC2POJfpdmQWcGXksANZkszCFtYHOA3a4+053PwJ8E7g4zzWNau7+srv/KvL1AYJ/bE4m+LncF7nsPuCD+alwdDOzU4D3A82RYwPeC6yPXKKfTZ6YWQ1wPnAvgLsfcfd96HenUJQBlWZWBlQBL6Pfnbxx958Br8WcTvS7cjGw1gOtwLFmdmK2alNYG+hk4Pmo4xci56QAmNlpwDuAXwKT3P1lCAIdcEL+KhvVvgQsA3oix8cD+9z9aORYv0P5UwfsAb4e6aZuNrNq9LuTd+7+IvBFYDdBSNsPbEW/O4Um0e9KTrOCwtpAFuecpswWADMbB3wXuN7dX893PQJm9gHgT+6+Nfr0/2/nfl6sqsM4jr8fnFzYJsKVmFgQbVMQBisYUiQGqU0/FkUi+Se40U20aNumoEXYToQI0fkDChoIokAoqEX0AxukSQlEHZABPy3OGRr0Tq2c7xfO+7W55557Fg9cnsPnnu/zvTMutYfamAMOAh8nOQDcwSXPLoyzT68ATwJ7gEcZltbuZ+/0aVvvc4a1B60AT2x6vxe41qgWjarqEYagdj7JxfH06sZj5/H1r1b1TdhzwMtV9TvDyMCLDE/aHhuXdsAeamkFWEnyzfj+c4bwZu+0dxT4Lcn1JOvAReAw9k5vtuqVbc0KhrUHfQs8Pe7I2ckw8LnUuKZJG2egzgE/Jflg00dLwInx+ARwebtrm7okZ5LsTbKfoVe+SPIm8CXw6niZ300jSf4E/qiqZ8ZTR4AfsXd6cBWYr6pd4z1u47uxd/qyVa8sAW+Pu0LngZsby6UPg3+KO0NVLTI8HdgBfJrk/cYlTVpVPQ8sAz/w71zUWYa5tc+AfQw3vteS3D8cqm1SVQvA6STHq+ophidtjwNXgLeS3G1Z31RV1bMMmz92Ar8CJxl+qNs7jVXVe8AbDDverwCnGOae7J0GquoCsADsBlaBd4FLzOiVMWB/xLB7dA04meS7h1abYU2SJKlfLoNKkiR1zLAmSZLUMcOaJElSxwxrkiRJHTOsSZIkdcywJkkzVNXtTceLVfVzVe1rWZOkaZr7/0skabqq6gjwIXAsydXW9UiaHsOaJG2hql4APgEWk/zSuh5J0+Sf4krSDFW1DtwCFpJ837oeSdPlzJokzbYOfA2807oQSdNmWJOk2e4BrwOHqups62IkTZcza5K0hSRrVXUcWK6q1STnWtckaXoMa5L0H5L8XVUvAV9V1Y0kl1vXJGla3GAgSZLUMWfWJEmSOmZYkyRJ6phhTZIkqWOGNUmSpI4Z1iRJkjpmWJMkSeqYYU2SJKljhjVJkqSO/QNkCj88gn/K1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value =  87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "error_rate = []\n",
    "# Will take some time\n",
    "best_k = 0\n",
    "k=0\n",
    "for i in range(1,100):\n",
    " \n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(X_train,y_train)\n",
    " pred_i = knn.predict(X_test)\n",
    " f=f1_score(y_test, pred_i, average='macro')\n",
    " if f>best_k:\n",
    "        best_k = f\n",
    "        k=i\n",
    " error_rate.append(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "markerfacecolor='red', markersize=10)\n",
    "plt.title('F1-Score vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.savefig('/Users/gaurav/Desktop/Hinglish/data/k/k_ex6-fasttext-1.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Best K value = \",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.592\n",
      "F1-Score =  0.5914976136177522\n",
      "[[629 218  53]\n",
      " [385 449 266]\n",
      " [ 80 222 698]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=87)\n",
    "clf = knn.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.459\n",
      "F1-Score =  0.462135374420752\n",
      "[[415 347 138]\n",
      " [334 440 326]\n",
      " [125 353 522]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "dtree_model.fit(X_train, y_train) \n",
    "y_pred = dtree_model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.5393333333333333\n",
      "F1-Score =  0.498848539556677\n",
      "[[802  43  55]\n",
      " [682 145 273]\n",
      " [202 127 671]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-53adc00c182e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMNB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Score = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    608\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    609\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "y_pred = MNB.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.47733333333333333\n",
      "F1-Score =  0.43558116889685344\n",
      "[[123 736  41]\n",
      " [ 73 811 216]\n",
      " [  8 494 498]]\n"
     ]
    }
   ],
   "source": [
    "diff = (max([max(i) for i in wordvec_arrays ]) - min([min(i) for i in wordvec_arrays ]))\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train+diff, y_train)\n",
    "y_pred = MNB.predict(X_test+diff)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.5776666666666667\n",
      "F1-Score =  0.5645962968637664\n",
      "[[676 152  72]\n",
      " [452 319 329]\n",
      " [ 97 165 738]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "log_model = log_model.fit(X_train, y_train)\n",
    "y_pred = log_model.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.856989351908366  minutes\n",
      "Accuracy Score =  0.588\n",
      "F1-Score =  0.5919501829469992\n",
      "[[564 279  57]\n",
      " [311 532 257]\n",
      " [ 63 269 668]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced')\n",
    "import time\n",
    "start_time=time.time()\n",
    "model.fit(X_train, y_train) \n",
    "duration = time.time()-start_time\n",
    "print(duration/60, \" minutes\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(\n",
    "        fasttext_arrays, \n",
    "        out,\n",
    "        train_size=0.85, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        train_size=0.82352942, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 200)\n",
      "(3000, 200)\n",
      "(3000, 200)\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape))\n",
    "print((X_test.shape))\n",
    "print((X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_results(nn_model_train,s): # plot performance over the training epochs\n",
    "  accuracy     = nn_model_train.history['accuracy']\n",
    "  val_accuracy = nn_model_train.history['val_accuracy']\n",
    "  loss         = nn_model_train.history['loss']\n",
    "  val_loss     = nn_model_train.history['val_loss']\n",
    "  epochs       = range(len(accuracy))\n",
    "  nb_epochs    = len(epochs)\n",
    "\n",
    "  f2 = plt.figure(2)\n",
    "  plt.figure(figsize = (30,10))\n",
    "\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.axis((0,nb_epochs,0.4,0.8))\n",
    "  plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "  plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.legend()\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.axis((0,nb_epochs,0.8,1.0))\n",
    "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "  plt.savefig('/Users/gaurav/Desktop/Hinglish/data/EX-6/'+s+'.png',bbox_inches='tight')\n",
    "  plt.draw()\n",
    "  plt.pause(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 64\n",
    "epochs      = 50\n",
    "learning_rate = 0.0003\n",
    "\n",
    "model = keras.Sequential()\n",
    " \n",
    "nr_hidden = 200\n",
    "nr_in     = 200\n",
    "nr_out    = 3 \n",
    "model.add(Dense(nr_in,activation='relu'))\n",
    "model.add(Dense(nr_hidden, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-100, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-100, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-150, activation = 'relu'))\n",
    "model.add(Dense(nr_hidden-150, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(nr_out,activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=learning_rate)\n",
    "model.compile(optimizer=opt,loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 200)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 3000 samples\n",
      "Epoch 1/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 1.0911 - accuracy: 0.3310 - val_loss: 1.0908 - val_accuracy: 0.3273\n",
      "Epoch 2/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 1.0861 - accuracy: 0.3310 - val_loss: 1.0864 - val_accuracy: 0.3277\n",
      "Epoch 3/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 1.0817 - accuracy: 0.3310 - val_loss: 1.0824 - val_accuracy: 0.3277\n",
      "Epoch 4/5500\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 1.0776 - accuracy: 0.3311 - val_loss: 1.0785 - val_accuracy: 0.3283\n",
      "Epoch 5/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 1.0735 - accuracy: 0.3318 - val_loss: 1.0745 - val_accuracy: 0.3327\n",
      "Epoch 6/5500\n",
      "14000/14000 [==============================] - 0s 36us/step - loss: 1.0695 - accuracy: 0.3560 - val_loss: 1.0708 - val_accuracy: 0.4160\n",
      "Epoch 7/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 1.0657 - accuracy: 0.4268 - val_loss: 1.0674 - val_accuracy: 0.4600\n",
      "Epoch 8/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 1.0622 - accuracy: 0.4529 - val_loss: 1.0642 - val_accuracy: 0.4727\n",
      "Epoch 9/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 1.0589 - accuracy: 0.4603 - val_loss: 1.0610 - val_accuracy: 0.4773\n",
      "Epoch 10/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 1.0555 - accuracy: 0.4647 - val_loss: 1.0579 - val_accuracy: 0.4750\n",
      "Epoch 11/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 1.0522 - accuracy: 0.4680 - val_loss: 1.0547 - val_accuracy: 0.4710\n",
      "Epoch 12/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 1.0488 - accuracy: 0.4692 - val_loss: 1.0516 - val_accuracy: 0.4757\n",
      "Epoch 13/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 1.0455 - accuracy: 0.4719 - val_loss: 1.0485 - val_accuracy: 0.4820\n",
      "Epoch 14/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 1.0421 - accuracy: 0.4782 - val_loss: 1.0452 - val_accuracy: 0.4867\n",
      "Epoch 15/5500\n",
      "14000/14000 [==============================] - 1s 37us/step - loss: 1.0387 - accuracy: 0.4785 - val_loss: 1.0420 - val_accuracy: 0.4910\n",
      "Epoch 16/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 1.0353 - accuracy: 0.4822 - val_loss: 1.0388 - val_accuracy: 0.4960\n",
      "Epoch 17/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 1.0320 - accuracy: 0.4872 - val_loss: 1.0357 - val_accuracy: 0.4970\n",
      "Epoch 18/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 1.0286 - accuracy: 0.4923 - val_loss: 1.0325 - val_accuracy: 0.4993\n",
      "Epoch 19/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 1.0254 - accuracy: 0.4941 - val_loss: 1.0295 - val_accuracy: 0.5033\n",
      "Epoch 20/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 1.0222 - accuracy: 0.4981 - val_loss: 1.0265 - val_accuracy: 0.5047\n",
      "Epoch 21/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 1.0191 - accuracy: 0.5021 - val_loss: 1.0235 - val_accuracy: 0.5067\n",
      "Epoch 22/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 1.0160 - accuracy: 0.5044 - val_loss: 1.0206 - val_accuracy: 0.5127\n",
      "Epoch 23/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 1.0130 - accuracy: 0.5091 - val_loss: 1.0178 - val_accuracy: 0.5127\n",
      "Epoch 24/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 1.0101 - accuracy: 0.5111 - val_loss: 1.0152 - val_accuracy: 0.5157\n",
      "Epoch 25/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 1.0073 - accuracy: 0.5134 - val_loss: 1.0125 - val_accuracy: 0.5197\n",
      "Epoch 26/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 1.0045 - accuracy: 0.5151 - val_loss: 1.0099 - val_accuracy: 0.5197\n",
      "Epoch 27/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 1.0019 - accuracy: 0.5171 - val_loss: 1.0075 - val_accuracy: 0.5223\n",
      "Epoch 28/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9993 - accuracy: 0.5205 - val_loss: 1.0051 - val_accuracy: 0.5243\n",
      "Epoch 29/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9968 - accuracy: 0.5206 - val_loss: 1.0028 - val_accuracy: 0.5237\n",
      "Epoch 30/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9943 - accuracy: 0.5220 - val_loss: 1.0005 - val_accuracy: 0.5267\n",
      "Epoch 31/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9920 - accuracy: 0.5217 - val_loss: 0.9984 - val_accuracy: 0.5293\n",
      "Epoch 32/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9897 - accuracy: 0.5219 - val_loss: 0.9962 - val_accuracy: 0.5307\n",
      "Epoch 33/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9875 - accuracy: 0.5234 - val_loss: 0.9942 - val_accuracy: 0.5293\n",
      "Epoch 34/5500\n",
      "14000/14000 [==============================] - 1s 36us/step - loss: 0.9853 - accuracy: 0.5229 - val_loss: 0.9922 - val_accuracy: 0.5303\n",
      "Epoch 35/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9832 - accuracy: 0.5243 - val_loss: 0.9903 - val_accuracy: 0.5303\n",
      "Epoch 36/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9811 - accuracy: 0.5254 - val_loss: 0.9883 - val_accuracy: 0.5303\n",
      "Epoch 37/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9791 - accuracy: 0.5257 - val_loss: 0.9865 - val_accuracy: 0.5290\n",
      "Epoch 38/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9771 - accuracy: 0.5264 - val_loss: 0.9848 - val_accuracy: 0.5290\n",
      "Epoch 39/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9752 - accuracy: 0.5256 - val_loss: 0.9830 - val_accuracy: 0.5303\n",
      "Epoch 40/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9733 - accuracy: 0.5257 - val_loss: 0.9813 - val_accuracy: 0.5307\n",
      "Epoch 41/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9715 - accuracy: 0.5271 - val_loss: 0.9796 - val_accuracy: 0.5290\n",
      "Epoch 42/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9698 - accuracy: 0.5278 - val_loss: 0.9781 - val_accuracy: 0.5267\n",
      "Epoch 43/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9681 - accuracy: 0.5282 - val_loss: 0.9765 - val_accuracy: 0.5273\n",
      "Epoch 44/5500\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 0.9664 - accuracy: 0.5284 - val_loss: 0.9750 - val_accuracy: 0.5277\n",
      "Epoch 45/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9648 - accuracy: 0.5286 - val_loss: 0.9734 - val_accuracy: 0.5270\n",
      "Epoch 46/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9632 - accuracy: 0.5281 - val_loss: 0.9720 - val_accuracy: 0.5287\n",
      "Epoch 47/5500\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 0.9616 - accuracy: 0.5296 - val_loss: 0.9706 - val_accuracy: 0.5283\n",
      "Epoch 48/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9601 - accuracy: 0.5296 - val_loss: 0.9693 - val_accuracy: 0.5277\n",
      "Epoch 49/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9587 - accuracy: 0.5305 - val_loss: 0.9679 - val_accuracy: 0.5273\n",
      "Epoch 50/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.9573 - accuracy: 0.5309 - val_loss: 0.9666 - val_accuracy: 0.5287\n",
      "Epoch 51/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9559 - accuracy: 0.5315 - val_loss: 0.9653 - val_accuracy: 0.5290\n",
      "Epoch 52/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9546 - accuracy: 0.5319 - val_loss: 0.9642 - val_accuracy: 0.5287\n",
      "Epoch 53/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9533 - accuracy: 0.5330 - val_loss: 0.9630 - val_accuracy: 0.5267\n",
      "Epoch 54/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9520 - accuracy: 0.5328 - val_loss: 0.9619 - val_accuracy: 0.5260\n",
      "Epoch 55/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9508 - accuracy: 0.5340 - val_loss: 0.9608 - val_accuracy: 0.5260\n",
      "Epoch 56/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9497 - accuracy: 0.5344 - val_loss: 0.9597 - val_accuracy: 0.5263\n",
      "Epoch 57/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9486 - accuracy: 0.5354 - val_loss: 0.9587 - val_accuracy: 0.5270\n",
      "Epoch 58/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9475 - accuracy: 0.5348 - val_loss: 0.9577 - val_accuracy: 0.5273\n",
      "Epoch 59/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9464 - accuracy: 0.5351 - val_loss: 0.9567 - val_accuracy: 0.5273\n",
      "Epoch 60/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9454 - accuracy: 0.5348 - val_loss: 0.9558 - val_accuracy: 0.5267\n",
      "Epoch 61/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9444 - accuracy: 0.5346 - val_loss: 0.9550 - val_accuracy: 0.5253\n",
      "Epoch 62/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9435 - accuracy: 0.5350 - val_loss: 0.9540 - val_accuracy: 0.5260\n",
      "Epoch 63/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9425 - accuracy: 0.5344 - val_loss: 0.9531 - val_accuracy: 0.5257\n",
      "Epoch 64/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9416 - accuracy: 0.5346 - val_loss: 0.9523 - val_accuracy: 0.5260\n",
      "Epoch 65/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9408 - accuracy: 0.5343 - val_loss: 0.9516 - val_accuracy: 0.5253\n",
      "Epoch 66/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9399 - accuracy: 0.5346 - val_loss: 0.9509 - val_accuracy: 0.5260\n",
      "Epoch 67/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9391 - accuracy: 0.5343 - val_loss: 0.9501 - val_accuracy: 0.5257\n",
      "Epoch 68/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9384 - accuracy: 0.5339 - val_loss: 0.9494 - val_accuracy: 0.5257\n",
      "Epoch 69/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9376 - accuracy: 0.5331 - val_loss: 0.9487 - val_accuracy: 0.5260\n",
      "Epoch 70/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9369 - accuracy: 0.5349 - val_loss: 0.9480 - val_accuracy: 0.5270\n",
      "Epoch 71/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9362 - accuracy: 0.5346 - val_loss: 0.9474 - val_accuracy: 0.5267\n",
      "Epoch 72/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9355 - accuracy: 0.5358 - val_loss: 0.9468 - val_accuracy: 0.5273\n",
      "Epoch 73/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9349 - accuracy: 0.5360 - val_loss: 0.9463 - val_accuracy: 0.5277\n",
      "Epoch 74/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9342 - accuracy: 0.5356 - val_loss: 0.9457 - val_accuracy: 0.5277\n",
      "Epoch 75/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9337 - accuracy: 0.5355 - val_loss: 0.9452 - val_accuracy: 0.5283\n",
      "Epoch 76/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9331 - accuracy: 0.5361 - val_loss: 0.9447 - val_accuracy: 0.5290\n",
      "Epoch 77/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9325 - accuracy: 0.5364 - val_loss: 0.9442 - val_accuracy: 0.5283\n",
      "Epoch 78/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9320 - accuracy: 0.5363 - val_loss: 0.9437 - val_accuracy: 0.5287\n",
      "Epoch 79/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9315 - accuracy: 0.5371 - val_loss: 0.9432 - val_accuracy: 0.5290\n",
      "Epoch 80/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9309 - accuracy: 0.5366 - val_loss: 0.9427 - val_accuracy: 0.5287\n",
      "Epoch 81/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9304 - accuracy: 0.5366 - val_loss: 0.9425 - val_accuracy: 0.5280\n",
      "Epoch 82/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9300 - accuracy: 0.5371 - val_loss: 0.9422 - val_accuracy: 0.5287\n",
      "Epoch 83/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9295 - accuracy: 0.5363 - val_loss: 0.9416 - val_accuracy: 0.5293\n",
      "Epoch 84/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9291 - accuracy: 0.5371 - val_loss: 0.9412 - val_accuracy: 0.5277\n",
      "Epoch 85/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9287 - accuracy: 0.5381 - val_loss: 0.9408 - val_accuracy: 0.5277\n",
      "Epoch 86/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9282 - accuracy: 0.5376 - val_loss: 0.9404 - val_accuracy: 0.5280\n",
      "Epoch 87/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9278 - accuracy: 0.5386 - val_loss: 0.9401 - val_accuracy: 0.5280\n",
      "Epoch 88/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.9275 - accuracy: 0.5385 - val_loss: 0.9400 - val_accuracy: 0.5300\n",
      "Epoch 89/5500\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.9283 - accuracy: 0.53 - ETA: 0s - loss: 0.9274 - accuracy: 0.53 - 0s 25us/step - loss: 0.9271 - accuracy: 0.5380 - val_loss: 0.9395 - val_accuracy: 0.5277\n",
      "Epoch 90/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9267 - accuracy: 0.5390 - val_loss: 0.9392 - val_accuracy: 0.5270\n",
      "Epoch 91/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9264 - accuracy: 0.5387 - val_loss: 0.9388 - val_accuracy: 0.5270\n",
      "Epoch 92/5500\n",
      "14000/14000 [==============================] - 1s 36us/step - loss: 0.9261 - accuracy: 0.5389 - val_loss: 0.9386 - val_accuracy: 0.5270\n",
      "Epoch 93/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9257 - accuracy: 0.5398 - val_loss: 0.9384 - val_accuracy: 0.5277\n",
      "Epoch 94/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9254 - accuracy: 0.5399 - val_loss: 0.9381 - val_accuracy: 0.5280\n",
      "Epoch 95/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9251 - accuracy: 0.5394 - val_loss: 0.9380 - val_accuracy: 0.5297\n",
      "Epoch 96/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9248 - accuracy: 0.5391 - val_loss: 0.9377 - val_accuracy: 0.5287\n",
      "Epoch 97/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9245 - accuracy: 0.5392 - val_loss: 0.9376 - val_accuracy: 0.5293\n",
      "Epoch 98/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9242 - accuracy: 0.5406 - val_loss: 0.9371 - val_accuracy: 0.5300\n",
      "Epoch 99/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9240 - accuracy: 0.5398 - val_loss: 0.9370 - val_accuracy: 0.5303\n",
      "Epoch 100/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9237 - accuracy: 0.5405 - val_loss: 0.9369 - val_accuracy: 0.5313\n",
      "Epoch 101/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9235 - accuracy: 0.5396 - val_loss: 0.9367 - val_accuracy: 0.5320\n",
      "Epoch 102/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9232 - accuracy: 0.5408 - val_loss: 0.9364 - val_accuracy: 0.5323\n",
      "Epoch 103/5500\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.9230 - accuracy: 0.5409 - val_loss: 0.9362 - val_accuracy: 0.5320\n",
      "Epoch 104/5500\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.9228 - accuracy: 0.5411 - val_loss: 0.9358 - val_accuracy: 0.5320\n",
      "Epoch 105/5500\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.9226 - accuracy: 0.5412 - val_loss: 0.9358 - val_accuracy: 0.5327\n",
      "Epoch 106/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9223 - accuracy: 0.5406 - val_loss: 0.9355 - val_accuracy: 0.5327\n",
      "Epoch 107/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9221 - accuracy: 0.5411 - val_loss: 0.9354 - val_accuracy: 0.5323\n",
      "Epoch 108/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9219 - accuracy: 0.5413 - val_loss: 0.9351 - val_accuracy: 0.5340\n",
      "Epoch 109/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9217 - accuracy: 0.5412 - val_loss: 0.9350 - val_accuracy: 0.5330\n",
      "Epoch 110/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9215 - accuracy: 0.5420 - val_loss: 0.9352 - val_accuracy: 0.5347\n",
      "Epoch 111/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9214 - accuracy: 0.5409 - val_loss: 0.9348 - val_accuracy: 0.5340\n",
      "Epoch 112/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9212 - accuracy: 0.5410 - val_loss: 0.9344 - val_accuracy: 0.5343\n",
      "Epoch 113/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9210 - accuracy: 0.5424 - val_loss: 0.9344 - val_accuracy: 0.5337\n",
      "Epoch 114/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9208 - accuracy: 0.5422 - val_loss: 0.9342 - val_accuracy: 0.5337\n",
      "Epoch 115/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9207 - accuracy: 0.5423 - val_loss: 0.9341 - val_accuracy: 0.5337\n",
      "Epoch 116/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9205 - accuracy: 0.5425 - val_loss: 0.9340 - val_accuracy: 0.5343\n",
      "Epoch 117/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9204 - accuracy: 0.5434 - val_loss: 0.9341 - val_accuracy: 0.5357\n",
      "Epoch 118/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9202 - accuracy: 0.5434 - val_loss: 0.9339 - val_accuracy: 0.5350\n",
      "Epoch 119/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9201 - accuracy: 0.5429 - val_loss: 0.9334 - val_accuracy: 0.5347\n",
      "Epoch 120/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9200 - accuracy: 0.5436 - val_loss: 0.9336 - val_accuracy: 0.5347\n",
      "Epoch 121/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9198 - accuracy: 0.5432 - val_loss: 0.9335 - val_accuracy: 0.5353\n",
      "Epoch 122/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9197 - accuracy: 0.5433 - val_loss: 0.9333 - val_accuracy: 0.5337\n",
      "Epoch 123/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9195 - accuracy: 0.5429 - val_loss: 0.9331 - val_accuracy: 0.5337\n",
      "Epoch 124/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9194 - accuracy: 0.5436 - val_loss: 0.9333 - val_accuracy: 0.5353\n",
      "Epoch 125/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9193 - accuracy: 0.5430 - val_loss: 0.9330 - val_accuracy: 0.5360\n",
      "Epoch 126/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9191 - accuracy: 0.5437 - val_loss: 0.9328 - val_accuracy: 0.5347\n",
      "Epoch 127/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9190 - accuracy: 0.5439 - val_loss: 0.9326 - val_accuracy: 0.5350\n",
      "Epoch 128/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9189 - accuracy: 0.5436 - val_loss: 0.9323 - val_accuracy: 0.5357\n",
      "Epoch 129/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.9188 - accuracy: 0.5445 - val_loss: 0.9327 - val_accuracy: 0.5357\n",
      "Epoch 130/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9187 - accuracy: 0.5431 - val_loss: 0.9324 - val_accuracy: 0.5360\n",
      "Epoch 131/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9186 - accuracy: 0.5444 - val_loss: 0.9323 - val_accuracy: 0.5353\n",
      "Epoch 132/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9185 - accuracy: 0.5434 - val_loss: 0.9323 - val_accuracy: 0.5360\n",
      "Epoch 133/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9184 - accuracy: 0.5441 - val_loss: 0.9320 - val_accuracy: 0.5350\n",
      "Epoch 134/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9183 - accuracy: 0.5440 - val_loss: 0.9318 - val_accuracy: 0.5347\n",
      "Epoch 135/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.9181 - accuracy: 0.5459 - val_loss: 0.9320 - val_accuracy: 0.5357\n",
      "Epoch 136/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9180 - accuracy: 0.5447 - val_loss: 0.9320 - val_accuracy: 0.5363\n",
      "Epoch 137/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9180 - accuracy: 0.5439 - val_loss: 0.9317 - val_accuracy: 0.5343\n",
      "Epoch 138/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9178 - accuracy: 0.5434 - val_loss: 0.9312 - val_accuracy: 0.5340\n",
      "Epoch 139/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9178 - accuracy: 0.5448 - val_loss: 0.9316 - val_accuracy: 0.5360\n",
      "Epoch 140/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.9177 - accuracy: 0.5454 - val_loss: 0.9314 - val_accuracy: 0.5350\n",
      "Epoch 141/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9176 - accuracy: 0.5442 - val_loss: 0.9313 - val_accuracy: 0.5340\n",
      "Epoch 142/5500\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.9175 - accuracy: 0.5444 - val_loss: 0.9313 - val_accuracy: 0.5350\n",
      "Epoch 143/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9174 - accuracy: 0.5442 - val_loss: 0.9312 - val_accuracy: 0.5350\n",
      "Epoch 144/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9172 - accuracy: 0.5443 - val_loss: 0.9305 - val_accuracy: 0.5360\n",
      "Epoch 145/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9173 - accuracy: 0.5449 - val_loss: 0.9310 - val_accuracy: 0.5343\n",
      "Epoch 146/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9172 - accuracy: 0.5442 - val_loss: 0.9306 - val_accuracy: 0.5337\n",
      "Epoch 147/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9171 - accuracy: 0.5451 - val_loss: 0.9306 - val_accuracy: 0.5330\n",
      "Epoch 148/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9170 - accuracy: 0.5449 - val_loss: 0.9307 - val_accuracy: 0.5347\n",
      "Epoch 149/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9169 - accuracy: 0.5449 - val_loss: 0.9304 - val_accuracy: 0.5320\n",
      "Epoch 150/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9169 - accuracy: 0.5451 - val_loss: 0.9304 - val_accuracy: 0.5327\n",
      "Epoch 151/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9168 - accuracy: 0.5446 - val_loss: 0.9302 - val_accuracy: 0.5317\n",
      "Epoch 152/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9167 - accuracy: 0.5449 - val_loss: 0.9305 - val_accuracy: 0.5363\n",
      "Epoch 153/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9167 - accuracy: 0.5451 - val_loss: 0.9304 - val_accuracy: 0.5350\n",
      "Epoch 154/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9166 - accuracy: 0.5455 - val_loss: 0.9303 - val_accuracy: 0.5357\n",
      "Epoch 155/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9165 - accuracy: 0.5464 - val_loss: 0.9304 - val_accuracy: 0.5353\n",
      "Epoch 156/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9165 - accuracy: 0.5449 - val_loss: 0.9300 - val_accuracy: 0.5320\n",
      "Epoch 157/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9164 - accuracy: 0.5453 - val_loss: 0.9298 - val_accuracy: 0.5320\n",
      "Epoch 158/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9163 - accuracy: 0.5457 - val_loss: 0.9297 - val_accuracy: 0.5310\n",
      "Epoch 159/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9162 - accuracy: 0.5451 - val_loss: 0.9294 - val_accuracy: 0.5323\n",
      "Epoch 160/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9162 - accuracy: 0.5449 - val_loss: 0.9293 - val_accuracy: 0.5327\n",
      "Epoch 161/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9161 - accuracy: 0.5452 - val_loss: 0.9296 - val_accuracy: 0.5317\n",
      "Epoch 162/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9161 - accuracy: 0.5452 - val_loss: 0.9295 - val_accuracy: 0.5310\n",
      "Epoch 163/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9160 - accuracy: 0.5449 - val_loss: 0.9297 - val_accuracy: 0.5353\n",
      "Epoch 164/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9159 - accuracy: 0.5454 - val_loss: 0.9296 - val_accuracy: 0.5337\n",
      "Epoch 165/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9159 - accuracy: 0.5445 - val_loss: 0.9293 - val_accuracy: 0.5317\n",
      "Epoch 166/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9158 - accuracy: 0.5458 - val_loss: 0.9293 - val_accuracy: 0.5333\n",
      "Epoch 167/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9157 - accuracy: 0.5462 - val_loss: 0.9302 - val_accuracy: 0.5333\n",
      "Epoch 168/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9157 - accuracy: 0.5453 - val_loss: 0.9296 - val_accuracy: 0.5343\n",
      "Epoch 169/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9157 - accuracy: 0.5459 - val_loss: 0.9292 - val_accuracy: 0.5330\n",
      "Epoch 170/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9156 - accuracy: 0.5452 - val_loss: 0.9294 - val_accuracy: 0.5337\n",
      "Epoch 171/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9155 - accuracy: 0.5447 - val_loss: 0.9296 - val_accuracy: 0.5330\n",
      "Epoch 172/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9155 - accuracy: 0.5454 - val_loss: 0.9291 - val_accuracy: 0.5337\n",
      "Epoch 173/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9155 - accuracy: 0.5453 - val_loss: 0.9289 - val_accuracy: 0.5327\n",
      "Epoch 174/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9154 - accuracy: 0.5461 - val_loss: 0.9291 - val_accuracy: 0.5333\n",
      "Epoch 175/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9154 - accuracy: 0.5444 - val_loss: 0.9292 - val_accuracy: 0.5333\n",
      "Epoch 176/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9153 - accuracy: 0.5459 - val_loss: 0.9294 - val_accuracy: 0.5330\n",
      "Epoch 177/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9153 - accuracy: 0.5447 - val_loss: 0.9286 - val_accuracy: 0.5323\n",
      "Epoch 178/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9152 - accuracy: 0.5443 - val_loss: 0.9285 - val_accuracy: 0.5330\n",
      "Epoch 179/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9152 - accuracy: 0.5466 - val_loss: 0.9286 - val_accuracy: 0.5323\n",
      "Epoch 180/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9151 - accuracy: 0.5458 - val_loss: 0.9285 - val_accuracy: 0.5337\n",
      "Epoch 181/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9151 - accuracy: 0.5451 - val_loss: 0.9285 - val_accuracy: 0.5327\n",
      "Epoch 182/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9150 - accuracy: 0.5453 - val_loss: 0.9284 - val_accuracy: 0.5327\n",
      "Epoch 183/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9150 - accuracy: 0.5466 - val_loss: 0.9283 - val_accuracy: 0.5330\n",
      "Epoch 184/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9149 - accuracy: 0.5460 - val_loss: 0.9286 - val_accuracy: 0.5323\n",
      "Epoch 185/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9149 - accuracy: 0.5456 - val_loss: 0.9284 - val_accuracy: 0.5333\n",
      "Epoch 186/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9148 - accuracy: 0.5456 - val_loss: 0.9291 - val_accuracy: 0.5327\n",
      "Epoch 187/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9148 - accuracy: 0.5459 - val_loss: 0.9284 - val_accuracy: 0.5323\n",
      "Epoch 188/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9148 - accuracy: 0.5457 - val_loss: 0.9280 - val_accuracy: 0.5337\n",
      "Epoch 189/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9147 - accuracy: 0.5457 - val_loss: 0.9281 - val_accuracy: 0.5320\n",
      "Epoch 190/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9147 - accuracy: 0.5454 - val_loss: 0.9281 - val_accuracy: 0.5327\n",
      "Epoch 191/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9146 - accuracy: 0.5458 - val_loss: 0.9277 - val_accuracy: 0.5320\n",
      "Epoch 192/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9146 - accuracy: 0.5455 - val_loss: 0.9278 - val_accuracy: 0.5330\n",
      "Epoch 193/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9146 - accuracy: 0.5466 - val_loss: 0.9280 - val_accuracy: 0.5327\n",
      "Epoch 194/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9145 - accuracy: 0.5464 - val_loss: 0.9283 - val_accuracy: 0.5333\n",
      "Epoch 195/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9145 - accuracy: 0.5461 - val_loss: 0.9283 - val_accuracy: 0.5327\n",
      "Epoch 196/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9145 - accuracy: 0.5451 - val_loss: 0.9276 - val_accuracy: 0.5333\n",
      "Epoch 197/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9144 - accuracy: 0.5453 - val_loss: 0.9282 - val_accuracy: 0.5330\n",
      "Epoch 198/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9144 - accuracy: 0.5464 - val_loss: 0.9278 - val_accuracy: 0.5340\n",
      "Epoch 199/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9143 - accuracy: 0.5456 - val_loss: 0.9275 - val_accuracy: 0.5330\n",
      "Epoch 200/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9143 - accuracy: 0.5466 - val_loss: 0.9275 - val_accuracy: 0.5333\n",
      "Epoch 201/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9143 - accuracy: 0.5460 - val_loss: 0.9278 - val_accuracy: 0.5323\n",
      "Epoch 202/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9142 - accuracy: 0.5461 - val_loss: 0.9275 - val_accuracy: 0.5323\n",
      "Epoch 203/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9142 - accuracy: 0.5454 - val_loss: 0.9275 - val_accuracy: 0.5333\n",
      "Epoch 204/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9141 - accuracy: 0.5462 - val_loss: 0.9271 - val_accuracy: 0.5313\n",
      "Epoch 205/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9141 - accuracy: 0.5465 - val_loss: 0.9272 - val_accuracy: 0.5333\n",
      "Epoch 206/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9141 - accuracy: 0.5470 - val_loss: 0.9276 - val_accuracy: 0.5333\n",
      "Epoch 207/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9141 - accuracy: 0.5469 - val_loss: 0.9274 - val_accuracy: 0.5347\n",
      "Epoch 208/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9140 - accuracy: 0.5463 - val_loss: 0.9271 - val_accuracy: 0.5330\n",
      "Epoch 209/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9140 - accuracy: 0.5472 - val_loss: 0.9276 - val_accuracy: 0.5327\n",
      "Epoch 210/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9140 - accuracy: 0.5469 - val_loss: 0.9275 - val_accuracy: 0.5333\n",
      "Epoch 211/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9139 - accuracy: 0.5469 - val_loss: 0.9271 - val_accuracy: 0.5347\n",
      "Epoch 212/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9139 - accuracy: 0.5466 - val_loss: 0.9276 - val_accuracy: 0.5313\n",
      "Epoch 213/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9139 - accuracy: 0.5467 - val_loss: 0.9269 - val_accuracy: 0.5333\n",
      "Epoch 214/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9138 - accuracy: 0.5454 - val_loss: 0.9268 - val_accuracy: 0.5333\n",
      "Epoch 215/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9138 - accuracy: 0.5468 - val_loss: 0.9268 - val_accuracy: 0.5337\n",
      "Epoch 216/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9138 - accuracy: 0.5470 - val_loss: 0.9271 - val_accuracy: 0.5333\n",
      "Epoch 217/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9137 - accuracy: 0.5478 - val_loss: 0.9270 - val_accuracy: 0.5333\n",
      "Epoch 218/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9137 - accuracy: 0.5474 - val_loss: 0.9269 - val_accuracy: 0.5337\n",
      "Epoch 219/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9136 - accuracy: 0.5471 - val_loss: 0.9262 - val_accuracy: 0.5313\n",
      "Epoch 220/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9137 - accuracy: 0.5464 - val_loss: 0.9268 - val_accuracy: 0.5330\n",
      "Epoch 221/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9136 - accuracy: 0.5469 - val_loss: 0.9268 - val_accuracy: 0.5333\n",
      "Epoch 222/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9136 - accuracy: 0.5467 - val_loss: 0.9264 - val_accuracy: 0.5330\n",
      "Epoch 223/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9136 - accuracy: 0.5464 - val_loss: 0.9265 - val_accuracy: 0.5327\n",
      "Epoch 224/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9135 - accuracy: 0.5469 - val_loss: 0.9268 - val_accuracy: 0.5340\n",
      "Epoch 225/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9135 - accuracy: 0.5475 - val_loss: 0.9266 - val_accuracy: 0.5327\n",
      "Epoch 226/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9134 - accuracy: 0.5469 - val_loss: 0.9264 - val_accuracy: 0.5330\n",
      "Epoch 227/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9134 - accuracy: 0.5482 - val_loss: 0.9263 - val_accuracy: 0.5330\n",
      "Epoch 228/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9134 - accuracy: 0.5479 - val_loss: 0.9267 - val_accuracy: 0.5340\n",
      "Epoch 229/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9133 - accuracy: 0.5475 - val_loss: 0.9269 - val_accuracy: 0.5327\n",
      "Epoch 230/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9133 - accuracy: 0.5471 - val_loss: 0.9265 - val_accuracy: 0.5337\n",
      "Epoch 231/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9133 - accuracy: 0.5474 - val_loss: 0.9268 - val_accuracy: 0.5330\n",
      "Epoch 232/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9132 - accuracy: 0.5481 - val_loss: 0.9259 - val_accuracy: 0.5333\n",
      "Epoch 233/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9132 - accuracy: 0.5472 - val_loss: 0.9261 - val_accuracy: 0.5333\n",
      "Epoch 234/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9132 - accuracy: 0.5475 - val_loss: 0.9264 - val_accuracy: 0.5340\n",
      "Epoch 235/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9132 - accuracy: 0.5469 - val_loss: 0.9265 - val_accuracy: 0.5343\n",
      "Epoch 236/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9131 - accuracy: 0.5486 - val_loss: 0.9263 - val_accuracy: 0.5337\n",
      "Epoch 237/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9131 - accuracy: 0.5485 - val_loss: 0.9261 - val_accuracy: 0.5327\n",
      "Epoch 238/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9131 - accuracy: 0.5469 - val_loss: 0.9259 - val_accuracy: 0.5337\n",
      "Epoch 239/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9130 - accuracy: 0.5474 - val_loss: 0.9266 - val_accuracy: 0.5337\n",
      "Epoch 240/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9130 - accuracy: 0.5481 - val_loss: 0.9263 - val_accuracy: 0.5343\n",
      "Epoch 241/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9130 - accuracy: 0.5479 - val_loss: 0.9265 - val_accuracy: 0.5330\n",
      "Epoch 242/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9129 - accuracy: 0.5483 - val_loss: 0.9256 - val_accuracy: 0.5340\n",
      "Epoch 243/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9129 - accuracy: 0.5484 - val_loss: 0.9258 - val_accuracy: 0.5333\n",
      "Epoch 244/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9129 - accuracy: 0.5484 - val_loss: 0.9258 - val_accuracy: 0.5337\n",
      "Epoch 245/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9128 - accuracy: 0.5485 - val_loss: 0.9256 - val_accuracy: 0.5340\n",
      "Epoch 246/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9128 - accuracy: 0.5484 - val_loss: 0.9257 - val_accuracy: 0.5340\n",
      "Epoch 247/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9128 - accuracy: 0.5479 - val_loss: 0.9260 - val_accuracy: 0.5333\n",
      "Epoch 248/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9128 - accuracy: 0.5481 - val_loss: 0.9260 - val_accuracy: 0.5337\n",
      "Epoch 249/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9128 - accuracy: 0.5481 - val_loss: 0.9259 - val_accuracy: 0.5333\n",
      "Epoch 250/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9128 - accuracy: 0.5480 - val_loss: 0.9261 - val_accuracy: 0.5353\n",
      "Epoch 251/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9127 - accuracy: 0.5480 - val_loss: 0.9260 - val_accuracy: 0.5347\n",
      "Epoch 252/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9127 - accuracy: 0.5488 - val_loss: 0.9258 - val_accuracy: 0.5330\n",
      "Epoch 253/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9126 - accuracy: 0.5486 - val_loss: 0.9262 - val_accuracy: 0.5337\n",
      "Epoch 254/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9126 - accuracy: 0.5485 - val_loss: 0.9259 - val_accuracy: 0.5347\n",
      "Epoch 255/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9126 - accuracy: 0.5485 - val_loss: 0.9255 - val_accuracy: 0.5347\n",
      "Epoch 256/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9125 - accuracy: 0.5476 - val_loss: 0.9262 - val_accuracy: 0.5357\n",
      "Epoch 257/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.9125 - accuracy: 0.5490 - val_loss: 0.9258 - val_accuracy: 0.5347\n",
      "Epoch 258/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9125 - accuracy: 0.5480 - val_loss: 0.9261 - val_accuracy: 0.5343\n",
      "Epoch 259/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9125 - accuracy: 0.5477 - val_loss: 0.9255 - val_accuracy: 0.5337\n",
      "Epoch 260/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9125 - accuracy: 0.5486 - val_loss: 0.9256 - val_accuracy: 0.5350\n",
      "Epoch 261/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9124 - accuracy: 0.5495 - val_loss: 0.9257 - val_accuracy: 0.5350\n",
      "Epoch 262/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9124 - accuracy: 0.5482 - val_loss: 0.9254 - val_accuracy: 0.5337\n",
      "Epoch 263/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9124 - accuracy: 0.5486 - val_loss: 0.9254 - val_accuracy: 0.5340\n",
      "Epoch 264/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9123 - accuracy: 0.5496 - val_loss: 0.9255 - val_accuracy: 0.5357\n",
      "Epoch 265/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9123 - accuracy: 0.5491 - val_loss: 0.9258 - val_accuracy: 0.5350\n",
      "Epoch 266/5500\n",
      "14000/14000 [==============================] - 1s 37us/step - loss: 0.9123 - accuracy: 0.5484 - val_loss: 0.9260 - val_accuracy: 0.5353\n",
      "Epoch 267/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.9123 - accuracy: 0.5493 - val_loss: 0.9253 - val_accuracy: 0.5347\n",
      "Epoch 268/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9122 - accuracy: 0.5490 - val_loss: 0.9252 - val_accuracy: 0.5353\n",
      "Epoch 269/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9122 - accuracy: 0.5481 - val_loss: 0.9256 - val_accuracy: 0.5337\n",
      "Epoch 270/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9122 - accuracy: 0.5497 - val_loss: 0.9256 - val_accuracy: 0.5340\n",
      "Epoch 271/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.9122 - accuracy: 0.5484 - val_loss: 0.9258 - val_accuracy: 0.5353\n",
      "Epoch 272/5500\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.9122 - accuracy: 0.5486 - val_loss: 0.9255 - val_accuracy: 0.5340\n",
      "Epoch 273/5500\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.9121 - accuracy: 0.5482 - val_loss: 0.9250 - val_accuracy: 0.5353\n",
      "Epoch 274/5500\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.9121 - accuracy: 0.5489 - val_loss: 0.9253 - val_accuracy: 0.5343\n",
      "Epoch 275/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9121 - accuracy: 0.5487 - val_loss: 0.9249 - val_accuracy: 0.5360\n",
      "Epoch 276/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9121 - accuracy: 0.5483 - val_loss: 0.9249 - val_accuracy: 0.5360\n",
      "Epoch 277/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9120 - accuracy: 0.5491 - val_loss: 0.9253 - val_accuracy: 0.5343\n",
      "Epoch 278/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9120 - accuracy: 0.5486 - val_loss: 0.9247 - val_accuracy: 0.5353\n",
      "Epoch 279/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9120 - accuracy: 0.5500 - val_loss: 0.9250 - val_accuracy: 0.5353\n",
      "Epoch 280/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9120 - accuracy: 0.5494 - val_loss: 0.9252 - val_accuracy: 0.5343\n",
      "Epoch 281/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9119 - accuracy: 0.5485 - val_loss: 0.9250 - val_accuracy: 0.5353\n",
      "Epoch 282/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9119 - accuracy: 0.5491 - val_loss: 0.9252 - val_accuracy: 0.5340\n",
      "Epoch 283/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9119 - accuracy: 0.5491 - val_loss: 0.9248 - val_accuracy: 0.5363\n",
      "Epoch 284/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9119 - accuracy: 0.5496 - val_loss: 0.9247 - val_accuracy: 0.5370\n",
      "Epoch 285/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9118 - accuracy: 0.5495 - val_loss: 0.9246 - val_accuracy: 0.5360\n",
      "Epoch 286/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9118 - accuracy: 0.5494 - val_loss: 0.9248 - val_accuracy: 0.5360\n",
      "Epoch 287/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9118 - accuracy: 0.5500 - val_loss: 0.9251 - val_accuracy: 0.5343\n",
      "Epoch 288/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9117 - accuracy: 0.5491 - val_loss: 0.9245 - val_accuracy: 0.5370\n",
      "Epoch 289/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9117 - accuracy: 0.5496 - val_loss: 0.9246 - val_accuracy: 0.5357\n",
      "Epoch 290/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9117 - accuracy: 0.5492 - val_loss: 0.9252 - val_accuracy: 0.5337\n",
      "Epoch 291/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.9117 - accuracy: 0.5502 - val_loss: 0.9246 - val_accuracy: 0.5357\n",
      "Epoch 292/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9117 - accuracy: 0.5502 - val_loss: 0.9248 - val_accuracy: 0.5360\n",
      "Epoch 293/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9116 - accuracy: 0.5502 - val_loss: 0.9245 - val_accuracy: 0.5360\n",
      "Epoch 294/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9116 - accuracy: 0.5492 - val_loss: 0.9242 - val_accuracy: 0.5357\n",
      "Epoch 295/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9116 - accuracy: 0.5505 - val_loss: 0.9247 - val_accuracy: 0.5357\n",
      "Epoch 296/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9116 - accuracy: 0.5489 - val_loss: 0.9250 - val_accuracy: 0.5340\n",
      "Epoch 297/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9116 - accuracy: 0.5495 - val_loss: 0.9247 - val_accuracy: 0.5347\n",
      "Epoch 298/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9115 - accuracy: 0.5496 - val_loss: 0.9245 - val_accuracy: 0.5357\n",
      "Epoch 299/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9115 - accuracy: 0.5500 - val_loss: 0.9240 - val_accuracy: 0.5357\n",
      "Epoch 300/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9115 - accuracy: 0.5496 - val_loss: 0.9244 - val_accuracy: 0.5363\n",
      "Epoch 301/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9115 - accuracy: 0.5500 - val_loss: 0.9244 - val_accuracy: 0.5360\n",
      "Epoch 302/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9114 - accuracy: 0.5494 - val_loss: 0.9242 - val_accuracy: 0.5370\n",
      "Epoch 303/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9114 - accuracy: 0.5499 - val_loss: 0.9244 - val_accuracy: 0.5363\n",
      "Epoch 304/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.9114 - accuracy: 0.5499 - val_loss: 0.9241 - val_accuracy: 0.5373\n",
      "Epoch 305/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9114 - accuracy: 0.5505 - val_loss: 0.9241 - val_accuracy: 0.5380\n",
      "Epoch 306/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.9113 - accuracy: 0.5499 - val_loss: 0.9245 - val_accuracy: 0.5347\n",
      "Epoch 307/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9113 - accuracy: 0.5498 - val_loss: 0.9243 - val_accuracy: 0.5363\n",
      "Epoch 308/5500\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.9113 - accuracy: 0.5489 - val_loss: 0.9242 - val_accuracy: 0.5367\n",
      "Epoch 309/5500\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 0.9113 - accuracy: 0.5490 - val_loss: 0.9240 - val_accuracy: 0.5370\n",
      "Epoch 310/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9113 - accuracy: 0.5497 - val_loss: 0.9240 - val_accuracy: 0.5377\n",
      "Epoch 311/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9113 - accuracy: 0.5500 - val_loss: 0.9244 - val_accuracy: 0.5350\n",
      "Epoch 312/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9112 - accuracy: 0.5503 - val_loss: 0.9242 - val_accuracy: 0.5363\n",
      "Epoch 313/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9112 - accuracy: 0.5501 - val_loss: 0.9239 - val_accuracy: 0.5373\n",
      "Epoch 314/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9112 - accuracy: 0.5500 - val_loss: 0.9239 - val_accuracy: 0.5377\n",
      "Epoch 315/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9111 - accuracy: 0.5496 - val_loss: 0.9241 - val_accuracy: 0.5367\n",
      "Epoch 316/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9111 - accuracy: 0.5507 - val_loss: 0.9245 - val_accuracy: 0.5347\n",
      "Epoch 317/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9111 - accuracy: 0.5501 - val_loss: 0.9244 - val_accuracy: 0.5350\n",
      "Epoch 318/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9111 - accuracy: 0.5498 - val_loss: 0.9241 - val_accuracy: 0.5357\n",
      "Epoch 319/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9111 - accuracy: 0.5497 - val_loss: 0.9243 - val_accuracy: 0.5360\n",
      "Epoch 320/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9110 - accuracy: 0.5494 - val_loss: 0.9240 - val_accuracy: 0.5363\n",
      "Epoch 321/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9110 - accuracy: 0.5493 - val_loss: 0.9237 - val_accuracy: 0.5367\n",
      "Epoch 322/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9110 - accuracy: 0.5494 - val_loss: 0.9244 - val_accuracy: 0.5350\n",
      "Epoch 323/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9110 - accuracy: 0.5510 - val_loss: 0.9240 - val_accuracy: 0.5353\n",
      "Epoch 324/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9110 - accuracy: 0.5497 - val_loss: 0.9239 - val_accuracy: 0.5360\n",
      "Epoch 325/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9109 - accuracy: 0.5507 - val_loss: 0.9245 - val_accuracy: 0.5360\n",
      "Epoch 326/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9109 - accuracy: 0.5501 - val_loss: 0.9238 - val_accuracy: 0.5373\n",
      "Epoch 327/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9108 - accuracy: 0.5492 - val_loss: 0.9237 - val_accuracy: 0.5370\n",
      "Epoch 328/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9108 - accuracy: 0.5499 - val_loss: 0.9245 - val_accuracy: 0.5357\n",
      "Epoch 329/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9108 - accuracy: 0.5507 - val_loss: 0.9246 - val_accuracy: 0.5357\n",
      "Epoch 330/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9108 - accuracy: 0.5495 - val_loss: 0.9234 - val_accuracy: 0.5373\n",
      "Epoch 331/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9108 - accuracy: 0.5509 - val_loss: 0.9239 - val_accuracy: 0.5367\n",
      "Epoch 332/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9108 - accuracy: 0.5486 - val_loss: 0.9239 - val_accuracy: 0.5360\n",
      "Epoch 333/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9107 - accuracy: 0.5501 - val_loss: 0.9243 - val_accuracy: 0.5367\n",
      "Epoch 334/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9108 - accuracy: 0.5493 - val_loss: 0.9238 - val_accuracy: 0.5360\n",
      "Epoch 335/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9107 - accuracy: 0.5503 - val_loss: 0.9240 - val_accuracy: 0.5370\n",
      "Epoch 336/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9107 - accuracy: 0.5501 - val_loss: 0.9239 - val_accuracy: 0.5370\n",
      "Epoch 337/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9107 - accuracy: 0.5499 - val_loss: 0.9235 - val_accuracy: 0.5360\n",
      "Epoch 338/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9106 - accuracy: 0.5499 - val_loss: 0.9233 - val_accuracy: 0.5367\n",
      "Epoch 339/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9106 - accuracy: 0.5505 - val_loss: 0.9236 - val_accuracy: 0.5360\n",
      "Epoch 340/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9106 - accuracy: 0.5491 - val_loss: 0.9237 - val_accuracy: 0.5370\n",
      "Epoch 341/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9106 - accuracy: 0.5503 - val_loss: 0.9233 - val_accuracy: 0.5370\n",
      "Epoch 342/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9106 - accuracy: 0.5499 - val_loss: 0.9234 - val_accuracy: 0.5360\n",
      "Epoch 343/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9105 - accuracy: 0.5503 - val_loss: 0.9233 - val_accuracy: 0.5353\n",
      "Epoch 344/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9105 - accuracy: 0.5504 - val_loss: 0.9236 - val_accuracy: 0.5367\n",
      "Epoch 345/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9105 - accuracy: 0.5497 - val_loss: 0.9236 - val_accuracy: 0.5377\n",
      "Epoch 346/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9105 - accuracy: 0.5504 - val_loss: 0.9239 - val_accuracy: 0.5370\n",
      "Epoch 347/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9105 - accuracy: 0.5508 - val_loss: 0.9240 - val_accuracy: 0.5363\n",
      "Epoch 348/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9104 - accuracy: 0.5495 - val_loss: 0.9233 - val_accuracy: 0.5350\n",
      "Epoch 349/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9104 - accuracy: 0.5501 - val_loss: 0.9232 - val_accuracy: 0.5347\n",
      "Epoch 350/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9104 - accuracy: 0.5491 - val_loss: 0.9230 - val_accuracy: 0.5373\n",
      "Epoch 351/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9104 - accuracy: 0.5502 - val_loss: 0.9231 - val_accuracy: 0.5353\n",
      "Epoch 352/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9104 - accuracy: 0.5509 - val_loss: 0.9235 - val_accuracy: 0.5373\n",
      "Epoch 353/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9103 - accuracy: 0.5503 - val_loss: 0.9231 - val_accuracy: 0.5350\n",
      "Epoch 354/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9103 - accuracy: 0.5498 - val_loss: 0.9233 - val_accuracy: 0.5357\n",
      "Epoch 355/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9103 - accuracy: 0.5505 - val_loss: 0.9238 - val_accuracy: 0.5380\n",
      "Epoch 356/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9103 - accuracy: 0.5489 - val_loss: 0.9234 - val_accuracy: 0.5387\n",
      "Epoch 357/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9102 - accuracy: 0.5496 - val_loss: 0.9236 - val_accuracy: 0.5377\n",
      "Epoch 358/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9102 - accuracy: 0.5504 - val_loss: 0.9235 - val_accuracy: 0.5367\n",
      "Epoch 359/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9102 - accuracy: 0.5495 - val_loss: 0.9232 - val_accuracy: 0.5367\n",
      "Epoch 360/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9102 - accuracy: 0.5499 - val_loss: 0.9230 - val_accuracy: 0.5347\n",
      "Epoch 361/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9102 - accuracy: 0.5508 - val_loss: 0.9231 - val_accuracy: 0.5360\n",
      "Epoch 362/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9101 - accuracy: 0.5494 - val_loss: 0.9227 - val_accuracy: 0.5363\n",
      "Epoch 363/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9101 - accuracy: 0.5509 - val_loss: 0.9234 - val_accuracy: 0.5370\n",
      "Epoch 364/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9101 - accuracy: 0.5497 - val_loss: 0.9226 - val_accuracy: 0.5373\n",
      "Epoch 365/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9101 - accuracy: 0.5498 - val_loss: 0.9228 - val_accuracy: 0.5350\n",
      "Epoch 366/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9100 - accuracy: 0.5500 - val_loss: 0.9228 - val_accuracy: 0.5347\n",
      "Epoch 367/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9100 - accuracy: 0.5500 - val_loss: 0.9226 - val_accuracy: 0.5353\n",
      "Epoch 368/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9100 - accuracy: 0.5505 - val_loss: 0.9235 - val_accuracy: 0.5373\n",
      "Epoch 369/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9100 - accuracy: 0.5497 - val_loss: 0.9235 - val_accuracy: 0.5377\n",
      "Epoch 370/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9099 - accuracy: 0.5499 - val_loss: 0.9228 - val_accuracy: 0.5360\n",
      "Epoch 371/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9099 - accuracy: 0.5508 - val_loss: 0.9226 - val_accuracy: 0.5350\n",
      "Epoch 372/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9099 - accuracy: 0.5503 - val_loss: 0.9230 - val_accuracy: 0.5380\n",
      "Epoch 373/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9099 - accuracy: 0.5496 - val_loss: 0.9226 - val_accuracy: 0.5363\n",
      "Epoch 374/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9099 - accuracy: 0.5492 - val_loss: 0.9229 - val_accuracy: 0.5373\n",
      "Epoch 375/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9098 - accuracy: 0.5496 - val_loss: 0.9223 - val_accuracy: 0.5367\n",
      "Epoch 376/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9099 - accuracy: 0.5506 - val_loss: 0.9227 - val_accuracy: 0.5367\n",
      "Epoch 377/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9097 - accuracy: 0.5494 - val_loss: 0.9221 - val_accuracy: 0.5360\n",
      "Epoch 378/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9098 - accuracy: 0.5500 - val_loss: 0.9228 - val_accuracy: 0.5383\n",
      "Epoch 379/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9097 - accuracy: 0.5507 - val_loss: 0.9234 - val_accuracy: 0.5373\n",
      "Epoch 380/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9098 - accuracy: 0.5493 - val_loss: 0.9229 - val_accuracy: 0.5390\n",
      "Epoch 381/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9097 - accuracy: 0.5500 - val_loss: 0.9231 - val_accuracy: 0.5370\n",
      "Epoch 382/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9097 - accuracy: 0.5500 - val_loss: 0.9223 - val_accuracy: 0.5363\n",
      "Epoch 383/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9097 - accuracy: 0.5500 - val_loss: 0.9225 - val_accuracy: 0.5377\n",
      "Epoch 384/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9096 - accuracy: 0.5496 - val_loss: 0.9220 - val_accuracy: 0.5357\n",
      "Epoch 385/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9096 - accuracy: 0.5496 - val_loss: 0.9232 - val_accuracy: 0.5377\n",
      "Epoch 386/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9096 - accuracy: 0.5497 - val_loss: 0.9224 - val_accuracy: 0.5363\n",
      "Epoch 387/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9096 - accuracy: 0.5498 - val_loss: 0.9220 - val_accuracy: 0.5363\n",
      "Epoch 388/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9095 - accuracy: 0.5510 - val_loss: 0.9233 - val_accuracy: 0.5367\n",
      "Epoch 389/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9096 - accuracy: 0.5499 - val_loss: 0.9228 - val_accuracy: 0.5377\n",
      "Epoch 390/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9095 - accuracy: 0.5516 - val_loss: 0.9224 - val_accuracy: 0.5383\n",
      "Epoch 391/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9095 - accuracy: 0.5502 - val_loss: 0.9222 - val_accuracy: 0.5367\n",
      "Epoch 392/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9095 - accuracy: 0.5495 - val_loss: 0.9227 - val_accuracy: 0.5383\n",
      "Epoch 393/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9094 - accuracy: 0.5496 - val_loss: 0.9220 - val_accuracy: 0.5367\n",
      "Epoch 394/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9095 - accuracy: 0.5499 - val_loss: 0.9226 - val_accuracy: 0.5393\n",
      "Epoch 395/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9094 - accuracy: 0.5492 - val_loss: 0.9223 - val_accuracy: 0.5377\n",
      "Epoch 396/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9094 - accuracy: 0.5500 - val_loss: 0.9224 - val_accuracy: 0.5380\n",
      "Epoch 397/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9094 - accuracy: 0.5496 - val_loss: 0.9220 - val_accuracy: 0.5370\n",
      "Epoch 398/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9094 - accuracy: 0.5492 - val_loss: 0.9223 - val_accuracy: 0.5390\n",
      "Epoch 399/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9094 - accuracy: 0.5483 - val_loss: 0.9219 - val_accuracy: 0.5363\n",
      "Epoch 400/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9093 - accuracy: 0.5496 - val_loss: 0.9225 - val_accuracy: 0.5397\n",
      "Epoch 401/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9093 - accuracy: 0.5493 - val_loss: 0.9222 - val_accuracy: 0.5377\n",
      "Epoch 402/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9093 - accuracy: 0.5491 - val_loss: 0.9219 - val_accuracy: 0.5380\n",
      "Epoch 403/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9093 - accuracy: 0.5490 - val_loss: 0.9226 - val_accuracy: 0.5383\n",
      "Epoch 404/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9092 - accuracy: 0.5489 - val_loss: 0.9221 - val_accuracy: 0.5380\n",
      "Epoch 405/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9092 - accuracy: 0.5500 - val_loss: 0.9219 - val_accuracy: 0.5380\n",
      "Epoch 406/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9092 - accuracy: 0.5495 - val_loss: 0.9220 - val_accuracy: 0.5383\n",
      "Epoch 407/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9092 - accuracy: 0.5501 - val_loss: 0.9216 - val_accuracy: 0.5360\n",
      "Epoch 408/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9091 - accuracy: 0.5500 - val_loss: 0.9227 - val_accuracy: 0.5377\n",
      "Epoch 409/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9092 - accuracy: 0.5501 - val_loss: 0.9221 - val_accuracy: 0.5387\n",
      "Epoch 410/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9091 - accuracy: 0.5495 - val_loss: 0.9220 - val_accuracy: 0.5390\n",
      "Epoch 411/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9091 - accuracy: 0.5492 - val_loss: 0.9220 - val_accuracy: 0.5387\n",
      "Epoch 412/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9091 - accuracy: 0.5493 - val_loss: 0.9221 - val_accuracy: 0.5400\n",
      "Epoch 413/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9091 - accuracy: 0.5493 - val_loss: 0.9220 - val_accuracy: 0.5383\n",
      "Epoch 414/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9090 - accuracy: 0.5498 - val_loss: 0.9221 - val_accuracy: 0.5403\n",
      "Epoch 415/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9090 - accuracy: 0.5496 - val_loss: 0.9216 - val_accuracy: 0.5370\n",
      "Epoch 416/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9088 - accuracy: 0.5504 - val_loss: 0.9225 - val_accuracy: 0.5383\n",
      "Epoch 417/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9089 - accuracy: 0.5506 - val_loss: 0.9213 - val_accuracy: 0.5367\n",
      "Epoch 418/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9090 - accuracy: 0.5490 - val_loss: 0.9217 - val_accuracy: 0.5383\n",
      "Epoch 419/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9090 - accuracy: 0.5496 - val_loss: 0.9216 - val_accuracy: 0.5380\n",
      "Epoch 420/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9089 - accuracy: 0.5501 - val_loss: 0.9216 - val_accuracy: 0.5383\n",
      "Epoch 421/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9089 - accuracy: 0.5485 - val_loss: 0.9222 - val_accuracy: 0.5387\n",
      "Epoch 422/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9089 - accuracy: 0.5497 - val_loss: 0.9213 - val_accuracy: 0.5370\n",
      "Epoch 423/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9089 - accuracy: 0.5487 - val_loss: 0.9216 - val_accuracy: 0.5387\n",
      "Epoch 424/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9088 - accuracy: 0.5505 - val_loss: 0.9220 - val_accuracy: 0.5397\n",
      "Epoch 425/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9088 - accuracy: 0.5495 - val_loss: 0.9215 - val_accuracy: 0.5370\n",
      "Epoch 426/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9088 - accuracy: 0.5491 - val_loss: 0.9220 - val_accuracy: 0.5393\n",
      "Epoch 427/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9087 - accuracy: 0.5493 - val_loss: 0.9213 - val_accuracy: 0.5380\n",
      "Epoch 428/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9087 - accuracy: 0.5505 - val_loss: 0.9210 - val_accuracy: 0.5363\n",
      "Epoch 429/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9087 - accuracy: 0.5492 - val_loss: 0.9217 - val_accuracy: 0.5397\n",
      "Epoch 430/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9087 - accuracy: 0.5502 - val_loss: 0.9212 - val_accuracy: 0.5383\n",
      "Epoch 431/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9087 - accuracy: 0.5499 - val_loss: 0.9217 - val_accuracy: 0.5400\n",
      "Epoch 432/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9087 - accuracy: 0.5492 - val_loss: 0.9214 - val_accuracy: 0.5387\n",
      "Epoch 433/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9086 - accuracy: 0.5500 - val_loss: 0.9218 - val_accuracy: 0.5397\n",
      "Epoch 434/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9086 - accuracy: 0.5501 - val_loss: 0.9212 - val_accuracy: 0.5373\n",
      "Epoch 435/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9086 - accuracy: 0.5495 - val_loss: 0.9213 - val_accuracy: 0.5380\n",
      "Epoch 436/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9086 - accuracy: 0.5497 - val_loss: 0.9213 - val_accuracy: 0.5380\n",
      "Epoch 437/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9085 - accuracy: 0.5496 - val_loss: 0.9221 - val_accuracy: 0.5377\n",
      "Epoch 438/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9085 - accuracy: 0.5496 - val_loss: 0.9212 - val_accuracy: 0.5380\n",
      "Epoch 439/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9085 - accuracy: 0.5486 - val_loss: 0.9215 - val_accuracy: 0.5397\n",
      "Epoch 440/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9085 - accuracy: 0.5499 - val_loss: 0.9208 - val_accuracy: 0.5370\n",
      "Epoch 441/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9085 - accuracy: 0.5501 - val_loss: 0.9217 - val_accuracy: 0.5397\n",
      "Epoch 442/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9085 - accuracy: 0.5492 - val_loss: 0.9211 - val_accuracy: 0.5387\n",
      "Epoch 443/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9085 - accuracy: 0.5509 - val_loss: 0.9215 - val_accuracy: 0.5397\n",
      "Epoch 444/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9084 - accuracy: 0.5497 - val_loss: 0.9216 - val_accuracy: 0.5403\n",
      "Epoch 445/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9083 - accuracy: 0.5498 - val_loss: 0.9223 - val_accuracy: 0.5380\n",
      "Epoch 446/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9084 - accuracy: 0.5504 - val_loss: 0.9209 - val_accuracy: 0.5373\n",
      "Epoch 447/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9083 - accuracy: 0.5496 - val_loss: 0.9221 - val_accuracy: 0.5383\n",
      "Epoch 448/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9084 - accuracy: 0.5496 - val_loss: 0.9213 - val_accuracy: 0.5393\n",
      "Epoch 449/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9083 - accuracy: 0.5497 - val_loss: 0.9210 - val_accuracy: 0.5383\n",
      "Epoch 450/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9083 - accuracy: 0.5491 - val_loss: 0.9211 - val_accuracy: 0.5373\n",
      "Epoch 451/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9083 - accuracy: 0.5499 - val_loss: 0.9221 - val_accuracy: 0.5383\n",
      "Epoch 452/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9083 - accuracy: 0.5522 - val_loss: 0.9208 - val_accuracy: 0.5380\n",
      "Epoch 453/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9083 - accuracy: 0.5500 - val_loss: 0.9208 - val_accuracy: 0.5387\n",
      "Epoch 454/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9082 - accuracy: 0.5486 - val_loss: 0.9212 - val_accuracy: 0.5397\n",
      "Epoch 455/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9082 - accuracy: 0.5491 - val_loss: 0.9210 - val_accuracy: 0.5383\n",
      "Epoch 456/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9082 - accuracy: 0.5500 - val_loss: 0.9207 - val_accuracy: 0.5377\n",
      "Epoch 457/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9082 - accuracy: 0.5501 - val_loss: 0.9211 - val_accuracy: 0.5397\n",
      "Epoch 458/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9082 - accuracy: 0.5497 - val_loss: 0.9207 - val_accuracy: 0.5373\n",
      "Epoch 459/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9082 - accuracy: 0.5501 - val_loss: 0.9208 - val_accuracy: 0.5380\n",
      "Epoch 460/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9081 - accuracy: 0.5493 - val_loss: 0.9210 - val_accuracy: 0.5400\n",
      "Epoch 461/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9081 - accuracy: 0.5500 - val_loss: 0.9206 - val_accuracy: 0.5373\n",
      "Epoch 462/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9081 - accuracy: 0.5504 - val_loss: 0.9208 - val_accuracy: 0.5380\n",
      "Epoch 463/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9081 - accuracy: 0.5502 - val_loss: 0.9206 - val_accuracy: 0.5373\n",
      "Epoch 464/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9081 - accuracy: 0.5495 - val_loss: 0.9209 - val_accuracy: 0.5400\n",
      "Epoch 465/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9080 - accuracy: 0.5513 - val_loss: 0.9212 - val_accuracy: 0.5387\n",
      "Epoch 466/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9080 - accuracy: 0.5498 - val_loss: 0.9212 - val_accuracy: 0.5397\n",
      "Epoch 467/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9080 - accuracy: 0.5489 - val_loss: 0.9215 - val_accuracy: 0.5400\n",
      "Epoch 468/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9079 - accuracy: 0.5504 - val_loss: 0.9204 - val_accuracy: 0.5397\n",
      "Epoch 469/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9080 - accuracy: 0.5503 - val_loss: 0.9204 - val_accuracy: 0.5377\n",
      "Epoch 470/5500\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.9080 - accuracy: 0.5487 - val_loss: 0.9211 - val_accuracy: 0.5397\n",
      "Epoch 471/5500\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.9079 - accuracy: 0.5514 - val_loss: 0.9208 - val_accuracy: 0.5400\n",
      "Epoch 472/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9079 - accuracy: 0.5496 - val_loss: 0.9203 - val_accuracy: 0.5380\n",
      "Epoch 473/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9079 - accuracy: 0.5505 - val_loss: 0.9208 - val_accuracy: 0.5407\n",
      "Epoch 474/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9079 - accuracy: 0.5497 - val_loss: 0.9203 - val_accuracy: 0.5373\n",
      "Epoch 475/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9078 - accuracy: 0.5492 - val_loss: 0.9203 - val_accuracy: 0.5387\n",
      "Epoch 476/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9079 - accuracy: 0.5505 - val_loss: 0.9204 - val_accuracy: 0.5380\n",
      "Epoch 477/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9078 - accuracy: 0.5493 - val_loss: 0.9217 - val_accuracy: 0.5387\n",
      "Epoch 478/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9078 - accuracy: 0.5522 - val_loss: 0.9199 - val_accuracy: 0.5377\n",
      "Epoch 479/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9078 - accuracy: 0.5501 - val_loss: 0.9201 - val_accuracy: 0.5380\n",
      "Epoch 480/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9078 - accuracy: 0.5501 - val_loss: 0.9202 - val_accuracy: 0.5367\n",
      "Epoch 481/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9078 - accuracy: 0.5500 - val_loss: 0.9210 - val_accuracy: 0.5390\n",
      "Epoch 482/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9077 - accuracy: 0.5500 - val_loss: 0.9210 - val_accuracy: 0.5393\n",
      "Epoch 483/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9078 - accuracy: 0.5486 - val_loss: 0.9209 - val_accuracy: 0.5397\n",
      "Epoch 484/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9077 - accuracy: 0.5496 - val_loss: 0.9201 - val_accuracy: 0.5380\n",
      "Epoch 485/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9077 - accuracy: 0.5490 - val_loss: 0.9201 - val_accuracy: 0.5380\n",
      "Epoch 486/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9077 - accuracy: 0.5501 - val_loss: 0.9208 - val_accuracy: 0.5400\n",
      "Epoch 487/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9077 - accuracy: 0.5499 - val_loss: 0.9204 - val_accuracy: 0.5377\n",
      "Epoch 488/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9076 - accuracy: 0.5499 - val_loss: 0.9199 - val_accuracy: 0.5383\n",
      "Epoch 489/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9077 - accuracy: 0.5496 - val_loss: 0.9203 - val_accuracy: 0.5390\n",
      "Epoch 490/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9076 - accuracy: 0.5485 - val_loss: 0.9201 - val_accuracy: 0.5373\n",
      "Epoch 491/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9076 - accuracy: 0.5501 - val_loss: 0.9201 - val_accuracy: 0.5377\n",
      "Epoch 492/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9076 - accuracy: 0.5510 - val_loss: 0.9206 - val_accuracy: 0.5413\n",
      "Epoch 493/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9075 - accuracy: 0.5501 - val_loss: 0.9210 - val_accuracy: 0.5400\n",
      "Epoch 494/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9076 - accuracy: 0.5497 - val_loss: 0.9204 - val_accuracy: 0.5403\n",
      "Epoch 495/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9075 - accuracy: 0.5506 - val_loss: 0.9201 - val_accuracy: 0.5380\n",
      "Epoch 496/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9076 - accuracy: 0.5493 - val_loss: 0.9202 - val_accuracy: 0.5393\n",
      "Epoch 497/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9075 - accuracy: 0.5502 - val_loss: 0.9206 - val_accuracy: 0.5380\n",
      "Epoch 498/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9075 - accuracy: 0.5493 - val_loss: 0.9203 - val_accuracy: 0.5387\n",
      "Epoch 499/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9075 - accuracy: 0.5504 - val_loss: 0.9198 - val_accuracy: 0.5373\n",
      "Epoch 500/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9074 - accuracy: 0.5500 - val_loss: 0.9205 - val_accuracy: 0.5397\n",
      "Epoch 501/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9075 - accuracy: 0.5502 - val_loss: 0.9203 - val_accuracy: 0.5393\n",
      "Epoch 502/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9074 - accuracy: 0.5506 - val_loss: 0.9204 - val_accuracy: 0.5400\n",
      "Epoch 503/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9074 - accuracy: 0.5511 - val_loss: 0.9202 - val_accuracy: 0.5383\n",
      "Epoch 504/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9074 - accuracy: 0.5492 - val_loss: 0.9207 - val_accuracy: 0.5393\n",
      "Epoch 505/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9074 - accuracy: 0.5494 - val_loss: 0.9200 - val_accuracy: 0.5390\n",
      "Epoch 506/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9073 - accuracy: 0.5513 - val_loss: 0.9209 - val_accuracy: 0.5387\n",
      "Epoch 507/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9073 - accuracy: 0.5505 - val_loss: 0.9201 - val_accuracy: 0.5387\n",
      "Epoch 508/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9073 - accuracy: 0.5504 - val_loss: 0.9198 - val_accuracy: 0.5377\n",
      "Epoch 509/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9073 - accuracy: 0.5498 - val_loss: 0.9200 - val_accuracy: 0.5390\n",
      "Epoch 510/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9073 - accuracy: 0.5509 - val_loss: 0.9202 - val_accuracy: 0.5393\n",
      "Epoch 511/5500\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.9073 - accuracy: 0.5496 - val_loss: 0.9201 - val_accuracy: 0.5383\n",
      "Epoch 512/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9073 - accuracy: 0.5502 - val_loss: 0.9201 - val_accuracy: 0.5383\n",
      "Epoch 513/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9072 - accuracy: 0.5494 - val_loss: 0.9209 - val_accuracy: 0.5397\n",
      "Epoch 514/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9072 - accuracy: 0.5504 - val_loss: 0.9203 - val_accuracy: 0.5407\n",
      "Epoch 515/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9072 - accuracy: 0.5501 - val_loss: 0.9201 - val_accuracy: 0.5383\n",
      "Epoch 516/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9072 - accuracy: 0.5501 - val_loss: 0.9204 - val_accuracy: 0.5387\n",
      "Epoch 517/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9071 - accuracy: 0.5505 - val_loss: 0.9192 - val_accuracy: 0.5380\n",
      "Epoch 518/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9072 - accuracy: 0.5494 - val_loss: 0.9196 - val_accuracy: 0.5393\n",
      "Epoch 519/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9071 - accuracy: 0.5502 - val_loss: 0.9199 - val_accuracy: 0.5390\n",
      "Epoch 520/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9071 - accuracy: 0.5510 - val_loss: 0.9197 - val_accuracy: 0.5380\n",
      "Epoch 521/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9071 - accuracy: 0.5496 - val_loss: 0.9197 - val_accuracy: 0.5397\n",
      "Epoch 522/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9071 - accuracy: 0.5503 - val_loss: 0.9199 - val_accuracy: 0.5387\n",
      "Epoch 523/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9070 - accuracy: 0.5507 - val_loss: 0.9192 - val_accuracy: 0.5373\n",
      "Epoch 524/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9071 - accuracy: 0.5509 - val_loss: 0.9197 - val_accuracy: 0.5390\n",
      "Epoch 525/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9071 - accuracy: 0.5502 - val_loss: 0.9199 - val_accuracy: 0.5397\n",
      "Epoch 526/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9069 - accuracy: 0.5498 - val_loss: 0.9191 - val_accuracy: 0.5387\n",
      "Epoch 527/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9070 - accuracy: 0.5513 - val_loss: 0.9200 - val_accuracy: 0.5400\n",
      "Epoch 528/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9069 - accuracy: 0.5503 - val_loss: 0.9191 - val_accuracy: 0.5380\n",
      "Epoch 529/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9070 - accuracy: 0.5509 - val_loss: 0.9196 - val_accuracy: 0.5397\n",
      "Epoch 530/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9069 - accuracy: 0.5503 - val_loss: 0.9194 - val_accuracy: 0.5383\n",
      "Epoch 531/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9069 - accuracy: 0.5511 - val_loss: 0.9198 - val_accuracy: 0.5397\n",
      "Epoch 532/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9069 - accuracy: 0.5509 - val_loss: 0.9196 - val_accuracy: 0.5397\n",
      "Epoch 533/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9069 - accuracy: 0.5501 - val_loss: 0.9201 - val_accuracy: 0.5393\n",
      "Epoch 534/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9069 - accuracy: 0.5511 - val_loss: 0.9194 - val_accuracy: 0.5400\n",
      "Epoch 535/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9068 - accuracy: 0.5507 - val_loss: 0.9189 - val_accuracy: 0.5390\n",
      "Epoch 536/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9069 - accuracy: 0.5507 - val_loss: 0.9196 - val_accuracy: 0.5390\n",
      "Epoch 537/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9068 - accuracy: 0.5500 - val_loss: 0.9196 - val_accuracy: 0.5393\n",
      "Epoch 538/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9068 - accuracy: 0.5509 - val_loss: 0.9193 - val_accuracy: 0.5377\n",
      "Epoch 539/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9068 - accuracy: 0.5511 - val_loss: 0.9193 - val_accuracy: 0.5390\n",
      "Epoch 540/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9068 - accuracy: 0.5509 - val_loss: 0.9197 - val_accuracy: 0.5377\n",
      "Epoch 541/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9068 - accuracy: 0.5508 - val_loss: 0.9202 - val_accuracy: 0.5383\n",
      "Epoch 542/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9068 - accuracy: 0.5508 - val_loss: 0.9196 - val_accuracy: 0.5393\n",
      "Epoch 543/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9067 - accuracy: 0.5514 - val_loss: 0.9193 - val_accuracy: 0.5397\n",
      "Epoch 544/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9067 - accuracy: 0.5502 - val_loss: 0.9198 - val_accuracy: 0.5393\n",
      "Epoch 545/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9067 - accuracy: 0.5506 - val_loss: 0.9200 - val_accuracy: 0.5383\n",
      "Epoch 546/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9067 - accuracy: 0.5514 - val_loss: 0.9197 - val_accuracy: 0.5390\n",
      "Epoch 547/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9066 - accuracy: 0.5520 - val_loss: 0.9195 - val_accuracy: 0.5387\n",
      "Epoch 548/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9067 - accuracy: 0.5504 - val_loss: 0.9197 - val_accuracy: 0.5390\n",
      "Epoch 549/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.9066 - accuracy: 0.5510 - val_loss: 0.9189 - val_accuracy: 0.5370\n",
      "Epoch 550/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9066 - accuracy: 0.5504 - val_loss: 0.9195 - val_accuracy: 0.5387\n",
      "Epoch 551/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9066 - accuracy: 0.5496 - val_loss: 0.9189 - val_accuracy: 0.5367\n",
      "Epoch 552/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9066 - accuracy: 0.5518 - val_loss: 0.9188 - val_accuracy: 0.5373\n",
      "Epoch 553/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9066 - accuracy: 0.5499 - val_loss: 0.9198 - val_accuracy: 0.5380\n",
      "Epoch 554/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9065 - accuracy: 0.5504 - val_loss: 0.9188 - val_accuracy: 0.5380\n",
      "Epoch 555/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9066 - accuracy: 0.5507 - val_loss: 0.9194 - val_accuracy: 0.5393\n",
      "Epoch 556/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9064 - accuracy: 0.5519 - val_loss: 0.9190 - val_accuracy: 0.5380\n",
      "Epoch 557/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9065 - accuracy: 0.5501 - val_loss: 0.9186 - val_accuracy: 0.5393\n",
      "Epoch 558/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9065 - accuracy: 0.5509 - val_loss: 0.9191 - val_accuracy: 0.5397\n",
      "Epoch 559/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9065 - accuracy: 0.5509 - val_loss: 0.9195 - val_accuracy: 0.5390\n",
      "Epoch 560/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9065 - accuracy: 0.5503 - val_loss: 0.9192 - val_accuracy: 0.5403\n",
      "Epoch 561/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9064 - accuracy: 0.5512 - val_loss: 0.9199 - val_accuracy: 0.5387\n",
      "Epoch 562/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9064 - accuracy: 0.5503 - val_loss: 0.9198 - val_accuracy: 0.5383\n",
      "Epoch 563/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9064 - accuracy: 0.5504 - val_loss: 0.9184 - val_accuracy: 0.5390\n",
      "Epoch 564/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9065 - accuracy: 0.5506 - val_loss: 0.9191 - val_accuracy: 0.5397\n",
      "Epoch 565/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9063 - accuracy: 0.5516 - val_loss: 0.9199 - val_accuracy: 0.5403\n",
      "Epoch 566/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9064 - accuracy: 0.5506 - val_loss: 0.9187 - val_accuracy: 0.5373\n",
      "Epoch 567/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9063 - accuracy: 0.5517 - val_loss: 0.9197 - val_accuracy: 0.5373\n",
      "Epoch 568/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9063 - accuracy: 0.5506 - val_loss: 0.9189 - val_accuracy: 0.5387\n",
      "Epoch 569/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9063 - accuracy: 0.5506 - val_loss: 0.9188 - val_accuracy: 0.5390\n",
      "Epoch 570/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9062 - accuracy: 0.5516 - val_loss: 0.9204 - val_accuracy: 0.5387\n",
      "Epoch 571/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9060 - accuracy: 0.5516 - val_loss: 0.9217 - val_accuracy: 0.5377\n",
      "Epoch 572/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9063 - accuracy: 0.5516 - val_loss: 0.9187 - val_accuracy: 0.5370\n",
      "Epoch 573/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9062 - accuracy: 0.5514 - val_loss: 0.9197 - val_accuracy: 0.5380\n",
      "Epoch 574/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9063 - accuracy: 0.5501 - val_loss: 0.9192 - val_accuracy: 0.5393\n",
      "Epoch 575/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9062 - accuracy: 0.5512 - val_loss: 0.9190 - val_accuracy: 0.5390\n",
      "Epoch 576/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9062 - accuracy: 0.5504 - val_loss: 0.9183 - val_accuracy: 0.5390\n",
      "Epoch 577/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9062 - accuracy: 0.5527 - val_loss: 0.9193 - val_accuracy: 0.5383\n",
      "Epoch 578/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9061 - accuracy: 0.5512 - val_loss: 0.9203 - val_accuracy: 0.5390\n",
      "Epoch 579/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9062 - accuracy: 0.5507 - val_loss: 0.9195 - val_accuracy: 0.5383\n",
      "Epoch 580/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9061 - accuracy: 0.5507 - val_loss: 0.9194 - val_accuracy: 0.5390\n",
      "Epoch 581/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9062 - accuracy: 0.5516 - val_loss: 0.9190 - val_accuracy: 0.5407\n",
      "Epoch 582/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9061 - accuracy: 0.5511 - val_loss: 0.9189 - val_accuracy: 0.5397\n",
      "Epoch 583/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9061 - accuracy: 0.5512 - val_loss: 0.9183 - val_accuracy: 0.5387\n",
      "Epoch 584/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9060 - accuracy: 0.5506 - val_loss: 0.9191 - val_accuracy: 0.5393\n",
      "Epoch 585/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9061 - accuracy: 0.5514 - val_loss: 0.9188 - val_accuracy: 0.5400\n",
      "Epoch 586/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9060 - accuracy: 0.5511 - val_loss: 0.9194 - val_accuracy: 0.5380\n",
      "Epoch 587/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9061 - accuracy: 0.5514 - val_loss: 0.9188 - val_accuracy: 0.5393\n",
      "Epoch 588/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9059 - accuracy: 0.5509 - val_loss: 0.9179 - val_accuracy: 0.5393\n",
      "Epoch 589/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9061 - accuracy: 0.5515 - val_loss: 0.9183 - val_accuracy: 0.5380\n",
      "Epoch 590/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9059 - accuracy: 0.5514 - val_loss: 0.9179 - val_accuracy: 0.5397\n",
      "Epoch 591/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9060 - accuracy: 0.5518 - val_loss: 0.9193 - val_accuracy: 0.5377\n",
      "Epoch 592/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9060 - accuracy: 0.5511 - val_loss: 0.9186 - val_accuracy: 0.5397\n",
      "Epoch 593/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9059 - accuracy: 0.5524 - val_loss: 0.9179 - val_accuracy: 0.5390\n",
      "Epoch 594/5500\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 0.9059 - accuracy: 0.5509 - val_loss: 0.9180 - val_accuracy: 0.5383\n",
      "Epoch 595/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9060 - accuracy: 0.5502 - val_loss: 0.9187 - val_accuracy: 0.5400\n",
      "Epoch 596/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9059 - accuracy: 0.5513 - val_loss: 0.9186 - val_accuracy: 0.5397\n",
      "Epoch 597/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9059 - accuracy: 0.5515 - val_loss: 0.9186 - val_accuracy: 0.5393\n",
      "Epoch 598/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9058 - accuracy: 0.5524 - val_loss: 0.9190 - val_accuracy: 0.5380\n",
      "Epoch 599/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9057 - accuracy: 0.5518 - val_loss: 0.9178 - val_accuracy: 0.5393\n",
      "Epoch 600/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9058 - accuracy: 0.5514 - val_loss: 0.9185 - val_accuracy: 0.5390\n",
      "Epoch 601/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9059 - accuracy: 0.5514 - val_loss: 0.9184 - val_accuracy: 0.5400\n",
      "Epoch 602/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9058 - accuracy: 0.5519 - val_loss: 0.9191 - val_accuracy: 0.5377\n",
      "Epoch 603/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9057 - accuracy: 0.5514 - val_loss: 0.9179 - val_accuracy: 0.5390\n",
      "Epoch 604/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9058 - accuracy: 0.5513 - val_loss: 0.9183 - val_accuracy: 0.5397\n",
      "Epoch 605/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9057 - accuracy: 0.5521 - val_loss: 0.9178 - val_accuracy: 0.5397\n",
      "Epoch 606/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9058 - accuracy: 0.5506 - val_loss: 0.9188 - val_accuracy: 0.5383\n",
      "Epoch 607/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9057 - accuracy: 0.5521 - val_loss: 0.9184 - val_accuracy: 0.5393\n",
      "Epoch 608/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9057 - accuracy: 0.5521 - val_loss: 0.9182 - val_accuracy: 0.5400\n",
      "Epoch 609/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9057 - accuracy: 0.5510 - val_loss: 0.9177 - val_accuracy: 0.5390\n",
      "Epoch 610/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9056 - accuracy: 0.5506 - val_loss: 0.9179 - val_accuracy: 0.5387\n",
      "Epoch 611/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9057 - accuracy: 0.5517 - val_loss: 0.9181 - val_accuracy: 0.5393\n",
      "Epoch 612/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9056 - accuracy: 0.5513 - val_loss: 0.9188 - val_accuracy: 0.5380\n",
      "Epoch 613/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9056 - accuracy: 0.5510 - val_loss: 0.9178 - val_accuracy: 0.5390\n",
      "Epoch 614/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9056 - accuracy: 0.5516 - val_loss: 0.9178 - val_accuracy: 0.5397\n",
      "Epoch 615/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9056 - accuracy: 0.5509 - val_loss: 0.9178 - val_accuracy: 0.5400\n",
      "Epoch 616/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9056 - accuracy: 0.5521 - val_loss: 0.9183 - val_accuracy: 0.5387\n",
      "Epoch 617/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9056 - accuracy: 0.5514 - val_loss: 0.9178 - val_accuracy: 0.5400\n",
      "Epoch 618/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9055 - accuracy: 0.5519 - val_loss: 0.9191 - val_accuracy: 0.5390\n",
      "Epoch 619/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9055 - accuracy: 0.5510 - val_loss: 0.9180 - val_accuracy: 0.5397\n",
      "Epoch 620/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9055 - accuracy: 0.5516 - val_loss: 0.9179 - val_accuracy: 0.5390\n",
      "Epoch 621/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9055 - accuracy: 0.5514 - val_loss: 0.9182 - val_accuracy: 0.5393\n",
      "Epoch 622/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9055 - accuracy: 0.5511 - val_loss: 0.9188 - val_accuracy: 0.5377\n",
      "Epoch 623/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9054 - accuracy: 0.5531 - val_loss: 0.9185 - val_accuracy: 0.5377\n",
      "Epoch 624/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9055 - accuracy: 0.5528 - val_loss: 0.9180 - val_accuracy: 0.5387\n",
      "Epoch 625/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9054 - accuracy: 0.5511 - val_loss: 0.9181 - val_accuracy: 0.5397\n",
      "Epoch 626/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9054 - accuracy: 0.5521 - val_loss: 0.9178 - val_accuracy: 0.5387\n",
      "Epoch 627/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9054 - accuracy: 0.5516 - val_loss: 0.9175 - val_accuracy: 0.5390\n",
      "Epoch 628/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9053 - accuracy: 0.5513 - val_loss: 0.9175 - val_accuracy: 0.5393\n",
      "Epoch 629/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9054 - accuracy: 0.5510 - val_loss: 0.9177 - val_accuracy: 0.5390\n",
      "Epoch 630/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9054 - accuracy: 0.5517 - val_loss: 0.9179 - val_accuracy: 0.5400\n",
      "Epoch 631/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9053 - accuracy: 0.5511 - val_loss: 0.9184 - val_accuracy: 0.5387\n",
      "Epoch 632/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9053 - accuracy: 0.5515 - val_loss: 0.9183 - val_accuracy: 0.5380\n",
      "Epoch 633/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9053 - accuracy: 0.5511 - val_loss: 0.9178 - val_accuracy: 0.5387\n",
      "Epoch 634/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9053 - accuracy: 0.5528 - val_loss: 0.9181 - val_accuracy: 0.5390\n",
      "Epoch 635/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9053 - accuracy: 0.5522 - val_loss: 0.9187 - val_accuracy: 0.5387\n",
      "Epoch 636/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9053 - accuracy: 0.5507 - val_loss: 0.9181 - val_accuracy: 0.5387\n",
      "Epoch 637/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9052 - accuracy: 0.5523 - val_loss: 0.9172 - val_accuracy: 0.5390\n",
      "Epoch 638/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9052 - accuracy: 0.5514 - val_loss: 0.9173 - val_accuracy: 0.5393\n",
      "Epoch 639/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9052 - accuracy: 0.5517 - val_loss: 0.9177 - val_accuracy: 0.5383\n",
      "Epoch 640/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9053 - accuracy: 0.5521 - val_loss: 0.9180 - val_accuracy: 0.5387\n",
      "Epoch 641/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9052 - accuracy: 0.5520 - val_loss: 0.9187 - val_accuracy: 0.5383\n",
      "Epoch 642/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9052 - accuracy: 0.5521 - val_loss: 0.9174 - val_accuracy: 0.5390\n",
      "Epoch 643/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9052 - accuracy: 0.5521 - val_loss: 0.9186 - val_accuracy: 0.5390\n",
      "Epoch 644/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9052 - accuracy: 0.5505 - val_loss: 0.9174 - val_accuracy: 0.5393\n",
      "Epoch 645/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9051 - accuracy: 0.5517 - val_loss: 0.9168 - val_accuracy: 0.5377\n",
      "Epoch 646/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.9052 - accuracy: 0.5521 - val_loss: 0.9175 - val_accuracy: 0.5390\n",
      "Epoch 647/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9051 - accuracy: 0.5524 - val_loss: 0.9185 - val_accuracy: 0.5383\n",
      "Epoch 648/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9051 - accuracy: 0.5515 - val_loss: 0.9185 - val_accuracy: 0.5393\n",
      "Epoch 649/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9051 - accuracy: 0.5522 - val_loss: 0.9182 - val_accuracy: 0.5383\n",
      "Epoch 650/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9051 - accuracy: 0.5521 - val_loss: 0.9172 - val_accuracy: 0.5390\n",
      "Epoch 651/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9051 - accuracy: 0.5524 - val_loss: 0.9174 - val_accuracy: 0.5393\n",
      "Epoch 652/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9050 - accuracy: 0.5519 - val_loss: 0.9173 - val_accuracy: 0.5397\n",
      "Epoch 653/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9050 - accuracy: 0.5519 - val_loss: 0.9170 - val_accuracy: 0.5397\n",
      "Epoch 654/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9050 - accuracy: 0.5534 - val_loss: 0.9172 - val_accuracy: 0.5393\n",
      "Epoch 655/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9050 - accuracy: 0.5517 - val_loss: 0.9182 - val_accuracy: 0.5383\n",
      "Epoch 656/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9049 - accuracy: 0.5521 - val_loss: 0.9170 - val_accuracy: 0.5383\n",
      "Epoch 657/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9050 - accuracy: 0.5501 - val_loss: 0.9179 - val_accuracy: 0.5390\n",
      "Epoch 658/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9050 - accuracy: 0.5523 - val_loss: 0.9177 - val_accuracy: 0.5393\n",
      "Epoch 659/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9049 - accuracy: 0.5515 - val_loss: 0.9168 - val_accuracy: 0.5393\n",
      "Epoch 660/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9049 - accuracy: 0.5520 - val_loss: 0.9179 - val_accuracy: 0.5393\n",
      "Epoch 661/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9049 - accuracy: 0.5518 - val_loss: 0.9177 - val_accuracy: 0.5380\n",
      "Epoch 662/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9049 - accuracy: 0.5521 - val_loss: 0.9171 - val_accuracy: 0.5390\n",
      "Epoch 663/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9049 - accuracy: 0.5515 - val_loss: 0.9174 - val_accuracy: 0.5383\n",
      "Epoch 664/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9049 - accuracy: 0.5523 - val_loss: 0.9184 - val_accuracy: 0.5403\n",
      "Epoch 665/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9049 - accuracy: 0.5516 - val_loss: 0.9180 - val_accuracy: 0.5380\n",
      "Epoch 666/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9048 - accuracy: 0.5509 - val_loss: 0.9171 - val_accuracy: 0.5393\n",
      "Epoch 667/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9048 - accuracy: 0.5524 - val_loss: 0.9170 - val_accuracy: 0.5393\n",
      "Epoch 668/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9048 - accuracy: 0.5541 - val_loss: 0.9167 - val_accuracy: 0.5387\n",
      "Epoch 669/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9047 - accuracy: 0.5529 - val_loss: 0.9177 - val_accuracy: 0.5383\n",
      "Epoch 670/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.9048 - accuracy: 0.5519 - val_loss: 0.9174 - val_accuracy: 0.5383\n",
      "Epoch 671/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9047 - accuracy: 0.5520 - val_loss: 0.9171 - val_accuracy: 0.5390\n",
      "Epoch 672/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9047 - accuracy: 0.5519 - val_loss: 0.9168 - val_accuracy: 0.5380\n",
      "Epoch 673/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9047 - accuracy: 0.5529 - val_loss: 0.9166 - val_accuracy: 0.5390\n",
      "Epoch 674/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9046 - accuracy: 0.5524 - val_loss: 0.9184 - val_accuracy: 0.5383\n",
      "Epoch 675/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9047 - accuracy: 0.5529 - val_loss: 0.9174 - val_accuracy: 0.5383\n",
      "Epoch 676/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9047 - accuracy: 0.5526 - val_loss: 0.9173 - val_accuracy: 0.5393\n",
      "Epoch 677/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9047 - accuracy: 0.5516 - val_loss: 0.9168 - val_accuracy: 0.5390\n",
      "Epoch 678/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9046 - accuracy: 0.5521 - val_loss: 0.9164 - val_accuracy: 0.5383\n",
      "Epoch 679/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9047 - accuracy: 0.5526 - val_loss: 0.9170 - val_accuracy: 0.5390\n",
      "Epoch 680/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9046 - accuracy: 0.5527 - val_loss: 0.9169 - val_accuracy: 0.5390\n",
      "Epoch 681/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9046 - accuracy: 0.5521 - val_loss: 0.9164 - val_accuracy: 0.5377\n",
      "Epoch 682/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.9046 - accuracy: 0.5517 - val_loss: 0.9174 - val_accuracy: 0.5383\n",
      "Epoch 683/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9045 - accuracy: 0.5526 - val_loss: 0.9168 - val_accuracy: 0.5387\n",
      "Epoch 684/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9045 - accuracy: 0.5519 - val_loss: 0.9167 - val_accuracy: 0.5380\n",
      "Epoch 685/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9046 - accuracy: 0.5515 - val_loss: 0.9172 - val_accuracy: 0.5377\n",
      "Epoch 686/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9046 - accuracy: 0.5514 - val_loss: 0.9168 - val_accuracy: 0.5387\n",
      "Epoch 687/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9045 - accuracy: 0.5528 - val_loss: 0.9168 - val_accuracy: 0.5387\n",
      "Epoch 688/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9045 - accuracy: 0.5516 - val_loss: 0.9174 - val_accuracy: 0.5383\n",
      "Epoch 689/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9045 - accuracy: 0.5511 - val_loss: 0.9167 - val_accuracy: 0.5390\n",
      "Epoch 690/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9044 - accuracy: 0.5531 - val_loss: 0.9166 - val_accuracy: 0.5387\n",
      "Epoch 691/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9045 - accuracy: 0.5518 - val_loss: 0.9171 - val_accuracy: 0.5377\n",
      "Epoch 692/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9045 - accuracy: 0.5519 - val_loss: 0.9169 - val_accuracy: 0.5383\n",
      "Epoch 693/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9044 - accuracy: 0.5524 - val_loss: 0.9178 - val_accuracy: 0.5377\n",
      "Epoch 694/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9044 - accuracy: 0.5524 - val_loss: 0.9179 - val_accuracy: 0.5377\n",
      "Epoch 695/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9044 - accuracy: 0.5529 - val_loss: 0.9178 - val_accuracy: 0.5380\n",
      "Epoch 696/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9044 - accuracy: 0.5517 - val_loss: 0.9166 - val_accuracy: 0.5380\n",
      "Epoch 697/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9043 - accuracy: 0.5522 - val_loss: 0.9175 - val_accuracy: 0.5387\n",
      "Epoch 698/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9044 - accuracy: 0.5525 - val_loss: 0.9164 - val_accuracy: 0.5383\n",
      "Epoch 699/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9044 - accuracy: 0.5526 - val_loss: 0.9163 - val_accuracy: 0.5383\n",
      "Epoch 700/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9043 - accuracy: 0.5522 - val_loss: 0.9161 - val_accuracy: 0.5387\n",
      "Epoch 701/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9043 - accuracy: 0.5523 - val_loss: 0.9177 - val_accuracy: 0.5393\n",
      "Epoch 702/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9043 - accuracy: 0.5515 - val_loss: 0.9170 - val_accuracy: 0.5383\n",
      "Epoch 703/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9043 - accuracy: 0.5517 - val_loss: 0.9163 - val_accuracy: 0.5390\n",
      "Epoch 704/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9042 - accuracy: 0.5505 - val_loss: 0.9179 - val_accuracy: 0.5387\n",
      "Epoch 705/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9043 - accuracy: 0.5520 - val_loss: 0.9167 - val_accuracy: 0.5393\n",
      "Epoch 706/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9043 - accuracy: 0.5518 - val_loss: 0.9164 - val_accuracy: 0.5390\n",
      "Epoch 707/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9042 - accuracy: 0.5517 - val_loss: 0.9160 - val_accuracy: 0.5390\n",
      "Epoch 708/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9043 - accuracy: 0.5516 - val_loss: 0.9167 - val_accuracy: 0.5397\n",
      "Epoch 709/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9042 - accuracy: 0.5519 - val_loss: 0.9169 - val_accuracy: 0.5377\n",
      "Epoch 710/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9042 - accuracy: 0.5514 - val_loss: 0.9174 - val_accuracy: 0.5390\n",
      "Epoch 711/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9042 - accuracy: 0.5519 - val_loss: 0.9159 - val_accuracy: 0.5387\n",
      "Epoch 712/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9042 - accuracy: 0.5524 - val_loss: 0.9162 - val_accuracy: 0.5393\n",
      "Epoch 713/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9041 - accuracy: 0.5516 - val_loss: 0.9163 - val_accuracy: 0.5390\n",
      "Epoch 714/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9041 - accuracy: 0.5519 - val_loss: 0.9164 - val_accuracy: 0.5383\n",
      "Epoch 715/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9039 - accuracy: 0.5513 - val_loss: 0.9194 - val_accuracy: 0.5363\n",
      "Epoch 716/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9042 - accuracy: 0.5526 - val_loss: 0.9171 - val_accuracy: 0.5390\n",
      "Epoch 717/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9041 - accuracy: 0.5508 - val_loss: 0.9175 - val_accuracy: 0.5387\n",
      "Epoch 718/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9040 - accuracy: 0.5516 - val_loss: 0.9162 - val_accuracy: 0.5387\n",
      "Epoch 719/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9041 - accuracy: 0.5531 - val_loss: 0.9171 - val_accuracy: 0.5393\n",
      "Epoch 720/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9040 - accuracy: 0.5511 - val_loss: 0.9158 - val_accuracy: 0.5407\n",
      "Epoch 721/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9040 - accuracy: 0.5513 - val_loss: 0.9156 - val_accuracy: 0.5383\n",
      "Epoch 722/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9041 - accuracy: 0.5530 - val_loss: 0.9164 - val_accuracy: 0.5383\n",
      "Epoch 723/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9040 - accuracy: 0.5533 - val_loss: 0.9169 - val_accuracy: 0.5383\n",
      "Epoch 724/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9040 - accuracy: 0.5512 - val_loss: 0.9172 - val_accuracy: 0.5380\n",
      "Epoch 725/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9039 - accuracy: 0.5530 - val_loss: 0.9179 - val_accuracy: 0.5407\n",
      "Epoch 726/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9040 - accuracy: 0.5524 - val_loss: 0.9175 - val_accuracy: 0.5380\n",
      "Epoch 727/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9039 - accuracy: 0.5515 - val_loss: 0.9166 - val_accuracy: 0.5377\n",
      "Epoch 728/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9039 - accuracy: 0.5521 - val_loss: 0.9168 - val_accuracy: 0.5387\n",
      "Epoch 729/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9039 - accuracy: 0.5527 - val_loss: 0.9168 - val_accuracy: 0.5380\n",
      "Epoch 730/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9040 - accuracy: 0.5519 - val_loss: 0.9160 - val_accuracy: 0.5387\n",
      "Epoch 731/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9039 - accuracy: 0.5528 - val_loss: 0.9168 - val_accuracy: 0.5387\n",
      "Epoch 732/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9038 - accuracy: 0.5529 - val_loss: 0.9172 - val_accuracy: 0.5387\n",
      "Epoch 733/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9039 - accuracy: 0.5510 - val_loss: 0.9162 - val_accuracy: 0.5377\n",
      "Epoch 734/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9039 - accuracy: 0.5519 - val_loss: 0.9158 - val_accuracy: 0.5397\n",
      "Epoch 735/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9038 - accuracy: 0.5524 - val_loss: 0.9165 - val_accuracy: 0.5370\n",
      "Epoch 736/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9038 - accuracy: 0.5532 - val_loss: 0.9173 - val_accuracy: 0.5380\n",
      "Epoch 737/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9038 - accuracy: 0.5516 - val_loss: 0.9169 - val_accuracy: 0.5393\n",
      "Epoch 738/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9037 - accuracy: 0.5528 - val_loss: 0.9162 - val_accuracy: 0.5380\n",
      "Epoch 739/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9038 - accuracy: 0.5531 - val_loss: 0.9162 - val_accuracy: 0.5377\n",
      "Epoch 740/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9038 - accuracy: 0.5515 - val_loss: 0.9160 - val_accuracy: 0.5397\n",
      "Epoch 741/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9037 - accuracy: 0.5521 - val_loss: 0.9159 - val_accuracy: 0.5387\n",
      "Epoch 742/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9038 - accuracy: 0.5526 - val_loss: 0.9164 - val_accuracy: 0.5377\n",
      "Epoch 743/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9037 - accuracy: 0.5536 - val_loss: 0.9159 - val_accuracy: 0.5387\n",
      "Epoch 744/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9038 - accuracy: 0.5527 - val_loss: 0.9155 - val_accuracy: 0.5397\n",
      "Epoch 745/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9037 - accuracy: 0.5521 - val_loss: 0.9167 - val_accuracy: 0.5397\n",
      "Epoch 746/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9036 - accuracy: 0.5511 - val_loss: 0.9168 - val_accuracy: 0.5400\n",
      "Epoch 747/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9037 - accuracy: 0.5511 - val_loss: 0.9160 - val_accuracy: 0.5380\n",
      "Epoch 748/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9037 - accuracy: 0.5522 - val_loss: 0.9166 - val_accuracy: 0.5373\n",
      "Epoch 749/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9036 - accuracy: 0.5527 - val_loss: 0.9160 - val_accuracy: 0.5397\n",
      "Epoch 750/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9036 - accuracy: 0.5519 - val_loss: 0.9159 - val_accuracy: 0.5393\n",
      "Epoch 751/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9036 - accuracy: 0.5531 - val_loss: 0.9159 - val_accuracy: 0.5390\n",
      "Epoch 752/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9036 - accuracy: 0.5521 - val_loss: 0.9157 - val_accuracy: 0.5397\n",
      "Epoch 753/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9036 - accuracy: 0.5527 - val_loss: 0.9154 - val_accuracy: 0.5403\n",
      "Epoch 754/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9036 - accuracy: 0.5524 - val_loss: 0.9158 - val_accuracy: 0.5400\n",
      "Epoch 755/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9036 - accuracy: 0.5521 - val_loss: 0.9158 - val_accuracy: 0.5397\n",
      "Epoch 756/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9036 - accuracy: 0.5540 - val_loss: 0.9163 - val_accuracy: 0.5387\n",
      "Epoch 757/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9036 - accuracy: 0.5536 - val_loss: 0.9161 - val_accuracy: 0.5367\n",
      "Epoch 758/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9035 - accuracy: 0.5519 - val_loss: 0.9152 - val_accuracy: 0.5390\n",
      "Epoch 759/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9036 - accuracy: 0.5529 - val_loss: 0.9157 - val_accuracy: 0.5393\n",
      "Epoch 760/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9034 - accuracy: 0.5530 - val_loss: 0.9150 - val_accuracy: 0.5393\n",
      "Epoch 761/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9035 - accuracy: 0.5517 - val_loss: 0.9151 - val_accuracy: 0.5403\n",
      "Epoch 762/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9035 - accuracy: 0.5521 - val_loss: 0.9163 - val_accuracy: 0.5380\n",
      "Epoch 763/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9035 - accuracy: 0.5521 - val_loss: 0.9155 - val_accuracy: 0.5400\n",
      "Epoch 764/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9035 - accuracy: 0.5524 - val_loss: 0.9162 - val_accuracy: 0.5380\n",
      "Epoch 765/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9035 - accuracy: 0.5527 - val_loss: 0.9154 - val_accuracy: 0.5380\n",
      "Epoch 766/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9035 - accuracy: 0.5519 - val_loss: 0.9155 - val_accuracy: 0.5400\n",
      "Epoch 767/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9034 - accuracy: 0.5529 - val_loss: 0.9157 - val_accuracy: 0.5397\n",
      "Epoch 768/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9035 - accuracy: 0.5521 - val_loss: 0.9160 - val_accuracy: 0.5363\n",
      "Epoch 769/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9034 - accuracy: 0.5516 - val_loss: 0.9158 - val_accuracy: 0.5387\n",
      "Epoch 770/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9034 - accuracy: 0.5534 - val_loss: 0.9157 - val_accuracy: 0.5400\n",
      "Epoch 771/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9034 - accuracy: 0.5534 - val_loss: 0.9153 - val_accuracy: 0.5397\n",
      "Epoch 772/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9033 - accuracy: 0.5525 - val_loss: 0.9162 - val_accuracy: 0.5377\n",
      "Epoch 773/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9034 - accuracy: 0.5541 - val_loss: 0.9154 - val_accuracy: 0.5403\n",
      "Epoch 774/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9034 - accuracy: 0.5534 - val_loss: 0.9152 - val_accuracy: 0.5387\n",
      "Epoch 775/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9034 - accuracy: 0.5525 - val_loss: 0.9159 - val_accuracy: 0.5380\n",
      "Epoch 776/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9033 - accuracy: 0.5521 - val_loss: 0.9164 - val_accuracy: 0.5393\n",
      "Epoch 777/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9033 - accuracy: 0.5524 - val_loss: 0.9154 - val_accuracy: 0.5397\n",
      "Epoch 778/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9033 - accuracy: 0.5526 - val_loss: 0.9153 - val_accuracy: 0.5393\n",
      "Epoch 779/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9033 - accuracy: 0.5527 - val_loss: 0.9153 - val_accuracy: 0.5390\n",
      "Epoch 780/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9033 - accuracy: 0.5529 - val_loss: 0.9156 - val_accuracy: 0.5387\n",
      "Epoch 781/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9032 - accuracy: 0.5522 - val_loss: 0.9158 - val_accuracy: 0.5377\n",
      "Epoch 782/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9032 - accuracy: 0.5521 - val_loss: 0.9160 - val_accuracy: 0.5377\n",
      "Epoch 783/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9032 - accuracy: 0.5532 - val_loss: 0.9147 - val_accuracy: 0.5403\n",
      "Epoch 784/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9032 - accuracy: 0.5510 - val_loss: 0.9163 - val_accuracy: 0.5387\n",
      "Epoch 785/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9032 - accuracy: 0.5538 - val_loss: 0.9161 - val_accuracy: 0.5380\n",
      "Epoch 786/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9032 - accuracy: 0.5523 - val_loss: 0.9157 - val_accuracy: 0.5390\n",
      "Epoch 787/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.9030 - accuracy: 0.5534 - val_loss: 0.9164 - val_accuracy: 0.5387\n",
      "Epoch 788/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9031 - accuracy: 0.5535 - val_loss: 0.9151 - val_accuracy: 0.5407\n",
      "Epoch 789/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9032 - accuracy: 0.5536 - val_loss: 0.9157 - val_accuracy: 0.5373\n",
      "Epoch 790/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9031 - accuracy: 0.5525 - val_loss: 0.9153 - val_accuracy: 0.5397\n",
      "Epoch 791/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9031 - accuracy: 0.5527 - val_loss: 0.9159 - val_accuracy: 0.5373\n",
      "Epoch 792/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9031 - accuracy: 0.5520 - val_loss: 0.9160 - val_accuracy: 0.5377\n",
      "Epoch 793/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9031 - accuracy: 0.5528 - val_loss: 0.9154 - val_accuracy: 0.5393\n",
      "Epoch 794/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9032 - accuracy: 0.5539 - val_loss: 0.9158 - val_accuracy: 0.5383\n",
      "Epoch 795/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9031 - accuracy: 0.5521 - val_loss: 0.9158 - val_accuracy: 0.5377\n",
      "Epoch 796/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9031 - accuracy: 0.5531 - val_loss: 0.9171 - val_accuracy: 0.5397\n",
      "Epoch 797/5500\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 0.9030 - accuracy: 0.5538 - val_loss: 0.9156 - val_accuracy: 0.5377\n",
      "Epoch 798/5500\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.9030 - accuracy: 0.5520 - val_loss: 0.9157 - val_accuracy: 0.5390\n",
      "Epoch 799/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9030 - accuracy: 0.5521 - val_loss: 0.9155 - val_accuracy: 0.5383\n",
      "Epoch 800/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9031 - accuracy: 0.5535 - val_loss: 0.9162 - val_accuracy: 0.5387\n",
      "Epoch 801/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9029 - accuracy: 0.5527 - val_loss: 0.9170 - val_accuracy: 0.5390\n",
      "Epoch 802/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.9030 - accuracy: 0.5522 - val_loss: 0.9152 - val_accuracy: 0.5407\n",
      "Epoch 803/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.9029 - accuracy: 0.5514 - val_loss: 0.9149 - val_accuracy: 0.5393\n",
      "Epoch 804/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9030 - accuracy: 0.5516 - val_loss: 0.9146 - val_accuracy: 0.5390\n",
      "Epoch 805/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9030 - accuracy: 0.5525 - val_loss: 0.9157 - val_accuracy: 0.5377\n",
      "Epoch 806/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9030 - accuracy: 0.5531 - val_loss: 0.9157 - val_accuracy: 0.5383\n",
      "Epoch 807/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9029 - accuracy: 0.5524 - val_loss: 0.9164 - val_accuracy: 0.5383\n",
      "Epoch 808/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9029 - accuracy: 0.5524 - val_loss: 0.9151 - val_accuracy: 0.5390\n",
      "Epoch 809/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9030 - accuracy: 0.5533 - val_loss: 0.9161 - val_accuracy: 0.5397\n",
      "Epoch 810/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9029 - accuracy: 0.5537 - val_loss: 0.9161 - val_accuracy: 0.5393\n",
      "Epoch 811/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9028 - accuracy: 0.5527 - val_loss: 0.9175 - val_accuracy: 0.5380\n",
      "Epoch 812/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9030 - accuracy: 0.5502 - val_loss: 0.9152 - val_accuracy: 0.5390\n",
      "Epoch 813/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9028 - accuracy: 0.5531 - val_loss: 0.9152 - val_accuracy: 0.5390\n",
      "Epoch 814/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9029 - accuracy: 0.5525 - val_loss: 0.9151 - val_accuracy: 0.5403\n",
      "Epoch 815/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9028 - accuracy: 0.5533 - val_loss: 0.9156 - val_accuracy: 0.5383\n",
      "Epoch 816/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9028 - accuracy: 0.5526 - val_loss: 0.9147 - val_accuracy: 0.5390\n",
      "Epoch 817/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9029 - accuracy: 0.5530 - val_loss: 0.9147 - val_accuracy: 0.5403\n",
      "Epoch 818/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9028 - accuracy: 0.5521 - val_loss: 0.9147 - val_accuracy: 0.5407\n",
      "Epoch 819/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9027 - accuracy: 0.5533 - val_loss: 0.9163 - val_accuracy: 0.5387\n",
      "Epoch 820/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9028 - accuracy: 0.5530 - val_loss: 0.9153 - val_accuracy: 0.5383\n",
      "Epoch 821/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9028 - accuracy: 0.5537 - val_loss: 0.9146 - val_accuracy: 0.5407\n",
      "Epoch 822/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9028 - accuracy: 0.5526 - val_loss: 0.9154 - val_accuracy: 0.5387\n",
      "Epoch 823/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9028 - accuracy: 0.5539 - val_loss: 0.9153 - val_accuracy: 0.5390\n",
      "Epoch 824/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9028 - accuracy: 0.5536 - val_loss: 0.9147 - val_accuracy: 0.5377\n",
      "Epoch 825/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9027 - accuracy: 0.5531 - val_loss: 0.9152 - val_accuracy: 0.5390\n",
      "Epoch 826/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9027 - accuracy: 0.5518 - val_loss: 0.9155 - val_accuracy: 0.5387\n",
      "Epoch 827/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9027 - accuracy: 0.5543 - val_loss: 0.9164 - val_accuracy: 0.5397\n",
      "Epoch 828/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9027 - accuracy: 0.5538 - val_loss: 0.9160 - val_accuracy: 0.5407\n",
      "Epoch 829/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9028 - accuracy: 0.5521 - val_loss: 0.9149 - val_accuracy: 0.5397\n",
      "Epoch 830/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9027 - accuracy: 0.5536 - val_loss: 0.9150 - val_accuracy: 0.5387\n",
      "Epoch 831/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9027 - accuracy: 0.5526 - val_loss: 0.9143 - val_accuracy: 0.5387\n",
      "Epoch 832/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9026 - accuracy: 0.5529 - val_loss: 0.9145 - val_accuracy: 0.5397\n",
      "Epoch 833/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9026 - accuracy: 0.5522 - val_loss: 0.9147 - val_accuracy: 0.5397\n",
      "Epoch 834/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9027 - accuracy: 0.5527 - val_loss: 0.9156 - val_accuracy: 0.5390\n",
      "Epoch 835/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9026 - accuracy: 0.5523 - val_loss: 0.9150 - val_accuracy: 0.5390\n",
      "Epoch 836/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9025 - accuracy: 0.5541 - val_loss: 0.9142 - val_accuracy: 0.5413\n",
      "Epoch 837/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9026 - accuracy: 0.5535 - val_loss: 0.9158 - val_accuracy: 0.5390\n",
      "Epoch 838/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9025 - accuracy: 0.5532 - val_loss: 0.9149 - val_accuracy: 0.5393\n",
      "Epoch 839/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9026 - accuracy: 0.5533 - val_loss: 0.9146 - val_accuracy: 0.5400\n",
      "Epoch 840/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9025 - accuracy: 0.5530 - val_loss: 0.9163 - val_accuracy: 0.5377\n",
      "Epoch 841/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9025 - accuracy: 0.5535 - val_loss: 0.9162 - val_accuracy: 0.5380\n",
      "Epoch 842/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9025 - accuracy: 0.5531 - val_loss: 0.9143 - val_accuracy: 0.5410\n",
      "Epoch 843/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9026 - accuracy: 0.5539 - val_loss: 0.9147 - val_accuracy: 0.5380\n",
      "Epoch 844/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9024 - accuracy: 0.5527 - val_loss: 0.9153 - val_accuracy: 0.5393\n",
      "Epoch 845/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9025 - accuracy: 0.5530 - val_loss: 0.9154 - val_accuracy: 0.5387\n",
      "Epoch 846/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9025 - accuracy: 0.5540 - val_loss: 0.9156 - val_accuracy: 0.5397\n",
      "Epoch 847/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9025 - accuracy: 0.5528 - val_loss: 0.9144 - val_accuracy: 0.5397\n",
      "Epoch 848/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9024 - accuracy: 0.5530 - val_loss: 0.9153 - val_accuracy: 0.5387\n",
      "Epoch 849/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9024 - accuracy: 0.5545 - val_loss: 0.9145 - val_accuracy: 0.5397\n",
      "Epoch 850/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9024 - accuracy: 0.5529 - val_loss: 0.9155 - val_accuracy: 0.5397\n",
      "Epoch 851/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9023 - accuracy: 0.5529 - val_loss: 0.9158 - val_accuracy: 0.5393\n",
      "Epoch 852/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9024 - accuracy: 0.5541 - val_loss: 0.9145 - val_accuracy: 0.5403\n",
      "Epoch 853/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9024 - accuracy: 0.5526 - val_loss: 0.9149 - val_accuracy: 0.5393\n",
      "Epoch 854/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9024 - accuracy: 0.5532 - val_loss: 0.9152 - val_accuracy: 0.5397\n",
      "Epoch 855/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9024 - accuracy: 0.5530 - val_loss: 0.9147 - val_accuracy: 0.5390\n",
      "Epoch 856/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9024 - accuracy: 0.5539 - val_loss: 0.9148 - val_accuracy: 0.5390\n",
      "Epoch 857/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9024 - accuracy: 0.5531 - val_loss: 0.9148 - val_accuracy: 0.5390\n",
      "Epoch 858/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9024 - accuracy: 0.5536 - val_loss: 0.9147 - val_accuracy: 0.5387\n",
      "Epoch 859/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9023 - accuracy: 0.5526 - val_loss: 0.9157 - val_accuracy: 0.5387\n",
      "Epoch 860/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9023 - accuracy: 0.5520 - val_loss: 0.9145 - val_accuracy: 0.5383\n",
      "Epoch 861/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9023 - accuracy: 0.5542 - val_loss: 0.9144 - val_accuracy: 0.5377\n",
      "Epoch 862/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9023 - accuracy: 0.5536 - val_loss: 0.9146 - val_accuracy: 0.5383\n",
      "Epoch 863/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9021 - accuracy: 0.5525 - val_loss: 0.9163 - val_accuracy: 0.5377\n",
      "Epoch 864/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9023 - accuracy: 0.5531 - val_loss: 0.9146 - val_accuracy: 0.5380\n",
      "Epoch 865/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9022 - accuracy: 0.5523 - val_loss: 0.9142 - val_accuracy: 0.5397\n",
      "Epoch 866/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9022 - accuracy: 0.5529 - val_loss: 0.9154 - val_accuracy: 0.5393\n",
      "Epoch 867/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9022 - accuracy: 0.5532 - val_loss: 0.9140 - val_accuracy: 0.5400\n",
      "Epoch 868/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9023 - accuracy: 0.5539 - val_loss: 0.9147 - val_accuracy: 0.5397\n",
      "Epoch 869/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9021 - accuracy: 0.5534 - val_loss: 0.9139 - val_accuracy: 0.5420\n",
      "Epoch 870/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9022 - accuracy: 0.5541 - val_loss: 0.9147 - val_accuracy: 0.5387\n",
      "Epoch 871/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9021 - accuracy: 0.5527 - val_loss: 0.9141 - val_accuracy: 0.5417\n",
      "Epoch 872/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9021 - accuracy: 0.5530 - val_loss: 0.9152 - val_accuracy: 0.5410\n",
      "Epoch 873/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9021 - accuracy: 0.5532 - val_loss: 0.9151 - val_accuracy: 0.5410\n",
      "Epoch 874/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9021 - accuracy: 0.5528 - val_loss: 0.9142 - val_accuracy: 0.5380\n",
      "Epoch 875/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9021 - accuracy: 0.5529 - val_loss: 0.9155 - val_accuracy: 0.5390\n",
      "Epoch 876/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9020 - accuracy: 0.5546 - val_loss: 0.9138 - val_accuracy: 0.5413\n",
      "Epoch 877/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9021 - accuracy: 0.5525 - val_loss: 0.9156 - val_accuracy: 0.5387\n",
      "Epoch 878/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9021 - accuracy: 0.5538 - val_loss: 0.9152 - val_accuracy: 0.5413\n",
      "Epoch 879/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9022 - accuracy: 0.5534 - val_loss: 0.9149 - val_accuracy: 0.5417\n",
      "Epoch 880/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9019 - accuracy: 0.5523 - val_loss: 0.9134 - val_accuracy: 0.5420\n",
      "Epoch 881/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9022 - accuracy: 0.5527 - val_loss: 0.9146 - val_accuracy: 0.5390\n",
      "Epoch 882/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9021 - accuracy: 0.5526 - val_loss: 0.9139 - val_accuracy: 0.5403\n",
      "Epoch 883/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9020 - accuracy: 0.5541 - val_loss: 0.9137 - val_accuracy: 0.5423\n",
      "Epoch 884/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9021 - accuracy: 0.5537 - val_loss: 0.9152 - val_accuracy: 0.5403\n",
      "Epoch 885/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9019 - accuracy: 0.5529 - val_loss: 0.9135 - val_accuracy: 0.5410\n",
      "Epoch 886/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9021 - accuracy: 0.5522 - val_loss: 0.9147 - val_accuracy: 0.5393\n",
      "Epoch 887/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9021 - accuracy: 0.5536 - val_loss: 0.9137 - val_accuracy: 0.5423\n",
      "Epoch 888/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9020 - accuracy: 0.5527 - val_loss: 0.9147 - val_accuracy: 0.5393\n",
      "Epoch 889/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9019 - accuracy: 0.5539 - val_loss: 0.9143 - val_accuracy: 0.5403\n",
      "Epoch 890/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9020 - accuracy: 0.5534 - val_loss: 0.9147 - val_accuracy: 0.5393\n",
      "Epoch 891/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9019 - accuracy: 0.5538 - val_loss: 0.9139 - val_accuracy: 0.5390\n",
      "Epoch 892/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9019 - accuracy: 0.5534 - val_loss: 0.9140 - val_accuracy: 0.5390\n",
      "Epoch 893/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9020 - accuracy: 0.5539 - val_loss: 0.9143 - val_accuracy: 0.5393\n",
      "Epoch 894/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9019 - accuracy: 0.5534 - val_loss: 0.9149 - val_accuracy: 0.5410\n",
      "Epoch 895/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9019 - accuracy: 0.5548 - val_loss: 0.9138 - val_accuracy: 0.5397\n",
      "Epoch 896/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9019 - accuracy: 0.5535 - val_loss: 0.9146 - val_accuracy: 0.5400\n",
      "Epoch 897/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9019 - accuracy: 0.5528 - val_loss: 0.9146 - val_accuracy: 0.5393\n",
      "Epoch 898/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9019 - accuracy: 0.5539 - val_loss: 0.9139 - val_accuracy: 0.5393\n",
      "Epoch 899/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9019 - accuracy: 0.5529 - val_loss: 0.9140 - val_accuracy: 0.5400\n",
      "Epoch 900/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9018 - accuracy: 0.5541 - val_loss: 0.9156 - val_accuracy: 0.5413\n",
      "Epoch 901/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9018 - accuracy: 0.5533 - val_loss: 0.9138 - val_accuracy: 0.5407\n",
      "Epoch 902/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9018 - accuracy: 0.5529 - val_loss: 0.9139 - val_accuracy: 0.5410\n",
      "Epoch 903/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9019 - accuracy: 0.5533 - val_loss: 0.9154 - val_accuracy: 0.5393\n",
      "Epoch 904/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9018 - accuracy: 0.5536 - val_loss: 0.9147 - val_accuracy: 0.5403\n",
      "Epoch 905/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9018 - accuracy: 0.5540 - val_loss: 0.9145 - val_accuracy: 0.5393\n",
      "Epoch 906/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9018 - accuracy: 0.5538 - val_loss: 0.9136 - val_accuracy: 0.5420\n",
      "Epoch 907/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9018 - accuracy: 0.5536 - val_loss: 0.9134 - val_accuracy: 0.5423\n",
      "Epoch 908/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9018 - accuracy: 0.5539 - val_loss: 0.9137 - val_accuracy: 0.5400\n",
      "Epoch 909/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9017 - accuracy: 0.5526 - val_loss: 0.9144 - val_accuracy: 0.5410\n",
      "Epoch 910/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9017 - accuracy: 0.5534 - val_loss: 0.9135 - val_accuracy: 0.5423\n",
      "Epoch 911/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9017 - accuracy: 0.5539 - val_loss: 0.9133 - val_accuracy: 0.5427\n",
      "Epoch 912/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9018 - accuracy: 0.5522 - val_loss: 0.9149 - val_accuracy: 0.5397\n",
      "Epoch 913/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9017 - accuracy: 0.5540 - val_loss: 0.9141 - val_accuracy: 0.5387\n",
      "Epoch 914/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9017 - accuracy: 0.5534 - val_loss: 0.9149 - val_accuracy: 0.5420\n",
      "Epoch 915/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9017 - accuracy: 0.5539 - val_loss: 0.9145 - val_accuracy: 0.5410\n",
      "Epoch 916/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9017 - accuracy: 0.5539 - val_loss: 0.9139 - val_accuracy: 0.5390\n",
      "Epoch 917/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9017 - accuracy: 0.5551 - val_loss: 0.9145 - val_accuracy: 0.5407\n",
      "Epoch 918/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9017 - accuracy: 0.5521 - val_loss: 0.9144 - val_accuracy: 0.5397\n",
      "Epoch 919/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9017 - accuracy: 0.5549 - val_loss: 0.9134 - val_accuracy: 0.5433\n",
      "Epoch 920/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9017 - accuracy: 0.5534 - val_loss: 0.9138 - val_accuracy: 0.5410\n",
      "Epoch 921/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9016 - accuracy: 0.5541 - val_loss: 0.9149 - val_accuracy: 0.5420\n",
      "Epoch 922/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9017 - accuracy: 0.5539 - val_loss: 0.9136 - val_accuracy: 0.5413\n",
      "Epoch 923/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9014 - accuracy: 0.5536 - val_loss: 0.9139 - val_accuracy: 0.5400\n",
      "Epoch 924/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9016 - accuracy: 0.5539 - val_loss: 0.9139 - val_accuracy: 0.5397\n",
      "Epoch 925/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9016 - accuracy: 0.5529 - val_loss: 0.9140 - val_accuracy: 0.5400\n",
      "Epoch 926/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9016 - accuracy: 0.5528 - val_loss: 0.9150 - val_accuracy: 0.5410\n",
      "Epoch 927/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9015 - accuracy: 0.5533 - val_loss: 0.9151 - val_accuracy: 0.5397\n",
      "Epoch 928/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9015 - accuracy: 0.5536 - val_loss: 0.9132 - val_accuracy: 0.5417\n",
      "Epoch 929/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9016 - accuracy: 0.5534 - val_loss: 0.9144 - val_accuracy: 0.5407\n",
      "Epoch 930/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9016 - accuracy: 0.5531 - val_loss: 0.9134 - val_accuracy: 0.5420\n",
      "Epoch 931/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9015 - accuracy: 0.5551 - val_loss: 0.9134 - val_accuracy: 0.5413\n",
      "Epoch 932/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9014 - accuracy: 0.5534 - val_loss: 0.9133 - val_accuracy: 0.5420\n",
      "Epoch 933/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9014 - accuracy: 0.5533 - val_loss: 0.9148 - val_accuracy: 0.5420\n",
      "Epoch 934/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9014 - accuracy: 0.5544 - val_loss: 0.9154 - val_accuracy: 0.5393\n",
      "Epoch 935/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9014 - accuracy: 0.5540 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 936/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9013 - accuracy: 0.5546 - val_loss: 0.9134 - val_accuracy: 0.5413\n",
      "Epoch 937/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9014 - accuracy: 0.5543 - val_loss: 0.9146 - val_accuracy: 0.5403\n",
      "Epoch 938/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9015 - accuracy: 0.5531 - val_loss: 0.9135 - val_accuracy: 0.5413\n",
      "Epoch 939/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9014 - accuracy: 0.5550 - val_loss: 0.9147 - val_accuracy: 0.5410\n",
      "Epoch 940/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9014 - accuracy: 0.5548 - val_loss: 0.9145 - val_accuracy: 0.5413\n",
      "Epoch 941/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9014 - accuracy: 0.5546 - val_loss: 0.9140 - val_accuracy: 0.5383\n",
      "Epoch 942/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9015 - accuracy: 0.5543 - val_loss: 0.9137 - val_accuracy: 0.5403\n",
      "Epoch 943/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9014 - accuracy: 0.5542 - val_loss: 0.9147 - val_accuracy: 0.5423\n",
      "Epoch 944/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9014 - accuracy: 0.5542 - val_loss: 0.9137 - val_accuracy: 0.5403\n",
      "Epoch 945/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9014 - accuracy: 0.5530 - val_loss: 0.9139 - val_accuracy: 0.5413\n",
      "Epoch 946/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9014 - accuracy: 0.5539 - val_loss: 0.9145 - val_accuracy: 0.5397\n",
      "Epoch 947/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9013 - accuracy: 0.5540 - val_loss: 0.9132 - val_accuracy: 0.5420\n",
      "Epoch 948/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9013 - accuracy: 0.5531 - val_loss: 0.9129 - val_accuracy: 0.5437\n",
      "Epoch 949/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9014 - accuracy: 0.5534 - val_loss: 0.9131 - val_accuracy: 0.5423\n",
      "Epoch 950/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9013 - accuracy: 0.5539 - val_loss: 0.9137 - val_accuracy: 0.5400\n",
      "Epoch 951/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9013 - accuracy: 0.5545 - val_loss: 0.9130 - val_accuracy: 0.5420\n",
      "Epoch 952/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9013 - accuracy: 0.5538 - val_loss: 0.9138 - val_accuracy: 0.5403\n",
      "Epoch 953/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9013 - accuracy: 0.5539 - val_loss: 0.9143 - val_accuracy: 0.5403\n",
      "Epoch 954/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9012 - accuracy: 0.5546 - val_loss: 0.9131 - val_accuracy: 0.5407\n",
      "Epoch 955/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9012 - accuracy: 0.5545 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 956/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9013 - accuracy: 0.5540 - val_loss: 0.9133 - val_accuracy: 0.5427\n",
      "Epoch 957/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9012 - accuracy: 0.5526 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 958/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9012 - accuracy: 0.5536 - val_loss: 0.9138 - val_accuracy: 0.5410\n",
      "Epoch 959/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9012 - accuracy: 0.5543 - val_loss: 0.9147 - val_accuracy: 0.5410\n",
      "Epoch 960/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9012 - accuracy: 0.5541 - val_loss: 0.9137 - val_accuracy: 0.5397\n",
      "Epoch 961/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9012 - accuracy: 0.5555 - val_loss: 0.9137 - val_accuracy: 0.5403\n",
      "Epoch 962/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9013 - accuracy: 0.5546 - val_loss: 0.9140 - val_accuracy: 0.5407\n",
      "Epoch 963/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9011 - accuracy: 0.5545 - val_loss: 0.9134 - val_accuracy: 0.5407\n",
      "Epoch 964/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9012 - accuracy: 0.5534 - val_loss: 0.9144 - val_accuracy: 0.5407\n",
      "Epoch 965/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9012 - accuracy: 0.5543 - val_loss: 0.9139 - val_accuracy: 0.5397\n",
      "Epoch 966/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9012 - accuracy: 0.5542 - val_loss: 0.9139 - val_accuracy: 0.5403\n",
      "Epoch 967/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9011 - accuracy: 0.5544 - val_loss: 0.9129 - val_accuracy: 0.5420\n",
      "Epoch 968/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9012 - accuracy: 0.5555 - val_loss: 0.9133 - val_accuracy: 0.5420\n",
      "Epoch 969/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9011 - accuracy: 0.5529 - val_loss: 0.9132 - val_accuracy: 0.5410\n",
      "Epoch 970/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9010 - accuracy: 0.5540 - val_loss: 0.9149 - val_accuracy: 0.5393\n",
      "Epoch 971/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9010 - accuracy: 0.5534 - val_loss: 0.9125 - val_accuracy: 0.5423\n",
      "Epoch 972/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9011 - accuracy: 0.5529 - val_loss: 0.9135 - val_accuracy: 0.5410\n",
      "Epoch 973/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9010 - accuracy: 0.5531 - val_loss: 0.9136 - val_accuracy: 0.5413\n",
      "Epoch 974/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9011 - accuracy: 0.5545 - val_loss: 0.9140 - val_accuracy: 0.5403\n",
      "Epoch 975/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9010 - accuracy: 0.5531 - val_loss: 0.9127 - val_accuracy: 0.5433\n",
      "Epoch 976/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9011 - accuracy: 0.5546 - val_loss: 0.9127 - val_accuracy: 0.5433\n",
      "Epoch 977/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9010 - accuracy: 0.5546 - val_loss: 0.9129 - val_accuracy: 0.5423\n",
      "Epoch 978/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9010 - accuracy: 0.5544 - val_loss: 0.9128 - val_accuracy: 0.5413\n",
      "Epoch 979/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9010 - accuracy: 0.5540 - val_loss: 0.9127 - val_accuracy: 0.5427\n",
      "Epoch 980/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9010 - accuracy: 0.5551 - val_loss: 0.9131 - val_accuracy: 0.5430\n",
      "Epoch 981/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9009 - accuracy: 0.5531 - val_loss: 0.9133 - val_accuracy: 0.5403\n",
      "Epoch 982/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9010 - accuracy: 0.5551 - val_loss: 0.9129 - val_accuracy: 0.5427\n",
      "Epoch 983/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9010 - accuracy: 0.5541 - val_loss: 0.9136 - val_accuracy: 0.5407\n",
      "Epoch 984/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9009 - accuracy: 0.5539 - val_loss: 0.9139 - val_accuracy: 0.5423\n",
      "Epoch 985/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9009 - accuracy: 0.5548 - val_loss: 0.9142 - val_accuracy: 0.5410\n",
      "Epoch 986/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9008 - accuracy: 0.5551 - val_loss: 0.9139 - val_accuracy: 0.5417\n",
      "Epoch 987/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9009 - accuracy: 0.5534 - val_loss: 0.9127 - val_accuracy: 0.5413\n",
      "Epoch 988/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9010 - accuracy: 0.5549 - val_loss: 0.9136 - val_accuracy: 0.5423\n",
      "Epoch 989/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9010 - accuracy: 0.5545 - val_loss: 0.9131 - val_accuracy: 0.5407\n",
      "Epoch 990/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9008 - accuracy: 0.5556 - val_loss: 0.9140 - val_accuracy: 0.5413\n",
      "Epoch 991/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9008 - accuracy: 0.5549 - val_loss: 0.9126 - val_accuracy: 0.5423\n",
      "Epoch 992/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9007 - accuracy: 0.5539 - val_loss: 0.9133 - val_accuracy: 0.5400\n",
      "Epoch 993/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9009 - accuracy: 0.5546 - val_loss: 0.9126 - val_accuracy: 0.5433\n",
      "Epoch 994/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9009 - accuracy: 0.5535 - val_loss: 0.9132 - val_accuracy: 0.5410\n",
      "Epoch 995/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9008 - accuracy: 0.5531 - val_loss: 0.9140 - val_accuracy: 0.5403\n",
      "Epoch 996/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9009 - accuracy: 0.5548 - val_loss: 0.9135 - val_accuracy: 0.5413\n",
      "Epoch 997/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9007 - accuracy: 0.5540 - val_loss: 0.9141 - val_accuracy: 0.5417\n",
      "Epoch 998/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9008 - accuracy: 0.5551 - val_loss: 0.9128 - val_accuracy: 0.5430\n",
      "Epoch 999/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9008 - accuracy: 0.5549 - val_loss: 0.9132 - val_accuracy: 0.5407\n",
      "Epoch 1000/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9008 - accuracy: 0.5551 - val_loss: 0.9124 - val_accuracy: 0.5423\n",
      "Epoch 1001/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9008 - accuracy: 0.5543 - val_loss: 0.9139 - val_accuracy: 0.5417\n",
      "Epoch 1002/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9007 - accuracy: 0.5543 - val_loss: 0.9132 - val_accuracy: 0.5407\n",
      "Epoch 1003/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9007 - accuracy: 0.5556 - val_loss: 0.9123 - val_accuracy: 0.5420\n",
      "Epoch 1004/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9008 - accuracy: 0.5541 - val_loss: 0.9137 - val_accuracy: 0.5430\n",
      "Epoch 1005/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9007 - accuracy: 0.5563 - val_loss: 0.9132 - val_accuracy: 0.5400\n",
      "Epoch 1006/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9007 - accuracy: 0.5542 - val_loss: 0.9135 - val_accuracy: 0.5430\n",
      "Epoch 1007/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9007 - accuracy: 0.5535 - val_loss: 0.9124 - val_accuracy: 0.5427\n",
      "Epoch 1008/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.9007 - accuracy: 0.5547 - val_loss: 0.9135 - val_accuracy: 0.5397\n",
      "Epoch 1009/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.9006 - accuracy: 0.5540 - val_loss: 0.9127 - val_accuracy: 0.5417\n",
      "Epoch 1010/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9007 - accuracy: 0.5558 - val_loss: 0.9122 - val_accuracy: 0.5437\n",
      "Epoch 1011/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9006 - accuracy: 0.5561 - val_loss: 0.9131 - val_accuracy: 0.5420\n",
      "Epoch 1012/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9007 - accuracy: 0.5547 - val_loss: 0.9130 - val_accuracy: 0.5410\n",
      "Epoch 1013/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9006 - accuracy: 0.5539 - val_loss: 0.9137 - val_accuracy: 0.5420\n",
      "Epoch 1014/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9005 - accuracy: 0.5548 - val_loss: 0.9120 - val_accuracy: 0.5403\n",
      "Epoch 1015/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9007 - accuracy: 0.5539 - val_loss: 0.9136 - val_accuracy: 0.5420\n",
      "Epoch 1016/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9005 - accuracy: 0.5547 - val_loss: 0.9128 - val_accuracy: 0.5427\n",
      "Epoch 1017/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9006 - accuracy: 0.5541 - val_loss: 0.9123 - val_accuracy: 0.5433\n",
      "Epoch 1018/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9006 - accuracy: 0.5555 - val_loss: 0.9126 - val_accuracy: 0.5433\n",
      "Epoch 1019/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9005 - accuracy: 0.5539 - val_loss: 0.9133 - val_accuracy: 0.5420\n",
      "Epoch 1020/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9006 - accuracy: 0.5544 - val_loss: 0.9121 - val_accuracy: 0.5450\n",
      "Epoch 1021/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9005 - accuracy: 0.5542 - val_loss: 0.9123 - val_accuracy: 0.5427\n",
      "Epoch 1022/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9005 - accuracy: 0.5541 - val_loss: 0.9120 - val_accuracy: 0.5400\n",
      "Epoch 1023/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9005 - accuracy: 0.5537 - val_loss: 0.9129 - val_accuracy: 0.5403\n",
      "Epoch 1024/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9004 - accuracy: 0.5550 - val_loss: 0.9121 - val_accuracy: 0.5427\n",
      "Epoch 1025/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9005 - accuracy: 0.5559 - val_loss: 0.9141 - val_accuracy: 0.5410\n",
      "Epoch 1026/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9005 - accuracy: 0.5526 - val_loss: 0.9123 - val_accuracy: 0.5443\n",
      "Epoch 1027/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9003 - accuracy: 0.5551 - val_loss: 0.9121 - val_accuracy: 0.5440\n",
      "Epoch 1028/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9005 - accuracy: 0.5559 - val_loss: 0.9131 - val_accuracy: 0.5400\n",
      "Epoch 1029/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9005 - accuracy: 0.5551 - val_loss: 0.9127 - val_accuracy: 0.5423\n",
      "Epoch 1030/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9004 - accuracy: 0.5548 - val_loss: 0.9121 - val_accuracy: 0.5437\n",
      "Epoch 1031/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9004 - accuracy: 0.5549 - val_loss: 0.9128 - val_accuracy: 0.5403\n",
      "Epoch 1032/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9004 - accuracy: 0.5545 - val_loss: 0.9128 - val_accuracy: 0.5417\n",
      "Epoch 1033/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9004 - accuracy: 0.5551 - val_loss: 0.9142 - val_accuracy: 0.5390\n",
      "Epoch 1034/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9004 - accuracy: 0.5556 - val_loss: 0.9127 - val_accuracy: 0.5420\n",
      "Epoch 1035/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9003 - accuracy: 0.5549 - val_loss: 0.9135 - val_accuracy: 0.5407\n",
      "Epoch 1036/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.9004 - accuracy: 0.5540 - val_loss: 0.9139 - val_accuracy: 0.5417\n",
      "Epoch 1037/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9004 - accuracy: 0.5535 - val_loss: 0.9137 - val_accuracy: 0.5413\n",
      "Epoch 1038/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9004 - accuracy: 0.5541 - val_loss: 0.9126 - val_accuracy: 0.5437\n",
      "Epoch 1039/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9004 - accuracy: 0.5551 - val_loss: 0.9120 - val_accuracy: 0.5440\n",
      "Epoch 1040/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9004 - accuracy: 0.5557 - val_loss: 0.9136 - val_accuracy: 0.5417\n",
      "Epoch 1041/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9002 - accuracy: 0.5542 - val_loss: 0.9130 - val_accuracy: 0.5407\n",
      "Epoch 1042/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9004 - accuracy: 0.5547 - val_loss: 0.9125 - val_accuracy: 0.5420\n",
      "Epoch 1043/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9004 - accuracy: 0.5548 - val_loss: 0.9129 - val_accuracy: 0.5400\n",
      "Epoch 1044/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9003 - accuracy: 0.5549 - val_loss: 0.9124 - val_accuracy: 0.5427\n",
      "Epoch 1045/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9003 - accuracy: 0.5551 - val_loss: 0.9128 - val_accuracy: 0.5407\n",
      "Epoch 1046/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9002 - accuracy: 0.5550 - val_loss: 0.9123 - val_accuracy: 0.5437\n",
      "Epoch 1047/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9002 - accuracy: 0.5536 - val_loss: 0.9126 - val_accuracy: 0.5417\n",
      "Epoch 1048/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9002 - accuracy: 0.5552 - val_loss: 0.9136 - val_accuracy: 0.5407\n",
      "Epoch 1049/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9002 - accuracy: 0.5542 - val_loss: 0.9123 - val_accuracy: 0.5430\n",
      "Epoch 1050/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9002 - accuracy: 0.5543 - val_loss: 0.9120 - val_accuracy: 0.5437\n",
      "Epoch 1051/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9000 - accuracy: 0.5544 - val_loss: 0.9126 - val_accuracy: 0.5413\n",
      "Epoch 1052/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9002 - accuracy: 0.5542 - val_loss: 0.9130 - val_accuracy: 0.5413\n",
      "Epoch 1053/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9001 - accuracy: 0.5555 - val_loss: 0.9120 - val_accuracy: 0.5430\n",
      "Epoch 1054/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9001 - accuracy: 0.5546 - val_loss: 0.9136 - val_accuracy: 0.5407\n",
      "Epoch 1055/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9000 - accuracy: 0.5568 - val_loss: 0.9137 - val_accuracy: 0.5400\n",
      "Epoch 1056/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9002 - accuracy: 0.5542 - val_loss: 0.9128 - val_accuracy: 0.5407\n",
      "Epoch 1057/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9001 - accuracy: 0.5561 - val_loss: 0.9131 - val_accuracy: 0.5407\n",
      "Epoch 1058/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9001 - accuracy: 0.5538 - val_loss: 0.9121 - val_accuracy: 0.5443\n",
      "Epoch 1059/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9001 - accuracy: 0.5556 - val_loss: 0.9120 - val_accuracy: 0.5427\n",
      "Epoch 1060/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.9000 - accuracy: 0.5546 - val_loss: 0.9137 - val_accuracy: 0.5413\n",
      "Epoch 1061/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9002 - accuracy: 0.5547 - val_loss: 0.9125 - val_accuracy: 0.5417\n",
      "Epoch 1062/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9001 - accuracy: 0.5541 - val_loss: 0.9131 - val_accuracy: 0.5410\n",
      "Epoch 1063/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9000 - accuracy: 0.5553 - val_loss: 0.9131 - val_accuracy: 0.5407\n",
      "Epoch 1064/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9001 - accuracy: 0.5557 - val_loss: 0.9130 - val_accuracy: 0.5407\n",
      "Epoch 1065/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9001 - accuracy: 0.5549 - val_loss: 0.9122 - val_accuracy: 0.5433\n",
      "Epoch 1066/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.8999 - accuracy: 0.5553 - val_loss: 0.9151 - val_accuracy: 0.5380\n",
      "Epoch 1067/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9001 - accuracy: 0.5539 - val_loss: 0.9119 - val_accuracy: 0.5433\n",
      "Epoch 1068/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9001 - accuracy: 0.5542 - val_loss: 0.9122 - val_accuracy: 0.5440\n",
      "Epoch 1069/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.9000 - accuracy: 0.5556 - val_loss: 0.9124 - val_accuracy: 0.5413\n",
      "Epoch 1070/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9001 - accuracy: 0.5544 - val_loss: 0.9124 - val_accuracy: 0.5420\n",
      "Epoch 1071/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.9000 - accuracy: 0.5551 - val_loss: 0.9127 - val_accuracy: 0.5403\n",
      "Epoch 1072/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8998 - accuracy: 0.5534 - val_loss: 0.9116 - val_accuracy: 0.5447\n",
      "Epoch 1073/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.9000 - accuracy: 0.5561 - val_loss: 0.9127 - val_accuracy: 0.5407\n",
      "Epoch 1074/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.9000 - accuracy: 0.5562 - val_loss: 0.9123 - val_accuracy: 0.5433\n",
      "Epoch 1075/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8999 - accuracy: 0.5539 - val_loss: 0.9136 - val_accuracy: 0.5397\n",
      "Epoch 1076/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.9000 - accuracy: 0.5561 - val_loss: 0.9121 - val_accuracy: 0.5427\n",
      "Epoch 1077/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8999 - accuracy: 0.5555 - val_loss: 0.9128 - val_accuracy: 0.5410\n",
      "Epoch 1078/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9000 - accuracy: 0.5552 - val_loss: 0.9119 - val_accuracy: 0.5443\n",
      "Epoch 1079/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.9000 - accuracy: 0.5548 - val_loss: 0.9128 - val_accuracy: 0.5400\n",
      "Epoch 1080/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8999 - accuracy: 0.5556 - val_loss: 0.9117 - val_accuracy: 0.5450\n",
      "Epoch 1081/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8999 - accuracy: 0.5539 - val_loss: 0.9127 - val_accuracy: 0.5407\n",
      "Epoch 1082/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8999 - accuracy: 0.5559 - val_loss: 0.9124 - val_accuracy: 0.5430\n",
      "Epoch 1083/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8997 - accuracy: 0.5550 - val_loss: 0.9143 - val_accuracy: 0.5390\n",
      "Epoch 1084/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8999 - accuracy: 0.5558 - val_loss: 0.9119 - val_accuracy: 0.5450\n",
      "Epoch 1085/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8999 - accuracy: 0.5554 - val_loss: 0.9125 - val_accuracy: 0.5400\n",
      "Epoch 1086/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8999 - accuracy: 0.5554 - val_loss: 0.9121 - val_accuracy: 0.5427\n",
      "Epoch 1087/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8998 - accuracy: 0.5530 - val_loss: 0.9126 - val_accuracy: 0.5410\n",
      "Epoch 1088/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8998 - accuracy: 0.5548 - val_loss: 0.9124 - val_accuracy: 0.5453\n",
      "Epoch 1089/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8998 - accuracy: 0.5542 - val_loss: 0.9126 - val_accuracy: 0.5443\n",
      "Epoch 1090/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8999 - accuracy: 0.5534 - val_loss: 0.9123 - val_accuracy: 0.5430\n",
      "Epoch 1091/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8998 - accuracy: 0.5549 - val_loss: 0.9126 - val_accuracy: 0.5423\n",
      "Epoch 1092/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8997 - accuracy: 0.5567 - val_loss: 0.9114 - val_accuracy: 0.5393\n",
      "Epoch 1093/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8997 - accuracy: 0.5544 - val_loss: 0.9129 - val_accuracy: 0.5413\n",
      "Epoch 1094/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8998 - accuracy: 0.5540 - val_loss: 0.9121 - val_accuracy: 0.5427\n",
      "Epoch 1095/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8997 - accuracy: 0.5542 - val_loss: 0.9123 - val_accuracy: 0.5417\n",
      "Epoch 1096/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8997 - accuracy: 0.5558 - val_loss: 0.9141 - val_accuracy: 0.5387\n",
      "Epoch 1097/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8997 - accuracy: 0.5534 - val_loss: 0.9131 - val_accuracy: 0.5430\n",
      "Epoch 1098/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8998 - accuracy: 0.5557 - val_loss: 0.9118 - val_accuracy: 0.5433\n",
      "Epoch 1099/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8997 - accuracy: 0.5551 - val_loss: 0.9126 - val_accuracy: 0.5407\n",
      "Epoch 1100/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8997 - accuracy: 0.5549 - val_loss: 0.9118 - val_accuracy: 0.5450\n",
      "Epoch 1101/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8998 - accuracy: 0.5541 - val_loss: 0.9122 - val_accuracy: 0.5437\n",
      "Epoch 1102/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8997 - accuracy: 0.5559 - val_loss: 0.9129 - val_accuracy: 0.5410\n",
      "Epoch 1103/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8997 - accuracy: 0.5559 - val_loss: 0.9114 - val_accuracy: 0.5423\n",
      "Epoch 1104/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8996 - accuracy: 0.5546 - val_loss: 0.9123 - val_accuracy: 0.5413\n",
      "Epoch 1105/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8996 - accuracy: 0.5564 - val_loss: 0.9119 - val_accuracy: 0.5437\n",
      "Epoch 1106/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8997 - accuracy: 0.5566 - val_loss: 0.9122 - val_accuracy: 0.5437\n",
      "Epoch 1107/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8997 - accuracy: 0.5546 - val_loss: 0.9117 - val_accuracy: 0.5450\n",
      "Epoch 1108/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8997 - accuracy: 0.5556 - val_loss: 0.9126 - val_accuracy: 0.5407\n",
      "Epoch 1109/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8994 - accuracy: 0.5559 - val_loss: 0.9156 - val_accuracy: 0.5383\n",
      "Epoch 1110/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8997 - accuracy: 0.5543 - val_loss: 0.9115 - val_accuracy: 0.5447\n",
      "Epoch 1111/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8996 - accuracy: 0.5546 - val_loss: 0.9122 - val_accuracy: 0.5440\n",
      "Epoch 1112/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8996 - accuracy: 0.5557 - val_loss: 0.9120 - val_accuracy: 0.5427\n",
      "Epoch 1113/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8996 - accuracy: 0.5556 - val_loss: 0.9122 - val_accuracy: 0.5433\n",
      "Epoch 1114/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8995 - accuracy: 0.5541 - val_loss: 0.9119 - val_accuracy: 0.5423\n",
      "Epoch 1115/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8994 - accuracy: 0.5551 - val_loss: 0.9115 - val_accuracy: 0.5463\n",
      "Epoch 1116/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8994 - accuracy: 0.5551 - val_loss: 0.9122 - val_accuracy: 0.5440\n",
      "Epoch 1117/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8995 - accuracy: 0.5541 - val_loss: 0.9116 - val_accuracy: 0.5447\n",
      "Epoch 1118/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8995 - accuracy: 0.5561 - val_loss: 0.9116 - val_accuracy: 0.5453\n",
      "Epoch 1119/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8995 - accuracy: 0.5551 - val_loss: 0.9121 - val_accuracy: 0.5427\n",
      "Epoch 1120/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8995 - accuracy: 0.5559 - val_loss: 0.9125 - val_accuracy: 0.5410\n",
      "Epoch 1121/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8994 - accuracy: 0.5542 - val_loss: 0.9116 - val_accuracy: 0.5443\n",
      "Epoch 1122/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8995 - accuracy: 0.5552 - val_loss: 0.9116 - val_accuracy: 0.5447\n",
      "Epoch 1123/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8996 - accuracy: 0.5561 - val_loss: 0.9113 - val_accuracy: 0.5427\n",
      "Epoch 1124/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8995 - accuracy: 0.5542 - val_loss: 0.9121 - val_accuracy: 0.5430\n",
      "Epoch 1125/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8994 - accuracy: 0.5555 - val_loss: 0.9120 - val_accuracy: 0.5440\n",
      "Epoch 1126/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8995 - accuracy: 0.5557 - val_loss: 0.9116 - val_accuracy: 0.5460\n",
      "Epoch 1127/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8994 - accuracy: 0.5563 - val_loss: 0.9111 - val_accuracy: 0.5407\n",
      "Epoch 1128/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8992 - accuracy: 0.5566 - val_loss: 0.9127 - val_accuracy: 0.5430\n",
      "Epoch 1129/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8993 - accuracy: 0.5573 - val_loss: 0.9111 - val_accuracy: 0.5397\n",
      "Epoch 1130/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8995 - accuracy: 0.5543 - val_loss: 0.9118 - val_accuracy: 0.5447\n",
      "Epoch 1131/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8994 - accuracy: 0.5561 - val_loss: 0.9117 - val_accuracy: 0.5463\n",
      "Epoch 1132/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8993 - accuracy: 0.5557 - val_loss: 0.9130 - val_accuracy: 0.5403\n",
      "Epoch 1133/5500\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.8994 - accuracy: 0.5552 - val_loss: 0.9115 - val_accuracy: 0.5450\n",
      "Epoch 1134/5500\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.8994 - accuracy: 0.5550 - val_loss: 0.9128 - val_accuracy: 0.5407\n",
      "Epoch 1135/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.8993 - accuracy: 0.5542 - val_loss: 0.9138 - val_accuracy: 0.5397\n",
      "Epoch 1136/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8994 - accuracy: 0.5560 - val_loss: 0.9118 - val_accuracy: 0.5460\n",
      "Epoch 1137/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8991 - accuracy: 0.5546 - val_loss: 0.9141 - val_accuracy: 0.5360\n",
      "Epoch 1138/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8994 - accuracy: 0.5549 - val_loss: 0.9113 - val_accuracy: 0.5420\n",
      "Epoch 1139/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8994 - accuracy: 0.5544 - val_loss: 0.9124 - val_accuracy: 0.5430\n",
      "Epoch 1140/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8994 - accuracy: 0.5554 - val_loss: 0.9117 - val_accuracy: 0.5427\n",
      "Epoch 1141/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8994 - accuracy: 0.5550 - val_loss: 0.9114 - val_accuracy: 0.5460\n",
      "Epoch 1142/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8992 - accuracy: 0.5552 - val_loss: 0.9126 - val_accuracy: 0.5430\n",
      "Epoch 1143/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8992 - accuracy: 0.5544 - val_loss: 0.9121 - val_accuracy: 0.5440\n",
      "Epoch 1144/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8993 - accuracy: 0.5550 - val_loss: 0.9122 - val_accuracy: 0.5433\n",
      "Epoch 1145/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8992 - accuracy: 0.5557 - val_loss: 0.9118 - val_accuracy: 0.5460\n",
      "Epoch 1146/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8991 - accuracy: 0.5555 - val_loss: 0.9127 - val_accuracy: 0.5403\n",
      "Epoch 1147/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8992 - accuracy: 0.5554 - val_loss: 0.9110 - val_accuracy: 0.5397\n",
      "Epoch 1148/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8993 - accuracy: 0.5558 - val_loss: 0.9110 - val_accuracy: 0.5457\n",
      "Epoch 1149/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8992 - accuracy: 0.5547 - val_loss: 0.9115 - val_accuracy: 0.5440\n",
      "Epoch 1150/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8992 - accuracy: 0.5546 - val_loss: 0.9117 - val_accuracy: 0.5427\n",
      "Epoch 1151/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8992 - accuracy: 0.5544 - val_loss: 0.9113 - val_accuracy: 0.5453\n",
      "Epoch 1152/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8992 - accuracy: 0.5566 - val_loss: 0.9127 - val_accuracy: 0.5400\n",
      "Epoch 1153/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8992 - accuracy: 0.5551 - val_loss: 0.9126 - val_accuracy: 0.5423\n",
      "Epoch 1154/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8992 - accuracy: 0.5552 - val_loss: 0.9126 - val_accuracy: 0.5400\n",
      "Epoch 1155/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8992 - accuracy: 0.5565 - val_loss: 0.9132 - val_accuracy: 0.5397\n",
      "Epoch 1156/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8991 - accuracy: 0.5548 - val_loss: 0.9110 - val_accuracy: 0.5433\n",
      "Epoch 1157/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8992 - accuracy: 0.5551 - val_loss: 0.9108 - val_accuracy: 0.5420\n",
      "Epoch 1158/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8991 - accuracy: 0.5563 - val_loss: 0.9115 - val_accuracy: 0.5427\n",
      "Epoch 1159/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8991 - accuracy: 0.5554 - val_loss: 0.9110 - val_accuracy: 0.5423\n",
      "Epoch 1160/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8991 - accuracy: 0.5543 - val_loss: 0.9116 - val_accuracy: 0.5450\n",
      "Epoch 1161/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8990 - accuracy: 0.5564 - val_loss: 0.9108 - val_accuracy: 0.5417\n",
      "Epoch 1162/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8991 - accuracy: 0.5553 - val_loss: 0.9112 - val_accuracy: 0.5450\n",
      "Epoch 1163/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8991 - accuracy: 0.5553 - val_loss: 0.9121 - val_accuracy: 0.5427\n",
      "Epoch 1164/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8991 - accuracy: 0.5568 - val_loss: 0.9111 - val_accuracy: 0.5453\n",
      "Epoch 1165/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8992 - accuracy: 0.5551 - val_loss: 0.9115 - val_accuracy: 0.5453\n",
      "Epoch 1166/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8991 - accuracy: 0.5566 - val_loss: 0.9116 - val_accuracy: 0.5433\n",
      "Epoch 1167/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8990 - accuracy: 0.5556 - val_loss: 0.9128 - val_accuracy: 0.5400\n",
      "Epoch 1168/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8991 - accuracy: 0.5559 - val_loss: 0.9126 - val_accuracy: 0.5400\n",
      "Epoch 1169/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8990 - accuracy: 0.5553 - val_loss: 0.9117 - val_accuracy: 0.5463\n",
      "Epoch 1170/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8991 - accuracy: 0.5553 - val_loss: 0.9108 - val_accuracy: 0.5410\n",
      "Epoch 1171/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8990 - accuracy: 0.5549 - val_loss: 0.9124 - val_accuracy: 0.5417\n",
      "Epoch 1172/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8990 - accuracy: 0.5569 - val_loss: 0.9109 - val_accuracy: 0.5433\n",
      "Epoch 1173/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8991 - accuracy: 0.5548 - val_loss: 0.9113 - val_accuracy: 0.5467\n",
      "Epoch 1174/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8989 - accuracy: 0.5544 - val_loss: 0.9112 - val_accuracy: 0.5460\n",
      "Epoch 1175/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8990 - accuracy: 0.5554 - val_loss: 0.9117 - val_accuracy: 0.5433\n",
      "Epoch 1176/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8988 - accuracy: 0.5541 - val_loss: 0.9119 - val_accuracy: 0.5433\n",
      "Epoch 1177/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8990 - accuracy: 0.5557 - val_loss: 0.9109 - val_accuracy: 0.5453\n",
      "Epoch 1178/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8989 - accuracy: 0.5543 - val_loss: 0.9129 - val_accuracy: 0.5390\n",
      "Epoch 1179/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8990 - accuracy: 0.5539 - val_loss: 0.9125 - val_accuracy: 0.5397\n",
      "Epoch 1180/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8990 - accuracy: 0.5546 - val_loss: 0.9117 - val_accuracy: 0.5433\n",
      "Epoch 1181/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8989 - accuracy: 0.5551 - val_loss: 0.9113 - val_accuracy: 0.5453\n",
      "Epoch 1182/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8988 - accuracy: 0.5536 - val_loss: 0.9107 - val_accuracy: 0.5420\n",
      "Epoch 1183/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8988 - accuracy: 0.5546 - val_loss: 0.9121 - val_accuracy: 0.5410\n",
      "Epoch 1184/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8990 - accuracy: 0.5558 - val_loss: 0.9112 - val_accuracy: 0.5457\n",
      "Epoch 1185/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8989 - accuracy: 0.5564 - val_loss: 0.9109 - val_accuracy: 0.5420\n",
      "Epoch 1186/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8989 - accuracy: 0.5553 - val_loss: 0.9107 - val_accuracy: 0.5413\n",
      "Epoch 1187/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8988 - accuracy: 0.5569 - val_loss: 0.9123 - val_accuracy: 0.5423\n",
      "Epoch 1188/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8989 - accuracy: 0.5552 - val_loss: 0.9121 - val_accuracy: 0.5433\n",
      "Epoch 1189/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8989 - accuracy: 0.5561 - val_loss: 0.9115 - val_accuracy: 0.5443\n",
      "Epoch 1190/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8987 - accuracy: 0.5551 - val_loss: 0.9112 - val_accuracy: 0.5453\n",
      "Epoch 1191/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8987 - accuracy: 0.5561 - val_loss: 0.9125 - val_accuracy: 0.5387\n",
      "Epoch 1192/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8987 - accuracy: 0.5559 - val_loss: 0.9127 - val_accuracy: 0.5393\n",
      "Epoch 1193/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8988 - accuracy: 0.5559 - val_loss: 0.9115 - val_accuracy: 0.5440\n",
      "Epoch 1194/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8986 - accuracy: 0.5561 - val_loss: 0.9104 - val_accuracy: 0.5420\n",
      "Epoch 1195/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8986 - accuracy: 0.5547 - val_loss: 0.9140 - val_accuracy: 0.5390\n",
      "Epoch 1196/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8988 - accuracy: 0.5566 - val_loss: 0.9111 - val_accuracy: 0.5467\n",
      "Epoch 1197/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8988 - accuracy: 0.5560 - val_loss: 0.9109 - val_accuracy: 0.5453\n",
      "Epoch 1198/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8988 - accuracy: 0.5549 - val_loss: 0.9112 - val_accuracy: 0.5437\n",
      "Epoch 1199/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8986 - accuracy: 0.5569 - val_loss: 0.9107 - val_accuracy: 0.5423\n",
      "Epoch 1200/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8988 - accuracy: 0.5544 - val_loss: 0.9108 - val_accuracy: 0.5450\n",
      "Epoch 1201/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8988 - accuracy: 0.5561 - val_loss: 0.9112 - val_accuracy: 0.5430\n",
      "Epoch 1202/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8986 - accuracy: 0.5559 - val_loss: 0.9123 - val_accuracy: 0.5393\n",
      "Epoch 1203/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8987 - accuracy: 0.5576 - val_loss: 0.9119 - val_accuracy: 0.5427\n",
      "Epoch 1204/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8987 - accuracy: 0.5543 - val_loss: 0.9116 - val_accuracy: 0.5440\n",
      "Epoch 1205/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8987 - accuracy: 0.5563 - val_loss: 0.9105 - val_accuracy: 0.5387\n",
      "Epoch 1206/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8988 - accuracy: 0.5558 - val_loss: 0.9107 - val_accuracy: 0.5450\n",
      "Epoch 1207/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8986 - accuracy: 0.5545 - val_loss: 0.9106 - val_accuracy: 0.5440\n",
      "Epoch 1208/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8987 - accuracy: 0.5546 - val_loss: 0.9123 - val_accuracy: 0.5383\n",
      "Epoch 1209/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8985 - accuracy: 0.5541 - val_loss: 0.9104 - val_accuracy: 0.5433\n",
      "Epoch 1210/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8987 - accuracy: 0.5550 - val_loss: 0.9115 - val_accuracy: 0.5437\n",
      "Epoch 1211/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8986 - accuracy: 0.5544 - val_loss: 0.9115 - val_accuracy: 0.5440\n",
      "Epoch 1212/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8986 - accuracy: 0.5541 - val_loss: 0.9115 - val_accuracy: 0.5467\n",
      "Epoch 1213/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8986 - accuracy: 0.5563 - val_loss: 0.9117 - val_accuracy: 0.5437\n",
      "Epoch 1214/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8984 - accuracy: 0.5559 - val_loss: 0.9103 - val_accuracy: 0.5400\n",
      "Epoch 1215/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8985 - accuracy: 0.5559 - val_loss: 0.9106 - val_accuracy: 0.5447\n",
      "Epoch 1216/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8986 - accuracy: 0.5566 - val_loss: 0.9120 - val_accuracy: 0.5400\n",
      "Epoch 1217/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8984 - accuracy: 0.5551 - val_loss: 0.9111 - val_accuracy: 0.5440\n",
      "Epoch 1218/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8986 - accuracy: 0.5543 - val_loss: 0.9111 - val_accuracy: 0.5443\n",
      "Epoch 1219/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8986 - accuracy: 0.5554 - val_loss: 0.9116 - val_accuracy: 0.5437\n",
      "Epoch 1220/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8986 - accuracy: 0.5554 - val_loss: 0.9120 - val_accuracy: 0.5403\n",
      "Epoch 1221/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8986 - accuracy: 0.5541 - val_loss: 0.9107 - val_accuracy: 0.5460\n",
      "Epoch 1222/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8985 - accuracy: 0.5555 - val_loss: 0.9110 - val_accuracy: 0.5447\n",
      "Epoch 1223/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8985 - accuracy: 0.5558 - val_loss: 0.9104 - val_accuracy: 0.5437\n",
      "Epoch 1224/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8985 - accuracy: 0.5551 - val_loss: 0.9108 - val_accuracy: 0.5460\n",
      "Epoch 1225/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8984 - accuracy: 0.5553 - val_loss: 0.9111 - val_accuracy: 0.5470\n",
      "Epoch 1226/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8984 - accuracy: 0.5558 - val_loss: 0.9132 - val_accuracy: 0.5390\n",
      "Epoch 1227/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8986 - accuracy: 0.5555 - val_loss: 0.9119 - val_accuracy: 0.5447\n",
      "Epoch 1228/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8983 - accuracy: 0.5562 - val_loss: 0.9107 - val_accuracy: 0.5460\n",
      "Epoch 1229/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8983 - accuracy: 0.5552 - val_loss: 0.9121 - val_accuracy: 0.5397\n",
      "Epoch 1230/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8985 - accuracy: 0.5559 - val_loss: 0.9116 - val_accuracy: 0.5430\n",
      "Epoch 1231/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8984 - accuracy: 0.5556 - val_loss: 0.9104 - val_accuracy: 0.5397\n",
      "Epoch 1232/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8984 - accuracy: 0.5569 - val_loss: 0.9114 - val_accuracy: 0.5433\n",
      "Epoch 1233/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8984 - accuracy: 0.5564 - val_loss: 0.9105 - val_accuracy: 0.5453\n",
      "Epoch 1234/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8984 - accuracy: 0.5557 - val_loss: 0.9105 - val_accuracy: 0.5393\n",
      "Epoch 1235/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8984 - accuracy: 0.5580 - val_loss: 0.9112 - val_accuracy: 0.5447\n",
      "Epoch 1236/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8983 - accuracy: 0.5575 - val_loss: 0.9112 - val_accuracy: 0.5443\n",
      "Epoch 1237/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8983 - accuracy: 0.5534 - val_loss: 0.9106 - val_accuracy: 0.5457\n",
      "Epoch 1238/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8985 - accuracy: 0.5559 - val_loss: 0.9107 - val_accuracy: 0.5457\n",
      "Epoch 1239/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8984 - accuracy: 0.5559 - val_loss: 0.9104 - val_accuracy: 0.5447\n",
      "Epoch 1240/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8984 - accuracy: 0.5566 - val_loss: 0.9104 - val_accuracy: 0.5440\n",
      "Epoch 1241/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8985 - accuracy: 0.5546 - val_loss: 0.9110 - val_accuracy: 0.5460\n",
      "Epoch 1242/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8982 - accuracy: 0.5563 - val_loss: 0.9120 - val_accuracy: 0.5407\n",
      "Epoch 1243/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8983 - accuracy: 0.5549 - val_loss: 0.9108 - val_accuracy: 0.5467\n",
      "Epoch 1244/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8983 - accuracy: 0.5552 - val_loss: 0.9111 - val_accuracy: 0.5440\n",
      "Epoch 1245/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8983 - accuracy: 0.5551 - val_loss: 0.9124 - val_accuracy: 0.5393\n",
      "Epoch 1246/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8983 - accuracy: 0.5557 - val_loss: 0.9107 - val_accuracy: 0.5460\n",
      "Epoch 1247/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8983 - accuracy: 0.5559 - val_loss: 0.9116 - val_accuracy: 0.5420\n",
      "Epoch 1248/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8982 - accuracy: 0.5539 - val_loss: 0.9118 - val_accuracy: 0.5417\n",
      "Epoch 1249/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8983 - accuracy: 0.5558 - val_loss: 0.9120 - val_accuracy: 0.5403\n",
      "Epoch 1250/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8982 - accuracy: 0.5562 - val_loss: 0.9108 - val_accuracy: 0.5437\n",
      "Epoch 1251/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8982 - accuracy: 0.5560 - val_loss: 0.9115 - val_accuracy: 0.5407\n",
      "Epoch 1252/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8983 - accuracy: 0.5543 - val_loss: 0.9109 - val_accuracy: 0.5450\n",
      "Epoch 1253/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8981 - accuracy: 0.5550 - val_loss: 0.9124 - val_accuracy: 0.5407\n",
      "Epoch 1254/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8983 - accuracy: 0.5551 - val_loss: 0.9103 - val_accuracy: 0.5413\n",
      "Epoch 1255/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8980 - accuracy: 0.5539 - val_loss: 0.9119 - val_accuracy: 0.5407\n",
      "Epoch 1256/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8982 - accuracy: 0.5564 - val_loss: 0.9106 - val_accuracy: 0.5450\n",
      "Epoch 1257/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8982 - accuracy: 0.5553 - val_loss: 0.9112 - val_accuracy: 0.5440\n",
      "Epoch 1258/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8980 - accuracy: 0.5555 - val_loss: 0.9120 - val_accuracy: 0.5407\n",
      "Epoch 1259/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8982 - accuracy: 0.5552 - val_loss: 0.9115 - val_accuracy: 0.5417\n",
      "Epoch 1260/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8981 - accuracy: 0.5561 - val_loss: 0.9121 - val_accuracy: 0.5393\n",
      "Epoch 1261/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8982 - accuracy: 0.5578 - val_loss: 0.9103 - val_accuracy: 0.5457\n",
      "Epoch 1262/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.8981 - accuracy: 0.5543 - val_loss: 0.9106 - val_accuracy: 0.5457\n",
      "Epoch 1263/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8982 - accuracy: 0.5551 - val_loss: 0.9110 - val_accuracy: 0.5453\n",
      "Epoch 1264/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8981 - accuracy: 0.5566 - val_loss: 0.9114 - val_accuracy: 0.5440\n",
      "Epoch 1265/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8982 - accuracy: 0.5559 - val_loss: 0.9113 - val_accuracy: 0.5427\n",
      "Epoch 1266/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8980 - accuracy: 0.5552 - val_loss: 0.9105 - val_accuracy: 0.5463\n",
      "Epoch 1267/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8981 - accuracy: 0.5564 - val_loss: 0.9109 - val_accuracy: 0.5453\n",
      "Epoch 1268/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8981 - accuracy: 0.5564 - val_loss: 0.9101 - val_accuracy: 0.5410\n",
      "Epoch 1269/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8980 - accuracy: 0.5549 - val_loss: 0.9117 - val_accuracy: 0.5410\n",
      "Epoch 1270/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8981 - accuracy: 0.5553 - val_loss: 0.9102 - val_accuracy: 0.5453\n",
      "Epoch 1271/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8979 - accuracy: 0.5551 - val_loss: 0.9139 - val_accuracy: 0.5373\n",
      "Epoch 1272/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8978 - accuracy: 0.5531 - val_loss: 0.9100 - val_accuracy: 0.5430\n",
      "Epoch 1273/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8981 - accuracy: 0.5556 - val_loss: 0.9099 - val_accuracy: 0.5410\n",
      "Epoch 1274/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8979 - accuracy: 0.5567 - val_loss: 0.9132 - val_accuracy: 0.5390\n",
      "Epoch 1275/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8980 - accuracy: 0.5544 - val_loss: 0.9108 - val_accuracy: 0.5450\n",
      "Epoch 1276/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8981 - accuracy: 0.5558 - val_loss: 0.9106 - val_accuracy: 0.5470\n",
      "Epoch 1277/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8981 - accuracy: 0.5571 - val_loss: 0.9116 - val_accuracy: 0.5407\n",
      "Epoch 1278/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8978 - accuracy: 0.5559 - val_loss: 0.9099 - val_accuracy: 0.5440\n",
      "Epoch 1279/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8979 - accuracy: 0.5554 - val_loss: 0.9108 - val_accuracy: 0.5460\n",
      "Epoch 1280/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8979 - accuracy: 0.5555 - val_loss: 0.9106 - val_accuracy: 0.5453\n",
      "Epoch 1281/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8980 - accuracy: 0.5556 - val_loss: 0.9102 - val_accuracy: 0.5460\n",
      "Epoch 1282/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8979 - accuracy: 0.5548 - val_loss: 0.9104 - val_accuracy: 0.5450\n",
      "Epoch 1283/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8979 - accuracy: 0.5550 - val_loss: 0.9122 - val_accuracy: 0.5403\n",
      "Epoch 1284/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8980 - accuracy: 0.5558 - val_loss: 0.9106 - val_accuracy: 0.5460\n",
      "Epoch 1285/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8979 - accuracy: 0.5566 - val_loss: 0.9101 - val_accuracy: 0.5453\n",
      "Epoch 1286/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8980 - accuracy: 0.5544 - val_loss: 0.9106 - val_accuracy: 0.5457\n",
      "Epoch 1287/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8977 - accuracy: 0.5551 - val_loss: 0.9101 - val_accuracy: 0.5453\n",
      "Epoch 1288/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8978 - accuracy: 0.5567 - val_loss: 0.9098 - val_accuracy: 0.5390\n",
      "Epoch 1289/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8979 - accuracy: 0.5549 - val_loss: 0.9110 - val_accuracy: 0.5443\n",
      "Epoch 1290/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8978 - accuracy: 0.5561 - val_loss: 0.9102 - val_accuracy: 0.5463\n",
      "Epoch 1291/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8978 - accuracy: 0.5553 - val_loss: 0.9115 - val_accuracy: 0.5427\n",
      "Epoch 1292/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8978 - accuracy: 0.5566 - val_loss: 0.9099 - val_accuracy: 0.5457\n",
      "Epoch 1293/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8978 - accuracy: 0.5555 - val_loss: 0.9099 - val_accuracy: 0.5407\n",
      "Epoch 1294/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8978 - accuracy: 0.5563 - val_loss: 0.9100 - val_accuracy: 0.5457\n",
      "Epoch 1295/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8977 - accuracy: 0.5551 - val_loss: 0.9097 - val_accuracy: 0.5413\n",
      "Epoch 1296/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8977 - accuracy: 0.5556 - val_loss: 0.9119 - val_accuracy: 0.5403\n",
      "Epoch 1297/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8977 - accuracy: 0.5551 - val_loss: 0.9102 - val_accuracy: 0.5447\n",
      "Epoch 1298/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8978 - accuracy: 0.5561 - val_loss: 0.9104 - val_accuracy: 0.5457\n",
      "Epoch 1299/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8977 - accuracy: 0.5570 - val_loss: 0.9115 - val_accuracy: 0.5410\n",
      "Epoch 1300/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8977 - accuracy: 0.5543 - val_loss: 0.9098 - val_accuracy: 0.5400\n",
      "Epoch 1301/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8978 - accuracy: 0.5554 - val_loss: 0.9103 - val_accuracy: 0.5447\n",
      "Epoch 1302/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8978 - accuracy: 0.5560 - val_loss: 0.9110 - val_accuracy: 0.5447\n",
      "Epoch 1303/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8977 - accuracy: 0.5567 - val_loss: 0.9102 - val_accuracy: 0.5463\n",
      "Epoch 1304/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8977 - accuracy: 0.5560 - val_loss: 0.9107 - val_accuracy: 0.5450\n",
      "Epoch 1305/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8976 - accuracy: 0.5571 - val_loss: 0.9119 - val_accuracy: 0.5380\n",
      "Epoch 1306/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8977 - accuracy: 0.5566 - val_loss: 0.9110 - val_accuracy: 0.5460\n",
      "Epoch 1307/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8975 - accuracy: 0.5574 - val_loss: 0.9098 - val_accuracy: 0.5410\n",
      "Epoch 1308/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8976 - accuracy: 0.5596 - val_loss: 0.9096 - val_accuracy: 0.5387\n",
      "Epoch 1309/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8978 - accuracy: 0.5562 - val_loss: 0.9102 - val_accuracy: 0.5447\n",
      "Epoch 1310/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8977 - accuracy: 0.5569 - val_loss: 0.9097 - val_accuracy: 0.5437\n",
      "Epoch 1311/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8978 - accuracy: 0.5556 - val_loss: 0.9106 - val_accuracy: 0.5450\n",
      "Epoch 1312/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8976 - accuracy: 0.5559 - val_loss: 0.9104 - val_accuracy: 0.5443\n",
      "Epoch 1313/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8976 - accuracy: 0.5571 - val_loss: 0.9103 - val_accuracy: 0.5460\n",
      "Epoch 1314/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8976 - accuracy: 0.5562 - val_loss: 0.9098 - val_accuracy: 0.5453\n",
      "Epoch 1315/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8975 - accuracy: 0.5554 - val_loss: 0.9106 - val_accuracy: 0.5447\n",
      "Epoch 1316/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8976 - accuracy: 0.5556 - val_loss: 0.9118 - val_accuracy: 0.5390\n",
      "Epoch 1317/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8976 - accuracy: 0.5560 - val_loss: 0.9105 - val_accuracy: 0.5463\n",
      "Epoch 1318/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8973 - accuracy: 0.5544 - val_loss: 0.9131 - val_accuracy: 0.5380\n",
      "Epoch 1319/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8976 - accuracy: 0.5564 - val_loss: 0.9101 - val_accuracy: 0.5457\n",
      "Epoch 1320/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8974 - accuracy: 0.5557 - val_loss: 0.9105 - val_accuracy: 0.5450\n",
      "Epoch 1321/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8976 - accuracy: 0.5566 - val_loss: 0.9100 - val_accuracy: 0.5450\n",
      "Epoch 1322/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8975 - accuracy: 0.5546 - val_loss: 0.9107 - val_accuracy: 0.5460\n",
      "Epoch 1323/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8975 - accuracy: 0.5546 - val_loss: 0.9099 - val_accuracy: 0.5453\n",
      "Epoch 1324/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8976 - accuracy: 0.5568 - val_loss: 0.9103 - val_accuracy: 0.5453\n",
      "Epoch 1325/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8975 - accuracy: 0.5563 - val_loss: 0.9099 - val_accuracy: 0.5453\n",
      "Epoch 1326/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8975 - accuracy: 0.5561 - val_loss: 0.9098 - val_accuracy: 0.5430\n",
      "Epoch 1327/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8975 - accuracy: 0.5565 - val_loss: 0.9106 - val_accuracy: 0.5457\n",
      "Epoch 1328/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8975 - accuracy: 0.5557 - val_loss: 0.9108 - val_accuracy: 0.5457\n",
      "Epoch 1329/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8975 - accuracy: 0.5571 - val_loss: 0.9107 - val_accuracy: 0.5457\n",
      "Epoch 1330/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8974 - accuracy: 0.5576 - val_loss: 0.9098 - val_accuracy: 0.5437\n",
      "Epoch 1331/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8974 - accuracy: 0.5561 - val_loss: 0.9100 - val_accuracy: 0.5443\n",
      "Epoch 1332/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8974 - accuracy: 0.5569 - val_loss: 0.9108 - val_accuracy: 0.5450\n",
      "Epoch 1333/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8974 - accuracy: 0.5570 - val_loss: 0.9105 - val_accuracy: 0.5453\n",
      "Epoch 1334/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8975 - accuracy: 0.5563 - val_loss: 0.9098 - val_accuracy: 0.5440\n",
      "Epoch 1335/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8974 - accuracy: 0.5557 - val_loss: 0.9108 - val_accuracy: 0.5423\n",
      "Epoch 1336/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8973 - accuracy: 0.5568 - val_loss: 0.9111 - val_accuracy: 0.5417\n",
      "Epoch 1337/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8975 - accuracy: 0.5559 - val_loss: 0.9101 - val_accuracy: 0.5457\n",
      "Epoch 1338/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8974 - accuracy: 0.5576 - val_loss: 0.9095 - val_accuracy: 0.5413\n",
      "Epoch 1339/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8972 - accuracy: 0.5559 - val_loss: 0.9094 - val_accuracy: 0.5417\n",
      "Epoch 1340/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8973 - accuracy: 0.5574 - val_loss: 0.9101 - val_accuracy: 0.5437\n",
      "Epoch 1341/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8973 - accuracy: 0.5556 - val_loss: 0.9103 - val_accuracy: 0.5450\n",
      "Epoch 1342/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8974 - accuracy: 0.5566 - val_loss: 0.9102 - val_accuracy: 0.5453\n",
      "Epoch 1343/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8973 - accuracy: 0.5567 - val_loss: 0.9099 - val_accuracy: 0.5453\n",
      "Epoch 1344/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8972 - accuracy: 0.5549 - val_loss: 0.9113 - val_accuracy: 0.5407\n",
      "Epoch 1345/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8974 - accuracy: 0.5562 - val_loss: 0.9096 - val_accuracy: 0.5427\n",
      "Epoch 1346/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8972 - accuracy: 0.5549 - val_loss: 0.9115 - val_accuracy: 0.5387\n",
      "Epoch 1347/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8971 - accuracy: 0.5551 - val_loss: 0.9127 - val_accuracy: 0.5390\n",
      "Epoch 1348/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8973 - accuracy: 0.5567 - val_loss: 0.9097 - val_accuracy: 0.5443\n",
      "Epoch 1349/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8972 - accuracy: 0.5549 - val_loss: 0.9113 - val_accuracy: 0.5410\n",
      "Epoch 1350/5500\n",
      "14000/14000 [==============================] - 1s 38us/step - loss: 0.8973 - accuracy: 0.5556 - val_loss: 0.9097 - val_accuracy: 0.5447\n",
      "Epoch 1351/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8973 - accuracy: 0.5562 - val_loss: 0.9105 - val_accuracy: 0.5463\n",
      "Epoch 1352/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8973 - accuracy: 0.5559 - val_loss: 0.9102 - val_accuracy: 0.5463\n",
      "Epoch 1353/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8972 - accuracy: 0.5561 - val_loss: 0.9094 - val_accuracy: 0.5443\n",
      "Epoch 1354/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8971 - accuracy: 0.5544 - val_loss: 0.9120 - val_accuracy: 0.5387\n",
      "Epoch 1355/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8973 - accuracy: 0.5559 - val_loss: 0.9103 - val_accuracy: 0.5443\n",
      "Epoch 1356/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8972 - accuracy: 0.5551 - val_loss: 0.9097 - val_accuracy: 0.5440\n",
      "Epoch 1357/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8972 - accuracy: 0.5566 - val_loss: 0.9102 - val_accuracy: 0.5443\n",
      "Epoch 1358/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8970 - accuracy: 0.5575 - val_loss: 0.9105 - val_accuracy: 0.5443\n",
      "Epoch 1359/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8972 - accuracy: 0.5576 - val_loss: 0.9108 - val_accuracy: 0.5423\n",
      "Epoch 1360/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8972 - accuracy: 0.5572 - val_loss: 0.9098 - val_accuracy: 0.5433\n",
      "Epoch 1361/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8972 - accuracy: 0.5563 - val_loss: 0.9099 - val_accuracy: 0.5447\n",
      "Epoch 1362/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8971 - accuracy: 0.5568 - val_loss: 0.9111 - val_accuracy: 0.5410\n",
      "Epoch 1363/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8972 - accuracy: 0.5559 - val_loss: 0.9115 - val_accuracy: 0.5387\n",
      "Epoch 1364/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8971 - accuracy: 0.5549 - val_loss: 0.9097 - val_accuracy: 0.5443\n",
      "Epoch 1365/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8971 - accuracy: 0.5577 - val_loss: 0.9092 - val_accuracy: 0.5433\n",
      "Epoch 1366/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8972 - accuracy: 0.5553 - val_loss: 0.9099 - val_accuracy: 0.5433\n",
      "Epoch 1367/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8970 - accuracy: 0.5574 - val_loss: 0.9125 - val_accuracy: 0.5403\n",
      "Epoch 1368/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8970 - accuracy: 0.5544 - val_loss: 0.9094 - val_accuracy: 0.5403\n",
      "Epoch 1369/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.8971 - accuracy: 0.5556 - val_loss: 0.9095 - val_accuracy: 0.5433\n",
      "Epoch 1370/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8971 - accuracy: 0.5553 - val_loss: 0.9098 - val_accuracy: 0.5447\n",
      "Epoch 1371/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8970 - accuracy: 0.5547 - val_loss: 0.9101 - val_accuracy: 0.5460\n",
      "Epoch 1372/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8971 - accuracy: 0.5557 - val_loss: 0.9097 - val_accuracy: 0.5437\n",
      "Epoch 1373/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8969 - accuracy: 0.5564 - val_loss: 0.9100 - val_accuracy: 0.5447\n",
      "Epoch 1374/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8971 - accuracy: 0.5558 - val_loss: 0.9101 - val_accuracy: 0.5460\n",
      "Epoch 1375/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8970 - accuracy: 0.5558 - val_loss: 0.9092 - val_accuracy: 0.5413\n",
      "Epoch 1376/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8971 - accuracy: 0.5575 - val_loss: 0.9099 - val_accuracy: 0.5447\n",
      "Epoch 1377/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8970 - accuracy: 0.5548 - val_loss: 0.9096 - val_accuracy: 0.5440\n",
      "Epoch 1378/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8969 - accuracy: 0.5561 - val_loss: 0.9102 - val_accuracy: 0.5453\n",
      "Epoch 1379/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8970 - accuracy: 0.5561 - val_loss: 0.9099 - val_accuracy: 0.5440\n",
      "Epoch 1380/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8970 - accuracy: 0.5557 - val_loss: 0.9096 - val_accuracy: 0.5437\n",
      "Epoch 1381/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8968 - accuracy: 0.5564 - val_loss: 0.9103 - val_accuracy: 0.5460\n",
      "Epoch 1382/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8971 - accuracy: 0.5554 - val_loss: 0.9097 - val_accuracy: 0.5447\n",
      "Epoch 1383/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8968 - accuracy: 0.5566 - val_loss: 0.9095 - val_accuracy: 0.5413\n",
      "Epoch 1384/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8969 - accuracy: 0.5579 - val_loss: 0.9092 - val_accuracy: 0.5423\n",
      "Epoch 1385/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8969 - accuracy: 0.5553 - val_loss: 0.9109 - val_accuracy: 0.5420\n",
      "Epoch 1386/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8968 - accuracy: 0.5562 - val_loss: 0.9097 - val_accuracy: 0.5427\n",
      "Epoch 1387/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8969 - accuracy: 0.5549 - val_loss: 0.9097 - val_accuracy: 0.5453\n",
      "Epoch 1388/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8969 - accuracy: 0.5564 - val_loss: 0.9096 - val_accuracy: 0.5430\n",
      "Epoch 1389/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8968 - accuracy: 0.5578 - val_loss: 0.9109 - val_accuracy: 0.5393\n",
      "Epoch 1390/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8969 - accuracy: 0.5578 - val_loss: 0.9094 - val_accuracy: 0.5417\n",
      "Epoch 1391/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8967 - accuracy: 0.5584 - val_loss: 0.9096 - val_accuracy: 0.5440\n",
      "Epoch 1392/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8967 - accuracy: 0.5569 - val_loss: 0.9130 - val_accuracy: 0.5390\n",
      "Epoch 1393/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8970 - accuracy: 0.5541 - val_loss: 0.9098 - val_accuracy: 0.5447\n",
      "Epoch 1394/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8967 - accuracy: 0.5551 - val_loss: 0.9105 - val_accuracy: 0.5433\n",
      "Epoch 1395/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8967 - accuracy: 0.5575 - val_loss: 0.9108 - val_accuracy: 0.5403\n",
      "Epoch 1396/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8968 - accuracy: 0.5559 - val_loss: 0.9095 - val_accuracy: 0.5417\n",
      "Epoch 1397/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8968 - accuracy: 0.5570 - val_loss: 0.9093 - val_accuracy: 0.5410\n",
      "Epoch 1398/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8969 - accuracy: 0.5566 - val_loss: 0.9100 - val_accuracy: 0.5463\n",
      "Epoch 1399/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8967 - accuracy: 0.5555 - val_loss: 0.9093 - val_accuracy: 0.5437\n",
      "Epoch 1400/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8967 - accuracy: 0.5566 - val_loss: 0.9100 - val_accuracy: 0.5457\n",
      "Epoch 1401/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8968 - accuracy: 0.5564 - val_loss: 0.9094 - val_accuracy: 0.5437\n",
      "Epoch 1402/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8967 - accuracy: 0.5579 - val_loss: 0.9092 - val_accuracy: 0.5433\n",
      "Epoch 1403/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8967 - accuracy: 0.5561 - val_loss: 0.9096 - val_accuracy: 0.5450\n",
      "Epoch 1404/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8968 - accuracy: 0.5555 - val_loss: 0.9091 - val_accuracy: 0.5410\n",
      "Epoch 1405/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8968 - accuracy: 0.5556 - val_loss: 0.9091 - val_accuracy: 0.5423\n",
      "Epoch 1406/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8966 - accuracy: 0.5543 - val_loss: 0.9088 - val_accuracy: 0.5427\n",
      "Epoch 1407/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8966 - accuracy: 0.5565 - val_loss: 0.9091 - val_accuracy: 0.5440\n",
      "Epoch 1408/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8967 - accuracy: 0.5561 - val_loss: 0.9089 - val_accuracy: 0.5437\n",
      "Epoch 1409/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8967 - accuracy: 0.5540 - val_loss: 0.9091 - val_accuracy: 0.5430\n",
      "Epoch 1410/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8967 - accuracy: 0.5558 - val_loss: 0.9097 - val_accuracy: 0.5447\n",
      "Epoch 1411/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8967 - accuracy: 0.5556 - val_loss: 0.9093 - val_accuracy: 0.5447\n",
      "Epoch 1412/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8965 - accuracy: 0.5569 - val_loss: 0.9090 - val_accuracy: 0.5440\n",
      "Epoch 1413/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8967 - accuracy: 0.5546 - val_loss: 0.9111 - val_accuracy: 0.5393\n",
      "Epoch 1414/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8965 - accuracy: 0.5556 - val_loss: 0.9120 - val_accuracy: 0.5390\n",
      "Epoch 1415/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8967 - accuracy: 0.5562 - val_loss: 0.9089 - val_accuracy: 0.5437\n",
      "Epoch 1416/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8966 - accuracy: 0.5562 - val_loss: 0.9097 - val_accuracy: 0.5467\n",
      "Epoch 1417/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8960 - accuracy: 0.5589 - val_loss: 0.9122 - val_accuracy: 0.5403\n",
      "Epoch 1418/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8966 - accuracy: 0.5563 - val_loss: 0.9101 - val_accuracy: 0.5447\n",
      "Epoch 1419/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8966 - accuracy: 0.5570 - val_loss: 0.9120 - val_accuracy: 0.5367\n",
      "Epoch 1420/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8966 - accuracy: 0.5556 - val_loss: 0.9107 - val_accuracy: 0.5427\n",
      "Epoch 1421/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8966 - accuracy: 0.5563 - val_loss: 0.9095 - val_accuracy: 0.5433\n",
      "Epoch 1422/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8964 - accuracy: 0.5561 - val_loss: 0.9088 - val_accuracy: 0.5420\n",
      "Epoch 1423/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8965 - accuracy: 0.5567 - val_loss: 0.9100 - val_accuracy: 0.5430\n",
      "Epoch 1424/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8965 - accuracy: 0.5551 - val_loss: 0.9090 - val_accuracy: 0.5420\n",
      "Epoch 1425/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8966 - accuracy: 0.5551 - val_loss: 0.9098 - val_accuracy: 0.5450\n",
      "Epoch 1426/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8966 - accuracy: 0.5559 - val_loss: 0.9104 - val_accuracy: 0.5423\n",
      "Epoch 1427/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8966 - accuracy: 0.5546 - val_loss: 0.9098 - val_accuracy: 0.5453\n",
      "Epoch 1428/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8965 - accuracy: 0.5551 - val_loss: 0.9095 - val_accuracy: 0.5467\n",
      "Epoch 1429/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8966 - accuracy: 0.5554 - val_loss: 0.9098 - val_accuracy: 0.5460\n",
      "Epoch 1430/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8965 - accuracy: 0.5555 - val_loss: 0.9101 - val_accuracy: 0.5437\n",
      "Epoch 1431/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8964 - accuracy: 0.5551 - val_loss: 0.9096 - val_accuracy: 0.5427\n",
      "Epoch 1432/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8963 - accuracy: 0.5556 - val_loss: 0.9095 - val_accuracy: 0.5447\n",
      "Epoch 1433/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8964 - accuracy: 0.5560 - val_loss: 0.9098 - val_accuracy: 0.5450\n",
      "Epoch 1434/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8965 - accuracy: 0.5566 - val_loss: 0.9100 - val_accuracy: 0.5440\n",
      "Epoch 1435/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8964 - accuracy: 0.5556 - val_loss: 0.9096 - val_accuracy: 0.5440\n",
      "Epoch 1436/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8964 - accuracy: 0.5563 - val_loss: 0.9096 - val_accuracy: 0.5457\n",
      "Epoch 1437/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8963 - accuracy: 0.5554 - val_loss: 0.9087 - val_accuracy: 0.5417\n",
      "Epoch 1438/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8964 - accuracy: 0.5554 - val_loss: 0.9097 - val_accuracy: 0.5457\n",
      "Epoch 1439/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8964 - accuracy: 0.5564 - val_loss: 0.9099 - val_accuracy: 0.5433\n",
      "Epoch 1440/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8963 - accuracy: 0.5554 - val_loss: 0.9089 - val_accuracy: 0.5440\n",
      "Epoch 1441/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8963 - accuracy: 0.5563 - val_loss: 0.9095 - val_accuracy: 0.5460\n",
      "Epoch 1442/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8963 - accuracy: 0.5561 - val_loss: 0.9105 - val_accuracy: 0.5400\n",
      "Epoch 1443/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8961 - accuracy: 0.5564 - val_loss: 0.9088 - val_accuracy: 0.5413\n",
      "Epoch 1444/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8962 - accuracy: 0.5571 - val_loss: 0.9087 - val_accuracy: 0.5440\n",
      "Epoch 1445/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8963 - accuracy: 0.5553 - val_loss: 0.9112 - val_accuracy: 0.5390\n",
      "Epoch 1446/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8963 - accuracy: 0.5564 - val_loss: 0.9086 - val_accuracy: 0.5423\n",
      "Epoch 1447/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8962 - accuracy: 0.5576 - val_loss: 0.9098 - val_accuracy: 0.5427\n",
      "Epoch 1448/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8962 - accuracy: 0.5549 - val_loss: 0.9100 - val_accuracy: 0.5430\n",
      "Epoch 1449/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8962 - accuracy: 0.5562 - val_loss: 0.9104 - val_accuracy: 0.5413\n",
      "Epoch 1450/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8961 - accuracy: 0.5554 - val_loss: 0.9115 - val_accuracy: 0.5410\n",
      "Epoch 1451/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8961 - accuracy: 0.5535 - val_loss: 0.9086 - val_accuracy: 0.5457\n",
      "Epoch 1452/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8962 - accuracy: 0.5571 - val_loss: 0.9106 - val_accuracy: 0.5400\n",
      "Epoch 1453/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8961 - accuracy: 0.5562 - val_loss: 0.9130 - val_accuracy: 0.5397\n",
      "Epoch 1454/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8962 - accuracy: 0.5561 - val_loss: 0.9115 - val_accuracy: 0.5393\n",
      "Epoch 1455/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8959 - accuracy: 0.5573 - val_loss: 0.9136 - val_accuracy: 0.5373\n",
      "Epoch 1456/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8962 - accuracy: 0.5582 - val_loss: 0.9095 - val_accuracy: 0.5427\n",
      "Epoch 1457/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8961 - accuracy: 0.5566 - val_loss: 0.9098 - val_accuracy: 0.5447\n",
      "Epoch 1458/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8962 - accuracy: 0.5560 - val_loss: 0.9096 - val_accuracy: 0.5443\n",
      "Epoch 1459/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8963 - accuracy: 0.5551 - val_loss: 0.9098 - val_accuracy: 0.5433\n",
      "Epoch 1460/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8962 - accuracy: 0.5569 - val_loss: 0.9096 - val_accuracy: 0.5433\n",
      "Epoch 1461/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8961 - accuracy: 0.5573 - val_loss: 0.9096 - val_accuracy: 0.5440\n",
      "Epoch 1462/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8959 - accuracy: 0.5557 - val_loss: 0.9096 - val_accuracy: 0.5420\n",
      "Epoch 1463/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8961 - accuracy: 0.5557 - val_loss: 0.9097 - val_accuracy: 0.5423\n",
      "Epoch 1464/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8962 - accuracy: 0.5564 - val_loss: 0.9089 - val_accuracy: 0.5437\n",
      "Epoch 1465/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8961 - accuracy: 0.5569 - val_loss: 0.9097 - val_accuracy: 0.5420\n",
      "Epoch 1466/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8962 - accuracy: 0.5568 - val_loss: 0.9089 - val_accuracy: 0.5440\n",
      "Epoch 1467/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8960 - accuracy: 0.5567 - val_loss: 0.9093 - val_accuracy: 0.5443\n",
      "Epoch 1468/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8961 - accuracy: 0.5566 - val_loss: 0.9088 - val_accuracy: 0.5437\n",
      "Epoch 1469/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8961 - accuracy: 0.5569 - val_loss: 0.9086 - val_accuracy: 0.5410\n",
      "Epoch 1470/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8960 - accuracy: 0.5556 - val_loss: 0.9088 - val_accuracy: 0.5430\n",
      "Epoch 1471/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8960 - accuracy: 0.5567 - val_loss: 0.9087 - val_accuracy: 0.5417\n",
      "Epoch 1472/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8961 - accuracy: 0.5560 - val_loss: 0.9095 - val_accuracy: 0.5430\n",
      "Epoch 1473/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8960 - accuracy: 0.5551 - val_loss: 0.9087 - val_accuracy: 0.5437\n",
      "Epoch 1474/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8960 - accuracy: 0.5581 - val_loss: 0.9105 - val_accuracy: 0.5397\n",
      "Epoch 1475/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8959 - accuracy: 0.5571 - val_loss: 0.9084 - val_accuracy: 0.5433\n",
      "Epoch 1476/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8960 - accuracy: 0.5563 - val_loss: 0.9087 - val_accuracy: 0.5433\n",
      "Epoch 1477/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8960 - accuracy: 0.5564 - val_loss: 0.9091 - val_accuracy: 0.5440\n",
      "Epoch 1478/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8960 - accuracy: 0.5558 - val_loss: 0.9089 - val_accuracy: 0.5457\n",
      "Epoch 1479/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8960 - accuracy: 0.5551 - val_loss: 0.9095 - val_accuracy: 0.5413\n",
      "Epoch 1480/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8959 - accuracy: 0.5560 - val_loss: 0.9097 - val_accuracy: 0.5413\n",
      "Epoch 1481/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8959 - accuracy: 0.5573 - val_loss: 0.9091 - val_accuracy: 0.5440\n",
      "Epoch 1482/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8960 - accuracy: 0.5565 - val_loss: 0.9096 - val_accuracy: 0.5447\n",
      "Epoch 1483/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8958 - accuracy: 0.5551 - val_loss: 0.9114 - val_accuracy: 0.5397\n",
      "Epoch 1484/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8958 - accuracy: 0.5561 - val_loss: 0.9111 - val_accuracy: 0.5393\n",
      "Epoch 1485/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8960 - accuracy: 0.5559 - val_loss: 0.9106 - val_accuracy: 0.5390\n",
      "Epoch 1486/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8959 - accuracy: 0.5549 - val_loss: 0.9085 - val_accuracy: 0.5430\n",
      "Epoch 1487/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8958 - accuracy: 0.5552 - val_loss: 0.9101 - val_accuracy: 0.5403\n",
      "Epoch 1488/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8956 - accuracy: 0.5546 - val_loss: 0.9088 - val_accuracy: 0.5440\n",
      "Epoch 1489/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8958 - accuracy: 0.5551 - val_loss: 0.9097 - val_accuracy: 0.5440\n",
      "Epoch 1490/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8958 - accuracy: 0.5560 - val_loss: 0.9103 - val_accuracy: 0.5403\n",
      "Epoch 1491/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8959 - accuracy: 0.5547 - val_loss: 0.9093 - val_accuracy: 0.5430\n",
      "Epoch 1492/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8958 - accuracy: 0.5571 - val_loss: 0.9092 - val_accuracy: 0.5457\n",
      "Epoch 1493/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8956 - accuracy: 0.5552 - val_loss: 0.9084 - val_accuracy: 0.5437\n",
      "Epoch 1494/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8957 - accuracy: 0.5557 - val_loss: 0.9112 - val_accuracy: 0.5393\n",
      "Epoch 1495/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8958 - accuracy: 0.5553 - val_loss: 0.9084 - val_accuracy: 0.5407\n",
      "Epoch 1496/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8959 - accuracy: 0.5561 - val_loss: 0.9084 - val_accuracy: 0.5420\n",
      "Epoch 1497/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8959 - accuracy: 0.5572 - val_loss: 0.9091 - val_accuracy: 0.5443\n",
      "Epoch 1498/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8957 - accuracy: 0.5580 - val_loss: 0.9093 - val_accuracy: 0.5430\n",
      "Epoch 1499/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8958 - accuracy: 0.5561 - val_loss: 0.9091 - val_accuracy: 0.5440\n",
      "Epoch 1500/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8956 - accuracy: 0.5566 - val_loss: 0.9114 - val_accuracy: 0.5400\n",
      "Epoch 1501/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8958 - accuracy: 0.5563 - val_loss: 0.9100 - val_accuracy: 0.5423\n",
      "Epoch 1502/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8958 - accuracy: 0.5570 - val_loss: 0.9112 - val_accuracy: 0.5393\n",
      "Epoch 1503/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8958 - accuracy: 0.5575 - val_loss: 0.9088 - val_accuracy: 0.5447\n",
      "Epoch 1504/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8956 - accuracy: 0.5561 - val_loss: 0.9089 - val_accuracy: 0.5457\n",
      "Epoch 1505/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8957 - accuracy: 0.5577 - val_loss: 0.9082 - val_accuracy: 0.5437\n",
      "Epoch 1506/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8956 - accuracy: 0.5566 - val_loss: 0.9113 - val_accuracy: 0.5407\n",
      "Epoch 1507/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8954 - accuracy: 0.5554 - val_loss: 0.9085 - val_accuracy: 0.5420\n",
      "Epoch 1508/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8954 - accuracy: 0.5569 - val_loss: 0.9107 - val_accuracy: 0.5407\n",
      "Epoch 1509/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8956 - accuracy: 0.5558 - val_loss: 0.9084 - val_accuracy: 0.5403\n",
      "Epoch 1510/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8958 - accuracy: 0.5547 - val_loss: 0.9083 - val_accuracy: 0.5423\n",
      "Epoch 1511/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8956 - accuracy: 0.5569 - val_loss: 0.9082 - val_accuracy: 0.5420\n",
      "Epoch 1512/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8956 - accuracy: 0.5566 - val_loss: 0.9090 - val_accuracy: 0.5450\n",
      "Epoch 1513/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8956 - accuracy: 0.5571 - val_loss: 0.9083 - val_accuracy: 0.5433\n",
      "Epoch 1514/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8957 - accuracy: 0.5556 - val_loss: 0.9091 - val_accuracy: 0.5433\n",
      "Epoch 1515/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8954 - accuracy: 0.5569 - val_loss: 0.9107 - val_accuracy: 0.5403\n",
      "Epoch 1516/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8957 - accuracy: 0.5564 - val_loss: 0.9087 - val_accuracy: 0.5447\n",
      "Epoch 1517/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8956 - accuracy: 0.5559 - val_loss: 0.9095 - val_accuracy: 0.5417\n",
      "Epoch 1518/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8956 - accuracy: 0.5563 - val_loss: 0.9099 - val_accuracy: 0.5410\n",
      "Epoch 1519/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8956 - accuracy: 0.5570 - val_loss: 0.9090 - val_accuracy: 0.5443\n",
      "Epoch 1520/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8955 - accuracy: 0.5556 - val_loss: 0.9082 - val_accuracy: 0.5427\n",
      "Epoch 1521/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8956 - accuracy: 0.5546 - val_loss: 0.9085 - val_accuracy: 0.5430\n",
      "Epoch 1522/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8956 - accuracy: 0.5561 - val_loss: 0.9092 - val_accuracy: 0.5447\n",
      "Epoch 1523/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8952 - accuracy: 0.5567 - val_loss: 0.9082 - val_accuracy: 0.5413\n",
      "Epoch 1524/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8954 - accuracy: 0.5561 - val_loss: 0.9091 - val_accuracy: 0.5410\n",
      "Epoch 1525/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8954 - accuracy: 0.5564 - val_loss: 0.9095 - val_accuracy: 0.5430\n",
      "Epoch 1526/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8954 - accuracy: 0.5548 - val_loss: 0.9081 - val_accuracy: 0.5433\n",
      "Epoch 1527/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8955 - accuracy: 0.5574 - val_loss: 0.9088 - val_accuracy: 0.5440\n",
      "Epoch 1528/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8954 - accuracy: 0.5557 - val_loss: 0.9080 - val_accuracy: 0.5423\n",
      "Epoch 1529/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8954 - accuracy: 0.5557 - val_loss: 0.9092 - val_accuracy: 0.5440\n",
      "Epoch 1530/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8953 - accuracy: 0.5566 - val_loss: 0.9082 - val_accuracy: 0.5420\n",
      "Epoch 1531/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8955 - accuracy: 0.5561 - val_loss: 0.9091 - val_accuracy: 0.5450\n",
      "Epoch 1532/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8954 - accuracy: 0.5560 - val_loss: 0.9081 - val_accuracy: 0.5437\n",
      "Epoch 1533/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8954 - accuracy: 0.5571 - val_loss: 0.9094 - val_accuracy: 0.5437\n",
      "Epoch 1534/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8954 - accuracy: 0.5560 - val_loss: 0.9086 - val_accuracy: 0.5443\n",
      "Epoch 1535/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8954 - accuracy: 0.5563 - val_loss: 0.9083 - val_accuracy: 0.5407\n",
      "Epoch 1536/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8954 - accuracy: 0.5575 - val_loss: 0.9089 - val_accuracy: 0.5433\n",
      "Epoch 1537/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8953 - accuracy: 0.5563 - val_loss: 0.9086 - val_accuracy: 0.5450\n",
      "Epoch 1538/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8953 - accuracy: 0.5560 - val_loss: 0.9079 - val_accuracy: 0.5430\n",
      "Epoch 1539/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8953 - accuracy: 0.5559 - val_loss: 0.9079 - val_accuracy: 0.5407\n",
      "Epoch 1540/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8951 - accuracy: 0.5571 - val_loss: 0.9093 - val_accuracy: 0.5440\n",
      "Epoch 1541/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8954 - accuracy: 0.5564 - val_loss: 0.9080 - val_accuracy: 0.5410\n",
      "Epoch 1542/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8954 - accuracy: 0.5569 - val_loss: 0.9084 - val_accuracy: 0.5443\n",
      "Epoch 1543/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8953 - accuracy: 0.5570 - val_loss: 0.9081 - val_accuracy: 0.5420\n",
      "Epoch 1544/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8951 - accuracy: 0.5572 - val_loss: 0.9085 - val_accuracy: 0.5407\n",
      "Epoch 1545/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8954 - accuracy: 0.5574 - val_loss: 0.9084 - val_accuracy: 0.5443\n",
      "Epoch 1546/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8954 - accuracy: 0.5561 - val_loss: 0.9084 - val_accuracy: 0.5437\n",
      "Epoch 1547/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8952 - accuracy: 0.5580 - val_loss: 0.9089 - val_accuracy: 0.5437\n",
      "Epoch 1548/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8951 - accuracy: 0.5574 - val_loss: 0.9116 - val_accuracy: 0.5377\n",
      "Epoch 1549/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8950 - accuracy: 0.5564 - val_loss: 0.9084 - val_accuracy: 0.5447\n",
      "Epoch 1550/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8953 - accuracy: 0.5556 - val_loss: 0.9099 - val_accuracy: 0.5417\n",
      "Epoch 1551/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8953 - accuracy: 0.5584 - val_loss: 0.9095 - val_accuracy: 0.5437\n",
      "Epoch 1552/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8953 - accuracy: 0.5577 - val_loss: 0.9090 - val_accuracy: 0.5457\n",
      "Epoch 1553/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8952 - accuracy: 0.5569 - val_loss: 0.9084 - val_accuracy: 0.5453\n",
      "Epoch 1554/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8952 - accuracy: 0.5574 - val_loss: 0.9088 - val_accuracy: 0.5437\n",
      "Epoch 1555/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8950 - accuracy: 0.5556 - val_loss: 0.9081 - val_accuracy: 0.5417\n",
      "Epoch 1556/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8952 - accuracy: 0.5561 - val_loss: 0.9103 - val_accuracy: 0.5410\n",
      "Epoch 1557/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8953 - accuracy: 0.5556 - val_loss: 0.9079 - val_accuracy: 0.5413\n",
      "Epoch 1558/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8951 - accuracy: 0.5571 - val_loss: 0.9080 - val_accuracy: 0.5430\n",
      "Epoch 1559/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8952 - accuracy: 0.5574 - val_loss: 0.9095 - val_accuracy: 0.5413\n",
      "Epoch 1560/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8952 - accuracy: 0.5572 - val_loss: 0.9107 - val_accuracy: 0.5420\n",
      "Epoch 1561/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8950 - accuracy: 0.5577 - val_loss: 0.9081 - val_accuracy: 0.5433\n",
      "Epoch 1562/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8952 - accuracy: 0.5566 - val_loss: 0.9091 - val_accuracy: 0.5443\n",
      "Epoch 1563/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8950 - accuracy: 0.5575 - val_loss: 0.9082 - val_accuracy: 0.5427\n",
      "Epoch 1564/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8950 - accuracy: 0.5577 - val_loss: 0.9081 - val_accuracy: 0.5447\n",
      "Epoch 1565/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8951 - accuracy: 0.5585 - val_loss: 0.9101 - val_accuracy: 0.5403\n",
      "Epoch 1566/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8950 - accuracy: 0.5586 - val_loss: 0.9083 - val_accuracy: 0.5417\n",
      "Epoch 1567/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8952 - accuracy: 0.5573 - val_loss: 0.9078 - val_accuracy: 0.5423\n",
      "Epoch 1568/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8951 - accuracy: 0.5575 - val_loss: 0.9079 - val_accuracy: 0.5397\n",
      "Epoch 1569/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8951 - accuracy: 0.5581 - val_loss: 0.9085 - val_accuracy: 0.5440\n",
      "Epoch 1570/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5576 - val_loss: 0.9079 - val_accuracy: 0.5403\n",
      "Epoch 1571/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8950 - accuracy: 0.5584 - val_loss: 0.9078 - val_accuracy: 0.5430\n",
      "Epoch 1572/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5565 - val_loss: 0.9079 - val_accuracy: 0.5410\n",
      "Epoch 1573/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5569 - val_loss: 0.9083 - val_accuracy: 0.5397\n",
      "Epoch 1574/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8952 - accuracy: 0.5563 - val_loss: 0.9080 - val_accuracy: 0.5400\n",
      "Epoch 1575/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8950 - accuracy: 0.5571 - val_loss: 0.9080 - val_accuracy: 0.5427\n",
      "Epoch 1576/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8950 - accuracy: 0.5572 - val_loss: 0.9077 - val_accuracy: 0.5423\n",
      "Epoch 1577/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8951 - accuracy: 0.5571 - val_loss: 0.9087 - val_accuracy: 0.5433\n",
      "Epoch 1578/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8950 - accuracy: 0.5561 - val_loss: 0.9102 - val_accuracy: 0.5407\n",
      "Epoch 1579/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8949 - accuracy: 0.5594 - val_loss: 0.9081 - val_accuracy: 0.5413\n",
      "Epoch 1580/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5571 - val_loss: 0.9107 - val_accuracy: 0.5433\n",
      "Epoch 1581/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8951 - accuracy: 0.5559 - val_loss: 0.9080 - val_accuracy: 0.5413\n",
      "Epoch 1582/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5570 - val_loss: 0.9082 - val_accuracy: 0.5420\n",
      "Epoch 1583/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8948 - accuracy: 0.5571 - val_loss: 0.9081 - val_accuracy: 0.5403\n",
      "Epoch 1584/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8948 - accuracy: 0.5560 - val_loss: 0.9082 - val_accuracy: 0.5437\n",
      "Epoch 1585/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8951 - accuracy: 0.5550 - val_loss: 0.9100 - val_accuracy: 0.5417\n",
      "Epoch 1586/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8950 - accuracy: 0.5587 - val_loss: 0.9077 - val_accuracy: 0.5423\n",
      "Epoch 1587/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8950 - accuracy: 0.5559 - val_loss: 0.9091 - val_accuracy: 0.5427\n",
      "Epoch 1588/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8946 - accuracy: 0.5579 - val_loss: 0.9079 - val_accuracy: 0.5410\n",
      "Epoch 1589/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5566 - val_loss: 0.9082 - val_accuracy: 0.5427\n",
      "Epoch 1590/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8949 - accuracy: 0.5584 - val_loss: 0.9078 - val_accuracy: 0.5413\n",
      "Epoch 1591/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8947 - accuracy: 0.5554 - val_loss: 0.9088 - val_accuracy: 0.5443\n",
      "Epoch 1592/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5574 - val_loss: 0.9090 - val_accuracy: 0.5433\n",
      "Epoch 1593/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5582 - val_loss: 0.9080 - val_accuracy: 0.5443\n",
      "Epoch 1594/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8948 - accuracy: 0.5585 - val_loss: 0.9082 - val_accuracy: 0.5437\n",
      "Epoch 1595/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8949 - accuracy: 0.5571 - val_loss: 0.9089 - val_accuracy: 0.5430\n",
      "Epoch 1596/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8949 - accuracy: 0.5555 - val_loss: 0.9079 - val_accuracy: 0.5403\n",
      "Epoch 1597/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8948 - accuracy: 0.5575 - val_loss: 0.9085 - val_accuracy: 0.5433\n",
      "Epoch 1598/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8947 - accuracy: 0.5576 - val_loss: 0.9093 - val_accuracy: 0.5403\n",
      "Epoch 1599/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8947 - accuracy: 0.5588 - val_loss: 0.9089 - val_accuracy: 0.5420\n",
      "Epoch 1600/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8947 - accuracy: 0.5564 - val_loss: 0.9077 - val_accuracy: 0.5397\n",
      "Epoch 1601/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8947 - accuracy: 0.5564 - val_loss: 0.9079 - val_accuracy: 0.5417\n",
      "Epoch 1602/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8948 - accuracy: 0.5564 - val_loss: 0.9083 - val_accuracy: 0.5423\n",
      "Epoch 1603/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8945 - accuracy: 0.5575 - val_loss: 0.9087 - val_accuracy: 0.5440\n",
      "Epoch 1604/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8945 - accuracy: 0.5570 - val_loss: 0.9085 - val_accuracy: 0.5430\n",
      "Epoch 1605/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8948 - accuracy: 0.5570 - val_loss: 0.9081 - val_accuracy: 0.5403\n",
      "Epoch 1606/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8947 - accuracy: 0.5565 - val_loss: 0.9086 - val_accuracy: 0.5433\n",
      "Epoch 1607/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8946 - accuracy: 0.5574 - val_loss: 0.9089 - val_accuracy: 0.5433\n",
      "Epoch 1608/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8947 - accuracy: 0.5571 - val_loss: 0.9082 - val_accuracy: 0.5447\n",
      "Epoch 1609/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8947 - accuracy: 0.5567 - val_loss: 0.9078 - val_accuracy: 0.5420\n",
      "Epoch 1610/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8947 - accuracy: 0.5566 - val_loss: 0.9081 - val_accuracy: 0.5420\n",
      "Epoch 1611/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8948 - accuracy: 0.5546 - val_loss: 0.9081 - val_accuracy: 0.5433\n",
      "Epoch 1612/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8944 - accuracy: 0.5579 - val_loss: 0.9124 - val_accuracy: 0.5400\n",
      "Epoch 1613/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8945 - accuracy: 0.5570 - val_loss: 0.9103 - val_accuracy: 0.5417\n",
      "Epoch 1614/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8946 - accuracy: 0.5571 - val_loss: 0.9078 - val_accuracy: 0.5450\n",
      "Epoch 1615/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8947 - accuracy: 0.5576 - val_loss: 0.9096 - val_accuracy: 0.5430\n",
      "Epoch 1616/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8947 - accuracy: 0.5570 - val_loss: 0.9094 - val_accuracy: 0.5420\n",
      "Epoch 1617/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8946 - accuracy: 0.5555 - val_loss: 0.9104 - val_accuracy: 0.5407\n",
      "Epoch 1618/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8946 - accuracy: 0.5570 - val_loss: 0.9104 - val_accuracy: 0.5410\n",
      "Epoch 1619/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8945 - accuracy: 0.5570 - val_loss: 0.9085 - val_accuracy: 0.5423\n",
      "Epoch 1620/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8946 - accuracy: 0.5572 - val_loss: 0.9082 - val_accuracy: 0.5427\n",
      "Epoch 1621/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8947 - accuracy: 0.5561 - val_loss: 0.9081 - val_accuracy: 0.5413\n",
      "Epoch 1622/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8945 - accuracy: 0.5585 - val_loss: 0.9088 - val_accuracy: 0.5440\n",
      "Epoch 1623/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8945 - accuracy: 0.5558 - val_loss: 0.9081 - val_accuracy: 0.5420\n",
      "Epoch 1624/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8947 - accuracy: 0.5550 - val_loss: 0.9083 - val_accuracy: 0.5427\n",
      "Epoch 1625/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8945 - accuracy: 0.5573 - val_loss: 0.9079 - val_accuracy: 0.5420\n",
      "Epoch 1626/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8945 - accuracy: 0.5578 - val_loss: 0.9094 - val_accuracy: 0.5437\n",
      "Epoch 1627/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8945 - accuracy: 0.5559 - val_loss: 0.9086 - val_accuracy: 0.5410\n",
      "Epoch 1628/5500\n",
      "14000/14000 [==============================] - 1s 37us/step - loss: 0.8943 - accuracy: 0.5571 - val_loss: 0.9073 - val_accuracy: 0.5433\n",
      "Epoch 1629/5500\n",
      "14000/14000 [==============================] - 1s 37us/step - loss: 0.8944 - accuracy: 0.5555 - val_loss: 0.9075 - val_accuracy: 0.5403\n",
      "Epoch 1630/5500\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.8945 - accuracy: 0.5573 - val_loss: 0.9089 - val_accuracy: 0.5443\n",
      "Epoch 1631/5500\n",
      "14000/14000 [==============================] - 1s 37us/step - loss: 0.8944 - accuracy: 0.5561 - val_loss: 0.9079 - val_accuracy: 0.5387\n",
      "Epoch 1632/5500\n",
      "14000/14000 [==============================] - 1s 36us/step - loss: 0.8944 - accuracy: 0.5575 - val_loss: 0.9076 - val_accuracy: 0.5400\n",
      "Epoch 1633/5500\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.8943 - accuracy: 0.5567 - val_loss: 0.9095 - val_accuracy: 0.5430\n",
      "Epoch 1634/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.8945 - accuracy: 0.5566 - val_loss: 0.9074 - val_accuracy: 0.5417\n",
      "Epoch 1635/5500\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.8945 - accuracy: 0.5574 - val_loss: 0.9078 - val_accuracy: 0.5420\n",
      "Epoch 1636/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8945 - accuracy: 0.5559 - val_loss: 0.9084 - val_accuracy: 0.5447\n",
      "Epoch 1637/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8943 - accuracy: 0.5560 - val_loss: 0.9118 - val_accuracy: 0.5413\n",
      "Epoch 1638/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8943 - accuracy: 0.5574 - val_loss: 0.9079 - val_accuracy: 0.5440\n",
      "Epoch 1639/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8944 - accuracy: 0.5578 - val_loss: 0.9082 - val_accuracy: 0.5423\n",
      "Epoch 1640/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8945 - accuracy: 0.5561 - val_loss: 0.9074 - val_accuracy: 0.5400\n",
      "Epoch 1641/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8943 - accuracy: 0.5557 - val_loss: 0.9098 - val_accuracy: 0.5423\n",
      "Epoch 1642/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8944 - accuracy: 0.5571 - val_loss: 0.9077 - val_accuracy: 0.5430\n",
      "Epoch 1643/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8944 - accuracy: 0.5559 - val_loss: 0.9132 - val_accuracy: 0.5410\n",
      "Epoch 1644/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8944 - accuracy: 0.5572 - val_loss: 0.9072 - val_accuracy: 0.5417\n",
      "Epoch 1645/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8942 - accuracy: 0.5564 - val_loss: 0.9072 - val_accuracy: 0.5397\n",
      "Epoch 1646/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8943 - accuracy: 0.5569 - val_loss: 0.9076 - val_accuracy: 0.5430\n",
      "Epoch 1647/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8943 - accuracy: 0.5577 - val_loss: 0.9072 - val_accuracy: 0.5413\n",
      "Epoch 1648/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8941 - accuracy: 0.5554 - val_loss: 0.9090 - val_accuracy: 0.5420\n",
      "Epoch 1649/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8942 - accuracy: 0.5570 - val_loss: 0.9084 - val_accuracy: 0.5417\n",
      "Epoch 1650/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8943 - accuracy: 0.5573 - val_loss: 0.9078 - val_accuracy: 0.5427\n",
      "Epoch 1651/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8940 - accuracy: 0.5581 - val_loss: 0.9082 - val_accuracy: 0.5427\n",
      "Epoch 1652/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8943 - accuracy: 0.5569 - val_loss: 0.9075 - val_accuracy: 0.5407\n",
      "Epoch 1653/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8941 - accuracy: 0.5583 - val_loss: 0.9106 - val_accuracy: 0.5417\n",
      "Epoch 1654/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8941 - accuracy: 0.5594 - val_loss: 0.9074 - val_accuracy: 0.5427\n",
      "Epoch 1655/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8943 - accuracy: 0.5571 - val_loss: 0.9073 - val_accuracy: 0.5417\n",
      "Epoch 1656/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8942 - accuracy: 0.5579 - val_loss: 0.9072 - val_accuracy: 0.5407\n",
      "Epoch 1657/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8943 - accuracy: 0.5583 - val_loss: 0.9074 - val_accuracy: 0.5437\n",
      "Epoch 1658/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8937 - accuracy: 0.5569 - val_loss: 0.9117 - val_accuracy: 0.5400\n",
      "Epoch 1659/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8942 - accuracy: 0.5585 - val_loss: 0.9071 - val_accuracy: 0.5417\n",
      "Epoch 1660/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8941 - accuracy: 0.5565 - val_loss: 0.9076 - val_accuracy: 0.5437\n",
      "Epoch 1661/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8944 - accuracy: 0.5569 - val_loss: 0.9088 - val_accuracy: 0.5440\n",
      "Epoch 1662/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8943 - accuracy: 0.5576 - val_loss: 0.9079 - val_accuracy: 0.5437\n",
      "Epoch 1663/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8941 - accuracy: 0.5591 - val_loss: 0.9085 - val_accuracy: 0.5423\n",
      "Epoch 1664/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8941 - accuracy: 0.5580 - val_loss: 0.9077 - val_accuracy: 0.5440\n",
      "Epoch 1665/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8939 - accuracy: 0.5573 - val_loss: 0.9071 - val_accuracy: 0.5420\n",
      "Epoch 1666/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8941 - accuracy: 0.5584 - val_loss: 0.9090 - val_accuracy: 0.5443\n",
      "Epoch 1667/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8940 - accuracy: 0.5564 - val_loss: 0.9081 - val_accuracy: 0.5420\n",
      "Epoch 1668/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8941 - accuracy: 0.5584 - val_loss: 0.9070 - val_accuracy: 0.5417\n",
      "Epoch 1669/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8940 - accuracy: 0.5592 - val_loss: 0.9084 - val_accuracy: 0.5430\n",
      "Epoch 1670/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8940 - accuracy: 0.5580 - val_loss: 0.9091 - val_accuracy: 0.5433\n",
      "Epoch 1671/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8943 - accuracy: 0.5571 - val_loss: 0.9072 - val_accuracy: 0.5423\n",
      "Epoch 1672/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8938 - accuracy: 0.5571 - val_loss: 0.9077 - val_accuracy: 0.5420\n",
      "Epoch 1673/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8941 - accuracy: 0.5561 - val_loss: 0.9073 - val_accuracy: 0.5410\n",
      "Epoch 1674/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8941 - accuracy: 0.5562 - val_loss: 0.9074 - val_accuracy: 0.5410\n",
      "Epoch 1675/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8939 - accuracy: 0.5609 - val_loss: 0.9071 - val_accuracy: 0.5407\n",
      "Epoch 1676/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8943 - accuracy: 0.5551 - val_loss: 0.9072 - val_accuracy: 0.5423\n",
      "Epoch 1677/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8940 - accuracy: 0.5546 - val_loss: 0.9077 - val_accuracy: 0.5420\n",
      "Epoch 1678/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8939 - accuracy: 0.5601 - val_loss: 0.9087 - val_accuracy: 0.5427\n",
      "Epoch 1679/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8937 - accuracy: 0.5586 - val_loss: 0.9076 - val_accuracy: 0.5417\n",
      "Epoch 1680/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8939 - accuracy: 0.5577 - val_loss: 0.9082 - val_accuracy: 0.5410\n",
      "Epoch 1681/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8937 - accuracy: 0.5586 - val_loss: 0.9071 - val_accuracy: 0.5417\n",
      "Epoch 1682/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8938 - accuracy: 0.5574 - val_loss: 0.9076 - val_accuracy: 0.5440\n",
      "Epoch 1683/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8940 - accuracy: 0.5586 - val_loss: 0.9106 - val_accuracy: 0.5397\n",
      "Epoch 1684/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8940 - accuracy: 0.5571 - val_loss: 0.9089 - val_accuracy: 0.5440\n",
      "Epoch 1685/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8940 - accuracy: 0.5566 - val_loss: 0.9069 - val_accuracy: 0.5437\n",
      "Epoch 1686/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8941 - accuracy: 0.5583 - val_loss: 0.9069 - val_accuracy: 0.5437\n",
      "Epoch 1687/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8941 - accuracy: 0.5569 - val_loss: 0.9072 - val_accuracy: 0.5403\n",
      "Epoch 1688/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8939 - accuracy: 0.5561 - val_loss: 0.9080 - val_accuracy: 0.5407\n",
      "Epoch 1689/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8940 - accuracy: 0.5577 - val_loss: 0.9071 - val_accuracy: 0.5407\n",
      "Epoch 1690/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8938 - accuracy: 0.5576 - val_loss: 0.9071 - val_accuracy: 0.5410\n",
      "Epoch 1691/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8939 - accuracy: 0.5576 - val_loss: 0.9083 - val_accuracy: 0.5407\n",
      "Epoch 1692/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8938 - accuracy: 0.5584 - val_loss: 0.9070 - val_accuracy: 0.5423\n",
      "Epoch 1693/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8937 - accuracy: 0.5586 - val_loss: 0.9106 - val_accuracy: 0.5407\n",
      "Epoch 1694/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8939 - accuracy: 0.5574 - val_loss: 0.9103 - val_accuracy: 0.5403\n",
      "Epoch 1695/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8937 - accuracy: 0.5594 - val_loss: 0.9096 - val_accuracy: 0.5420\n",
      "Epoch 1696/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8938 - accuracy: 0.5581 - val_loss: 0.9075 - val_accuracy: 0.5413\n",
      "Epoch 1697/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8939 - accuracy: 0.5569 - val_loss: 0.9083 - val_accuracy: 0.5440\n",
      "Epoch 1698/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8937 - accuracy: 0.5571 - val_loss: 0.9074 - val_accuracy: 0.5430\n",
      "Epoch 1699/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8938 - accuracy: 0.5561 - val_loss: 0.9078 - val_accuracy: 0.5427\n",
      "Epoch 1700/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8938 - accuracy: 0.5576 - val_loss: 0.9074 - val_accuracy: 0.5397\n",
      "Epoch 1701/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8937 - accuracy: 0.5584 - val_loss: 0.9082 - val_accuracy: 0.5443\n",
      "Epoch 1702/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8937 - accuracy: 0.5579 - val_loss: 0.9070 - val_accuracy: 0.5407\n",
      "Epoch 1703/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8937 - accuracy: 0.5567 - val_loss: 0.9075 - val_accuracy: 0.5437\n",
      "Epoch 1704/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8937 - accuracy: 0.5595 - val_loss: 0.9074 - val_accuracy: 0.5420\n",
      "Epoch 1705/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8937 - accuracy: 0.5574 - val_loss: 0.9089 - val_accuracy: 0.5447\n",
      "Epoch 1706/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8937 - accuracy: 0.5582 - val_loss: 0.9086 - val_accuracy: 0.5447\n",
      "Epoch 1707/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8938 - accuracy: 0.5596 - val_loss: 0.9083 - val_accuracy: 0.5437\n",
      "Epoch 1708/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8938 - accuracy: 0.5582 - val_loss: 0.9070 - val_accuracy: 0.5417\n",
      "Epoch 1709/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8936 - accuracy: 0.5574 - val_loss: 0.9077 - val_accuracy: 0.5433\n",
      "Epoch 1710/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8936 - accuracy: 0.5581 - val_loss: 0.9069 - val_accuracy: 0.5450\n",
      "Epoch 1711/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8937 - accuracy: 0.5586 - val_loss: 0.9092 - val_accuracy: 0.5443\n",
      "Epoch 1712/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8937 - accuracy: 0.5566 - val_loss: 0.9068 - val_accuracy: 0.5420\n",
      "Epoch 1713/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8932 - accuracy: 0.5566 - val_loss: 0.9073 - val_accuracy: 0.5423\n",
      "Epoch 1714/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8936 - accuracy: 0.5586 - val_loss: 0.9071 - val_accuracy: 0.5403\n",
      "Epoch 1715/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8936 - accuracy: 0.5586 - val_loss: 0.9072 - val_accuracy: 0.5417\n",
      "Epoch 1716/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8937 - accuracy: 0.5591 - val_loss: 0.9076 - val_accuracy: 0.5403\n",
      "Epoch 1717/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8937 - accuracy: 0.5584 - val_loss: 0.9074 - val_accuracy: 0.5423\n",
      "Epoch 1718/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8936 - accuracy: 0.5579 - val_loss: 0.9077 - val_accuracy: 0.5440\n",
      "Epoch 1719/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8935 - accuracy: 0.5574 - val_loss: 0.9102 - val_accuracy: 0.5430\n",
      "Epoch 1720/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8933 - accuracy: 0.5571 - val_loss: 0.9070 - val_accuracy: 0.5423\n",
      "Epoch 1721/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8935 - accuracy: 0.5596 - val_loss: 0.9108 - val_accuracy: 0.5410\n",
      "Epoch 1722/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8935 - accuracy: 0.5567 - val_loss: 0.9091 - val_accuracy: 0.5450\n",
      "Epoch 1723/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8936 - accuracy: 0.5571 - val_loss: 0.9076 - val_accuracy: 0.5423\n",
      "Epoch 1724/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8935 - accuracy: 0.5568 - val_loss: 0.9070 - val_accuracy: 0.5407\n",
      "Epoch 1725/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8937 - accuracy: 0.5576 - val_loss: 0.9068 - val_accuracy: 0.5417\n",
      "Epoch 1726/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8934 - accuracy: 0.5582 - val_loss: 0.9069 - val_accuracy: 0.5423\n",
      "Epoch 1727/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8935 - accuracy: 0.5578 - val_loss: 0.9068 - val_accuracy: 0.5403\n",
      "Epoch 1728/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8935 - accuracy: 0.5589 - val_loss: 0.9073 - val_accuracy: 0.5423\n",
      "Epoch 1729/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8933 - accuracy: 0.5578 - val_loss: 0.9094 - val_accuracy: 0.5443\n",
      "Epoch 1730/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8934 - accuracy: 0.5570 - val_loss: 0.9072 - val_accuracy: 0.5413\n",
      "Epoch 1731/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8934 - accuracy: 0.5575 - val_loss: 0.9088 - val_accuracy: 0.5437\n",
      "Epoch 1732/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8931 - accuracy: 0.5581 - val_loss: 0.9099 - val_accuracy: 0.5420\n",
      "Epoch 1733/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8934 - accuracy: 0.5563 - val_loss: 0.9078 - val_accuracy: 0.5420\n",
      "Epoch 1734/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8935 - accuracy: 0.5560 - val_loss: 0.9083 - val_accuracy: 0.5440\n",
      "Epoch 1735/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8936 - accuracy: 0.5575 - val_loss: 0.9067 - val_accuracy: 0.5397\n",
      "Epoch 1736/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8936 - accuracy: 0.5580 - val_loss: 0.9066 - val_accuracy: 0.5413\n",
      "Epoch 1737/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8933 - accuracy: 0.5573 - val_loss: 0.9082 - val_accuracy: 0.5430\n",
      "Epoch 1738/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8933 - accuracy: 0.5567 - val_loss: 0.9073 - val_accuracy: 0.5417\n",
      "Epoch 1739/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8934 - accuracy: 0.5569 - val_loss: 0.9074 - val_accuracy: 0.5433\n",
      "Epoch 1740/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8931 - accuracy: 0.5581 - val_loss: 0.9073 - val_accuracy: 0.5413\n",
      "Epoch 1741/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8934 - accuracy: 0.5571 - val_loss: 0.9079 - val_accuracy: 0.5410\n",
      "Epoch 1742/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8933 - accuracy: 0.5590 - val_loss: 0.9068 - val_accuracy: 0.5427\n",
      "Epoch 1743/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8932 - accuracy: 0.5601 - val_loss: 0.9073 - val_accuracy: 0.5420\n",
      "Epoch 1744/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8931 - accuracy: 0.5576 - val_loss: 0.9073 - val_accuracy: 0.5420\n",
      "Epoch 1745/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8932 - accuracy: 0.5592 - val_loss: 0.9065 - val_accuracy: 0.5423\n",
      "Epoch 1746/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8932 - accuracy: 0.5584 - val_loss: 0.9086 - val_accuracy: 0.5453\n",
      "Epoch 1747/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8933 - accuracy: 0.5570 - val_loss: 0.9083 - val_accuracy: 0.5447\n",
      "Epoch 1748/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8933 - accuracy: 0.5579 - val_loss: 0.9082 - val_accuracy: 0.5447\n",
      "Epoch 1749/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8933 - accuracy: 0.5578 - val_loss: 0.9069 - val_accuracy: 0.5407\n",
      "Epoch 1750/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8933 - accuracy: 0.5581 - val_loss: 0.9066 - val_accuracy: 0.5423\n",
      "Epoch 1751/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8933 - accuracy: 0.5602 - val_loss: 0.9064 - val_accuracy: 0.5423\n",
      "Epoch 1752/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8933 - accuracy: 0.5581 - val_loss: 0.9079 - val_accuracy: 0.5437\n",
      "Epoch 1753/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8932 - accuracy: 0.5593 - val_loss: 0.9064 - val_accuracy: 0.5420\n",
      "Epoch 1754/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8934 - accuracy: 0.5590 - val_loss: 0.9065 - val_accuracy: 0.5410\n",
      "Epoch 1755/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8932 - accuracy: 0.5581 - val_loss: 0.9071 - val_accuracy: 0.5420\n",
      "Epoch 1756/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8932 - accuracy: 0.5571 - val_loss: 0.9080 - val_accuracy: 0.5407\n",
      "Epoch 1757/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8931 - accuracy: 0.5582 - val_loss: 0.9063 - val_accuracy: 0.5427\n",
      "Epoch 1758/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8930 - accuracy: 0.5598 - val_loss: 0.9107 - val_accuracy: 0.5430\n",
      "Epoch 1759/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8931 - accuracy: 0.5589 - val_loss: 0.9065 - val_accuracy: 0.5407\n",
      "Epoch 1760/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8930 - accuracy: 0.5571 - val_loss: 0.9070 - val_accuracy: 0.5400\n",
      "Epoch 1761/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8931 - accuracy: 0.5569 - val_loss: 0.9070 - val_accuracy: 0.5430\n",
      "Epoch 1762/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8931 - accuracy: 0.5574 - val_loss: 0.9069 - val_accuracy: 0.5410\n",
      "Epoch 1763/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8930 - accuracy: 0.5579 - val_loss: 0.9064 - val_accuracy: 0.5413\n",
      "Epoch 1764/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8932 - accuracy: 0.5574 - val_loss: 0.9067 - val_accuracy: 0.5400\n",
      "Epoch 1765/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8932 - accuracy: 0.5581 - val_loss: 0.9081 - val_accuracy: 0.5453\n",
      "Epoch 1766/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8929 - accuracy: 0.5579 - val_loss: 0.9068 - val_accuracy: 0.5420\n",
      "Epoch 1767/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8928 - accuracy: 0.5579 - val_loss: 0.9066 - val_accuracy: 0.5417\n",
      "Epoch 1768/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8928 - accuracy: 0.5591 - val_loss: 0.9066 - val_accuracy: 0.5463\n",
      "Epoch 1769/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8931 - accuracy: 0.5597 - val_loss: 0.9085 - val_accuracy: 0.5457\n",
      "Epoch 1770/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8931 - accuracy: 0.5579 - val_loss: 0.9081 - val_accuracy: 0.5443\n",
      "Epoch 1771/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8930 - accuracy: 0.5577 - val_loss: 0.9077 - val_accuracy: 0.5400\n",
      "Epoch 1772/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8930 - accuracy: 0.5610 - val_loss: 0.9075 - val_accuracy: 0.5417\n",
      "Epoch 1773/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8931 - accuracy: 0.5577 - val_loss: 0.9082 - val_accuracy: 0.5440\n",
      "Epoch 1774/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8932 - accuracy: 0.5584 - val_loss: 0.9078 - val_accuracy: 0.5423\n",
      "Epoch 1775/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8928 - accuracy: 0.5589 - val_loss: 0.9106 - val_accuracy: 0.5433\n",
      "Epoch 1776/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8931 - accuracy: 0.5578 - val_loss: 0.9093 - val_accuracy: 0.5457\n",
      "Epoch 1777/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8929 - accuracy: 0.5601 - val_loss: 0.9065 - val_accuracy: 0.5420\n",
      "Epoch 1778/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8930 - accuracy: 0.5587 - val_loss: 0.9063 - val_accuracy: 0.5427\n",
      "Epoch 1779/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8928 - accuracy: 0.5583 - val_loss: 0.9063 - val_accuracy: 0.5457\n",
      "Epoch 1780/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8930 - accuracy: 0.5599 - val_loss: 0.9063 - val_accuracy: 0.5430\n",
      "Epoch 1781/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8930 - accuracy: 0.5593 - val_loss: 0.9096 - val_accuracy: 0.5443\n",
      "Epoch 1782/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8929 - accuracy: 0.5572 - val_loss: 0.9075 - val_accuracy: 0.5407\n",
      "Epoch 1783/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8926 - accuracy: 0.5590 - val_loss: 0.9061 - val_accuracy: 0.5447\n",
      "Epoch 1784/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8929 - accuracy: 0.5589 - val_loss: 0.9067 - val_accuracy: 0.5407\n",
      "Epoch 1785/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8926 - accuracy: 0.5588 - val_loss: 0.9066 - val_accuracy: 0.5420\n",
      "Epoch 1786/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8928 - accuracy: 0.5586 - val_loss: 0.9104 - val_accuracy: 0.5440\n",
      "Epoch 1787/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8927 - accuracy: 0.5566 - val_loss: 0.9064 - val_accuracy: 0.5420\n",
      "Epoch 1788/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8929 - accuracy: 0.5594 - val_loss: 0.9063 - val_accuracy: 0.5410\n",
      "Epoch 1789/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8929 - accuracy: 0.5581 - val_loss: 0.9095 - val_accuracy: 0.5457\n",
      "Epoch 1790/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8929 - accuracy: 0.5579 - val_loss: 0.9063 - val_accuracy: 0.5440\n",
      "Epoch 1791/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8927 - accuracy: 0.5570 - val_loss: 0.9077 - val_accuracy: 0.5440\n",
      "Epoch 1792/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8929 - accuracy: 0.5569 - val_loss: 0.9063 - val_accuracy: 0.5433\n",
      "Epoch 1793/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8928 - accuracy: 0.5581 - val_loss: 0.9084 - val_accuracy: 0.5460\n",
      "Epoch 1794/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8930 - accuracy: 0.5585 - val_loss: 0.9066 - val_accuracy: 0.5400\n",
      "Epoch 1795/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8924 - accuracy: 0.5577 - val_loss: 0.9064 - val_accuracy: 0.5430\n",
      "Epoch 1796/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8928 - accuracy: 0.5585 - val_loss: 0.9082 - val_accuracy: 0.5453\n",
      "Epoch 1797/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8926 - accuracy: 0.5575 - val_loss: 0.9064 - val_accuracy: 0.5413\n",
      "Epoch 1798/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8928 - accuracy: 0.5566 - val_loss: 0.9063 - val_accuracy: 0.5407\n",
      "Epoch 1799/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8927 - accuracy: 0.5575 - val_loss: 0.9075 - val_accuracy: 0.5410\n",
      "Epoch 1800/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8927 - accuracy: 0.5578 - val_loss: 0.9063 - val_accuracy: 0.5410\n",
      "Epoch 1801/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8929 - accuracy: 0.5581 - val_loss: 0.9068 - val_accuracy: 0.5403\n",
      "Epoch 1802/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8926 - accuracy: 0.5581 - val_loss: 0.9065 - val_accuracy: 0.5440\n",
      "Epoch 1803/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8927 - accuracy: 0.5574 - val_loss: 0.9082 - val_accuracy: 0.5463\n",
      "Epoch 1804/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8927 - accuracy: 0.5601 - val_loss: 0.9063 - val_accuracy: 0.5413\n",
      "Epoch 1805/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8926 - accuracy: 0.5589 - val_loss: 0.9061 - val_accuracy: 0.5420\n",
      "Epoch 1806/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8926 - accuracy: 0.5578 - val_loss: 0.9063 - val_accuracy: 0.5400\n",
      "Epoch 1807/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8926 - accuracy: 0.5574 - val_loss: 0.9065 - val_accuracy: 0.5407\n",
      "Epoch 1808/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8926 - accuracy: 0.5593 - val_loss: 0.9067 - val_accuracy: 0.5420\n",
      "Epoch 1809/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8925 - accuracy: 0.5597 - val_loss: 0.9062 - val_accuracy: 0.5420\n",
      "Epoch 1810/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8927 - accuracy: 0.5561 - val_loss: 0.9067 - val_accuracy: 0.5413\n",
      "Epoch 1811/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8927 - accuracy: 0.5583 - val_loss: 0.9074 - val_accuracy: 0.5433\n",
      "Epoch 1812/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8922 - accuracy: 0.5601 - val_loss: 0.9069 - val_accuracy: 0.5440\n",
      "Epoch 1813/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8925 - accuracy: 0.5590 - val_loss: 0.9069 - val_accuracy: 0.5440\n",
      "Epoch 1814/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8926 - accuracy: 0.5577 - val_loss: 0.9059 - val_accuracy: 0.5467\n",
      "Epoch 1815/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8927 - accuracy: 0.5585 - val_loss: 0.9063 - val_accuracy: 0.5420\n",
      "Epoch 1816/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8926 - accuracy: 0.5589 - val_loss: 0.9064 - val_accuracy: 0.5413\n",
      "Epoch 1817/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8927 - accuracy: 0.5561 - val_loss: 0.9068 - val_accuracy: 0.5413\n",
      "Epoch 1818/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8926 - accuracy: 0.5572 - val_loss: 0.9066 - val_accuracy: 0.5420\n",
      "Epoch 1819/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8926 - accuracy: 0.5589 - val_loss: 0.9091 - val_accuracy: 0.5470\n",
      "Epoch 1820/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8924 - accuracy: 0.5574 - val_loss: 0.9068 - val_accuracy: 0.5423\n",
      "Epoch 1821/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8924 - accuracy: 0.5574 - val_loss: 0.9060 - val_accuracy: 0.5420\n",
      "Epoch 1822/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8925 - accuracy: 0.5574 - val_loss: 0.9059 - val_accuracy: 0.5440\n",
      "Epoch 1823/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8923 - accuracy: 0.5588 - val_loss: 0.9059 - val_accuracy: 0.5453\n",
      "Epoch 1824/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8925 - accuracy: 0.5578 - val_loss: 0.9092 - val_accuracy: 0.5467\n",
      "Epoch 1825/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8927 - accuracy: 0.5579 - val_loss: 0.9060 - val_accuracy: 0.5420\n",
      "Epoch 1826/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8923 - accuracy: 0.5593 - val_loss: 0.9058 - val_accuracy: 0.5443\n",
      "Epoch 1827/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8925 - accuracy: 0.5593 - val_loss: 0.9090 - val_accuracy: 0.5467\n",
      "Epoch 1828/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8924 - accuracy: 0.5598 - val_loss: 0.9072 - val_accuracy: 0.5433\n",
      "Epoch 1829/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8924 - accuracy: 0.5570 - val_loss: 0.9061 - val_accuracy: 0.5423\n",
      "Epoch 1830/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8923 - accuracy: 0.5584 - val_loss: 0.9061 - val_accuracy: 0.5400\n",
      "Epoch 1831/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8921 - accuracy: 0.5579 - val_loss: 0.9067 - val_accuracy: 0.5423\n",
      "Epoch 1832/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8925 - accuracy: 0.5595 - val_loss: 0.9058 - val_accuracy: 0.5447\n",
      "Epoch 1833/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8924 - accuracy: 0.5606 - val_loss: 0.9072 - val_accuracy: 0.5440\n",
      "Epoch 1834/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8922 - accuracy: 0.5584 - val_loss: 0.9070 - val_accuracy: 0.5427\n",
      "Epoch 1835/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8922 - accuracy: 0.5592 - val_loss: 0.9069 - val_accuracy: 0.5420\n",
      "Epoch 1836/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8923 - accuracy: 0.5584 - val_loss: 0.9064 - val_accuracy: 0.5413\n",
      "Epoch 1837/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8925 - accuracy: 0.5589 - val_loss: 0.9075 - val_accuracy: 0.5450\n",
      "Epoch 1838/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8923 - accuracy: 0.5610 - val_loss: 0.9087 - val_accuracy: 0.5473\n",
      "Epoch 1839/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8923 - accuracy: 0.5608 - val_loss: 0.9086 - val_accuracy: 0.5473\n",
      "Epoch 1840/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8922 - accuracy: 0.5590 - val_loss: 0.9059 - val_accuracy: 0.5453\n",
      "Epoch 1841/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8920 - accuracy: 0.5596 - val_loss: 0.9062 - val_accuracy: 0.5403\n",
      "Epoch 1842/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8922 - accuracy: 0.5590 - val_loss: 0.9074 - val_accuracy: 0.5427\n",
      "Epoch 1843/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8921 - accuracy: 0.5598 - val_loss: 0.9060 - val_accuracy: 0.5447\n",
      "Epoch 1844/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8924 - accuracy: 0.5594 - val_loss: 0.9066 - val_accuracy: 0.5430\n",
      "Epoch 1845/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8923 - accuracy: 0.5576 - val_loss: 0.9064 - val_accuracy: 0.5423\n",
      "Epoch 1846/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8921 - accuracy: 0.5596 - val_loss: 0.9065 - val_accuracy: 0.5413\n",
      "Epoch 1847/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8922 - accuracy: 0.5589 - val_loss: 0.9065 - val_accuracy: 0.5423\n",
      "Epoch 1848/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8921 - accuracy: 0.5588 - val_loss: 0.9058 - val_accuracy: 0.5413\n",
      "Epoch 1849/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8923 - accuracy: 0.5581 - val_loss: 0.9058 - val_accuracy: 0.5427\n",
      "Epoch 1850/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8922 - accuracy: 0.5580 - val_loss: 0.9063 - val_accuracy: 0.5400\n",
      "Epoch 1851/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8918 - accuracy: 0.5593 - val_loss: 0.9058 - val_accuracy: 0.5397\n",
      "Epoch 1852/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8920 - accuracy: 0.5596 - val_loss: 0.9060 - val_accuracy: 0.5427\n",
      "Epoch 1853/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8922 - accuracy: 0.5597 - val_loss: 0.9061 - val_accuracy: 0.5413\n",
      "Epoch 1854/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8920 - accuracy: 0.5617 - val_loss: 0.9063 - val_accuracy: 0.5427\n",
      "Epoch 1855/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8922 - accuracy: 0.5608 - val_loss: 0.9064 - val_accuracy: 0.5430\n",
      "Epoch 1856/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8922 - accuracy: 0.5594 - val_loss: 0.9058 - val_accuracy: 0.5417\n",
      "Epoch 1857/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8919 - accuracy: 0.5597 - val_loss: 0.9065 - val_accuracy: 0.5410\n",
      "Epoch 1858/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8922 - accuracy: 0.5601 - val_loss: 0.9071 - val_accuracy: 0.5443\n",
      "Epoch 1859/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8921 - accuracy: 0.5600 - val_loss: 0.9078 - val_accuracy: 0.5447\n",
      "Epoch 1860/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8921 - accuracy: 0.5595 - val_loss: 0.9062 - val_accuracy: 0.5403\n",
      "Epoch 1861/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8921 - accuracy: 0.5583 - val_loss: 0.9061 - val_accuracy: 0.5413\n",
      "Epoch 1862/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8920 - accuracy: 0.5607 - val_loss: 0.9068 - val_accuracy: 0.5430\n",
      "Epoch 1863/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8920 - accuracy: 0.5601 - val_loss: 0.9060 - val_accuracy: 0.5397\n",
      "Epoch 1864/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8920 - accuracy: 0.5579 - val_loss: 0.9074 - val_accuracy: 0.5453\n",
      "Epoch 1865/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8919 - accuracy: 0.5599 - val_loss: 0.9055 - val_accuracy: 0.5457\n",
      "Epoch 1866/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8921 - accuracy: 0.5594 - val_loss: 0.9062 - val_accuracy: 0.5413\n",
      "Epoch 1867/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8920 - accuracy: 0.5599 - val_loss: 0.9055 - val_accuracy: 0.5467\n",
      "Epoch 1868/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8920 - accuracy: 0.5591 - val_loss: 0.9104 - val_accuracy: 0.5470\n",
      "Epoch 1869/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8920 - accuracy: 0.5586 - val_loss: 0.9067 - val_accuracy: 0.5427\n",
      "Epoch 1870/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8918 - accuracy: 0.5586 - val_loss: 0.9057 - val_accuracy: 0.5430\n",
      "Epoch 1871/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8920 - accuracy: 0.5586 - val_loss: 0.9064 - val_accuracy: 0.5413\n",
      "Epoch 1872/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8915 - accuracy: 0.5601 - val_loss: 0.9057 - val_accuracy: 0.5447\n",
      "Epoch 1873/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8917 - accuracy: 0.5609 - val_loss: 0.9062 - val_accuracy: 0.5440\n",
      "Epoch 1874/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8921 - accuracy: 0.5574 - val_loss: 0.9057 - val_accuracy: 0.5417\n",
      "Epoch 1875/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8920 - accuracy: 0.5579 - val_loss: 0.9057 - val_accuracy: 0.5427\n",
      "Epoch 1876/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8920 - accuracy: 0.5591 - val_loss: 0.9057 - val_accuracy: 0.5423\n",
      "Epoch 1877/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8918 - accuracy: 0.5603 - val_loss: 0.9061 - val_accuracy: 0.5427\n",
      "Epoch 1878/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8916 - accuracy: 0.5599 - val_loss: 0.9068 - val_accuracy: 0.5440\n",
      "Epoch 1879/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8916 - accuracy: 0.5609 - val_loss: 0.9056 - val_accuracy: 0.5420\n",
      "Epoch 1880/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8919 - accuracy: 0.5593 - val_loss: 0.9058 - val_accuracy: 0.5417\n",
      "Epoch 1881/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8919 - accuracy: 0.5597 - val_loss: 0.9059 - val_accuracy: 0.5433\n",
      "Epoch 1882/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8916 - accuracy: 0.5579 - val_loss: 0.9075 - val_accuracy: 0.5443\n",
      "Epoch 1883/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8919 - accuracy: 0.5601 - val_loss: 0.9055 - val_accuracy: 0.5433\n",
      "Epoch 1884/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8916 - accuracy: 0.5606 - val_loss: 0.9057 - val_accuracy: 0.5413\n",
      "Epoch 1885/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8918 - accuracy: 0.5586 - val_loss: 0.9059 - val_accuracy: 0.5413\n",
      "Epoch 1886/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8918 - accuracy: 0.5604 - val_loss: 0.9059 - val_accuracy: 0.5410\n",
      "Epoch 1887/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8916 - accuracy: 0.5586 - val_loss: 0.9063 - val_accuracy: 0.5457\n",
      "Epoch 1888/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8917 - accuracy: 0.5612 - val_loss: 0.9055 - val_accuracy: 0.5423\n",
      "Epoch 1889/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8917 - accuracy: 0.5594 - val_loss: 0.9058 - val_accuracy: 0.5420\n",
      "Epoch 1890/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8917 - accuracy: 0.5598 - val_loss: 0.9054 - val_accuracy: 0.5460\n",
      "Epoch 1891/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8917 - accuracy: 0.5591 - val_loss: 0.9069 - val_accuracy: 0.5443\n",
      "Epoch 1892/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8919 - accuracy: 0.5606 - val_loss: 0.9057 - val_accuracy: 0.5400\n",
      "Epoch 1893/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8915 - accuracy: 0.5603 - val_loss: 0.9056 - val_accuracy: 0.5440\n",
      "Epoch 1894/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8916 - accuracy: 0.5586 - val_loss: 0.9064 - val_accuracy: 0.5423\n",
      "Epoch 1895/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.8917 - accuracy: 0.5596 - val_loss: 0.9074 - val_accuracy: 0.5440\n",
      "Epoch 1896/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.8917 - accuracy: 0.5591 - val_loss: 0.9054 - val_accuracy: 0.5433\n",
      "Epoch 1897/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8916 - accuracy: 0.5586 - val_loss: 0.9080 - val_accuracy: 0.5467\n",
      "Epoch 1898/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8916 - accuracy: 0.5589 - val_loss: 0.9057 - val_accuracy: 0.5427\n",
      "Epoch 1899/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8916 - accuracy: 0.5614 - val_loss: 0.9056 - val_accuracy: 0.5430\n",
      "Epoch 1900/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8915 - accuracy: 0.5596 - val_loss: 0.9069 - val_accuracy: 0.5430\n",
      "Epoch 1901/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8917 - accuracy: 0.5574 - val_loss: 0.9062 - val_accuracy: 0.5430\n",
      "Epoch 1902/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8916 - accuracy: 0.5596 - val_loss: 0.9072 - val_accuracy: 0.5437\n",
      "Epoch 1903/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8916 - accuracy: 0.5604 - val_loss: 0.9054 - val_accuracy: 0.5427\n",
      "Epoch 1904/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8917 - accuracy: 0.5609 - val_loss: 0.9056 - val_accuracy: 0.5420\n",
      "Epoch 1905/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8916 - accuracy: 0.5590 - val_loss: 0.9055 - val_accuracy: 0.5453\n",
      "Epoch 1906/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8914 - accuracy: 0.5574 - val_loss: 0.9063 - val_accuracy: 0.5417\n",
      "Epoch 1907/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8914 - accuracy: 0.5581 - val_loss: 0.9053 - val_accuracy: 0.5433\n",
      "Epoch 1908/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8916 - accuracy: 0.5593 - val_loss: 0.9059 - val_accuracy: 0.5433\n",
      "Epoch 1909/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8915 - accuracy: 0.5596 - val_loss: 0.9075 - val_accuracy: 0.5477\n",
      "Epoch 1910/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8914 - accuracy: 0.5603 - val_loss: 0.9052 - val_accuracy: 0.5443\n",
      "Epoch 1911/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8914 - accuracy: 0.5599 - val_loss: 0.9057 - val_accuracy: 0.5400\n",
      "Epoch 1912/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8916 - accuracy: 0.5602 - val_loss: 0.9058 - val_accuracy: 0.5403\n",
      "Epoch 1913/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8913 - accuracy: 0.5591 - val_loss: 0.9053 - val_accuracy: 0.5457\n",
      "Epoch 1914/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8916 - accuracy: 0.5618 - val_loss: 0.9057 - val_accuracy: 0.5413\n",
      "Epoch 1915/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8916 - accuracy: 0.5600 - val_loss: 0.9052 - val_accuracy: 0.5450\n",
      "Epoch 1916/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8911 - accuracy: 0.5608 - val_loss: 0.9143 - val_accuracy: 0.5423\n",
      "Epoch 1917/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8915 - accuracy: 0.5616 - val_loss: 0.9053 - val_accuracy: 0.5443\n",
      "Epoch 1918/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8911 - accuracy: 0.5594 - val_loss: 0.9080 - val_accuracy: 0.5470\n",
      "Epoch 1919/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8914 - accuracy: 0.5578 - val_loss: 0.9059 - val_accuracy: 0.5407\n",
      "Epoch 1920/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8915 - accuracy: 0.5601 - val_loss: 0.9060 - val_accuracy: 0.5417\n",
      "Epoch 1921/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8912 - accuracy: 0.5579 - val_loss: 0.9055 - val_accuracy: 0.5423\n",
      "Epoch 1922/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.8913 - accuracy: 0.5594 - val_loss: 0.9073 - val_accuracy: 0.5473\n",
      "Epoch 1923/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8914 - accuracy: 0.5601 - val_loss: 0.9058 - val_accuracy: 0.5397\n",
      "Epoch 1924/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8912 - accuracy: 0.5595 - val_loss: 0.9076 - val_accuracy: 0.5477\n",
      "Epoch 1925/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8911 - accuracy: 0.5603 - val_loss: 0.9062 - val_accuracy: 0.5423\n",
      "Epoch 1926/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8912 - accuracy: 0.5594 - val_loss: 0.9093 - val_accuracy: 0.5473\n",
      "Epoch 1927/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8911 - accuracy: 0.5595 - val_loss: 0.9058 - val_accuracy: 0.5410\n",
      "Epoch 1928/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8912 - accuracy: 0.5606 - val_loss: 0.9086 - val_accuracy: 0.5463\n",
      "Epoch 1929/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8913 - accuracy: 0.5576 - val_loss: 0.9052 - val_accuracy: 0.5450\n",
      "Epoch 1930/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8912 - accuracy: 0.5595 - val_loss: 0.9067 - val_accuracy: 0.5433\n",
      "Epoch 1931/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8908 - accuracy: 0.5611 - val_loss: 0.9053 - val_accuracy: 0.5433\n",
      "Epoch 1932/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8913 - accuracy: 0.5586 - val_loss: 0.9059 - val_accuracy: 0.5423\n",
      "Epoch 1933/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8912 - accuracy: 0.5595 - val_loss: 0.9051 - val_accuracy: 0.5457\n",
      "Epoch 1934/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8914 - accuracy: 0.5601 - val_loss: 0.9054 - val_accuracy: 0.5427\n",
      "Epoch 1935/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8911 - accuracy: 0.5599 - val_loss: 0.9061 - val_accuracy: 0.5417\n",
      "Epoch 1936/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8913 - accuracy: 0.5610 - val_loss: 0.9055 - val_accuracy: 0.5427\n",
      "Epoch 1937/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8913 - accuracy: 0.5601 - val_loss: 0.9062 - val_accuracy: 0.5423\n",
      "Epoch 1938/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8912 - accuracy: 0.5593 - val_loss: 0.9055 - val_accuracy: 0.5427\n",
      "Epoch 1939/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8913 - accuracy: 0.5595 - val_loss: 0.9073 - val_accuracy: 0.5460\n",
      "Epoch 1940/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8911 - accuracy: 0.5605 - val_loss: 0.9052 - val_accuracy: 0.5433\n",
      "Epoch 1941/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8910 - accuracy: 0.5583 - val_loss: 0.9052 - val_accuracy: 0.5460\n",
      "Epoch 1942/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8911 - accuracy: 0.5620 - val_loss: 0.9054 - val_accuracy: 0.5433\n",
      "Epoch 1943/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8911 - accuracy: 0.5608 - val_loss: 0.9055 - val_accuracy: 0.5427\n",
      "Epoch 1944/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8909 - accuracy: 0.5598 - val_loss: 0.9054 - val_accuracy: 0.5423\n",
      "Epoch 1945/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8908 - accuracy: 0.5613 - val_loss: 0.9089 - val_accuracy: 0.5487\n",
      "Epoch 1946/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8909 - accuracy: 0.5611 - val_loss: 0.9080 - val_accuracy: 0.5473\n",
      "Epoch 1947/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8911 - accuracy: 0.5595 - val_loss: 0.9054 - val_accuracy: 0.5427\n",
      "Epoch 1948/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8912 - accuracy: 0.5590 - val_loss: 0.9069 - val_accuracy: 0.5443\n",
      "Epoch 1949/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8913 - accuracy: 0.5596 - val_loss: 0.9052 - val_accuracy: 0.5430\n",
      "Epoch 1950/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8912 - accuracy: 0.5616 - val_loss: 0.9069 - val_accuracy: 0.5447\n",
      "Epoch 1951/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8909 - accuracy: 0.5594 - val_loss: 0.9051 - val_accuracy: 0.5443\n",
      "Epoch 1952/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8910 - accuracy: 0.5596 - val_loss: 0.9056 - val_accuracy: 0.5427\n",
      "Epoch 1953/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8909 - accuracy: 0.5566 - val_loss: 0.9055 - val_accuracy: 0.5410\n",
      "Epoch 1954/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8913 - accuracy: 0.5612 - val_loss: 0.9059 - val_accuracy: 0.5417\n",
      "Epoch 1955/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8910 - accuracy: 0.5613 - val_loss: 0.9053 - val_accuracy: 0.5433\n",
      "Epoch 1956/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8908 - accuracy: 0.5604 - val_loss: 0.9057 - val_accuracy: 0.5420\n",
      "Epoch 1957/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8910 - accuracy: 0.5609 - val_loss: 0.9051 - val_accuracy: 0.5447\n",
      "Epoch 1958/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8908 - accuracy: 0.5596 - val_loss: 0.9065 - val_accuracy: 0.5450\n",
      "Epoch 1959/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8909 - accuracy: 0.5622 - val_loss: 0.9080 - val_accuracy: 0.5473\n",
      "Epoch 1960/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8912 - accuracy: 0.5596 - val_loss: 0.9048 - val_accuracy: 0.5460\n",
      "Epoch 1961/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8908 - accuracy: 0.5608 - val_loss: 0.9059 - val_accuracy: 0.5440\n",
      "Epoch 1962/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8908 - accuracy: 0.5589 - val_loss: 0.9065 - val_accuracy: 0.5443\n",
      "Epoch 1963/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8909 - accuracy: 0.5594 - val_loss: 0.9089 - val_accuracy: 0.5487\n",
      "Epoch 1964/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8909 - accuracy: 0.5598 - val_loss: 0.9052 - val_accuracy: 0.5427\n",
      "Epoch 1965/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8910 - accuracy: 0.5613 - val_loss: 0.9059 - val_accuracy: 0.5413\n",
      "Epoch 1966/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8910 - accuracy: 0.5584 - val_loss: 0.9063 - val_accuracy: 0.5443\n",
      "Epoch 1967/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8908 - accuracy: 0.5588 - val_loss: 0.9048 - val_accuracy: 0.5440\n",
      "Epoch 1968/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8908 - accuracy: 0.5605 - val_loss: 0.9069 - val_accuracy: 0.5463\n",
      "Epoch 1969/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8908 - accuracy: 0.5618 - val_loss: 0.9070 - val_accuracy: 0.5457\n",
      "Epoch 1970/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8908 - accuracy: 0.5586 - val_loss: 0.9052 - val_accuracy: 0.5430\n",
      "Epoch 1971/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8904 - accuracy: 0.5616 - val_loss: 0.9060 - val_accuracy: 0.5480\n",
      "Epoch 1972/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8906 - accuracy: 0.5608 - val_loss: 0.9055 - val_accuracy: 0.5433\n",
      "Epoch 1973/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8907 - accuracy: 0.5616 - val_loss: 0.9053 - val_accuracy: 0.5417\n",
      "Epoch 1974/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8906 - accuracy: 0.5579 - val_loss: 0.9101 - val_accuracy: 0.5457\n",
      "Epoch 1975/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8907 - accuracy: 0.5615 - val_loss: 0.9066 - val_accuracy: 0.5450\n",
      "Epoch 1976/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8906 - accuracy: 0.5610 - val_loss: 0.9055 - val_accuracy: 0.5433\n",
      "Epoch 1977/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8904 - accuracy: 0.5606 - val_loss: 0.9072 - val_accuracy: 0.5477\n",
      "Epoch 1978/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8906 - accuracy: 0.5613 - val_loss: 0.9049 - val_accuracy: 0.5437\n",
      "Epoch 1979/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8910 - accuracy: 0.5593 - val_loss: 0.9051 - val_accuracy: 0.5437\n",
      "Epoch 1980/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8905 - accuracy: 0.5602 - val_loss: 0.9052 - val_accuracy: 0.5407\n",
      "Epoch 1981/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8905 - accuracy: 0.5638 - val_loss: 0.9051 - val_accuracy: 0.5433\n",
      "Epoch 1982/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8905 - accuracy: 0.5614 - val_loss: 0.9084 - val_accuracy: 0.5490\n",
      "Epoch 1983/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8905 - accuracy: 0.5616 - val_loss: 0.9059 - val_accuracy: 0.5440\n",
      "Epoch 1984/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8906 - accuracy: 0.5607 - val_loss: 0.9066 - val_accuracy: 0.5470\n",
      "Epoch 1985/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8905 - accuracy: 0.5596 - val_loss: 0.9064 - val_accuracy: 0.5443\n",
      "Epoch 1986/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8909 - accuracy: 0.5606 - val_loss: 0.9056 - val_accuracy: 0.5443\n",
      "Epoch 1987/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8905 - accuracy: 0.5611 - val_loss: 0.9049 - val_accuracy: 0.5440\n",
      "Epoch 1988/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8907 - accuracy: 0.5596 - val_loss: 0.9048 - val_accuracy: 0.5447\n",
      "Epoch 1989/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8908 - accuracy: 0.5604 - val_loss: 0.9054 - val_accuracy: 0.5427\n",
      "Epoch 1990/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8907 - accuracy: 0.5602 - val_loss: 0.9056 - val_accuracy: 0.5440\n",
      "Epoch 1991/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8906 - accuracy: 0.5614 - val_loss: 0.9055 - val_accuracy: 0.5433\n",
      "Epoch 1992/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8905 - accuracy: 0.5611 - val_loss: 0.9083 - val_accuracy: 0.5493\n",
      "Epoch 1993/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8903 - accuracy: 0.5601 - val_loss: 0.9048 - val_accuracy: 0.5447\n",
      "Epoch 1994/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8906 - accuracy: 0.5609 - val_loss: 0.9068 - val_accuracy: 0.5457\n",
      "Epoch 1995/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8903 - accuracy: 0.5609 - val_loss: 0.9054 - val_accuracy: 0.5440\n",
      "Epoch 1996/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8906 - accuracy: 0.5621 - val_loss: 0.9056 - val_accuracy: 0.5427\n",
      "Epoch 1997/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8905 - accuracy: 0.5599 - val_loss: 0.9057 - val_accuracy: 0.5440\n",
      "Epoch 1998/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8905 - accuracy: 0.5609 - val_loss: 0.9051 - val_accuracy: 0.5443\n",
      "Epoch 1999/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 36us/step - loss: 0.8904 - accuracy: 0.5591 - val_loss: 0.9048 - val_accuracy: 0.5447\n",
      "Epoch 2000/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8905 - accuracy: 0.5616 - val_loss: 0.9053 - val_accuracy: 0.5430\n",
      "Epoch 2001/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8901 - accuracy: 0.5621 - val_loss: 0.9097 - val_accuracy: 0.5453\n",
      "Epoch 2002/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8906 - accuracy: 0.5598 - val_loss: 0.9052 - val_accuracy: 0.5437\n",
      "Epoch 2003/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8903 - accuracy: 0.5617 - val_loss: 0.9071 - val_accuracy: 0.5467\n",
      "Epoch 2004/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8902 - accuracy: 0.5602 - val_loss: 0.9062 - val_accuracy: 0.5453\n",
      "Epoch 2005/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8907 - accuracy: 0.5601 - val_loss: 0.9050 - val_accuracy: 0.5427\n",
      "Epoch 2006/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8906 - accuracy: 0.5622 - val_loss: 0.9054 - val_accuracy: 0.5447\n",
      "Epoch 2007/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8904 - accuracy: 0.5608 - val_loss: 0.9060 - val_accuracy: 0.5460\n",
      "Epoch 2008/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8904 - accuracy: 0.5608 - val_loss: 0.9057 - val_accuracy: 0.5470\n",
      "Epoch 2009/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8905 - accuracy: 0.5606 - val_loss: 0.9048 - val_accuracy: 0.5423\n",
      "Epoch 2010/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8905 - accuracy: 0.5605 - val_loss: 0.9059 - val_accuracy: 0.5440\n",
      "Epoch 2011/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8903 - accuracy: 0.5635 - val_loss: 0.9047 - val_accuracy: 0.5457\n",
      "Epoch 2012/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8904 - accuracy: 0.5629 - val_loss: 0.9047 - val_accuracy: 0.5453\n",
      "Epoch 2013/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8900 - accuracy: 0.5612 - val_loss: 0.9045 - val_accuracy: 0.5467\n",
      "Epoch 2014/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8903 - accuracy: 0.5619 - val_loss: 0.9082 - val_accuracy: 0.5487\n",
      "Epoch 2015/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8903 - accuracy: 0.5612 - val_loss: 0.9064 - val_accuracy: 0.5460\n",
      "Epoch 2016/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8901 - accuracy: 0.5616 - val_loss: 0.9085 - val_accuracy: 0.5463\n",
      "Epoch 2017/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8902 - accuracy: 0.5606 - val_loss: 0.9046 - val_accuracy: 0.5460\n",
      "Epoch 2018/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8903 - accuracy: 0.5585 - val_loss: 0.9069 - val_accuracy: 0.5460\n",
      "Epoch 2019/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8904 - accuracy: 0.5610 - val_loss: 0.9065 - val_accuracy: 0.5457\n",
      "Epoch 2020/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8902 - accuracy: 0.5622 - val_loss: 0.9048 - val_accuracy: 0.5453\n",
      "Epoch 2021/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8900 - accuracy: 0.5605 - val_loss: 0.9086 - val_accuracy: 0.5497\n",
      "Epoch 2022/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8901 - accuracy: 0.5608 - val_loss: 0.9106 - val_accuracy: 0.5470\n",
      "Epoch 2023/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8900 - accuracy: 0.5609 - val_loss: 0.9053 - val_accuracy: 0.5430\n",
      "Epoch 2024/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8901 - accuracy: 0.5606 - val_loss: 0.9051 - val_accuracy: 0.5430\n",
      "Epoch 2025/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8902 - accuracy: 0.5605 - val_loss: 0.9059 - val_accuracy: 0.5450\n",
      "Epoch 2026/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8902 - accuracy: 0.5626 - val_loss: 0.9111 - val_accuracy: 0.5447\n",
      "Epoch 2027/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8900 - accuracy: 0.5594 - val_loss: 0.9117 - val_accuracy: 0.5433\n",
      "Epoch 2028/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8903 - accuracy: 0.5609 - val_loss: 0.9050 - val_accuracy: 0.5440\n",
      "Epoch 2029/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8903 - accuracy: 0.5626 - val_loss: 0.9056 - val_accuracy: 0.5437\n",
      "Epoch 2030/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8901 - accuracy: 0.5605 - val_loss: 0.9049 - val_accuracy: 0.5437\n",
      "Epoch 2031/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8904 - accuracy: 0.5592 - val_loss: 0.9047 - val_accuracy: 0.5430\n",
      "Epoch 2032/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8901 - accuracy: 0.5613 - val_loss: 0.9045 - val_accuracy: 0.5457\n",
      "Epoch 2033/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8901 - accuracy: 0.5593 - val_loss: 0.9046 - val_accuracy: 0.5457\n",
      "Epoch 2034/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8900 - accuracy: 0.5608 - val_loss: 0.9075 - val_accuracy: 0.5470\n",
      "Epoch 2035/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8902 - accuracy: 0.5583 - val_loss: 0.9045 - val_accuracy: 0.5470\n",
      "Epoch 2036/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8900 - accuracy: 0.5602 - val_loss: 0.9046 - val_accuracy: 0.5477\n",
      "Epoch 2037/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8896 - accuracy: 0.5606 - val_loss: 0.9061 - val_accuracy: 0.5440\n",
      "Epoch 2038/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8900 - accuracy: 0.5585 - val_loss: 0.9046 - val_accuracy: 0.5460\n",
      "Epoch 2039/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8897 - accuracy: 0.5626 - val_loss: 0.9109 - val_accuracy: 0.5457\n",
      "Epoch 2040/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8899 - accuracy: 0.5601 - val_loss: 0.9056 - val_accuracy: 0.5457\n",
      "Epoch 2041/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8901 - accuracy: 0.5609 - val_loss: 0.9050 - val_accuracy: 0.5430\n",
      "Epoch 2042/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8898 - accuracy: 0.5624 - val_loss: 0.9048 - val_accuracy: 0.5450\n",
      "Epoch 2043/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8902 - accuracy: 0.5624 - val_loss: 0.9044 - val_accuracy: 0.5470\n",
      "Epoch 2044/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8901 - accuracy: 0.5614 - val_loss: 0.9069 - val_accuracy: 0.5467\n",
      "Epoch 2045/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8897 - accuracy: 0.5607 - val_loss: 0.9103 - val_accuracy: 0.5467\n",
      "Epoch 2046/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8901 - accuracy: 0.5613 - val_loss: 0.9052 - val_accuracy: 0.5430\n",
      "Epoch 2047/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8900 - accuracy: 0.5618 - val_loss: 0.9050 - val_accuracy: 0.5447\n",
      "Epoch 2048/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8900 - accuracy: 0.5606 - val_loss: 0.9045 - val_accuracy: 0.5463\n",
      "Epoch 2049/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8900 - accuracy: 0.5615 - val_loss: 0.9050 - val_accuracy: 0.5440\n",
      "Epoch 2050/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8897 - accuracy: 0.5608 - val_loss: 0.9054 - val_accuracy: 0.5480\n",
      "Epoch 2051/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8897 - accuracy: 0.5606 - val_loss: 0.9065 - val_accuracy: 0.5453\n",
      "Epoch 2052/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8898 - accuracy: 0.5599 - val_loss: 0.9046 - val_accuracy: 0.5440\n",
      "Epoch 2053/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8898 - accuracy: 0.5600 - val_loss: 0.9052 - val_accuracy: 0.5450\n",
      "Epoch 2054/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8897 - accuracy: 0.5621 - val_loss: 0.9062 - val_accuracy: 0.5463\n",
      "Epoch 2055/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8897 - accuracy: 0.5626 - val_loss: 0.9113 - val_accuracy: 0.5463\n",
      "Epoch 2056/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8897 - accuracy: 0.5619 - val_loss: 0.9059 - val_accuracy: 0.5453\n",
      "Epoch 2057/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8897 - accuracy: 0.5632 - val_loss: 0.9049 - val_accuracy: 0.5463\n",
      "Epoch 2058/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8897 - accuracy: 0.5616 - val_loss: 0.9072 - val_accuracy: 0.5467\n",
      "Epoch 2059/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8896 - accuracy: 0.5603 - val_loss: 0.9104 - val_accuracy: 0.5453\n",
      "Epoch 2060/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8896 - accuracy: 0.5611 - val_loss: 0.9059 - val_accuracy: 0.5473\n",
      "Epoch 2061/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8899 - accuracy: 0.5620 - val_loss: 0.9061 - val_accuracy: 0.5457\n",
      "Epoch 2062/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8896 - accuracy: 0.5621 - val_loss: 0.9043 - val_accuracy: 0.5457\n",
      "Epoch 2063/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8893 - accuracy: 0.5595 - val_loss: 0.9081 - val_accuracy: 0.5483\n",
      "Epoch 2064/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8896 - accuracy: 0.5597 - val_loss: 0.9075 - val_accuracy: 0.5467\n",
      "Epoch 2065/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8898 - accuracy: 0.5610 - val_loss: 0.9068 - val_accuracy: 0.5490\n",
      "Epoch 2066/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8899 - accuracy: 0.5605 - val_loss: 0.9046 - val_accuracy: 0.5440\n",
      "Epoch 2067/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8896 - accuracy: 0.5616 - val_loss: 0.9049 - val_accuracy: 0.5430\n",
      "Epoch 2068/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8898 - accuracy: 0.5624 - val_loss: 0.9089 - val_accuracy: 0.5483\n",
      "Epoch 2069/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8898 - accuracy: 0.5604 - val_loss: 0.9044 - val_accuracy: 0.5443\n",
      "Epoch 2070/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8898 - accuracy: 0.5606 - val_loss: 0.9054 - val_accuracy: 0.5463\n",
      "Epoch 2071/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8898 - accuracy: 0.5604 - val_loss: 0.9066 - val_accuracy: 0.5453\n",
      "Epoch 2072/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8897 - accuracy: 0.5594 - val_loss: 0.9047 - val_accuracy: 0.5473\n",
      "Epoch 2073/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8898 - accuracy: 0.5604 - val_loss: 0.9043 - val_accuracy: 0.5460\n",
      "Epoch 2074/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8896 - accuracy: 0.5617 - val_loss: 0.9075 - val_accuracy: 0.5487\n",
      "Epoch 2075/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8896 - accuracy: 0.5613 - val_loss: 0.9056 - val_accuracy: 0.5480\n",
      "Epoch 2076/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8895 - accuracy: 0.5622 - val_loss: 0.9046 - val_accuracy: 0.5437\n",
      "Epoch 2077/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8898 - accuracy: 0.5635 - val_loss: 0.9056 - val_accuracy: 0.5470\n",
      "Epoch 2078/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8895 - accuracy: 0.5608 - val_loss: 0.9092 - val_accuracy: 0.5490\n",
      "Epoch 2079/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8898 - accuracy: 0.5614 - val_loss: 0.9042 - val_accuracy: 0.5447\n",
      "Epoch 2080/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8894 - accuracy: 0.5633 - val_loss: 0.9053 - val_accuracy: 0.5450\n",
      "Epoch 2081/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8895 - accuracy: 0.5612 - val_loss: 0.9044 - val_accuracy: 0.5460\n",
      "Epoch 2082/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8897 - accuracy: 0.5609 - val_loss: 0.9052 - val_accuracy: 0.5430\n",
      "Epoch 2083/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8897 - accuracy: 0.5603 - val_loss: 0.9042 - val_accuracy: 0.5470\n",
      "Epoch 2084/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8896 - accuracy: 0.5630 - val_loss: 0.9093 - val_accuracy: 0.5477\n",
      "Epoch 2085/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8894 - accuracy: 0.5606 - val_loss: 0.9080 - val_accuracy: 0.5477\n",
      "Epoch 2086/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8892 - accuracy: 0.5611 - val_loss: 0.9061 - val_accuracy: 0.5463\n",
      "Epoch 2087/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8894 - accuracy: 0.5623 - val_loss: 0.9044 - val_accuracy: 0.5463\n",
      "Epoch 2088/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8895 - accuracy: 0.5625 - val_loss: 0.9056 - val_accuracy: 0.5447\n",
      "Epoch 2089/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8894 - accuracy: 0.5612 - val_loss: 0.9049 - val_accuracy: 0.5480\n",
      "Epoch 2090/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8892 - accuracy: 0.5610 - val_loss: 0.9046 - val_accuracy: 0.5473\n",
      "Epoch 2091/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8894 - accuracy: 0.5601 - val_loss: 0.9071 - val_accuracy: 0.5453\n",
      "Epoch 2092/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8891 - accuracy: 0.5623 - val_loss: 0.9047 - val_accuracy: 0.5467\n",
      "Epoch 2093/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8892 - accuracy: 0.5619 - val_loss: 0.9062 - val_accuracy: 0.5463\n",
      "Epoch 2094/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8893 - accuracy: 0.5606 - val_loss: 0.9046 - val_accuracy: 0.5433\n",
      "Epoch 2095/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8893 - accuracy: 0.5632 - val_loss: 0.9042 - val_accuracy: 0.5443\n",
      "Epoch 2096/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8890 - accuracy: 0.5617 - val_loss: 0.9073 - val_accuracy: 0.5453\n",
      "Epoch 2097/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8891 - accuracy: 0.5626 - val_loss: 0.9079 - val_accuracy: 0.5477\n",
      "Epoch 2098/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8892 - accuracy: 0.5632 - val_loss: 0.9098 - val_accuracy: 0.5457\n",
      "Epoch 2099/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8895 - accuracy: 0.5630 - val_loss: 0.9044 - val_accuracy: 0.5447\n",
      "Epoch 2100/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8892 - accuracy: 0.5596 - val_loss: 0.9043 - val_accuracy: 0.5457\n",
      "Epoch 2101/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8893 - accuracy: 0.5608 - val_loss: 0.9059 - val_accuracy: 0.5467\n",
      "Epoch 2102/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8892 - accuracy: 0.5594 - val_loss: 0.9041 - val_accuracy: 0.5470\n",
      "Epoch 2103/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8892 - accuracy: 0.5616 - val_loss: 0.9052 - val_accuracy: 0.5490\n",
      "Epoch 2104/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8888 - accuracy: 0.5639 - val_loss: 0.9042 - val_accuracy: 0.5447\n",
      "Epoch 2105/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8891 - accuracy: 0.5606 - val_loss: 0.9039 - val_accuracy: 0.5457\n",
      "Epoch 2106/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8892 - accuracy: 0.5614 - val_loss: 0.9039 - val_accuracy: 0.5463\n",
      "Epoch 2107/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8894 - accuracy: 0.5611 - val_loss: 0.9042 - val_accuracy: 0.5443\n",
      "Epoch 2108/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8887 - accuracy: 0.5631 - val_loss: 0.9040 - val_accuracy: 0.5497\n",
      "Epoch 2109/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8892 - accuracy: 0.5598 - val_loss: 0.9047 - val_accuracy: 0.5493\n",
      "Epoch 2110/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8891 - accuracy: 0.5636 - val_loss: 0.9040 - val_accuracy: 0.5453\n",
      "Epoch 2111/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8893 - accuracy: 0.5620 - val_loss: 0.9039 - val_accuracy: 0.5490\n",
      "Epoch 2112/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8890 - accuracy: 0.5595 - val_loss: 0.9051 - val_accuracy: 0.5463\n",
      "Epoch 2113/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8891 - accuracy: 0.5609 - val_loss: 0.9047 - val_accuracy: 0.5470\n",
      "Epoch 2114/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8889 - accuracy: 0.5625 - val_loss: 0.9041 - val_accuracy: 0.5463\n",
      "Epoch 2115/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8890 - accuracy: 0.5614 - val_loss: 0.9052 - val_accuracy: 0.5470\n",
      "Epoch 2116/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8893 - accuracy: 0.5615 - val_loss: 0.9042 - val_accuracy: 0.5447\n",
      "Epoch 2117/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8890 - accuracy: 0.5617 - val_loss: 0.9050 - val_accuracy: 0.5457\n",
      "Epoch 2118/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8889 - accuracy: 0.5616 - val_loss: 0.9070 - val_accuracy: 0.5473\n",
      "Epoch 2119/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8890 - accuracy: 0.5639 - val_loss: 0.9042 - val_accuracy: 0.5460\n",
      "Epoch 2120/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8890 - accuracy: 0.5608 - val_loss: 0.9040 - val_accuracy: 0.5490\n",
      "Epoch 2121/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8887 - accuracy: 0.5654 - val_loss: 0.9111 - val_accuracy: 0.5453\n",
      "Epoch 2122/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8890 - accuracy: 0.5631 - val_loss: 0.9040 - val_accuracy: 0.5483\n",
      "Epoch 2123/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8893 - accuracy: 0.5603 - val_loss: 0.9043 - val_accuracy: 0.5450\n",
      "Epoch 2124/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8889 - accuracy: 0.5608 - val_loss: 0.9039 - val_accuracy: 0.5477\n",
      "Epoch 2125/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8888 - accuracy: 0.5615 - val_loss: 0.9042 - val_accuracy: 0.5457\n",
      "Epoch 2126/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8889 - accuracy: 0.5592 - val_loss: 0.9046 - val_accuracy: 0.5473\n",
      "Epoch 2127/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8889 - accuracy: 0.5609 - val_loss: 0.9044 - val_accuracy: 0.5457\n",
      "Epoch 2128/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8890 - accuracy: 0.5611 - val_loss: 0.9045 - val_accuracy: 0.5487\n",
      "Epoch 2129/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8889 - accuracy: 0.5607 - val_loss: 0.9039 - val_accuracy: 0.5477\n",
      "Epoch 2130/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8888 - accuracy: 0.5631 - val_loss: 0.9037 - val_accuracy: 0.5463\n",
      "Epoch 2131/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8887 - accuracy: 0.5609 - val_loss: 0.9070 - val_accuracy: 0.5477\n",
      "Epoch 2132/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8889 - accuracy: 0.5614 - val_loss: 0.9058 - val_accuracy: 0.5460\n",
      "Epoch 2133/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8887 - accuracy: 0.5622 - val_loss: 0.9056 - val_accuracy: 0.5477\n",
      "Epoch 2134/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8886 - accuracy: 0.5621 - val_loss: 0.9037 - val_accuracy: 0.5480\n",
      "Epoch 2135/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8887 - accuracy: 0.5629 - val_loss: 0.9052 - val_accuracy: 0.5473\n",
      "Epoch 2136/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8889 - accuracy: 0.5614 - val_loss: 0.9040 - val_accuracy: 0.5460\n",
      "Epoch 2137/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8888 - accuracy: 0.5618 - val_loss: 0.9038 - val_accuracy: 0.5487\n",
      "Epoch 2138/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8885 - accuracy: 0.5629 - val_loss: 0.9113 - val_accuracy: 0.5483\n",
      "Epoch 2139/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8891 - accuracy: 0.5629 - val_loss: 0.9041 - val_accuracy: 0.5423\n",
      "Epoch 2140/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8886 - accuracy: 0.5649 - val_loss: 0.9039 - val_accuracy: 0.5453\n",
      "Epoch 2141/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8888 - accuracy: 0.5646 - val_loss: 0.9038 - val_accuracy: 0.5457\n",
      "Epoch 2142/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8885 - accuracy: 0.5624 - val_loss: 0.9068 - val_accuracy: 0.5467\n",
      "Epoch 2143/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8886 - accuracy: 0.5635 - val_loss: 0.9085 - val_accuracy: 0.5480\n",
      "Epoch 2144/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8886 - accuracy: 0.5622 - val_loss: 0.9037 - val_accuracy: 0.5490\n",
      "Epoch 2145/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8888 - accuracy: 0.5616 - val_loss: 0.9073 - val_accuracy: 0.5480\n",
      "Epoch 2146/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8885 - accuracy: 0.5614 - val_loss: 0.9039 - val_accuracy: 0.5453\n",
      "Epoch 2147/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8887 - accuracy: 0.5604 - val_loss: 0.9039 - val_accuracy: 0.5450\n",
      "Epoch 2148/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8885 - accuracy: 0.5619 - val_loss: 0.9040 - val_accuracy: 0.5460\n",
      "Epoch 2149/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8884 - accuracy: 0.5631 - val_loss: 0.9081 - val_accuracy: 0.5477\n",
      "Epoch 2150/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8886 - accuracy: 0.5636 - val_loss: 0.9040 - val_accuracy: 0.5447\n",
      "Epoch 2151/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8885 - accuracy: 0.5624 - val_loss: 0.9052 - val_accuracy: 0.5470\n",
      "Epoch 2152/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8885 - accuracy: 0.5632 - val_loss: 0.9038 - val_accuracy: 0.5463\n",
      "Epoch 2153/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8885 - accuracy: 0.5636 - val_loss: 0.9053 - val_accuracy: 0.5473\n",
      "Epoch 2154/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8886 - accuracy: 0.5616 - val_loss: 0.9069 - val_accuracy: 0.5483\n",
      "Epoch 2155/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8882 - accuracy: 0.5608 - val_loss: 0.9039 - val_accuracy: 0.5463\n",
      "Epoch 2156/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8886 - accuracy: 0.5623 - val_loss: 0.9047 - val_accuracy: 0.5460\n",
      "Epoch 2157/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8886 - accuracy: 0.5631 - val_loss: 0.9038 - val_accuracy: 0.5477\n",
      "Epoch 2158/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8887 - accuracy: 0.5610 - val_loss: 0.9049 - val_accuracy: 0.5480\n",
      "Epoch 2159/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8885 - accuracy: 0.5631 - val_loss: 0.9045 - val_accuracy: 0.5447\n",
      "Epoch 2160/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8885 - accuracy: 0.5629 - val_loss: 0.9039 - val_accuracy: 0.5453\n",
      "Epoch 2161/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8884 - accuracy: 0.5617 - val_loss: 0.9036 - val_accuracy: 0.5463\n",
      "Epoch 2162/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.8887 - accuracy: 0.5614 - val_loss: 0.9046 - val_accuracy: 0.5463\n",
      "Epoch 2163/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.8887 - accuracy: 0.5608 - val_loss: 0.9068 - val_accuracy: 0.5493\n",
      "Epoch 2164/5500\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.8882 - accuracy: 0.5593 - val_loss: 0.9058 - val_accuracy: 0.5467\n",
      "Epoch 2165/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8885 - accuracy: 0.5643 - val_loss: 0.9036 - val_accuracy: 0.5470\n",
      "Epoch 2166/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8879 - accuracy: 0.5635 - val_loss: 0.9111 - val_accuracy: 0.5507\n",
      "Epoch 2167/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8880 - accuracy: 0.5635 - val_loss: 0.9036 - val_accuracy: 0.5457\n",
      "Epoch 2168/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8884 - accuracy: 0.5627 - val_loss: 0.9043 - val_accuracy: 0.5463\n",
      "Epoch 2169/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8883 - accuracy: 0.5624 - val_loss: 0.9043 - val_accuracy: 0.5463\n",
      "Epoch 2170/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8884 - accuracy: 0.5616 - val_loss: 0.9038 - val_accuracy: 0.5467\n",
      "Epoch 2171/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8884 - accuracy: 0.5605 - val_loss: 0.9058 - val_accuracy: 0.5477\n",
      "Epoch 2172/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8885 - accuracy: 0.5630 - val_loss: 0.9109 - val_accuracy: 0.5450\n",
      "Epoch 2173/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8880 - accuracy: 0.5598 - val_loss: 0.9040 - val_accuracy: 0.5457\n",
      "Epoch 2174/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8886 - accuracy: 0.5638 - val_loss: 0.9045 - val_accuracy: 0.5473\n",
      "Epoch 2175/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8883 - accuracy: 0.5631 - val_loss: 0.9050 - val_accuracy: 0.5507\n",
      "Epoch 2176/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8885 - accuracy: 0.5616 - val_loss: 0.9038 - val_accuracy: 0.5477\n",
      "Epoch 2177/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8879 - accuracy: 0.5631 - val_loss: 0.9045 - val_accuracy: 0.5463\n",
      "Epoch 2178/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8882 - accuracy: 0.5616 - val_loss: 0.9037 - val_accuracy: 0.5473\n",
      "Epoch 2179/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8883 - accuracy: 0.5610 - val_loss: 0.9079 - val_accuracy: 0.5490\n",
      "Epoch 2180/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8884 - accuracy: 0.5613 - val_loss: 0.9070 - val_accuracy: 0.5477\n",
      "Epoch 2181/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8878 - accuracy: 0.5634 - val_loss: 0.9059 - val_accuracy: 0.5500\n",
      "Epoch 2182/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8883 - accuracy: 0.5631 - val_loss: 0.9052 - val_accuracy: 0.5473\n",
      "Epoch 2183/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8881 - accuracy: 0.5628 - val_loss: 0.9037 - val_accuracy: 0.5480\n",
      "Epoch 2184/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8880 - accuracy: 0.5607 - val_loss: 0.9036 - val_accuracy: 0.5463\n",
      "Epoch 2185/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8881 - accuracy: 0.5628 - val_loss: 0.9043 - val_accuracy: 0.5463\n",
      "Epoch 2186/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8880 - accuracy: 0.5624 - val_loss: 0.9056 - val_accuracy: 0.5490\n",
      "Epoch 2187/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8881 - accuracy: 0.5614 - val_loss: 0.9036 - val_accuracy: 0.5483\n",
      "Epoch 2188/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5603 - val_loss: 0.9038 - val_accuracy: 0.5483\n",
      "Epoch 2189/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8882 - accuracy: 0.5618 - val_loss: 0.9044 - val_accuracy: 0.5477\n",
      "Epoch 2190/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8882 - accuracy: 0.5601 - val_loss: 0.9042 - val_accuracy: 0.5497\n",
      "Epoch 2191/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5616 - val_loss: 0.9066 - val_accuracy: 0.5503\n",
      "Epoch 2192/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8883 - accuracy: 0.5618 - val_loss: 0.9040 - val_accuracy: 0.5463\n",
      "Epoch 2193/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5616 - val_loss: 0.9055 - val_accuracy: 0.5487\n",
      "Epoch 2194/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8884 - accuracy: 0.5611 - val_loss: 0.9033 - val_accuracy: 0.5500\n",
      "Epoch 2195/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5614 - val_loss: 0.9050 - val_accuracy: 0.5493\n",
      "Epoch 2196/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5629 - val_loss: 0.9036 - val_accuracy: 0.5457\n",
      "Epoch 2197/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8880 - accuracy: 0.5631 - val_loss: 0.9037 - val_accuracy: 0.5463\n",
      "Epoch 2198/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8881 - accuracy: 0.5623 - val_loss: 0.9046 - val_accuracy: 0.5463\n",
      "Epoch 2199/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8880 - accuracy: 0.5632 - val_loss: 0.9057 - val_accuracy: 0.5497\n",
      "Epoch 2200/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8878 - accuracy: 0.5627 - val_loss: 0.9059 - val_accuracy: 0.5503\n",
      "Epoch 2201/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8883 - accuracy: 0.5624 - val_loss: 0.9033 - val_accuracy: 0.5497\n",
      "Epoch 2202/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8882 - accuracy: 0.5595 - val_loss: 0.9051 - val_accuracy: 0.5493\n",
      "Epoch 2203/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8877 - accuracy: 0.5641 - val_loss: 0.9040 - val_accuracy: 0.5460\n",
      "Epoch 2204/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5603 - val_loss: 0.9033 - val_accuracy: 0.5490\n",
      "Epoch 2205/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8879 - accuracy: 0.5618 - val_loss: 0.9085 - val_accuracy: 0.5463\n",
      "Epoch 2206/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8879 - accuracy: 0.5644 - val_loss: 0.9043 - val_accuracy: 0.5497\n",
      "Epoch 2207/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8880 - accuracy: 0.5612 - val_loss: 0.9039 - val_accuracy: 0.5473\n",
      "Epoch 2208/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8878 - accuracy: 0.5606 - val_loss: 0.9039 - val_accuracy: 0.5460\n",
      "Epoch 2209/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8881 - accuracy: 0.5637 - val_loss: 0.9055 - val_accuracy: 0.5473\n",
      "Epoch 2210/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8880 - accuracy: 0.5628 - val_loss: 0.9033 - val_accuracy: 0.5463\n",
      "Epoch 2211/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8875 - accuracy: 0.5598 - val_loss: 0.9036 - val_accuracy: 0.5487\n",
      "Epoch 2212/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5609 - val_loss: 0.9048 - val_accuracy: 0.5473\n",
      "Epoch 2213/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8879 - accuracy: 0.5646 - val_loss: 0.9060 - val_accuracy: 0.5500\n",
      "Epoch 2214/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8881 - accuracy: 0.5612 - val_loss: 0.9041 - val_accuracy: 0.5493\n",
      "Epoch 2215/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8878 - accuracy: 0.5639 - val_loss: 0.9035 - val_accuracy: 0.5453\n",
      "Epoch 2216/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8880 - accuracy: 0.5589 - val_loss: 0.9041 - val_accuracy: 0.5460\n",
      "Epoch 2217/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8878 - accuracy: 0.5630 - val_loss: 0.9047 - val_accuracy: 0.5507\n",
      "Epoch 2218/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8876 - accuracy: 0.5624 - val_loss: 0.9041 - val_accuracy: 0.5463\n",
      "Epoch 2219/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8878 - accuracy: 0.5605 - val_loss: 0.9039 - val_accuracy: 0.5503\n",
      "Epoch 2220/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8877 - accuracy: 0.5602 - val_loss: 0.9049 - val_accuracy: 0.5477\n",
      "Epoch 2221/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8873 - accuracy: 0.5615 - val_loss: 0.9032 - val_accuracy: 0.5473\n",
      "Epoch 2222/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8877 - accuracy: 0.5623 - val_loss: 0.9048 - val_accuracy: 0.5467\n",
      "Epoch 2223/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8875 - accuracy: 0.5618 - val_loss: 0.9040 - val_accuracy: 0.5450\n",
      "Epoch 2224/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8878 - accuracy: 0.5641 - val_loss: 0.9043 - val_accuracy: 0.5477\n",
      "Epoch 2225/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8878 - accuracy: 0.5626 - val_loss: 0.9038 - val_accuracy: 0.5470\n",
      "Epoch 2226/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8879 - accuracy: 0.5637 - val_loss: 0.9062 - val_accuracy: 0.5493\n",
      "Epoch 2227/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8877 - accuracy: 0.5612 - val_loss: 0.9049 - val_accuracy: 0.5490\n",
      "Epoch 2228/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8875 - accuracy: 0.5627 - val_loss: 0.9072 - val_accuracy: 0.5490\n",
      "Epoch 2229/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8876 - accuracy: 0.5629 - val_loss: 0.9044 - val_accuracy: 0.5490\n",
      "Epoch 2230/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8876 - accuracy: 0.5630 - val_loss: 0.9041 - val_accuracy: 0.5507\n",
      "Epoch 2231/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8877 - accuracy: 0.5613 - val_loss: 0.9052 - val_accuracy: 0.5490\n",
      "Epoch 2232/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8878 - accuracy: 0.5620 - val_loss: 0.9035 - val_accuracy: 0.5473\n",
      "Epoch 2233/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8878 - accuracy: 0.5634 - val_loss: 0.9047 - val_accuracy: 0.5477\n",
      "Epoch 2234/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8875 - accuracy: 0.5621 - val_loss: 0.9048 - val_accuracy: 0.5457\n",
      "Epoch 2235/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8872 - accuracy: 0.5650 - val_loss: 0.9039 - val_accuracy: 0.5480\n",
      "Epoch 2236/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8877 - accuracy: 0.5621 - val_loss: 0.9099 - val_accuracy: 0.5493\n",
      "Epoch 2237/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8875 - accuracy: 0.5622 - val_loss: 0.9051 - val_accuracy: 0.5493\n",
      "Epoch 2238/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8877 - accuracy: 0.5661 - val_loss: 0.9031 - val_accuracy: 0.5487\n",
      "Epoch 2239/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8876 - accuracy: 0.5649 - val_loss: 0.9043 - val_accuracy: 0.5507\n",
      "Epoch 2240/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8874 - accuracy: 0.5609 - val_loss: 0.9032 - val_accuracy: 0.5467\n",
      "Epoch 2241/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8872 - accuracy: 0.5624 - val_loss: 0.9035 - val_accuracy: 0.5457\n",
      "Epoch 2242/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8875 - accuracy: 0.5628 - val_loss: 0.9052 - val_accuracy: 0.5477\n",
      "Epoch 2243/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8872 - accuracy: 0.5624 - val_loss: 0.9040 - val_accuracy: 0.5460\n",
      "Epoch 2244/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8875 - accuracy: 0.5634 - val_loss: 0.9031 - val_accuracy: 0.5487\n",
      "Epoch 2245/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8873 - accuracy: 0.5616 - val_loss: 0.9031 - val_accuracy: 0.5493\n",
      "Epoch 2246/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8874 - accuracy: 0.5644 - val_loss: 0.9048 - val_accuracy: 0.5490\n",
      "Epoch 2247/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8877 - accuracy: 0.5609 - val_loss: 0.9035 - val_accuracy: 0.5463\n",
      "Epoch 2248/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8871 - accuracy: 0.5634 - val_loss: 0.9046 - val_accuracy: 0.5487\n",
      "Epoch 2249/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8874 - accuracy: 0.5644 - val_loss: 0.9050 - val_accuracy: 0.5513\n",
      "Epoch 2250/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8873 - accuracy: 0.5643 - val_loss: 0.9044 - val_accuracy: 0.5507\n",
      "Epoch 2251/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8873 - accuracy: 0.5634 - val_loss: 0.9058 - val_accuracy: 0.5477\n",
      "Epoch 2252/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8873 - accuracy: 0.5653 - val_loss: 0.9052 - val_accuracy: 0.5473\n",
      "Epoch 2253/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8875 - accuracy: 0.5627 - val_loss: 0.9040 - val_accuracy: 0.5470\n",
      "Epoch 2254/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8875 - accuracy: 0.5632 - val_loss: 0.9051 - val_accuracy: 0.5487\n",
      "Epoch 2255/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8876 - accuracy: 0.5626 - val_loss: 0.9030 - val_accuracy: 0.5470\n",
      "Epoch 2256/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8873 - accuracy: 0.5646 - val_loss: 0.9036 - val_accuracy: 0.5460\n",
      "Epoch 2257/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8872 - accuracy: 0.5635 - val_loss: 0.9057 - val_accuracy: 0.5497\n",
      "Epoch 2258/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8872 - accuracy: 0.5643 - val_loss: 0.9035 - val_accuracy: 0.5490\n",
      "Epoch 2259/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8873 - accuracy: 0.5632 - val_loss: 0.9070 - val_accuracy: 0.5480\n",
      "Epoch 2260/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8873 - accuracy: 0.5616 - val_loss: 0.9032 - val_accuracy: 0.5467\n",
      "Epoch 2261/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8870 - accuracy: 0.5625 - val_loss: 0.9043 - val_accuracy: 0.5520\n",
      "Epoch 2262/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8871 - accuracy: 0.5619 - val_loss: 0.9048 - val_accuracy: 0.5490\n",
      "Epoch 2263/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8873 - accuracy: 0.5629 - val_loss: 0.9051 - val_accuracy: 0.5497\n",
      "Epoch 2264/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8873 - accuracy: 0.5636 - val_loss: 0.9050 - val_accuracy: 0.5473\n",
      "Epoch 2265/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8874 - accuracy: 0.5621 - val_loss: 0.9036 - val_accuracy: 0.5467\n",
      "Epoch 2266/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8876 - accuracy: 0.5626 - val_loss: 0.9050 - val_accuracy: 0.5480\n",
      "Epoch 2267/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8869 - accuracy: 0.5637 - val_loss: 0.9081 - val_accuracy: 0.5463\n",
      "Epoch 2268/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8873 - accuracy: 0.5626 - val_loss: 0.9030 - val_accuracy: 0.5500\n",
      "Epoch 2269/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8871 - accuracy: 0.5629 - val_loss: 0.9065 - val_accuracy: 0.5490\n",
      "Epoch 2270/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8872 - accuracy: 0.5624 - val_loss: 0.9035 - val_accuracy: 0.5483\n",
      "Epoch 2271/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8871 - accuracy: 0.5634 - val_loss: 0.9042 - val_accuracy: 0.5477\n",
      "Epoch 2272/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8871 - accuracy: 0.5641 - val_loss: 0.9035 - val_accuracy: 0.5483\n",
      "Epoch 2273/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8873 - accuracy: 0.5622 - val_loss: 0.9035 - val_accuracy: 0.5473\n",
      "Epoch 2274/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8870 - accuracy: 0.5632 - val_loss: 0.9058 - val_accuracy: 0.5497\n",
      "Epoch 2275/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8871 - accuracy: 0.5622 - val_loss: 0.9043 - val_accuracy: 0.5497\n",
      "Epoch 2276/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8867 - accuracy: 0.5626 - val_loss: 0.9035 - val_accuracy: 0.5490\n",
      "Epoch 2277/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8870 - accuracy: 0.5607 - val_loss: 0.9032 - val_accuracy: 0.5477\n",
      "Epoch 2278/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8867 - accuracy: 0.5637 - val_loss: 0.9028 - val_accuracy: 0.5493\n",
      "Epoch 2279/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8870 - accuracy: 0.5619 - val_loss: 0.9031 - val_accuracy: 0.5467\n",
      "Epoch 2280/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8870 - accuracy: 0.5641 - val_loss: 0.9029 - val_accuracy: 0.5473\n",
      "Epoch 2281/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8871 - accuracy: 0.5639 - val_loss: 0.9032 - val_accuracy: 0.5477\n",
      "Epoch 2282/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8871 - accuracy: 0.5631 - val_loss: 0.9070 - val_accuracy: 0.5493\n",
      "Epoch 2283/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8874 - accuracy: 0.5602 - val_loss: 0.9036 - val_accuracy: 0.5470\n",
      "Epoch 2284/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8871 - accuracy: 0.5625 - val_loss: 0.9030 - val_accuracy: 0.5467\n",
      "Epoch 2285/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8872 - accuracy: 0.5639 - val_loss: 0.9031 - val_accuracy: 0.5470\n",
      "Epoch 2286/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8869 - accuracy: 0.5622 - val_loss: 0.9082 - val_accuracy: 0.5493\n",
      "Epoch 2287/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8871 - accuracy: 0.5639 - val_loss: 0.9052 - val_accuracy: 0.5493\n",
      "Epoch 2288/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8870 - accuracy: 0.5631 - val_loss: 0.9032 - val_accuracy: 0.5473\n",
      "Epoch 2289/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8867 - accuracy: 0.5641 - val_loss: 0.9033 - val_accuracy: 0.5443\n",
      "Epoch 2290/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8871 - accuracy: 0.5639 - val_loss: 0.9039 - val_accuracy: 0.5483\n",
      "Epoch 2291/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8867 - accuracy: 0.5661 - val_loss: 0.9081 - val_accuracy: 0.5490\n",
      "Epoch 2292/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8870 - accuracy: 0.5639 - val_loss: 0.9030 - val_accuracy: 0.5493\n",
      "Epoch 2293/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8869 - accuracy: 0.5647 - val_loss: 0.9030 - val_accuracy: 0.5463\n",
      "Epoch 2294/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8867 - accuracy: 0.5651 - val_loss: 0.9046 - val_accuracy: 0.5477\n",
      "Epoch 2295/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8864 - accuracy: 0.5624 - val_loss: 0.9053 - val_accuracy: 0.5497\n",
      "Epoch 2296/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8865 - accuracy: 0.5667 - val_loss: 0.9041 - val_accuracy: 0.5487\n",
      "Epoch 2297/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8871 - accuracy: 0.5651 - val_loss: 0.9042 - val_accuracy: 0.5477\n",
      "Epoch 2298/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8872 - accuracy: 0.5625 - val_loss: 0.9030 - val_accuracy: 0.5480\n",
      "Epoch 2299/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8866 - accuracy: 0.5629 - val_loss: 0.9038 - val_accuracy: 0.5473\n",
      "Epoch 2300/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8863 - accuracy: 0.5629 - val_loss: 0.9026 - val_accuracy: 0.5483\n",
      "Epoch 2301/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8866 - accuracy: 0.5621 - val_loss: 0.9061 - val_accuracy: 0.5490\n",
      "Epoch 2302/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8866 - accuracy: 0.5653 - val_loss: 0.9032 - val_accuracy: 0.5493\n",
      "Epoch 2303/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8869 - accuracy: 0.5639 - val_loss: 0.9052 - val_accuracy: 0.5497\n",
      "Epoch 2304/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8870 - accuracy: 0.5619 - val_loss: 0.9056 - val_accuracy: 0.5490\n",
      "Epoch 2305/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8866 - accuracy: 0.5645 - val_loss: 0.9026 - val_accuracy: 0.5510\n",
      "Epoch 2306/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8864 - accuracy: 0.5648 - val_loss: 0.9042 - val_accuracy: 0.5497\n",
      "Epoch 2307/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8863 - accuracy: 0.5654 - val_loss: 0.9034 - val_accuracy: 0.5480\n",
      "Epoch 2308/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8866 - accuracy: 0.5668 - val_loss: 0.9032 - val_accuracy: 0.5460\n",
      "Epoch 2309/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8868 - accuracy: 0.5631 - val_loss: 0.9091 - val_accuracy: 0.5490\n",
      "Epoch 2310/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8869 - accuracy: 0.5633 - val_loss: 0.9043 - val_accuracy: 0.5507\n",
      "Epoch 2311/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8869 - accuracy: 0.5630 - val_loss: 0.9040 - val_accuracy: 0.5497\n",
      "Epoch 2312/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8867 - accuracy: 0.5664 - val_loss: 0.9031 - val_accuracy: 0.5480\n",
      "Epoch 2313/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8862 - accuracy: 0.5641 - val_loss: 0.9031 - val_accuracy: 0.5443\n",
      "Epoch 2314/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8868 - accuracy: 0.5634 - val_loss: 0.9054 - val_accuracy: 0.5507\n",
      "Epoch 2315/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8863 - accuracy: 0.5663 - val_loss: 0.9082 - val_accuracy: 0.5467\n",
      "Epoch 2316/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8863 - accuracy: 0.5634 - val_loss: 0.9041 - val_accuracy: 0.5500\n",
      "Epoch 2317/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8864 - accuracy: 0.5631 - val_loss: 0.9043 - val_accuracy: 0.5473\n",
      "Epoch 2318/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8863 - accuracy: 0.5656 - val_loss: 0.9137 - val_accuracy: 0.5433\n",
      "Epoch 2319/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8866 - accuracy: 0.5644 - val_loss: 0.9039 - val_accuracy: 0.5490\n",
      "Epoch 2320/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8864 - accuracy: 0.5629 - val_loss: 0.9030 - val_accuracy: 0.5480\n",
      "Epoch 2321/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8864 - accuracy: 0.5653 - val_loss: 0.9033 - val_accuracy: 0.5477\n",
      "Epoch 2322/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8865 - accuracy: 0.5625 - val_loss: 0.9030 - val_accuracy: 0.5477\n",
      "Epoch 2323/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8868 - accuracy: 0.5643 - val_loss: 0.9033 - val_accuracy: 0.5477\n",
      "Epoch 2324/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8865 - accuracy: 0.5629 - val_loss: 0.9044 - val_accuracy: 0.5497\n",
      "Epoch 2325/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8865 - accuracy: 0.5636 - val_loss: 0.9036 - val_accuracy: 0.5497\n",
      "Epoch 2326/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8864 - accuracy: 0.5640 - val_loss: 0.9029 - val_accuracy: 0.5500\n",
      "Epoch 2327/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8865 - accuracy: 0.5627 - val_loss: 0.9056 - val_accuracy: 0.5483\n",
      "Epoch 2328/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8864 - accuracy: 0.5651 - val_loss: 0.9027 - val_accuracy: 0.5467\n",
      "Epoch 2329/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8865 - accuracy: 0.5626 - val_loss: 0.9121 - val_accuracy: 0.5420\n",
      "Epoch 2330/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8865 - accuracy: 0.5636 - val_loss: 0.9027 - val_accuracy: 0.5470\n",
      "Epoch 2331/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8864 - accuracy: 0.5626 - val_loss: 0.9033 - val_accuracy: 0.5493\n",
      "Epoch 2332/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8859 - accuracy: 0.5616 - val_loss: 0.9096 - val_accuracy: 0.5423\n",
      "Epoch 2333/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8863 - accuracy: 0.5623 - val_loss: 0.9028 - val_accuracy: 0.5503\n",
      "Epoch 2334/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8866 - accuracy: 0.5614 - val_loss: 0.9058 - val_accuracy: 0.5477\n",
      "Epoch 2335/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8859 - accuracy: 0.5638 - val_loss: 0.9048 - val_accuracy: 0.5493\n",
      "Epoch 2336/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8863 - accuracy: 0.5634 - val_loss: 0.9044 - val_accuracy: 0.5490\n",
      "Epoch 2337/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8862 - accuracy: 0.5639 - val_loss: 0.9030 - val_accuracy: 0.5480\n",
      "Epoch 2338/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8864 - accuracy: 0.5621 - val_loss: 0.9031 - val_accuracy: 0.5477\n",
      "Epoch 2339/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8862 - accuracy: 0.5634 - val_loss: 0.9045 - val_accuracy: 0.5493\n",
      "Epoch 2340/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8861 - accuracy: 0.5633 - val_loss: 0.9061 - val_accuracy: 0.5480\n",
      "Epoch 2341/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8865 - accuracy: 0.5641 - val_loss: 0.9035 - val_accuracy: 0.5493\n",
      "Epoch 2342/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8863 - accuracy: 0.5641 - val_loss: 0.9027 - val_accuracy: 0.5507\n",
      "Epoch 2343/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8861 - accuracy: 0.5636 - val_loss: 0.9044 - val_accuracy: 0.5487\n",
      "Epoch 2344/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8859 - accuracy: 0.5635 - val_loss: 0.9039 - val_accuracy: 0.5497\n",
      "Epoch 2345/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8859 - accuracy: 0.5644 - val_loss: 0.9031 - val_accuracy: 0.5483\n",
      "Epoch 2346/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8862 - accuracy: 0.5631 - val_loss: 0.9027 - val_accuracy: 0.5510\n",
      "Epoch 2347/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8860 - accuracy: 0.5621 - val_loss: 0.9033 - val_accuracy: 0.5500\n",
      "Epoch 2348/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8861 - accuracy: 0.5637 - val_loss: 0.9077 - val_accuracy: 0.5497\n",
      "Epoch 2349/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8860 - accuracy: 0.5645 - val_loss: 0.9026 - val_accuracy: 0.5487\n",
      "Epoch 2350/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8865 - accuracy: 0.5643 - val_loss: 0.9034 - val_accuracy: 0.5493\n",
      "Epoch 2351/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8860 - accuracy: 0.5612 - val_loss: 0.9080 - val_accuracy: 0.5460\n",
      "Epoch 2352/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8865 - accuracy: 0.5615 - val_loss: 0.9077 - val_accuracy: 0.5480\n",
      "Epoch 2353/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8861 - accuracy: 0.5639 - val_loss: 0.9039 - val_accuracy: 0.5517\n",
      "Epoch 2354/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8860 - accuracy: 0.5649 - val_loss: 0.9030 - val_accuracy: 0.5480\n",
      "Epoch 2355/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8858 - accuracy: 0.5656 - val_loss: 0.9054 - val_accuracy: 0.5483\n",
      "Epoch 2356/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8861 - accuracy: 0.5651 - val_loss: 0.9031 - val_accuracy: 0.5487\n",
      "Epoch 2357/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8860 - accuracy: 0.5612 - val_loss: 0.9030 - val_accuracy: 0.5487\n",
      "Epoch 2358/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8861 - accuracy: 0.5637 - val_loss: 0.9042 - val_accuracy: 0.5503\n",
      "Epoch 2359/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8864 - accuracy: 0.5639 - val_loss: 0.9024 - val_accuracy: 0.5493\n",
      "Epoch 2360/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8858 - accuracy: 0.5636 - val_loss: 0.9049 - val_accuracy: 0.5503\n",
      "Epoch 2361/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8860 - accuracy: 0.5624 - val_loss: 0.9046 - val_accuracy: 0.5500\n",
      "Epoch 2362/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8858 - accuracy: 0.5643 - val_loss: 0.9025 - val_accuracy: 0.5510\n",
      "Epoch 2363/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8858 - accuracy: 0.5646 - val_loss: 0.9032 - val_accuracy: 0.5470\n",
      "Epoch 2364/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8859 - accuracy: 0.5644 - val_loss: 0.9024 - val_accuracy: 0.5487\n",
      "Epoch 2365/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8861 - accuracy: 0.5644 - val_loss: 0.9033 - val_accuracy: 0.5507\n",
      "Epoch 2366/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8857 - accuracy: 0.5642 - val_loss: 0.9053 - val_accuracy: 0.5493\n",
      "Epoch 2367/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8855 - accuracy: 0.5667 - val_loss: 0.9064 - val_accuracy: 0.5490\n",
      "Epoch 2368/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8859 - accuracy: 0.5649 - val_loss: 0.9024 - val_accuracy: 0.5503\n",
      "Epoch 2369/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8857 - accuracy: 0.5620 - val_loss: 0.9082 - val_accuracy: 0.5473\n",
      "Epoch 2370/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8859 - accuracy: 0.5633 - val_loss: 0.9030 - val_accuracy: 0.5473\n",
      "Epoch 2371/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8855 - accuracy: 0.5661 - val_loss: 0.9025 - val_accuracy: 0.5500\n",
      "Epoch 2372/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8857 - accuracy: 0.5644 - val_loss: 0.9030 - val_accuracy: 0.5493\n",
      "Epoch 2373/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8856 - accuracy: 0.5654 - val_loss: 0.9028 - val_accuracy: 0.5473\n",
      "Epoch 2374/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8862 - accuracy: 0.5606 - val_loss: 0.9029 - val_accuracy: 0.5480\n",
      "Epoch 2375/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8858 - accuracy: 0.5641 - val_loss: 0.9032 - val_accuracy: 0.5487\n",
      "Epoch 2376/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8861 - accuracy: 0.5641 - val_loss: 0.9057 - val_accuracy: 0.5503\n",
      "Epoch 2377/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8859 - accuracy: 0.5638 - val_loss: 0.9079 - val_accuracy: 0.5463\n",
      "Epoch 2378/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8856 - accuracy: 0.5620 - val_loss: 0.9049 - val_accuracy: 0.5503\n",
      "Epoch 2379/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8859 - accuracy: 0.5644 - val_loss: 0.9029 - val_accuracy: 0.5483\n",
      "Epoch 2380/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8857 - accuracy: 0.5631 - val_loss: 0.9030 - val_accuracy: 0.5487\n",
      "Epoch 2381/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8857 - accuracy: 0.5631 - val_loss: 0.9032 - val_accuracy: 0.5490\n",
      "Epoch 2382/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8857 - accuracy: 0.5633 - val_loss: 0.9036 - val_accuracy: 0.5503\n",
      "Epoch 2383/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5653 - val_loss: 0.9078 - val_accuracy: 0.5467\n",
      "Epoch 2384/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5650 - val_loss: 0.9030 - val_accuracy: 0.5467\n",
      "Epoch 2385/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5642 - val_loss: 0.9066 - val_accuracy: 0.5473\n",
      "Epoch 2386/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8859 - accuracy: 0.5633 - val_loss: 0.9068 - val_accuracy: 0.5473\n",
      "Epoch 2387/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8859 - accuracy: 0.5636 - val_loss: 0.9097 - val_accuracy: 0.5480\n",
      "Epoch 2388/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8858 - accuracy: 0.5624 - val_loss: 0.9027 - val_accuracy: 0.5490\n",
      "Epoch 2389/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8859 - accuracy: 0.5620 - val_loss: 0.9030 - val_accuracy: 0.5500\n",
      "Epoch 2390/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8855 - accuracy: 0.5653 - val_loss: 0.9037 - val_accuracy: 0.5497\n",
      "Epoch 2391/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8858 - accuracy: 0.5641 - val_loss: 0.9031 - val_accuracy: 0.5483\n",
      "Epoch 2392/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8856 - accuracy: 0.5651 - val_loss: 0.9025 - val_accuracy: 0.5487\n",
      "Epoch 2393/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8857 - accuracy: 0.5646 - val_loss: 0.9027 - val_accuracy: 0.5483\n",
      "Epoch 2394/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8858 - accuracy: 0.5646 - val_loss: 0.9029 - val_accuracy: 0.5480\n",
      "Epoch 2395/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8856 - accuracy: 0.5636 - val_loss: 0.9040 - val_accuracy: 0.5503\n",
      "Epoch 2396/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8855 - accuracy: 0.5631 - val_loss: 0.9041 - val_accuracy: 0.5500\n",
      "Epoch 2397/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8859 - accuracy: 0.5621 - val_loss: 0.9087 - val_accuracy: 0.5483\n",
      "Epoch 2398/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8857 - accuracy: 0.5636 - val_loss: 0.9025 - val_accuracy: 0.5513\n",
      "Epoch 2399/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8859 - accuracy: 0.5632 - val_loss: 0.9024 - val_accuracy: 0.5503\n",
      "Epoch 2400/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8857 - accuracy: 0.5641 - val_loss: 0.9029 - val_accuracy: 0.5513\n",
      "Epoch 2401/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8853 - accuracy: 0.5643 - val_loss: 0.9059 - val_accuracy: 0.5467\n",
      "Epoch 2402/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8855 - accuracy: 0.5639 - val_loss: 0.9031 - val_accuracy: 0.5493\n",
      "Epoch 2403/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8854 - accuracy: 0.5648 - val_loss: 0.9031 - val_accuracy: 0.5503\n",
      "Epoch 2404/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8855 - accuracy: 0.5660 - val_loss: 0.9078 - val_accuracy: 0.5480\n",
      "Epoch 2405/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8851 - accuracy: 0.5637 - val_loss: 0.9027 - val_accuracy: 0.5480\n",
      "Epoch 2406/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8853 - accuracy: 0.5663 - val_loss: 0.9026 - val_accuracy: 0.5507\n",
      "Epoch 2407/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8852 - accuracy: 0.5656 - val_loss: 0.9031 - val_accuracy: 0.5510\n",
      "Epoch 2408/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8855 - accuracy: 0.5641 - val_loss: 0.9024 - val_accuracy: 0.5487\n",
      "Epoch 2409/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8855 - accuracy: 0.5648 - val_loss: 0.9035 - val_accuracy: 0.5480\n",
      "Epoch 2410/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8855 - accuracy: 0.5646 - val_loss: 0.9027 - val_accuracy: 0.5510\n",
      "Epoch 2411/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8852 - accuracy: 0.5644 - val_loss: 0.9024 - val_accuracy: 0.5477\n",
      "Epoch 2412/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8854 - accuracy: 0.5644 - val_loss: 0.9125 - val_accuracy: 0.5450\n",
      "Epoch 2413/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5640 - val_loss: 0.9027 - val_accuracy: 0.5477\n",
      "Epoch 2414/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8856 - accuracy: 0.5644 - val_loss: 0.9025 - val_accuracy: 0.5457\n",
      "Epoch 2415/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8845 - accuracy: 0.5664 - val_loss: 0.9061 - val_accuracy: 0.5470\n",
      "Epoch 2416/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5643 - val_loss: 0.9050 - val_accuracy: 0.5500\n",
      "Epoch 2417/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5619 - val_loss: 0.9048 - val_accuracy: 0.5527\n",
      "Epoch 2418/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8852 - accuracy: 0.5633 - val_loss: 0.9037 - val_accuracy: 0.5513\n",
      "Epoch 2419/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8853 - accuracy: 0.5644 - val_loss: 0.9050 - val_accuracy: 0.5473\n",
      "Epoch 2420/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8856 - accuracy: 0.5614 - val_loss: 0.9027 - val_accuracy: 0.5510\n",
      "Epoch 2421/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5665 - val_loss: 0.9029 - val_accuracy: 0.5530\n",
      "Epoch 2422/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8852 - accuracy: 0.5646 - val_loss: 0.9031 - val_accuracy: 0.5493\n",
      "Epoch 2423/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8849 - accuracy: 0.5629 - val_loss: 0.9112 - val_accuracy: 0.5427\n",
      "Epoch 2424/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8850 - accuracy: 0.5609 - val_loss: 0.9031 - val_accuracy: 0.5483\n",
      "Epoch 2425/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8849 - accuracy: 0.5639 - val_loss: 0.9034 - val_accuracy: 0.5493\n",
      "Epoch 2426/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8847 - accuracy: 0.5656 - val_loss: 0.9086 - val_accuracy: 0.5453\n",
      "Epoch 2427/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8853 - accuracy: 0.5646 - val_loss: 0.9045 - val_accuracy: 0.5490\n",
      "Epoch 2428/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8851 - accuracy: 0.5648 - val_loss: 0.9036 - val_accuracy: 0.5497\n",
      "Epoch 2429/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8851 - accuracy: 0.5644 - val_loss: 0.9023 - val_accuracy: 0.5510\n",
      "Epoch 2430/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5623 - val_loss: 0.9035 - val_accuracy: 0.5490\n",
      "Epoch 2431/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8848 - accuracy: 0.5651 - val_loss: 0.9035 - val_accuracy: 0.5480\n",
      "Epoch 2432/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8853 - accuracy: 0.5639 - val_loss: 0.9025 - val_accuracy: 0.5513\n",
      "Epoch 2433/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8851 - accuracy: 0.5643 - val_loss: 0.9025 - val_accuracy: 0.5497\n",
      "Epoch 2434/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8851 - accuracy: 0.5621 - val_loss: 0.9061 - val_accuracy: 0.5490\n",
      "Epoch 2435/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8848 - accuracy: 0.5664 - val_loss: 0.9048 - val_accuracy: 0.5497\n",
      "Epoch 2436/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8856 - accuracy: 0.5632 - val_loss: 0.9028 - val_accuracy: 0.5513\n",
      "Epoch 2437/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8851 - accuracy: 0.5639 - val_loss: 0.9026 - val_accuracy: 0.5497\n",
      "Epoch 2438/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8854 - accuracy: 0.5654 - val_loss: 0.9022 - val_accuracy: 0.5497\n",
      "Epoch 2439/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8851 - accuracy: 0.5641 - val_loss: 0.9030 - val_accuracy: 0.5487\n",
      "Epoch 2440/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8849 - accuracy: 0.5646 - val_loss: 0.9038 - val_accuracy: 0.5497\n",
      "Epoch 2441/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8848 - accuracy: 0.5659 - val_loss: 0.9031 - val_accuracy: 0.5480\n",
      "Epoch 2442/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8850 - accuracy: 0.5637 - val_loss: 0.9028 - val_accuracy: 0.5493\n",
      "Epoch 2443/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8851 - accuracy: 0.5654 - val_loss: 0.9119 - val_accuracy: 0.5433\n",
      "Epoch 2444/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8850 - accuracy: 0.5679 - val_loss: 0.9026 - val_accuracy: 0.5487\n",
      "Epoch 2445/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8847 - accuracy: 0.5633 - val_loss: 0.9033 - val_accuracy: 0.5480\n",
      "Epoch 2446/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8850 - accuracy: 0.5640 - val_loss: 0.9221 - val_accuracy: 0.5423\n",
      "Epoch 2447/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8853 - accuracy: 0.5642 - val_loss: 0.9073 - val_accuracy: 0.5497\n",
      "Epoch 2448/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8850 - accuracy: 0.5626 - val_loss: 0.9024 - val_accuracy: 0.5507\n",
      "Epoch 2449/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8850 - accuracy: 0.5652 - val_loss: 0.9039 - val_accuracy: 0.5520\n",
      "Epoch 2450/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8846 - accuracy: 0.5635 - val_loss: 0.9058 - val_accuracy: 0.5477\n",
      "Epoch 2451/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8850 - accuracy: 0.5642 - val_loss: 0.9072 - val_accuracy: 0.5490\n",
      "Epoch 2452/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8839 - accuracy: 0.5670 - val_loss: 0.9179 - val_accuracy: 0.5417\n",
      "Epoch 2453/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8851 - accuracy: 0.5647 - val_loss: 0.9021 - val_accuracy: 0.5483\n",
      "Epoch 2454/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8845 - accuracy: 0.5636 - val_loss: 0.9049 - val_accuracy: 0.5517\n",
      "Epoch 2455/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8846 - accuracy: 0.5643 - val_loss: 0.9023 - val_accuracy: 0.5463\n",
      "Epoch 2456/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8845 - accuracy: 0.5649 - val_loss: 0.9024 - val_accuracy: 0.5483\n",
      "Epoch 2457/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8853 - accuracy: 0.5638 - val_loss: 0.9024 - val_accuracy: 0.5503\n",
      "Epoch 2458/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8845 - accuracy: 0.5644 - val_loss: 0.9031 - val_accuracy: 0.5513\n",
      "Epoch 2459/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8851 - accuracy: 0.5611 - val_loss: 0.9025 - val_accuracy: 0.5470\n",
      "Epoch 2460/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8847 - accuracy: 0.5641 - val_loss: 0.9033 - val_accuracy: 0.5513\n",
      "Epoch 2461/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8854 - accuracy: 0.5632 - val_loss: 0.9025 - val_accuracy: 0.5487\n",
      "Epoch 2462/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8846 - accuracy: 0.5655 - val_loss: 0.9028 - val_accuracy: 0.5480\n",
      "Epoch 2463/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8850 - accuracy: 0.5617 - val_loss: 0.9039 - val_accuracy: 0.5527\n",
      "Epoch 2464/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8845 - accuracy: 0.5654 - val_loss: 0.9030 - val_accuracy: 0.5510\n",
      "Epoch 2465/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8845 - accuracy: 0.5631 - val_loss: 0.9052 - val_accuracy: 0.5490\n",
      "Epoch 2466/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8847 - accuracy: 0.5654 - val_loss: 0.9024 - val_accuracy: 0.5513\n",
      "Epoch 2467/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8842 - accuracy: 0.5637 - val_loss: 0.9146 - val_accuracy: 0.5417\n",
      "Epoch 2468/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8847 - accuracy: 0.5654 - val_loss: 0.9155 - val_accuracy: 0.5403\n",
      "Epoch 2469/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8848 - accuracy: 0.5641 - val_loss: 0.9023 - val_accuracy: 0.5513\n",
      "Epoch 2470/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8847 - accuracy: 0.5646 - val_loss: 0.9027 - val_accuracy: 0.5480\n",
      "Epoch 2471/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8848 - accuracy: 0.5620 - val_loss: 0.9030 - val_accuracy: 0.5487\n",
      "Epoch 2472/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8849 - accuracy: 0.5681 - val_loss: 0.9019 - val_accuracy: 0.5497\n",
      "Epoch 2473/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8847 - accuracy: 0.5656 - val_loss: 0.9020 - val_accuracy: 0.5477\n",
      "Epoch 2474/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8844 - accuracy: 0.5669 - val_loss: 0.9022 - val_accuracy: 0.5527\n",
      "Epoch 2475/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8845 - accuracy: 0.5661 - val_loss: 0.9050 - val_accuracy: 0.5503\n",
      "Epoch 2476/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8844 - accuracy: 0.5651 - val_loss: 0.9038 - val_accuracy: 0.5517\n",
      "Epoch 2477/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8850 - accuracy: 0.5616 - val_loss: 0.9020 - val_accuracy: 0.5493\n",
      "Epoch 2478/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8841 - accuracy: 0.5655 - val_loss: 0.9085 - val_accuracy: 0.5473\n",
      "Epoch 2479/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8846 - accuracy: 0.5649 - val_loss: 0.9040 - val_accuracy: 0.5510\n",
      "Epoch 2480/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8847 - accuracy: 0.5647 - val_loss: 0.9021 - val_accuracy: 0.5473\n",
      "Epoch 2481/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8846 - accuracy: 0.5658 - val_loss: 0.9026 - val_accuracy: 0.5493\n",
      "Epoch 2482/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8842 - accuracy: 0.5656 - val_loss: 0.9094 - val_accuracy: 0.5457\n",
      "Epoch 2483/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8842 - accuracy: 0.5654 - val_loss: 0.9037 - val_accuracy: 0.5493\n",
      "Epoch 2484/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8839 - accuracy: 0.5659 - val_loss: 0.9026 - val_accuracy: 0.5493\n",
      "Epoch 2485/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8844 - accuracy: 0.5628 - val_loss: 0.9021 - val_accuracy: 0.5517\n",
      "Epoch 2486/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8843 - accuracy: 0.5664 - val_loss: 0.9028 - val_accuracy: 0.5523\n",
      "Epoch 2487/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8844 - accuracy: 0.5639 - val_loss: 0.9033 - val_accuracy: 0.5510\n",
      "Epoch 2488/5500\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.8846 - accuracy: 0.5636 - val_loss: 0.9025 - val_accuracy: 0.5497\n",
      "Epoch 2489/5500\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.8843 - accuracy: 0.5621 - val_loss: 0.9072 - val_accuracy: 0.5490\n",
      "Epoch 2490/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.8845 - accuracy: 0.5633 - val_loss: 0.9028 - val_accuracy: 0.5483\n",
      "Epoch 2491/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8843 - accuracy: 0.5647 - val_loss: 0.9055 - val_accuracy: 0.5483\n",
      "Epoch 2492/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8836 - accuracy: 0.5684 - val_loss: 0.9022 - val_accuracy: 0.5517\n",
      "Epoch 2493/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8845 - accuracy: 0.5655 - val_loss: 0.9026 - val_accuracy: 0.5520\n",
      "Epoch 2494/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8841 - accuracy: 0.5648 - val_loss: 0.9051 - val_accuracy: 0.5517\n",
      "Epoch 2495/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8843 - accuracy: 0.5645 - val_loss: 0.9069 - val_accuracy: 0.5467\n",
      "Epoch 2496/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8850 - accuracy: 0.5662 - val_loss: 0.9043 - val_accuracy: 0.5507\n",
      "Epoch 2497/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8842 - accuracy: 0.5671 - val_loss: 0.9021 - val_accuracy: 0.5470\n",
      "Epoch 2498/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8845 - accuracy: 0.5640 - val_loss: 0.9026 - val_accuracy: 0.5503\n",
      "Epoch 2499/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8843 - accuracy: 0.5654 - val_loss: 0.9027 - val_accuracy: 0.5500\n",
      "Epoch 2500/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8845 - accuracy: 0.5637 - val_loss: 0.9042 - val_accuracy: 0.5543\n",
      "Epoch 2501/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8840 - accuracy: 0.5644 - val_loss: 0.9020 - val_accuracy: 0.5490\n",
      "Epoch 2502/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8845 - accuracy: 0.5664 - val_loss: 0.9024 - val_accuracy: 0.5470\n",
      "Epoch 2503/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8843 - accuracy: 0.5633 - val_loss: 0.9022 - val_accuracy: 0.5490\n",
      "Epoch 2504/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8842 - accuracy: 0.5659 - val_loss: 0.9020 - val_accuracy: 0.5493\n",
      "Epoch 2505/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8842 - accuracy: 0.5632 - val_loss: 0.9095 - val_accuracy: 0.5473\n",
      "Epoch 2506/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8842 - accuracy: 0.5641 - val_loss: 0.9068 - val_accuracy: 0.5503\n",
      "Epoch 2507/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8841 - accuracy: 0.5617 - val_loss: 0.9023 - val_accuracy: 0.5510\n",
      "Epoch 2508/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8842 - accuracy: 0.5669 - val_loss: 0.9020 - val_accuracy: 0.5503\n",
      "Epoch 2509/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8844 - accuracy: 0.5640 - val_loss: 0.9021 - val_accuracy: 0.5507\n",
      "Epoch 2510/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8838 - accuracy: 0.5630 - val_loss: 0.9068 - val_accuracy: 0.5500\n",
      "Epoch 2511/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8842 - accuracy: 0.5630 - val_loss: 0.9022 - val_accuracy: 0.5497\n",
      "Epoch 2512/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8839 - accuracy: 0.5659 - val_loss: 0.9037 - val_accuracy: 0.5507\n",
      "Epoch 2513/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8837 - accuracy: 0.5649 - val_loss: 0.9019 - val_accuracy: 0.5487\n",
      "Epoch 2514/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8842 - accuracy: 0.5651 - val_loss: 0.9022 - val_accuracy: 0.5503\n",
      "Epoch 2515/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8842 - accuracy: 0.5655 - val_loss: 0.9037 - val_accuracy: 0.5510\n",
      "Epoch 2516/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8839 - accuracy: 0.5661 - val_loss: 0.9035 - val_accuracy: 0.5493\n",
      "Epoch 2517/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8839 - accuracy: 0.5649 - val_loss: 0.9025 - val_accuracy: 0.5527\n",
      "Epoch 2518/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8837 - accuracy: 0.5648 - val_loss: 0.9025 - val_accuracy: 0.5473\n",
      "Epoch 2519/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8841 - accuracy: 0.5649 - val_loss: 0.9021 - val_accuracy: 0.5507\n",
      "Epoch 2520/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8840 - accuracy: 0.5639 - val_loss: 0.9026 - val_accuracy: 0.5527\n",
      "Epoch 2521/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8837 - accuracy: 0.5643 - val_loss: 0.9024 - val_accuracy: 0.5500\n",
      "Epoch 2522/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8839 - accuracy: 0.5668 - val_loss: 0.9017 - val_accuracy: 0.5513\n",
      "Epoch 2523/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8840 - accuracy: 0.5654 - val_loss: 0.9028 - val_accuracy: 0.5503\n",
      "Epoch 2524/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8838 - accuracy: 0.5649 - val_loss: 0.9037 - val_accuracy: 0.5493\n",
      "Epoch 2525/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8835 - accuracy: 0.5656 - val_loss: 0.9022 - val_accuracy: 0.5490\n",
      "Epoch 2526/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8841 - accuracy: 0.5639 - val_loss: 0.9032 - val_accuracy: 0.5537\n",
      "Epoch 2527/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8840 - accuracy: 0.5656 - val_loss: 0.9021 - val_accuracy: 0.5473\n",
      "Epoch 2528/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8837 - accuracy: 0.5656 - val_loss: 0.9181 - val_accuracy: 0.5403\n",
      "Epoch 2529/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8834 - accuracy: 0.5645 - val_loss: 0.9021 - val_accuracy: 0.5513\n",
      "Epoch 2530/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8838 - accuracy: 0.5643 - val_loss: 0.9024 - val_accuracy: 0.5497\n",
      "Epoch 2531/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8837 - accuracy: 0.5638 - val_loss: 0.9031 - val_accuracy: 0.5463\n",
      "Epoch 2532/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8840 - accuracy: 0.5659 - val_loss: 0.9030 - val_accuracy: 0.5510\n",
      "Epoch 2533/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8842 - accuracy: 0.5636 - val_loss: 0.9021 - val_accuracy: 0.5510\n",
      "Epoch 2534/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8833 - accuracy: 0.5643 - val_loss: 0.9132 - val_accuracy: 0.5423\n",
      "Epoch 2535/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8835 - accuracy: 0.5666 - val_loss: 0.9126 - val_accuracy: 0.5447\n",
      "Epoch 2536/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8839 - accuracy: 0.5654 - val_loss: 0.9045 - val_accuracy: 0.5513\n",
      "Epoch 2537/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8839 - accuracy: 0.5661 - val_loss: 0.9020 - val_accuracy: 0.5493\n",
      "Epoch 2538/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8833 - accuracy: 0.5661 - val_loss: 0.9030 - val_accuracy: 0.5520\n",
      "Epoch 2539/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8843 - accuracy: 0.5639 - val_loss: 0.9037 - val_accuracy: 0.5517\n",
      "Epoch 2540/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8839 - accuracy: 0.5674 - val_loss: 0.9212 - val_accuracy: 0.5400\n",
      "Epoch 2541/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8843 - accuracy: 0.5637 - val_loss: 0.9020 - val_accuracy: 0.5483\n",
      "Epoch 2542/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8833 - accuracy: 0.5659 - val_loss: 0.9047 - val_accuracy: 0.5507\n",
      "Epoch 2543/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8833 - accuracy: 0.5629 - val_loss: 0.9018 - val_accuracy: 0.5483\n",
      "Epoch 2544/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8834 - accuracy: 0.5620 - val_loss: 0.9075 - val_accuracy: 0.5473\n",
      "Epoch 2545/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8838 - accuracy: 0.5656 - val_loss: 0.9024 - val_accuracy: 0.5500\n",
      "Epoch 2546/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8839 - accuracy: 0.5656 - val_loss: 0.9018 - val_accuracy: 0.5497\n",
      "Epoch 2547/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8841 - accuracy: 0.5659 - val_loss: 0.9031 - val_accuracy: 0.5510\n",
      "Epoch 2548/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8838 - accuracy: 0.5646 - val_loss: 0.9024 - val_accuracy: 0.5530\n",
      "Epoch 2549/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8836 - accuracy: 0.5668 - val_loss: 0.9022 - val_accuracy: 0.5533\n",
      "Epoch 2550/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8834 - accuracy: 0.5659 - val_loss: 0.9027 - val_accuracy: 0.5507\n",
      "Epoch 2551/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8827 - accuracy: 0.5656 - val_loss: 0.9038 - val_accuracy: 0.5507\n",
      "Epoch 2552/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8838 - accuracy: 0.5661 - val_loss: 0.9019 - val_accuracy: 0.5463\n",
      "Epoch 2553/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8841 - accuracy: 0.5642 - val_loss: 0.9028 - val_accuracy: 0.5520\n",
      "Epoch 2554/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8838 - accuracy: 0.5662 - val_loss: 0.9038 - val_accuracy: 0.5507\n",
      "Epoch 2555/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8835 - accuracy: 0.5677 - val_loss: 0.9052 - val_accuracy: 0.5493\n",
      "Epoch 2556/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8841 - accuracy: 0.5655 - val_loss: 0.9043 - val_accuracy: 0.5520\n",
      "Epoch 2557/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8834 - accuracy: 0.5621 - val_loss: 0.9019 - val_accuracy: 0.5487\n",
      "Epoch 2558/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8836 - accuracy: 0.5654 - val_loss: 0.9017 - val_accuracy: 0.5490\n",
      "Epoch 2559/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8834 - accuracy: 0.5647 - val_loss: 0.9046 - val_accuracy: 0.5480\n",
      "Epoch 2560/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8835 - accuracy: 0.5671 - val_loss: 0.9020 - val_accuracy: 0.5513\n",
      "Epoch 2561/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8830 - accuracy: 0.5645 - val_loss: 0.9027 - val_accuracy: 0.5540\n",
      "Epoch 2562/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8841 - accuracy: 0.5631 - val_loss: 0.9041 - val_accuracy: 0.5517\n",
      "Epoch 2563/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8834 - accuracy: 0.5681 - val_loss: 0.9024 - val_accuracy: 0.5510\n",
      "Epoch 2564/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8832 - accuracy: 0.5650 - val_loss: 0.9050 - val_accuracy: 0.5517\n",
      "Epoch 2565/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8829 - accuracy: 0.5663 - val_loss: 0.9064 - val_accuracy: 0.5490\n",
      "Epoch 2566/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8835 - accuracy: 0.5649 - val_loss: 0.9021 - val_accuracy: 0.5473\n",
      "Epoch 2567/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8835 - accuracy: 0.5645 - val_loss: 0.9057 - val_accuracy: 0.5467\n",
      "Epoch 2568/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8834 - accuracy: 0.5672 - val_loss: 0.9020 - val_accuracy: 0.5480\n",
      "Epoch 2569/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8836 - accuracy: 0.5669 - val_loss: 0.9023 - val_accuracy: 0.5527\n",
      "Epoch 2570/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8832 - accuracy: 0.5668 - val_loss: 0.9017 - val_accuracy: 0.5493\n",
      "Epoch 2571/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8833 - accuracy: 0.5661 - val_loss: 0.9018 - val_accuracy: 0.5517\n",
      "Epoch 2572/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8829 - accuracy: 0.5626 - val_loss: 0.9024 - val_accuracy: 0.5500\n",
      "Epoch 2573/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8833 - accuracy: 0.5632 - val_loss: 0.9031 - val_accuracy: 0.5523\n",
      "Epoch 2574/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8837 - accuracy: 0.5659 - val_loss: 0.9019 - val_accuracy: 0.5507\n",
      "Epoch 2575/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8834 - accuracy: 0.5685 - val_loss: 0.9021 - val_accuracy: 0.5517\n",
      "Epoch 2576/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8832 - accuracy: 0.5651 - val_loss: 0.9038 - val_accuracy: 0.5537\n",
      "Epoch 2577/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8832 - accuracy: 0.5643 - val_loss: 0.9024 - val_accuracy: 0.5540\n",
      "Epoch 2578/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8829 - accuracy: 0.5645 - val_loss: 0.9018 - val_accuracy: 0.5510\n",
      "Epoch 2579/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8833 - accuracy: 0.5648 - val_loss: 0.9106 - val_accuracy: 0.5477\n",
      "Epoch 2580/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8836 - accuracy: 0.5647 - val_loss: 0.9018 - val_accuracy: 0.5473\n",
      "Epoch 2581/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8829 - accuracy: 0.5676 - val_loss: 0.9040 - val_accuracy: 0.5490\n",
      "Epoch 2582/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8829 - accuracy: 0.5638 - val_loss: 0.9057 - val_accuracy: 0.5513\n",
      "Epoch 2583/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8834 - accuracy: 0.5620 - val_loss: 0.9017 - val_accuracy: 0.5503\n",
      "Epoch 2584/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8830 - accuracy: 0.5632 - val_loss: 0.9033 - val_accuracy: 0.5493\n",
      "Epoch 2585/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8832 - accuracy: 0.5639 - val_loss: 0.9074 - val_accuracy: 0.5490\n",
      "Epoch 2586/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8831 - accuracy: 0.5668 - val_loss: 0.9014 - val_accuracy: 0.5497\n",
      "Epoch 2587/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8830 - accuracy: 0.5634 - val_loss: 0.9019 - val_accuracy: 0.5483\n",
      "Epoch 2588/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8831 - accuracy: 0.5672 - val_loss: 0.9024 - val_accuracy: 0.5527\n",
      "Epoch 2589/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8831 - accuracy: 0.5648 - val_loss: 0.9016 - val_accuracy: 0.5527\n",
      "Epoch 2590/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8830 - accuracy: 0.5645 - val_loss: 0.9015 - val_accuracy: 0.5517\n",
      "Epoch 2591/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8832 - accuracy: 0.5671 - val_loss: 0.9048 - val_accuracy: 0.5517\n",
      "Epoch 2592/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8826 - accuracy: 0.5686 - val_loss: 0.9039 - val_accuracy: 0.5537\n",
      "Epoch 2593/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8832 - accuracy: 0.5666 - val_loss: 0.9037 - val_accuracy: 0.5520\n",
      "Epoch 2594/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8832 - accuracy: 0.5651 - val_loss: 0.9030 - val_accuracy: 0.5513\n",
      "Epoch 2595/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8830 - accuracy: 0.5661 - val_loss: 0.9020 - val_accuracy: 0.5473\n",
      "Epoch 2596/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8828 - accuracy: 0.5648 - val_loss: 0.9041 - val_accuracy: 0.5513\n",
      "Epoch 2597/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8832 - accuracy: 0.5678 - val_loss: 0.9174 - val_accuracy: 0.5403\n",
      "Epoch 2598/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8834 - accuracy: 0.5627 - val_loss: 0.9027 - val_accuracy: 0.5470\n",
      "Epoch 2599/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8831 - accuracy: 0.5645 - val_loss: 0.9016 - val_accuracy: 0.5527\n",
      "Epoch 2600/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8827 - accuracy: 0.5664 - val_loss: 0.9022 - val_accuracy: 0.5487\n",
      "Epoch 2601/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8832 - accuracy: 0.5673 - val_loss: 0.9024 - val_accuracy: 0.5517\n",
      "Epoch 2602/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8831 - accuracy: 0.5640 - val_loss: 0.9097 - val_accuracy: 0.5477\n",
      "Epoch 2603/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.8828 - accuracy: 0.5639 - val_loss: 0.9129 - val_accuracy: 0.5473\n",
      "Epoch 2604/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8837 - accuracy: 0.5650 - val_loss: 0.9043 - val_accuracy: 0.5500\n",
      "Epoch 2605/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8835 - accuracy: 0.5652 - val_loss: 0.9024 - val_accuracy: 0.5493\n",
      "Epoch 2606/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8827 - accuracy: 0.5669 - val_loss: 0.9028 - val_accuracy: 0.5493\n",
      "Epoch 2607/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8833 - accuracy: 0.5651 - val_loss: 0.9051 - val_accuracy: 0.5513\n",
      "Epoch 2608/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8826 - accuracy: 0.5635 - val_loss: 0.9017 - val_accuracy: 0.5530\n",
      "Epoch 2609/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8829 - accuracy: 0.5650 - val_loss: 0.9034 - val_accuracy: 0.5490\n",
      "Epoch 2610/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8830 - accuracy: 0.5629 - val_loss: 0.9020 - val_accuracy: 0.5523\n",
      "Epoch 2611/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8829 - accuracy: 0.5652 - val_loss: 0.9026 - val_accuracy: 0.5487\n",
      "Epoch 2612/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8829 - accuracy: 0.5650 - val_loss: 0.9016 - val_accuracy: 0.5507\n",
      "Epoch 2613/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8832 - accuracy: 0.5639 - val_loss: 0.9034 - val_accuracy: 0.5540\n",
      "Epoch 2614/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8824 - accuracy: 0.5654 - val_loss: 0.9095 - val_accuracy: 0.5467\n",
      "Epoch 2615/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8829 - accuracy: 0.5658 - val_loss: 0.9028 - val_accuracy: 0.5490\n",
      "Epoch 2616/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8825 - accuracy: 0.5641 - val_loss: 0.9014 - val_accuracy: 0.5537\n",
      "Epoch 2617/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8827 - accuracy: 0.5631 - val_loss: 0.9097 - val_accuracy: 0.5477\n",
      "Epoch 2618/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8829 - accuracy: 0.5653 - val_loss: 0.9021 - val_accuracy: 0.5520\n",
      "Epoch 2619/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8823 - accuracy: 0.5664 - val_loss: 0.9025 - val_accuracy: 0.5513\n",
      "Epoch 2620/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8829 - accuracy: 0.5656 - val_loss: 0.9056 - val_accuracy: 0.5497\n",
      "Epoch 2621/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8827 - accuracy: 0.5634 - val_loss: 0.9038 - val_accuracy: 0.5477\n",
      "Epoch 2622/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8831 - accuracy: 0.5674 - val_loss: 0.9049 - val_accuracy: 0.5517\n",
      "Epoch 2623/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8830 - accuracy: 0.5654 - val_loss: 0.9067 - val_accuracy: 0.5480\n",
      "Epoch 2624/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8826 - accuracy: 0.5661 - val_loss: 0.9024 - val_accuracy: 0.5490\n",
      "Epoch 2625/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8824 - accuracy: 0.5653 - val_loss: 0.9044 - val_accuracy: 0.5517\n",
      "Epoch 2626/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8825 - accuracy: 0.5679 - val_loss: 0.9075 - val_accuracy: 0.5487\n",
      "Epoch 2627/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8833 - accuracy: 0.5674 - val_loss: 0.9062 - val_accuracy: 0.5500\n",
      "Epoch 2628/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8825 - accuracy: 0.5649 - val_loss: 0.9021 - val_accuracy: 0.5527\n",
      "Epoch 2629/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8830 - accuracy: 0.5661 - val_loss: 0.9021 - val_accuracy: 0.5500\n",
      "Epoch 2630/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8828 - accuracy: 0.5664 - val_loss: 0.9016 - val_accuracy: 0.5490\n",
      "Epoch 2631/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8824 - accuracy: 0.5665 - val_loss: 0.9020 - val_accuracy: 0.5523\n",
      "Epoch 2632/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8829 - accuracy: 0.5658 - val_loss: 0.9078 - val_accuracy: 0.5487\n",
      "Epoch 2633/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8822 - accuracy: 0.5664 - val_loss: 0.9035 - val_accuracy: 0.5513\n",
      "Epoch 2634/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8825 - accuracy: 0.5654 - val_loss: 0.9193 - val_accuracy: 0.5420\n",
      "Epoch 2635/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8824 - accuracy: 0.5679 - val_loss: 0.9015 - val_accuracy: 0.5487\n",
      "Epoch 2636/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8829 - accuracy: 0.5654 - val_loss: 0.9022 - val_accuracy: 0.5517\n",
      "Epoch 2637/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8826 - accuracy: 0.5656 - val_loss: 0.9064 - val_accuracy: 0.5490\n",
      "Epoch 2638/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8827 - accuracy: 0.5658 - val_loss: 0.9067 - val_accuracy: 0.5510\n",
      "Epoch 2639/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8821 - accuracy: 0.5649 - val_loss: 0.9192 - val_accuracy: 0.5407\n",
      "Epoch 2640/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8827 - accuracy: 0.5629 - val_loss: 0.9016 - val_accuracy: 0.5540\n",
      "Epoch 2641/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8828 - accuracy: 0.5669 - val_loss: 0.9018 - val_accuracy: 0.5507\n",
      "Epoch 2642/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8819 - accuracy: 0.5676 - val_loss: 0.9016 - val_accuracy: 0.5467\n",
      "Epoch 2643/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8828 - accuracy: 0.5616 - val_loss: 0.9017 - val_accuracy: 0.5497\n",
      "Epoch 2644/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8825 - accuracy: 0.5667 - val_loss: 0.9035 - val_accuracy: 0.5487\n",
      "Epoch 2645/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8828 - accuracy: 0.5657 - val_loss: 0.9055 - val_accuracy: 0.5507\n",
      "Epoch 2646/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8823 - accuracy: 0.5655 - val_loss: 0.9014 - val_accuracy: 0.5527\n",
      "Epoch 2647/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8827 - accuracy: 0.5646 - val_loss: 0.9113 - val_accuracy: 0.5457\n",
      "Epoch 2648/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8821 - accuracy: 0.5670 - val_loss: 0.9037 - val_accuracy: 0.5500\n",
      "Epoch 2649/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8823 - accuracy: 0.5670 - val_loss: 0.9013 - val_accuracy: 0.5497\n",
      "Epoch 2650/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8824 - accuracy: 0.5664 - val_loss: 0.9034 - val_accuracy: 0.5533\n",
      "Epoch 2651/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8818 - accuracy: 0.5670 - val_loss: 0.9028 - val_accuracy: 0.5473\n",
      "Epoch 2652/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8820 - accuracy: 0.5658 - val_loss: 0.9036 - val_accuracy: 0.5490\n",
      "Epoch 2653/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8833 - accuracy: 0.5669 - val_loss: 0.9129 - val_accuracy: 0.5430\n",
      "Epoch 2654/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8823 - accuracy: 0.5668 - val_loss: 0.9017 - val_accuracy: 0.5530\n",
      "Epoch 2655/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8823 - accuracy: 0.5683 - val_loss: 0.9025 - val_accuracy: 0.5497\n",
      "Epoch 2656/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8822 - accuracy: 0.5649 - val_loss: 0.9028 - val_accuracy: 0.5493\n",
      "Epoch 2657/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8825 - accuracy: 0.5671 - val_loss: 0.9044 - val_accuracy: 0.5527\n",
      "Epoch 2658/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8823 - accuracy: 0.5669 - val_loss: 0.9015 - val_accuracy: 0.5513\n",
      "Epoch 2659/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8816 - accuracy: 0.5674 - val_loss: 0.9036 - val_accuracy: 0.5507\n",
      "Epoch 2660/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8824 - accuracy: 0.5663 - val_loss: 0.9019 - val_accuracy: 0.5523\n",
      "Epoch 2661/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8823 - accuracy: 0.5676 - val_loss: 0.9035 - val_accuracy: 0.5493\n",
      "Epoch 2662/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8812 - accuracy: 0.5686 - val_loss: 0.9030 - val_accuracy: 0.5527\n",
      "Epoch 2663/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8818 - accuracy: 0.5654 - val_loss: 0.9023 - val_accuracy: 0.5513\n",
      "Epoch 2664/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8823 - accuracy: 0.5674 - val_loss: 0.9087 - val_accuracy: 0.5487\n",
      "Epoch 2665/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8821 - accuracy: 0.5677 - val_loss: 0.9023 - val_accuracy: 0.5550\n",
      "Epoch 2666/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8822 - accuracy: 0.5679 - val_loss: 0.9094 - val_accuracy: 0.5490\n",
      "Epoch 2667/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8819 - accuracy: 0.5682 - val_loss: 0.9027 - val_accuracy: 0.5497\n",
      "Epoch 2668/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8821 - accuracy: 0.5636 - val_loss: 0.9032 - val_accuracy: 0.5520\n",
      "Epoch 2669/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8826 - accuracy: 0.5648 - val_loss: 0.9016 - val_accuracy: 0.5500\n",
      "Epoch 2670/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8824 - accuracy: 0.5669 - val_loss: 0.9032 - val_accuracy: 0.5477\n",
      "Epoch 2671/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8823 - accuracy: 0.5683 - val_loss: 0.9014 - val_accuracy: 0.5497\n",
      "Epoch 2672/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8815 - accuracy: 0.5669 - val_loss: 0.9014 - val_accuracy: 0.5470\n",
      "Epoch 2673/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8820 - accuracy: 0.5691 - val_loss: 0.9022 - val_accuracy: 0.5507\n",
      "Epoch 2674/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8818 - accuracy: 0.5694 - val_loss: 0.9039 - val_accuracy: 0.5487\n",
      "Epoch 2675/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8822 - accuracy: 0.5664 - val_loss: 0.9042 - val_accuracy: 0.5500\n",
      "Epoch 2676/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8823 - accuracy: 0.5657 - val_loss: 0.9020 - val_accuracy: 0.5490\n",
      "Epoch 2677/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8819 - accuracy: 0.5659 - val_loss: 0.9014 - val_accuracy: 0.5493\n",
      "Epoch 2678/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8815 - accuracy: 0.5664 - val_loss: 0.9015 - val_accuracy: 0.5517\n",
      "Epoch 2679/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8816 - accuracy: 0.5659 - val_loss: 0.9108 - val_accuracy: 0.5457\n",
      "Epoch 2680/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8820 - accuracy: 0.5651 - val_loss: 0.9060 - val_accuracy: 0.5510\n",
      "Epoch 2681/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8818 - accuracy: 0.5664 - val_loss: 0.9169 - val_accuracy: 0.5427\n",
      "Epoch 2682/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8818 - accuracy: 0.5656 - val_loss: 0.9019 - val_accuracy: 0.5503\n",
      "Epoch 2683/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8820 - accuracy: 0.5675 - val_loss: 0.9146 - val_accuracy: 0.5430\n",
      "Epoch 2684/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8819 - accuracy: 0.5656 - val_loss: 0.9015 - val_accuracy: 0.5537\n",
      "Epoch 2685/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8817 - accuracy: 0.5674 - val_loss: 0.9031 - val_accuracy: 0.5533\n",
      "Epoch 2686/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8825 - accuracy: 0.5656 - val_loss: 0.9015 - val_accuracy: 0.5507\n",
      "Epoch 2687/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8822 - accuracy: 0.5654 - val_loss: 0.9014 - val_accuracy: 0.5503\n",
      "Epoch 2688/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8819 - accuracy: 0.5659 - val_loss: 0.9092 - val_accuracy: 0.5457\n",
      "Epoch 2689/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8818 - accuracy: 0.5668 - val_loss: 0.9025 - val_accuracy: 0.5517\n",
      "Epoch 2690/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8819 - accuracy: 0.5641 - val_loss: 0.9049 - val_accuracy: 0.5477\n",
      "Epoch 2691/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8818 - accuracy: 0.5671 - val_loss: 0.9017 - val_accuracy: 0.5497\n",
      "Epoch 2692/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8814 - accuracy: 0.5661 - val_loss: 0.9017 - val_accuracy: 0.5513\n",
      "Epoch 2693/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8820 - accuracy: 0.5676 - val_loss: 0.9053 - val_accuracy: 0.5497\n",
      "Epoch 2694/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8819 - accuracy: 0.5671 - val_loss: 0.9022 - val_accuracy: 0.5497\n",
      "Epoch 2695/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8819 - accuracy: 0.5660 - val_loss: 0.9026 - val_accuracy: 0.5540\n",
      "Epoch 2696/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8818 - accuracy: 0.5679 - val_loss: 0.9019 - val_accuracy: 0.5517\n",
      "Epoch 2697/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8815 - accuracy: 0.5676 - val_loss: 0.9013 - val_accuracy: 0.5480\n",
      "Epoch 2698/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8822 - accuracy: 0.5656 - val_loss: 0.9056 - val_accuracy: 0.5500\n",
      "Epoch 2699/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8813 - accuracy: 0.5671 - val_loss: 0.9146 - val_accuracy: 0.5420\n",
      "Epoch 2700/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8819 - accuracy: 0.5674 - val_loss: 0.9015 - val_accuracy: 0.5473\n",
      "Epoch 2701/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8815 - accuracy: 0.5702 - val_loss: 0.9012 - val_accuracy: 0.5530\n",
      "Epoch 2702/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8817 - accuracy: 0.5636 - val_loss: 0.9014 - val_accuracy: 0.5527\n",
      "Epoch 2703/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8813 - accuracy: 0.5687 - val_loss: 0.9042 - val_accuracy: 0.5480\n",
      "Epoch 2704/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8817 - accuracy: 0.5675 - val_loss: 0.9053 - val_accuracy: 0.5503\n",
      "Epoch 2705/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8814 - accuracy: 0.5664 - val_loss: 0.9016 - val_accuracy: 0.5557\n",
      "Epoch 2706/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8817 - accuracy: 0.5654 - val_loss: 0.9227 - val_accuracy: 0.5387\n",
      "Epoch 2707/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8815 - accuracy: 0.5642 - val_loss: 0.9036 - val_accuracy: 0.5490\n",
      "Epoch 2708/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8817 - accuracy: 0.5689 - val_loss: 0.9014 - val_accuracy: 0.5537\n",
      "Epoch 2709/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8815 - accuracy: 0.5679 - val_loss: 0.9045 - val_accuracy: 0.5500\n",
      "Epoch 2710/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8818 - accuracy: 0.5649 - val_loss: 0.9042 - val_accuracy: 0.5530\n",
      "Epoch 2711/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8812 - accuracy: 0.5629 - val_loss: 0.9013 - val_accuracy: 0.5530\n",
      "Epoch 2712/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8817 - accuracy: 0.5661 - val_loss: 0.9015 - val_accuracy: 0.5543\n",
      "Epoch 2713/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8814 - accuracy: 0.5681 - val_loss: 0.9034 - val_accuracy: 0.5460\n",
      "Epoch 2714/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8815 - accuracy: 0.5656 - val_loss: 0.9030 - val_accuracy: 0.5500\n",
      "Epoch 2715/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8812 - accuracy: 0.5676 - val_loss: 0.9033 - val_accuracy: 0.5503\n",
      "Epoch 2716/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8815 - accuracy: 0.5684 - val_loss: 0.9016 - val_accuracy: 0.5543\n",
      "Epoch 2717/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8807 - accuracy: 0.5634 - val_loss: 0.9022 - val_accuracy: 0.5497\n",
      "Epoch 2718/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8815 - accuracy: 0.5684 - val_loss: 0.9053 - val_accuracy: 0.5520\n",
      "Epoch 2719/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8815 - accuracy: 0.5648 - val_loss: 0.9014 - val_accuracy: 0.5507\n",
      "Epoch 2720/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8812 - accuracy: 0.5645 - val_loss: 0.9019 - val_accuracy: 0.5473\n",
      "Epoch 2721/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8813 - accuracy: 0.5687 - val_loss: 0.9031 - val_accuracy: 0.5510\n",
      "Epoch 2722/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8812 - accuracy: 0.5674 - val_loss: 0.9029 - val_accuracy: 0.5533\n",
      "Epoch 2723/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8814 - accuracy: 0.5677 - val_loss: 0.9026 - val_accuracy: 0.5557\n",
      "Epoch 2724/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8808 - accuracy: 0.5668 - val_loss: 0.9026 - val_accuracy: 0.5487\n",
      "Epoch 2725/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8812 - accuracy: 0.5679 - val_loss: 0.9038 - val_accuracy: 0.5493\n",
      "Epoch 2726/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8810 - accuracy: 0.5684 - val_loss: 0.9124 - val_accuracy: 0.5377\n",
      "Epoch 2727/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8817 - accuracy: 0.5670 - val_loss: 0.9066 - val_accuracy: 0.5497\n",
      "Epoch 2728/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8809 - accuracy: 0.5653 - val_loss: 0.9020 - val_accuracy: 0.5507\n",
      "Epoch 2729/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8817 - accuracy: 0.5651 - val_loss: 0.9016 - val_accuracy: 0.5547\n",
      "Epoch 2730/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8816 - accuracy: 0.5674 - val_loss: 0.9018 - val_accuracy: 0.5487\n",
      "Epoch 2731/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8812 - accuracy: 0.5676 - val_loss: 0.9013 - val_accuracy: 0.5530\n",
      "Epoch 2732/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8810 - accuracy: 0.5649 - val_loss: 0.9060 - val_accuracy: 0.5513\n",
      "Epoch 2733/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8810 - accuracy: 0.5654 - val_loss: 0.9061 - val_accuracy: 0.5483\n",
      "Epoch 2734/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8807 - accuracy: 0.5655 - val_loss: 0.9014 - val_accuracy: 0.5533\n",
      "Epoch 2735/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8807 - accuracy: 0.5662 - val_loss: 0.9013 - val_accuracy: 0.5503\n",
      "Epoch 2736/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8816 - accuracy: 0.5665 - val_loss: 0.9012 - val_accuracy: 0.5517\n",
      "Epoch 2737/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8809 - accuracy: 0.5679 - val_loss: 0.9010 - val_accuracy: 0.5503\n",
      "Epoch 2738/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8808 - accuracy: 0.5645 - val_loss: 0.9162 - val_accuracy: 0.5383\n",
      "Epoch 2739/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8813 - accuracy: 0.5658 - val_loss: 0.9013 - val_accuracy: 0.5543\n",
      "Epoch 2740/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8810 - accuracy: 0.5656 - val_loss: 0.9048 - val_accuracy: 0.5517\n",
      "Epoch 2741/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8816 - accuracy: 0.5679 - val_loss: 0.9022 - val_accuracy: 0.5480\n",
      "Epoch 2742/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8811 - accuracy: 0.5659 - val_loss: 0.9178 - val_accuracy: 0.5430\n",
      "Epoch 2743/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8819 - accuracy: 0.5662 - val_loss: 0.9017 - val_accuracy: 0.5483\n",
      "Epoch 2744/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8819 - accuracy: 0.5655 - val_loss: 0.9058 - val_accuracy: 0.5503\n",
      "Epoch 2745/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8808 - accuracy: 0.5673 - val_loss: 0.9018 - val_accuracy: 0.5513\n",
      "Epoch 2746/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8807 - accuracy: 0.5665 - val_loss: 0.9017 - val_accuracy: 0.5503\n",
      "Epoch 2747/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8805 - accuracy: 0.5688 - val_loss: 0.9034 - val_accuracy: 0.5503\n",
      "Epoch 2748/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8812 - accuracy: 0.5654 - val_loss: 0.9044 - val_accuracy: 0.5477\n",
      "Epoch 2749/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8813 - accuracy: 0.5668 - val_loss: 0.9018 - val_accuracy: 0.5490\n",
      "Epoch 2750/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8811 - accuracy: 0.5669 - val_loss: 0.9013 - val_accuracy: 0.5543\n",
      "Epoch 2751/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8811 - accuracy: 0.5691 - val_loss: 0.9118 - val_accuracy: 0.5457\n",
      "Epoch 2752/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8814 - accuracy: 0.5645 - val_loss: 0.9141 - val_accuracy: 0.5423\n",
      "Epoch 2753/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8819 - accuracy: 0.5646 - val_loss: 0.9025 - val_accuracy: 0.5500\n",
      "Epoch 2754/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8820 - accuracy: 0.5672 - val_loss: 0.9040 - val_accuracy: 0.5510\n",
      "Epoch 2755/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8814 - accuracy: 0.5676 - val_loss: 0.9030 - val_accuracy: 0.5513\n",
      "Epoch 2756/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8812 - accuracy: 0.5683 - val_loss: 0.9019 - val_accuracy: 0.5580\n",
      "Epoch 2757/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8812 - accuracy: 0.5650 - val_loss: 0.9055 - val_accuracy: 0.5497\n",
      "Epoch 2758/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8814 - accuracy: 0.5685 - val_loss: 0.9093 - val_accuracy: 0.5477\n",
      "Epoch 2759/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8805 - accuracy: 0.5694 - val_loss: 0.9068 - val_accuracy: 0.5493\n",
      "Epoch 2760/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8813 - accuracy: 0.5681 - val_loss: 0.9020 - val_accuracy: 0.5520\n",
      "Epoch 2761/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8811 - accuracy: 0.5698 - val_loss: 0.9092 - val_accuracy: 0.5477\n",
      "Epoch 2762/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8818 - accuracy: 0.5658 - val_loss: 0.9019 - val_accuracy: 0.5530\n",
      "Epoch 2763/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8806 - accuracy: 0.5667 - val_loss: 0.9045 - val_accuracy: 0.5493\n",
      "Epoch 2764/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8801 - accuracy: 0.5671 - val_loss: 0.9023 - val_accuracy: 0.5517\n",
      "Epoch 2765/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8806 - accuracy: 0.5686 - val_loss: 0.9040 - val_accuracy: 0.5523\n",
      "Epoch 2766/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8814 - accuracy: 0.5661 - val_loss: 0.9016 - val_accuracy: 0.5480\n",
      "Epoch 2767/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8809 - accuracy: 0.5663 - val_loss: 0.9017 - val_accuracy: 0.5500\n",
      "Epoch 2768/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8808 - accuracy: 0.5699 - val_loss: 0.9012 - val_accuracy: 0.5537\n",
      "Epoch 2769/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8815 - accuracy: 0.5686 - val_loss: 0.9023 - val_accuracy: 0.5517\n",
      "Epoch 2770/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8807 - accuracy: 0.5670 - val_loss: 0.9045 - val_accuracy: 0.5473\n",
      "Epoch 2771/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8801 - accuracy: 0.5676 - val_loss: 0.9089 - val_accuracy: 0.5447\n",
      "Epoch 2772/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8811 - accuracy: 0.5654 - val_loss: 0.9077 - val_accuracy: 0.5490\n",
      "Epoch 2773/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8807 - accuracy: 0.5679 - val_loss: 0.9014 - val_accuracy: 0.5503\n",
      "Epoch 2774/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8806 - accuracy: 0.5661 - val_loss: 0.9017 - val_accuracy: 0.5517\n",
      "Epoch 2775/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8804 - accuracy: 0.5683 - val_loss: 0.9085 - val_accuracy: 0.5493\n",
      "Epoch 2776/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8812 - accuracy: 0.5651 - val_loss: 0.9009 - val_accuracy: 0.5517\n",
      "Epoch 2777/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8811 - accuracy: 0.5661 - val_loss: 0.9022 - val_accuracy: 0.5473\n",
      "Epoch 2778/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8815 - accuracy: 0.5658 - val_loss: 0.9009 - val_accuracy: 0.5503\n",
      "Epoch 2779/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8808 - accuracy: 0.5657 - val_loss: 0.9017 - val_accuracy: 0.5500\n",
      "Epoch 2780/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8811 - accuracy: 0.5689 - val_loss: 0.9026 - val_accuracy: 0.5493\n",
      "Epoch 2781/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8806 - accuracy: 0.5666 - val_loss: 0.9013 - val_accuracy: 0.5490\n",
      "Epoch 2782/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8807 - accuracy: 0.5679 - val_loss: 0.9025 - val_accuracy: 0.5523\n",
      "Epoch 2783/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8806 - accuracy: 0.5664 - val_loss: 0.9017 - val_accuracy: 0.5510\n",
      "Epoch 2784/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8798 - accuracy: 0.5696 - val_loss: 0.9016 - val_accuracy: 0.5493\n",
      "Epoch 2785/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8805 - accuracy: 0.5656 - val_loss: 0.9021 - val_accuracy: 0.5497\n",
      "Epoch 2786/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8805 - accuracy: 0.5674 - val_loss: 0.9108 - val_accuracy: 0.5463\n",
      "Epoch 2787/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8803 - accuracy: 0.5668 - val_loss: 0.9019 - val_accuracy: 0.5507\n",
      "Epoch 2788/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8801 - accuracy: 0.5709 - val_loss: 0.9013 - val_accuracy: 0.5550\n",
      "Epoch 2789/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8802 - accuracy: 0.5687 - val_loss: 0.9016 - val_accuracy: 0.5503\n",
      "Epoch 2790/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8802 - accuracy: 0.5659 - val_loss: 0.9036 - val_accuracy: 0.5500\n",
      "Epoch 2791/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8811 - accuracy: 0.5679 - val_loss: 0.9138 - val_accuracy: 0.5430\n",
      "Epoch 2792/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8803 - accuracy: 0.5666 - val_loss: 0.9014 - val_accuracy: 0.5560\n",
      "Epoch 2793/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8804 - accuracy: 0.5684 - val_loss: 0.9024 - val_accuracy: 0.5530\n",
      "Epoch 2794/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8809 - accuracy: 0.5630 - val_loss: 0.9025 - val_accuracy: 0.5520\n",
      "Epoch 2795/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8808 - accuracy: 0.5665 - val_loss: 0.9183 - val_accuracy: 0.5437\n",
      "Epoch 2796/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8808 - accuracy: 0.5656 - val_loss: 0.9029 - val_accuracy: 0.5520\n",
      "Epoch 2797/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8803 - accuracy: 0.5666 - val_loss: 0.9008 - val_accuracy: 0.5503\n",
      "Epoch 2798/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8799 - accuracy: 0.5691 - val_loss: 0.9069 - val_accuracy: 0.5483\n",
      "Epoch 2799/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8803 - accuracy: 0.5669 - val_loss: 0.9020 - val_accuracy: 0.5490\n",
      "Epoch 2800/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8801 - accuracy: 0.5696 - val_loss: 0.9008 - val_accuracy: 0.5443\n",
      "Epoch 2801/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8803 - accuracy: 0.5676 - val_loss: 0.9115 - val_accuracy: 0.5447\n",
      "Epoch 2802/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8806 - accuracy: 0.5670 - val_loss: 0.9013 - val_accuracy: 0.5577\n",
      "Epoch 2803/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8806 - accuracy: 0.5687 - val_loss: 0.9023 - val_accuracy: 0.5483\n",
      "Epoch 2804/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8804 - accuracy: 0.5674 - val_loss: 0.9026 - val_accuracy: 0.5517\n",
      "Epoch 2805/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8808 - accuracy: 0.5653 - val_loss: 0.9062 - val_accuracy: 0.5467\n",
      "Epoch 2806/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8802 - accuracy: 0.5640 - val_loss: 0.9017 - val_accuracy: 0.5523\n",
      "Epoch 2807/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8807 - accuracy: 0.5678 - val_loss: 0.9068 - val_accuracy: 0.5477\n",
      "Epoch 2808/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8804 - accuracy: 0.5671 - val_loss: 0.9014 - val_accuracy: 0.5520\n",
      "Epoch 2809/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8809 - accuracy: 0.5679 - val_loss: 0.9033 - val_accuracy: 0.5477\n",
      "Epoch 2810/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8799 - accuracy: 0.5682 - val_loss: 0.9034 - val_accuracy: 0.5537\n",
      "Epoch 2811/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8797 - accuracy: 0.5674 - val_loss: 0.9026 - val_accuracy: 0.5510\n",
      "Epoch 2812/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8803 - accuracy: 0.5674 - val_loss: 0.9042 - val_accuracy: 0.5503\n",
      "Epoch 2813/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8804 - accuracy: 0.5673 - val_loss: 0.9009 - val_accuracy: 0.5503\n",
      "Epoch 2814/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8806 - accuracy: 0.5678 - val_loss: 0.9039 - val_accuracy: 0.5497\n",
      "Epoch 2815/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8801 - accuracy: 0.5688 - val_loss: 0.9010 - val_accuracy: 0.5557\n",
      "Epoch 2816/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8804 - accuracy: 0.5695 - val_loss: 0.9040 - val_accuracy: 0.5490\n",
      "Epoch 2817/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8799 - accuracy: 0.5636 - val_loss: 0.9021 - val_accuracy: 0.5490\n",
      "Epoch 2818/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8804 - accuracy: 0.5681 - val_loss: 0.9071 - val_accuracy: 0.5483\n",
      "Epoch 2819/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8802 - accuracy: 0.5690 - val_loss: 0.9071 - val_accuracy: 0.5500\n",
      "Epoch 2820/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8802 - accuracy: 0.5674 - val_loss: 0.9027 - val_accuracy: 0.5463\n",
      "Epoch 2821/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8800 - accuracy: 0.5678 - val_loss: 0.9018 - val_accuracy: 0.5550\n",
      "Epoch 2822/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8800 - accuracy: 0.5679 - val_loss: 0.9078 - val_accuracy: 0.5470\n",
      "Epoch 2823/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8797 - accuracy: 0.5708 - val_loss: 0.9114 - val_accuracy: 0.5453\n",
      "Epoch 2824/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8802 - accuracy: 0.5686 - val_loss: 0.9063 - val_accuracy: 0.5533\n",
      "Epoch 2825/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8803 - accuracy: 0.5679 - val_loss: 0.9009 - val_accuracy: 0.5517\n",
      "Epoch 2826/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8805 - accuracy: 0.5711 - val_loss: 0.9009 - val_accuracy: 0.5490\n",
      "Epoch 2827/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8807 - accuracy: 0.5647 - val_loss: 0.9072 - val_accuracy: 0.5467\n",
      "Epoch 2828/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8805 - accuracy: 0.5641 - val_loss: 0.9091 - val_accuracy: 0.5503\n",
      "Epoch 2829/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8802 - accuracy: 0.5686 - val_loss: 0.9041 - val_accuracy: 0.5510\n",
      "Epoch 2830/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8800 - accuracy: 0.5671 - val_loss: 0.9013 - val_accuracy: 0.5517\n",
      "Epoch 2831/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8800 - accuracy: 0.5664 - val_loss: 0.9012 - val_accuracy: 0.5527\n",
      "Epoch 2832/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8803 - accuracy: 0.5666 - val_loss: 0.9015 - val_accuracy: 0.5553\n",
      "Epoch 2833/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8797 - accuracy: 0.5687 - val_loss: 0.9021 - val_accuracy: 0.5503\n",
      "Epoch 2834/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8804 - accuracy: 0.5662 - val_loss: 0.9090 - val_accuracy: 0.5490\n",
      "Epoch 2835/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8802 - accuracy: 0.5642 - val_loss: 0.9090 - val_accuracy: 0.5493\n",
      "Epoch 2836/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8808 - accuracy: 0.5687 - val_loss: 0.9006 - val_accuracy: 0.5510\n",
      "Epoch 2837/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8805 - accuracy: 0.5677 - val_loss: 0.9013 - val_accuracy: 0.5480\n",
      "Epoch 2838/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8804 - accuracy: 0.5671 - val_loss: 0.9032 - val_accuracy: 0.5507\n",
      "Epoch 2839/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8797 - accuracy: 0.5657 - val_loss: 0.9157 - val_accuracy: 0.5410\n",
      "Epoch 2840/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8801 - accuracy: 0.5657 - val_loss: 0.9025 - val_accuracy: 0.5510\n",
      "Epoch 2841/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8804 - accuracy: 0.5661 - val_loss: 0.9046 - val_accuracy: 0.5517\n",
      "Epoch 2842/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8800 - accuracy: 0.5683 - val_loss: 0.9059 - val_accuracy: 0.5493\n",
      "Epoch 2843/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8801 - accuracy: 0.5661 - val_loss: 0.9012 - val_accuracy: 0.5513\n",
      "Epoch 2844/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8798 - accuracy: 0.5671 - val_loss: 0.9010 - val_accuracy: 0.5533\n",
      "Epoch 2845/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8799 - accuracy: 0.5681 - val_loss: 0.9031 - val_accuracy: 0.5523\n",
      "Epoch 2846/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8795 - accuracy: 0.5664 - val_loss: 0.9015 - val_accuracy: 0.5490\n",
      "Epoch 2847/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8800 - accuracy: 0.5677 - val_loss: 0.9029 - val_accuracy: 0.5517\n",
      "Epoch 2848/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8801 - accuracy: 0.5647 - val_loss: 0.9066 - val_accuracy: 0.5477\n",
      "Epoch 2849/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8801 - accuracy: 0.5674 - val_loss: 0.9025 - val_accuracy: 0.5510\n",
      "Epoch 2850/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8797 - accuracy: 0.5698 - val_loss: 0.9125 - val_accuracy: 0.5377\n",
      "Epoch 2851/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8796 - accuracy: 0.5685 - val_loss: 0.9038 - val_accuracy: 0.5537\n",
      "Epoch 2852/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8798 - accuracy: 0.5691 - val_loss: 0.9044 - val_accuracy: 0.5523\n",
      "Epoch 2853/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8802 - accuracy: 0.5646 - val_loss: 0.9012 - val_accuracy: 0.5487\n",
      "Epoch 2854/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8793 - accuracy: 0.5697 - val_loss: 0.9016 - val_accuracy: 0.5540\n",
      "Epoch 2855/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8802 - accuracy: 0.5647 - val_loss: 0.9014 - val_accuracy: 0.5507\n",
      "Epoch 2856/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8796 - accuracy: 0.5667 - val_loss: 0.9017 - val_accuracy: 0.5553\n",
      "Epoch 2857/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8800 - accuracy: 0.5666 - val_loss: 0.9012 - val_accuracy: 0.5473\n",
      "Epoch 2858/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8809 - accuracy: 0.5679 - val_loss: 0.9016 - val_accuracy: 0.5557\n",
      "Epoch 2859/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8796 - accuracy: 0.5658 - val_loss: 0.9016 - val_accuracy: 0.5577\n",
      "Epoch 2860/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8795 - accuracy: 0.5669 - val_loss: 0.9007 - val_accuracy: 0.5503\n",
      "Epoch 2861/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8791 - accuracy: 0.5684 - val_loss: 0.9031 - val_accuracy: 0.5513\n",
      "Epoch 2862/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8796 - accuracy: 0.5661 - val_loss: 0.9029 - val_accuracy: 0.5493\n",
      "Epoch 2863/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8800 - accuracy: 0.5675 - val_loss: 0.9012 - val_accuracy: 0.5467\n",
      "Epoch 2864/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8791 - accuracy: 0.5679 - val_loss: 0.9019 - val_accuracy: 0.5517\n",
      "Epoch 2865/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8794 - accuracy: 0.5696 - val_loss: 0.9056 - val_accuracy: 0.5517\n",
      "Epoch 2866/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8795 - accuracy: 0.5690 - val_loss: 0.9012 - val_accuracy: 0.5537\n",
      "Epoch 2867/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8807 - accuracy: 0.5686 - val_loss: 0.9009 - val_accuracy: 0.5480\n",
      "Epoch 2868/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8792 - accuracy: 0.5704 - val_loss: 0.9028 - val_accuracy: 0.5480\n",
      "Epoch 2869/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8799 - accuracy: 0.5688 - val_loss: 0.9018 - val_accuracy: 0.5507\n",
      "Epoch 2870/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8807 - accuracy: 0.5677 - val_loss: 0.9011 - val_accuracy: 0.5540\n",
      "Epoch 2871/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8793 - accuracy: 0.5679 - val_loss: 0.9005 - val_accuracy: 0.5480\n",
      "Epoch 2872/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8797 - accuracy: 0.5696 - val_loss: 0.9031 - val_accuracy: 0.5513\n",
      "Epoch 2873/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8792 - accuracy: 0.5656 - val_loss: 0.9055 - val_accuracy: 0.5483\n",
      "Epoch 2874/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8794 - accuracy: 0.5700 - val_loss: 0.9027 - val_accuracy: 0.5517\n",
      "Epoch 2875/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8795 - accuracy: 0.5681 - val_loss: 0.9033 - val_accuracy: 0.5513\n",
      "Epoch 2876/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8789 - accuracy: 0.5680 - val_loss: 0.9073 - val_accuracy: 0.5493\n",
      "Epoch 2877/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8798 - accuracy: 0.5693 - val_loss: 0.9022 - val_accuracy: 0.5503\n",
      "Epoch 2878/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8789 - accuracy: 0.5696 - val_loss: 0.9009 - val_accuracy: 0.5530\n",
      "Epoch 2879/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8803 - accuracy: 0.5655 - val_loss: 0.9113 - val_accuracy: 0.5390\n",
      "Epoch 2880/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8796 - accuracy: 0.5686 - val_loss: 0.9130 - val_accuracy: 0.5370\n",
      "Epoch 2881/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8794 - accuracy: 0.5680 - val_loss: 0.9015 - val_accuracy: 0.5527\n",
      "Epoch 2882/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8799 - accuracy: 0.5667 - val_loss: 0.9104 - val_accuracy: 0.5453\n",
      "Epoch 2883/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8797 - accuracy: 0.5674 - val_loss: 0.9007 - val_accuracy: 0.5530\n",
      "Epoch 2884/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8802 - accuracy: 0.5653 - val_loss: 0.9057 - val_accuracy: 0.5493\n",
      "Epoch 2885/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8797 - accuracy: 0.5685 - val_loss: 0.9056 - val_accuracy: 0.5523\n",
      "Epoch 2886/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8793 - accuracy: 0.5681 - val_loss: 0.9010 - val_accuracy: 0.5520\n",
      "Epoch 2887/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8793 - accuracy: 0.5669 - val_loss: 0.9108 - val_accuracy: 0.5447\n",
      "Epoch 2888/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8794 - accuracy: 0.5691 - val_loss: 0.9014 - val_accuracy: 0.5500\n",
      "Epoch 2889/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8790 - accuracy: 0.5689 - val_loss: 0.9005 - val_accuracy: 0.5473\n",
      "Epoch 2890/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8793 - accuracy: 0.5651 - val_loss: 0.9070 - val_accuracy: 0.5487\n",
      "Epoch 2891/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8795 - accuracy: 0.5699 - val_loss: 0.9017 - val_accuracy: 0.5527\n",
      "Epoch 2892/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8794 - accuracy: 0.5671 - val_loss: 0.9021 - val_accuracy: 0.5523\n",
      "Epoch 2893/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8791 - accuracy: 0.5638 - val_loss: 0.9016 - val_accuracy: 0.5513\n",
      "Epoch 2894/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8791 - accuracy: 0.5673 - val_loss: 0.9027 - val_accuracy: 0.5500\n",
      "Epoch 2895/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8791 - accuracy: 0.5703 - val_loss: 0.9023 - val_accuracy: 0.5523\n",
      "Epoch 2896/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8792 - accuracy: 0.5707 - val_loss: 0.9039 - val_accuracy: 0.5497\n",
      "Epoch 2897/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8791 - accuracy: 0.5695 - val_loss: 0.9010 - val_accuracy: 0.5483\n",
      "Epoch 2898/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8792 - accuracy: 0.5705 - val_loss: 0.9009 - val_accuracy: 0.5563\n",
      "Epoch 2899/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8797 - accuracy: 0.5669 - val_loss: 0.9009 - val_accuracy: 0.5580\n",
      "Epoch 2900/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8798 - accuracy: 0.5685 - val_loss: 0.9036 - val_accuracy: 0.5507\n",
      "Epoch 2901/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8801 - accuracy: 0.5652 - val_loss: 0.9021 - val_accuracy: 0.5510\n",
      "Epoch 2902/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8807 - accuracy: 0.5674 - val_loss: 0.9010 - val_accuracy: 0.5497\n",
      "Epoch 2903/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8789 - accuracy: 0.5701 - val_loss: 0.9014 - val_accuracy: 0.5513\n",
      "Epoch 2904/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8793 - accuracy: 0.5666 - val_loss: 0.9245 - val_accuracy: 0.5413\n",
      "Epoch 2905/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8797 - accuracy: 0.5685 - val_loss: 0.9012 - val_accuracy: 0.5487\n",
      "Epoch 2906/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8791 - accuracy: 0.5687 - val_loss: 0.9013 - val_accuracy: 0.5500\n",
      "Epoch 2907/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8784 - accuracy: 0.5701 - val_loss: 0.9004 - val_accuracy: 0.5570\n",
      "Epoch 2908/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8788 - accuracy: 0.5705 - val_loss: 0.9017 - val_accuracy: 0.5560\n",
      "Epoch 2909/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8794 - accuracy: 0.5660 - val_loss: 0.9056 - val_accuracy: 0.5570\n",
      "Epoch 2910/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8791 - accuracy: 0.5674 - val_loss: 0.9051 - val_accuracy: 0.5537\n",
      "Epoch 2911/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8791 - accuracy: 0.5686 - val_loss: 0.9104 - val_accuracy: 0.5447\n",
      "Epoch 2912/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8794 - accuracy: 0.5678 - val_loss: 0.9003 - val_accuracy: 0.5473\n",
      "Epoch 2913/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8790 - accuracy: 0.5669 - val_loss: 0.9008 - val_accuracy: 0.5507\n",
      "Epoch 2914/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8795 - accuracy: 0.5671 - val_loss: 0.9020 - val_accuracy: 0.5530\n",
      "Epoch 2915/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8791 - accuracy: 0.5700 - val_loss: 0.9063 - val_accuracy: 0.5520\n",
      "Epoch 2916/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8787 - accuracy: 0.5684 - val_loss: 0.9037 - val_accuracy: 0.5507\n",
      "Epoch 2917/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8790 - accuracy: 0.5689 - val_loss: 0.9014 - val_accuracy: 0.5483\n",
      "Epoch 2918/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8789 - accuracy: 0.5675 - val_loss: 0.9107 - val_accuracy: 0.5477\n",
      "Epoch 2919/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8786 - accuracy: 0.5689 - val_loss: 0.9025 - val_accuracy: 0.5533\n",
      "Epoch 2920/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8791 - accuracy: 0.5704 - val_loss: 0.9039 - val_accuracy: 0.5483\n",
      "Epoch 2921/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8791 - accuracy: 0.5678 - val_loss: 0.9059 - val_accuracy: 0.5543\n",
      "Epoch 2922/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8789 - accuracy: 0.5684 - val_loss: 0.9015 - val_accuracy: 0.5523\n",
      "Epoch 2923/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8789 - accuracy: 0.5688 - val_loss: 0.9007 - val_accuracy: 0.5500\n",
      "Epoch 2924/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8781 - accuracy: 0.5694 - val_loss: 0.9031 - val_accuracy: 0.5517\n",
      "Epoch 2925/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8790 - accuracy: 0.5670 - val_loss: 0.9009 - val_accuracy: 0.5520\n",
      "Epoch 2926/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8792 - accuracy: 0.5679 - val_loss: 0.9003 - val_accuracy: 0.5510\n",
      "Epoch 2927/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8792 - accuracy: 0.5668 - val_loss: 0.9013 - val_accuracy: 0.5540\n",
      "Epoch 2928/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8792 - accuracy: 0.5679 - val_loss: 0.9009 - val_accuracy: 0.5513\n",
      "Epoch 2929/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8787 - accuracy: 0.5706 - val_loss: 0.9098 - val_accuracy: 0.5460\n",
      "Epoch 2930/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8790 - accuracy: 0.5674 - val_loss: 0.9059 - val_accuracy: 0.5510\n",
      "Epoch 2931/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8782 - accuracy: 0.5663 - val_loss: 0.9056 - val_accuracy: 0.5487\n",
      "Epoch 2932/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8792 - accuracy: 0.5693 - val_loss: 0.9048 - val_accuracy: 0.5510\n",
      "Epoch 2933/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8790 - accuracy: 0.5697 - val_loss: 0.9009 - val_accuracy: 0.5603\n",
      "Epoch 2934/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8787 - accuracy: 0.5678 - val_loss: 0.9006 - val_accuracy: 0.5483\n",
      "Epoch 2935/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8788 - accuracy: 0.5676 - val_loss: 0.9002 - val_accuracy: 0.5483\n",
      "Epoch 2936/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8793 - accuracy: 0.5681 - val_loss: 0.9012 - val_accuracy: 0.5520\n",
      "Epoch 2937/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8789 - accuracy: 0.5669 - val_loss: 0.9008 - val_accuracy: 0.5513\n",
      "Epoch 2938/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8786 - accuracy: 0.5691 - val_loss: 0.9016 - val_accuracy: 0.5533\n",
      "Epoch 2939/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8786 - accuracy: 0.5683 - val_loss: 0.9003 - val_accuracy: 0.5533\n",
      "Epoch 2940/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8787 - accuracy: 0.5680 - val_loss: 0.9157 - val_accuracy: 0.5363\n",
      "Epoch 2941/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8789 - accuracy: 0.5678 - val_loss: 0.9029 - val_accuracy: 0.5523\n",
      "Epoch 2942/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8781 - accuracy: 0.5697 - val_loss: 0.9095 - val_accuracy: 0.5460\n",
      "Epoch 2943/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8781 - accuracy: 0.5692 - val_loss: 0.9160 - val_accuracy: 0.5467\n",
      "Epoch 2944/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8789 - accuracy: 0.5685 - val_loss: 0.9009 - val_accuracy: 0.5503\n",
      "Epoch 2945/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8783 - accuracy: 0.5684 - val_loss: 0.9071 - val_accuracy: 0.5473\n",
      "Epoch 2946/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8787 - accuracy: 0.5706 - val_loss: 0.9019 - val_accuracy: 0.5500\n",
      "Epoch 2947/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8790 - accuracy: 0.5690 - val_loss: 0.9019 - val_accuracy: 0.5517\n",
      "Epoch 2948/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8794 - accuracy: 0.5686 - val_loss: 0.9004 - val_accuracy: 0.5493\n",
      "Epoch 2949/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8785 - accuracy: 0.5703 - val_loss: 0.9011 - val_accuracy: 0.5530\n",
      "Epoch 2950/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8787 - accuracy: 0.5665 - val_loss: 0.9044 - val_accuracy: 0.5527\n",
      "Epoch 2951/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8787 - accuracy: 0.5669 - val_loss: 0.9014 - val_accuracy: 0.5513\n",
      "Epoch 2952/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8785 - accuracy: 0.5709 - val_loss: 0.9076 - val_accuracy: 0.5510\n",
      "Epoch 2953/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8788 - accuracy: 0.5647 - val_loss: 0.9039 - val_accuracy: 0.5500\n",
      "Epoch 2954/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8787 - accuracy: 0.5666 - val_loss: 0.9005 - val_accuracy: 0.5520\n",
      "Epoch 2955/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8785 - accuracy: 0.5669 - val_loss: 0.9028 - val_accuracy: 0.5547\n",
      "Epoch 2956/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8789 - accuracy: 0.5681 - val_loss: 0.9187 - val_accuracy: 0.5437\n",
      "Epoch 2957/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8784 - accuracy: 0.5683 - val_loss: 0.9005 - val_accuracy: 0.5517\n",
      "Epoch 2958/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8783 - accuracy: 0.5684 - val_loss: 0.9034 - val_accuracy: 0.5513\n",
      "Epoch 2959/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8785 - accuracy: 0.5682 - val_loss: 0.9006 - val_accuracy: 0.5553\n",
      "Epoch 2960/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8780 - accuracy: 0.5666 - val_loss: 0.9026 - val_accuracy: 0.5493\n",
      "Epoch 2961/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8790 - accuracy: 0.5677 - val_loss: 0.9002 - val_accuracy: 0.5513\n",
      "Epoch 2962/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8785 - accuracy: 0.5713 - val_loss: 0.9013 - val_accuracy: 0.5533\n",
      "Epoch 2963/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8783 - accuracy: 0.5695 - val_loss: 0.9122 - val_accuracy: 0.5450\n",
      "Epoch 2964/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8781 - accuracy: 0.5684 - val_loss: 0.9013 - val_accuracy: 0.5500\n",
      "Epoch 2965/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8788 - accuracy: 0.5655 - val_loss: 0.9014 - val_accuracy: 0.5580\n",
      "Epoch 2966/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8783 - accuracy: 0.5691 - val_loss: 0.9073 - val_accuracy: 0.5450\n",
      "Epoch 2967/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8789 - accuracy: 0.5664 - val_loss: 0.9047 - val_accuracy: 0.5490\n",
      "Epoch 2968/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8786 - accuracy: 0.5663 - val_loss: 0.9011 - val_accuracy: 0.5527\n",
      "Epoch 2969/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8787 - accuracy: 0.5684 - val_loss: 0.9008 - val_accuracy: 0.5513\n",
      "Epoch 2970/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8776 - accuracy: 0.5667 - val_loss: 0.9003 - val_accuracy: 0.5520\n",
      "Epoch 2971/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8786 - accuracy: 0.5649 - val_loss: 0.9008 - val_accuracy: 0.5517\n",
      "Epoch 2972/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8791 - accuracy: 0.5698 - val_loss: 0.9103 - val_accuracy: 0.5507\n",
      "Epoch 2973/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8788 - accuracy: 0.5669 - val_loss: 0.9165 - val_accuracy: 0.5443\n",
      "Epoch 2974/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8777 - accuracy: 0.5709 - val_loss: 0.9024 - val_accuracy: 0.5527\n",
      "Epoch 2975/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8779 - accuracy: 0.5696 - val_loss: 0.9118 - val_accuracy: 0.5473\n",
      "Epoch 2976/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8784 - accuracy: 0.5674 - val_loss: 0.9009 - val_accuracy: 0.5507\n",
      "Epoch 2977/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8796 - accuracy: 0.5669 - val_loss: 0.9018 - val_accuracy: 0.5510\n",
      "Epoch 2978/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8788 - accuracy: 0.5674 - val_loss: 0.9006 - val_accuracy: 0.5520\n",
      "Epoch 2979/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8781 - accuracy: 0.5663 - val_loss: 0.9079 - val_accuracy: 0.5477\n",
      "Epoch 2980/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8783 - accuracy: 0.5699 - val_loss: 0.9002 - val_accuracy: 0.5517\n",
      "Epoch 2981/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8775 - accuracy: 0.5664 - val_loss: 0.9013 - val_accuracy: 0.5553\n",
      "Epoch 2982/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8777 - accuracy: 0.5680 - val_loss: 0.9006 - val_accuracy: 0.5530\n",
      "Epoch 2983/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8782 - accuracy: 0.5675 - val_loss: 0.9020 - val_accuracy: 0.5480\n",
      "Epoch 2984/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8778 - accuracy: 0.5687 - val_loss: 0.9116 - val_accuracy: 0.5483\n",
      "Epoch 2985/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8788 - accuracy: 0.5684 - val_loss: 0.9009 - val_accuracy: 0.5520\n",
      "Epoch 2986/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8782 - accuracy: 0.5700 - val_loss: 0.9006 - val_accuracy: 0.5553\n",
      "Epoch 2987/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8781 - accuracy: 0.5707 - val_loss: 0.9012 - val_accuracy: 0.5503\n",
      "Epoch 2988/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8790 - accuracy: 0.5696 - val_loss: 0.9027 - val_accuracy: 0.5500\n",
      "Epoch 2989/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8776 - accuracy: 0.5683 - val_loss: 0.9026 - val_accuracy: 0.5527\n",
      "Epoch 2990/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8782 - accuracy: 0.5676 - val_loss: 0.9078 - val_accuracy: 0.5483\n",
      "Epoch 2991/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8784 - accuracy: 0.5693 - val_loss: 0.9035 - val_accuracy: 0.5523\n",
      "Epoch 2992/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8783 - accuracy: 0.5683 - val_loss: 0.9037 - val_accuracy: 0.5520\n",
      "Epoch 2993/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8782 - accuracy: 0.5685 - val_loss: 0.9010 - val_accuracy: 0.5520\n",
      "Epoch 2994/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8780 - accuracy: 0.5656 - val_loss: 0.9027 - val_accuracy: 0.5520\n",
      "Epoch 2995/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8785 - accuracy: 0.5704 - val_loss: 0.9015 - val_accuracy: 0.5513\n",
      "Epoch 2996/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8780 - accuracy: 0.5686 - val_loss: 0.9026 - val_accuracy: 0.5510\n",
      "Epoch 2997/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8787 - accuracy: 0.5714 - val_loss: 0.9058 - val_accuracy: 0.5473\n",
      "Epoch 2998/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8780 - accuracy: 0.5678 - val_loss: 0.9065 - val_accuracy: 0.5500\n",
      "Epoch 2999/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8775 - accuracy: 0.5708 - val_loss: 0.9018 - val_accuracy: 0.5477\n",
      "Epoch 3000/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8782 - accuracy: 0.5696 - val_loss: 0.9018 - val_accuracy: 0.5550\n",
      "Epoch 3001/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8786 - accuracy: 0.5681 - val_loss: 0.9001 - val_accuracy: 0.5497\n",
      "Epoch 3002/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8781 - accuracy: 0.5681 - val_loss: 0.9007 - val_accuracy: 0.5553\n",
      "Epoch 3003/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8782 - accuracy: 0.5676 - val_loss: 0.9025 - val_accuracy: 0.5540\n",
      "Epoch 3004/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8780 - accuracy: 0.5686 - val_loss: 0.9037 - val_accuracy: 0.5527\n",
      "Epoch 3005/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8785 - accuracy: 0.5682 - val_loss: 0.9005 - val_accuracy: 0.5493\n",
      "Epoch 3006/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8770 - accuracy: 0.5716 - val_loss: 0.9004 - val_accuracy: 0.5503\n",
      "Epoch 3007/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8777 - accuracy: 0.5680 - val_loss: 0.9003 - val_accuracy: 0.5513\n",
      "Epoch 3008/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8784 - accuracy: 0.5648 - val_loss: 0.9104 - val_accuracy: 0.5507\n",
      "Epoch 3009/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8781 - accuracy: 0.5698 - val_loss: 0.9005 - val_accuracy: 0.5533\n",
      "Epoch 3010/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8779 - accuracy: 0.5717 - val_loss: 0.9170 - val_accuracy: 0.5437\n",
      "Epoch 3011/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8776 - accuracy: 0.5701 - val_loss: 0.9010 - val_accuracy: 0.5557\n",
      "Epoch 3012/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8778 - accuracy: 0.5677 - val_loss: 0.9024 - val_accuracy: 0.5523\n",
      "Epoch 3013/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8770 - accuracy: 0.5689 - val_loss: 0.9073 - val_accuracy: 0.5520\n",
      "Epoch 3014/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8773 - accuracy: 0.5706 - val_loss: 0.8999 - val_accuracy: 0.5540\n",
      "Epoch 3015/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8781 - accuracy: 0.5726 - val_loss: 0.9013 - val_accuracy: 0.5537\n",
      "Epoch 3016/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8773 - accuracy: 0.5711 - val_loss: 0.9062 - val_accuracy: 0.5507\n",
      "Epoch 3017/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8769 - accuracy: 0.5698 - val_loss: 0.9002 - val_accuracy: 0.5537\n",
      "Epoch 3018/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8776 - accuracy: 0.5685 - val_loss: 0.9015 - val_accuracy: 0.5513\n",
      "Epoch 3019/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8774 - accuracy: 0.5699 - val_loss: 0.9002 - val_accuracy: 0.5513\n",
      "Epoch 3020/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8786 - accuracy: 0.5669 - val_loss: 0.9034 - val_accuracy: 0.5520\n",
      "Epoch 3021/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8772 - accuracy: 0.5707 - val_loss: 0.9043 - val_accuracy: 0.5470\n",
      "Epoch 3022/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8779 - accuracy: 0.5721 - val_loss: 0.8999 - val_accuracy: 0.5517\n",
      "Epoch 3023/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8773 - accuracy: 0.5701 - val_loss: 0.9008 - val_accuracy: 0.5493\n",
      "Epoch 3024/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8771 - accuracy: 0.5729 - val_loss: 0.9045 - val_accuracy: 0.5567\n",
      "Epoch 3025/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8778 - accuracy: 0.5671 - val_loss: 0.9001 - val_accuracy: 0.5533\n",
      "Epoch 3026/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8776 - accuracy: 0.5729 - val_loss: 0.9047 - val_accuracy: 0.5500\n",
      "Epoch 3027/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8780 - accuracy: 0.5680 - val_loss: 0.9003 - val_accuracy: 0.5497\n",
      "Epoch 3028/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8773 - accuracy: 0.5685 - val_loss: 0.9014 - val_accuracy: 0.5497\n",
      "Epoch 3029/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8768 - accuracy: 0.5679 - val_loss: 0.9028 - val_accuracy: 0.5517\n",
      "Epoch 3030/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8785 - accuracy: 0.5694 - val_loss: 0.9007 - val_accuracy: 0.5527\n",
      "Epoch 3031/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8779 - accuracy: 0.5680 - val_loss: 0.9041 - val_accuracy: 0.5530\n",
      "Epoch 3032/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8776 - accuracy: 0.5716 - val_loss: 0.9136 - val_accuracy: 0.5390\n",
      "Epoch 3033/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8771 - accuracy: 0.5717 - val_loss: 0.9108 - val_accuracy: 0.5487\n",
      "Epoch 3034/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8779 - accuracy: 0.5690 - val_loss: 0.9000 - val_accuracy: 0.5483\n",
      "Epoch 3035/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8781 - accuracy: 0.5710 - val_loss: 0.9009 - val_accuracy: 0.5503\n",
      "Epoch 3036/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8777 - accuracy: 0.5706 - val_loss: 0.9015 - val_accuracy: 0.5550\n",
      "Epoch 3037/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8784 - accuracy: 0.5711 - val_loss: 0.9224 - val_accuracy: 0.5410\n",
      "Epoch 3038/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8768 - accuracy: 0.5686 - val_loss: 0.9001 - val_accuracy: 0.5560\n",
      "Epoch 3039/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8766 - accuracy: 0.5726 - val_loss: 0.9152 - val_accuracy: 0.5453\n",
      "Epoch 3040/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8774 - accuracy: 0.5681 - val_loss: 0.9023 - val_accuracy: 0.5517\n",
      "Epoch 3041/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8777 - accuracy: 0.5673 - val_loss: 0.9027 - val_accuracy: 0.5553\n",
      "Epoch 3042/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8776 - accuracy: 0.5709 - val_loss: 0.9086 - val_accuracy: 0.5513\n",
      "Epoch 3043/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8762 - accuracy: 0.5690 - val_loss: 0.9010 - val_accuracy: 0.5520\n",
      "Epoch 3044/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8774 - accuracy: 0.5672 - val_loss: 0.9022 - val_accuracy: 0.5527\n",
      "Epoch 3045/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8773 - accuracy: 0.5711 - val_loss: 0.9062 - val_accuracy: 0.5510\n",
      "Epoch 3046/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8777 - accuracy: 0.5706 - val_loss: 0.9293 - val_accuracy: 0.5310\n",
      "Epoch 3047/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8773 - accuracy: 0.5710 - val_loss: 0.9028 - val_accuracy: 0.5503\n",
      "Epoch 3048/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8780 - accuracy: 0.5722 - val_loss: 0.9026 - val_accuracy: 0.5503\n",
      "Epoch 3049/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8779 - accuracy: 0.5694 - val_loss: 0.9007 - val_accuracy: 0.5550\n",
      "Epoch 3050/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8769 - accuracy: 0.5699 - val_loss: 0.9111 - val_accuracy: 0.5487\n",
      "Epoch 3051/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8769 - accuracy: 0.5684 - val_loss: 0.9025 - val_accuracy: 0.5507\n",
      "Epoch 3052/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8775 - accuracy: 0.5686 - val_loss: 0.9013 - val_accuracy: 0.5487\n",
      "Epoch 3053/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8769 - accuracy: 0.5671 - val_loss: 0.9003 - val_accuracy: 0.5540\n",
      "Epoch 3054/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8785 - accuracy: 0.5682 - val_loss: 0.9050 - val_accuracy: 0.5513\n",
      "Epoch 3055/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8772 - accuracy: 0.5691 - val_loss: 0.9004 - val_accuracy: 0.5500\n",
      "Epoch 3056/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8773 - accuracy: 0.5701 - val_loss: 0.9030 - val_accuracy: 0.5497\n",
      "Epoch 3057/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8767 - accuracy: 0.5706 - val_loss: 0.9038 - val_accuracy: 0.5500\n",
      "Epoch 3058/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8770 - accuracy: 0.5711 - val_loss: 0.9008 - val_accuracy: 0.5503\n",
      "Epoch 3059/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8772 - accuracy: 0.5693 - val_loss: 0.9024 - val_accuracy: 0.5500\n",
      "Epoch 3060/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8780 - accuracy: 0.5686 - val_loss: 0.9008 - val_accuracy: 0.5537\n",
      "Epoch 3061/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8767 - accuracy: 0.5672 - val_loss: 0.9042 - val_accuracy: 0.5520\n",
      "Epoch 3062/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8771 - accuracy: 0.5670 - val_loss: 0.9021 - val_accuracy: 0.5527\n",
      "Epoch 3063/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8769 - accuracy: 0.5697 - val_loss: 0.9001 - val_accuracy: 0.5553\n",
      "Epoch 3064/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8776 - accuracy: 0.5725 - val_loss: 0.9005 - val_accuracy: 0.5523\n",
      "Epoch 3065/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8775 - accuracy: 0.5669 - val_loss: 0.9004 - val_accuracy: 0.5543\n",
      "Epoch 3066/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8779 - accuracy: 0.5675 - val_loss: 0.9005 - val_accuracy: 0.5510\n",
      "Epoch 3067/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8775 - accuracy: 0.5711 - val_loss: 0.9052 - val_accuracy: 0.5510\n",
      "Epoch 3068/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8769 - accuracy: 0.5716 - val_loss: 0.9006 - val_accuracy: 0.5507\n",
      "Epoch 3069/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8775 - accuracy: 0.5719 - val_loss: 0.9244 - val_accuracy: 0.5413\n",
      "Epoch 3070/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8769 - accuracy: 0.5703 - val_loss: 0.9094 - val_accuracy: 0.5543\n",
      "Epoch 3071/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8770 - accuracy: 0.5656 - val_loss: 0.9017 - val_accuracy: 0.5503\n",
      "Epoch 3072/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8766 - accuracy: 0.5717 - val_loss: 0.9011 - val_accuracy: 0.5547\n",
      "Epoch 3073/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8774 - accuracy: 0.5686 - val_loss: 0.9013 - val_accuracy: 0.5500\n",
      "Epoch 3074/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8772 - accuracy: 0.5691 - val_loss: 0.9070 - val_accuracy: 0.5560\n",
      "Epoch 3075/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8775 - accuracy: 0.5697 - val_loss: 0.8998 - val_accuracy: 0.5523\n",
      "Epoch 3076/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8765 - accuracy: 0.5713 - val_loss: 0.9065 - val_accuracy: 0.5463\n",
      "Epoch 3077/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8769 - accuracy: 0.5685 - val_loss: 0.9003 - val_accuracy: 0.5567\n",
      "Epoch 3078/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8769 - accuracy: 0.5714 - val_loss: 0.9008 - val_accuracy: 0.5520\n",
      "Epoch 3079/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8775 - accuracy: 0.5694 - val_loss: 0.9001 - val_accuracy: 0.5503\n",
      "Epoch 3080/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8771 - accuracy: 0.5690 - val_loss: 0.9000 - val_accuracy: 0.5540\n",
      "Epoch 3081/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8765 - accuracy: 0.5699 - val_loss: 0.9049 - val_accuracy: 0.5490\n",
      "Epoch 3082/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8764 - accuracy: 0.5714 - val_loss: 0.9022 - val_accuracy: 0.5530\n",
      "Epoch 3083/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8775 - accuracy: 0.5661 - val_loss: 0.9013 - val_accuracy: 0.5547\n",
      "Epoch 3084/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8774 - accuracy: 0.5689 - val_loss: 0.9094 - val_accuracy: 0.5407\n",
      "Epoch 3085/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8769 - accuracy: 0.5708 - val_loss: 0.8997 - val_accuracy: 0.5497\n",
      "Epoch 3086/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8780 - accuracy: 0.5709 - val_loss: 0.8998 - val_accuracy: 0.5510\n",
      "Epoch 3087/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8760 - accuracy: 0.5729 - val_loss: 0.9007 - val_accuracy: 0.5593\n",
      "Epoch 3088/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8771 - accuracy: 0.5689 - val_loss: 0.9003 - val_accuracy: 0.5557\n",
      "Epoch 3089/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8769 - accuracy: 0.5689 - val_loss: 0.9025 - val_accuracy: 0.5550\n",
      "Epoch 3090/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8772 - accuracy: 0.5694 - val_loss: 0.9004 - val_accuracy: 0.5520\n",
      "Epoch 3091/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8757 - accuracy: 0.5706 - val_loss: 0.9063 - val_accuracy: 0.5510\n",
      "Epoch 3092/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8776 - accuracy: 0.5701 - val_loss: 0.9020 - val_accuracy: 0.5557\n",
      "Epoch 3093/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8766 - accuracy: 0.5709 - val_loss: 0.9038 - val_accuracy: 0.5497\n",
      "Epoch 3094/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8764 - accuracy: 0.5681 - val_loss: 0.9148 - val_accuracy: 0.5423\n",
      "Epoch 3095/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8769 - accuracy: 0.5700 - val_loss: 0.9015 - val_accuracy: 0.5550\n",
      "Epoch 3096/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.8765 - accuracy: 0.5699 - val_loss: 0.9032 - val_accuracy: 0.5550\n",
      "Epoch 3097/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.8762 - accuracy: 0.5719 - val_loss: 0.9006 - val_accuracy: 0.5517\n",
      "Epoch 3098/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8760 - accuracy: 0.5710 - val_loss: 0.9011 - val_accuracy: 0.5527\n",
      "Epoch 3099/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8764 - accuracy: 0.5709 - val_loss: 0.8996 - val_accuracy: 0.5530\n",
      "Epoch 3100/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8769 - accuracy: 0.5711 - val_loss: 0.9027 - val_accuracy: 0.5513\n",
      "Epoch 3101/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8764 - accuracy: 0.5727 - val_loss: 0.9000 - val_accuracy: 0.5517\n",
      "Epoch 3102/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8764 - accuracy: 0.5713 - val_loss: 0.9011 - val_accuracy: 0.5523\n",
      "Epoch 3103/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8766 - accuracy: 0.5682 - val_loss: 0.9261 - val_accuracy: 0.5313\n",
      "Epoch 3104/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8770 - accuracy: 0.5696 - val_loss: 0.9118 - val_accuracy: 0.5477\n",
      "Epoch 3105/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8761 - accuracy: 0.5706 - val_loss: 0.9064 - val_accuracy: 0.5493\n",
      "Epoch 3106/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8763 - accuracy: 0.5719 - val_loss: 0.8996 - val_accuracy: 0.5553\n",
      "Epoch 3107/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8773 - accuracy: 0.5681 - val_loss: 0.9020 - val_accuracy: 0.5527\n",
      "Epoch 3108/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8775 - accuracy: 0.5681 - val_loss: 0.9185 - val_accuracy: 0.5440\n",
      "Epoch 3109/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8759 - accuracy: 0.5711 - val_loss: 0.9005 - val_accuracy: 0.5543\n",
      "Epoch 3110/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8770 - accuracy: 0.5705 - val_loss: 0.9034 - val_accuracy: 0.5520\n",
      "Epoch 3111/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8761 - accuracy: 0.5715 - val_loss: 0.9089 - val_accuracy: 0.5480\n",
      "Epoch 3112/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8764 - accuracy: 0.5709 - val_loss: 0.9026 - val_accuracy: 0.5557\n",
      "Epoch 3113/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8768 - accuracy: 0.5675 - val_loss: 0.9007 - val_accuracy: 0.5570\n",
      "Epoch 3114/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8770 - accuracy: 0.5719 - val_loss: 0.9015 - val_accuracy: 0.5547\n",
      "Epoch 3115/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8760 - accuracy: 0.5716 - val_loss: 0.9038 - val_accuracy: 0.5510\n",
      "Epoch 3116/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8780 - accuracy: 0.5687 - val_loss: 0.9002 - val_accuracy: 0.5537\n",
      "Epoch 3117/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8764 - accuracy: 0.5677 - val_loss: 0.9103 - val_accuracy: 0.5400\n",
      "Epoch 3118/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8766 - accuracy: 0.5700 - val_loss: 0.9017 - val_accuracy: 0.5570\n",
      "Epoch 3119/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8759 - accuracy: 0.5696 - val_loss: 0.9050 - val_accuracy: 0.5520\n",
      "Epoch 3120/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8764 - accuracy: 0.5677 - val_loss: 0.9006 - val_accuracy: 0.5557\n",
      "Epoch 3121/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8761 - accuracy: 0.5719 - val_loss: 0.9005 - val_accuracy: 0.5573\n",
      "Epoch 3122/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8759 - accuracy: 0.5664 - val_loss: 0.9020 - val_accuracy: 0.5523\n",
      "Epoch 3123/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8773 - accuracy: 0.5716 - val_loss: 0.8998 - val_accuracy: 0.5570\n",
      "Epoch 3124/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8766 - accuracy: 0.5678 - val_loss: 0.9059 - val_accuracy: 0.5500\n",
      "Epoch 3125/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8764 - accuracy: 0.5706 - val_loss: 0.9064 - val_accuracy: 0.5567\n",
      "Epoch 3126/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8769 - accuracy: 0.5669 - val_loss: 0.9014 - val_accuracy: 0.5527\n",
      "Epoch 3127/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8766 - accuracy: 0.5690 - val_loss: 0.9024 - val_accuracy: 0.5533\n",
      "Epoch 3128/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8771 - accuracy: 0.5687 - val_loss: 0.9378 - val_accuracy: 0.5320\n",
      "Epoch 3129/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8758 - accuracy: 0.5715 - val_loss: 0.8998 - val_accuracy: 0.5497\n",
      "Epoch 3130/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8761 - accuracy: 0.5692 - val_loss: 0.9000 - val_accuracy: 0.5590\n",
      "Epoch 3131/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8759 - accuracy: 0.5703 - val_loss: 0.9008 - val_accuracy: 0.5510\n",
      "Epoch 3132/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8765 - accuracy: 0.5718 - val_loss: 0.9005 - val_accuracy: 0.5533\n",
      "Epoch 3133/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8756 - accuracy: 0.5697 - val_loss: 0.9045 - val_accuracy: 0.5540\n",
      "Epoch 3134/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8765 - accuracy: 0.5730 - val_loss: 0.9128 - val_accuracy: 0.5433\n",
      "Epoch 3135/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8768 - accuracy: 0.5690 - val_loss: 0.8998 - val_accuracy: 0.5523\n",
      "Epoch 3136/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8760 - accuracy: 0.5709 - val_loss: 0.9040 - val_accuracy: 0.5560\n",
      "Epoch 3137/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8758 - accuracy: 0.5717 - val_loss: 0.9028 - val_accuracy: 0.5557\n",
      "Epoch 3138/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8766 - accuracy: 0.5709 - val_loss: 0.9021 - val_accuracy: 0.5567\n",
      "Epoch 3139/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8765 - accuracy: 0.5689 - val_loss: 0.8998 - val_accuracy: 0.5503\n",
      "Epoch 3140/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8766 - accuracy: 0.5691 - val_loss: 0.9006 - val_accuracy: 0.5537\n",
      "Epoch 3141/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8762 - accuracy: 0.5713 - val_loss: 0.9000 - val_accuracy: 0.5503\n",
      "Epoch 3142/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8764 - accuracy: 0.5690 - val_loss: 0.9063 - val_accuracy: 0.5537\n",
      "Epoch 3143/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8754 - accuracy: 0.5726 - val_loss: 0.9049 - val_accuracy: 0.5517\n",
      "Epoch 3144/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8774 - accuracy: 0.5664 - val_loss: 0.9284 - val_accuracy: 0.5357\n",
      "Epoch 3145/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8764 - accuracy: 0.5697 - val_loss: 0.8995 - val_accuracy: 0.5520\n",
      "Epoch 3146/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8757 - accuracy: 0.5708 - val_loss: 0.9002 - val_accuracy: 0.5527\n",
      "Epoch 3147/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8757 - accuracy: 0.5709 - val_loss: 0.9009 - val_accuracy: 0.5510\n",
      "Epoch 3148/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8762 - accuracy: 0.5695 - val_loss: 0.9001 - val_accuracy: 0.5520\n",
      "Epoch 3149/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8770 - accuracy: 0.5696 - val_loss: 0.9151 - val_accuracy: 0.5400\n",
      "Epoch 3150/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8761 - accuracy: 0.5685 - val_loss: 0.9068 - val_accuracy: 0.5527\n",
      "Epoch 3151/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8761 - accuracy: 0.5689 - val_loss: 0.9124 - val_accuracy: 0.5480\n",
      "Epoch 3152/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8759 - accuracy: 0.5713 - val_loss: 0.9012 - val_accuracy: 0.5553\n",
      "Epoch 3153/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8770 - accuracy: 0.5677 - val_loss: 0.9007 - val_accuracy: 0.5523\n",
      "Epoch 3154/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8770 - accuracy: 0.5696 - val_loss: 0.9001 - val_accuracy: 0.5500\n",
      "Epoch 3155/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8770 - accuracy: 0.5677 - val_loss: 0.9053 - val_accuracy: 0.5550\n",
      "Epoch 3156/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8754 - accuracy: 0.5714 - val_loss: 0.9007 - val_accuracy: 0.5567\n",
      "Epoch 3157/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8766 - accuracy: 0.5701 - val_loss: 0.9005 - val_accuracy: 0.5577\n",
      "Epoch 3158/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8755 - accuracy: 0.5701 - val_loss: 0.9006 - val_accuracy: 0.5500\n",
      "Epoch 3159/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8756 - accuracy: 0.5683 - val_loss: 0.9026 - val_accuracy: 0.5547\n",
      "Epoch 3160/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8757 - accuracy: 0.5697 - val_loss: 0.9015 - val_accuracy: 0.5557\n",
      "Epoch 3161/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8754 - accuracy: 0.5719 - val_loss: 0.9034 - val_accuracy: 0.5567\n",
      "Epoch 3162/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8756 - accuracy: 0.5712 - val_loss: 0.9042 - val_accuracy: 0.5490\n",
      "Epoch 3163/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8756 - accuracy: 0.5718 - val_loss: 0.9040 - val_accuracy: 0.5513\n",
      "Epoch 3164/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8758 - accuracy: 0.5714 - val_loss: 0.9033 - val_accuracy: 0.5500\n",
      "Epoch 3165/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8757 - accuracy: 0.5697 - val_loss: 0.8999 - val_accuracy: 0.5530\n",
      "Epoch 3166/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8757 - accuracy: 0.5705 - val_loss: 0.9023 - val_accuracy: 0.5553\n",
      "Epoch 3167/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8755 - accuracy: 0.5745 - val_loss: 0.9006 - val_accuracy: 0.5550\n",
      "Epoch 3168/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8758 - accuracy: 0.5728 - val_loss: 0.9078 - val_accuracy: 0.5453\n",
      "Epoch 3169/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8751 - accuracy: 0.5696 - val_loss: 0.9115 - val_accuracy: 0.5470\n",
      "Epoch 3170/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8756 - accuracy: 0.5695 - val_loss: 0.9064 - val_accuracy: 0.5530\n",
      "Epoch 3171/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8765 - accuracy: 0.5702 - val_loss: 0.9018 - val_accuracy: 0.5537\n",
      "Epoch 3172/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8750 - accuracy: 0.5713 - val_loss: 0.9015 - val_accuracy: 0.5527\n",
      "Epoch 3173/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8757 - accuracy: 0.5690 - val_loss: 0.9064 - val_accuracy: 0.5490\n",
      "Epoch 3174/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8762 - accuracy: 0.5724 - val_loss: 0.9093 - val_accuracy: 0.5513\n",
      "Epoch 3175/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8759 - accuracy: 0.5686 - val_loss: 0.8996 - val_accuracy: 0.5513\n",
      "Epoch 3176/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8764 - accuracy: 0.5705 - val_loss: 0.9036 - val_accuracy: 0.5520\n",
      "Epoch 3177/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8764 - accuracy: 0.5705 - val_loss: 0.8998 - val_accuracy: 0.5507\n",
      "Epoch 3178/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8766 - accuracy: 0.5677 - val_loss: 0.8994 - val_accuracy: 0.5530\n",
      "Epoch 3179/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8757 - accuracy: 0.5713 - val_loss: 0.9013 - val_accuracy: 0.5523\n",
      "Epoch 3180/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8760 - accuracy: 0.5680 - val_loss: 0.9046 - val_accuracy: 0.5597\n",
      "Epoch 3181/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8755 - accuracy: 0.5710 - val_loss: 0.9042 - val_accuracy: 0.5603\n",
      "Epoch 3182/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8750 - accuracy: 0.5717 - val_loss: 0.9007 - val_accuracy: 0.5557\n",
      "Epoch 3183/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8751 - accuracy: 0.5693 - val_loss: 0.9014 - val_accuracy: 0.5550\n",
      "Epoch 3184/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8757 - accuracy: 0.5734 - val_loss: 0.9060 - val_accuracy: 0.5553\n",
      "Epoch 3185/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8761 - accuracy: 0.5736 - val_loss: 0.9018 - val_accuracy: 0.5500\n",
      "Epoch 3186/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8764 - accuracy: 0.5698 - val_loss: 0.9008 - val_accuracy: 0.5540\n",
      "Epoch 3187/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8765 - accuracy: 0.5700 - val_loss: 0.9008 - val_accuracy: 0.5550\n",
      "Epoch 3188/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8763 - accuracy: 0.5700 - val_loss: 0.9108 - val_accuracy: 0.5467\n",
      "Epoch 3189/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8752 - accuracy: 0.5736 - val_loss: 0.9012 - val_accuracy: 0.5570\n",
      "Epoch 3190/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8762 - accuracy: 0.5713 - val_loss: 0.9095 - val_accuracy: 0.5557\n",
      "Epoch 3191/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8752 - accuracy: 0.5717 - val_loss: 0.9044 - val_accuracy: 0.5557\n",
      "Epoch 3192/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8751 - accuracy: 0.5695 - val_loss: 0.9005 - val_accuracy: 0.5557\n",
      "Epoch 3193/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8757 - accuracy: 0.5711 - val_loss: 0.8994 - val_accuracy: 0.5533\n",
      "Epoch 3194/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8749 - accuracy: 0.5729 - val_loss: 0.9007 - val_accuracy: 0.5517\n",
      "Epoch 3195/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8759 - accuracy: 0.5711 - val_loss: 0.9050 - val_accuracy: 0.5573\n",
      "Epoch 3196/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8755 - accuracy: 0.5714 - val_loss: 0.8998 - val_accuracy: 0.5513\n",
      "Epoch 3197/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8751 - accuracy: 0.5736 - val_loss: 0.9324 - val_accuracy: 0.5357\n",
      "Epoch 3198/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8759 - accuracy: 0.5690 - val_loss: 0.9107 - val_accuracy: 0.5480\n",
      "Epoch 3199/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8747 - accuracy: 0.5723 - val_loss: 0.9018 - val_accuracy: 0.5517\n",
      "Epoch 3200/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8763 - accuracy: 0.5699 - val_loss: 0.9061 - val_accuracy: 0.5497\n",
      "Epoch 3201/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8758 - accuracy: 0.5696 - val_loss: 0.9078 - val_accuracy: 0.5500\n",
      "Epoch 3202/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8750 - accuracy: 0.5717 - val_loss: 0.9004 - val_accuracy: 0.5563\n",
      "Epoch 3203/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8746 - accuracy: 0.5716 - val_loss: 0.9019 - val_accuracy: 0.5530\n",
      "Epoch 3204/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8757 - accuracy: 0.5732 - val_loss: 0.9040 - val_accuracy: 0.5603\n",
      "Epoch 3205/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8763 - accuracy: 0.5704 - val_loss: 0.8997 - val_accuracy: 0.5557\n",
      "Epoch 3206/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8751 - accuracy: 0.5709 - val_loss: 0.9060 - val_accuracy: 0.5453\n",
      "Epoch 3207/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8748 - accuracy: 0.5714 - val_loss: 0.9001 - val_accuracy: 0.5527\n",
      "Epoch 3208/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8751 - accuracy: 0.5709 - val_loss: 0.9127 - val_accuracy: 0.5493\n",
      "Epoch 3209/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8760 - accuracy: 0.5721 - val_loss: 0.9052 - val_accuracy: 0.5533\n",
      "Epoch 3210/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8757 - accuracy: 0.5681 - val_loss: 0.9001 - val_accuracy: 0.5493\n",
      "Epoch 3211/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8745 - accuracy: 0.5756 - val_loss: 0.9001 - val_accuracy: 0.5580\n",
      "Epoch 3212/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8752 - accuracy: 0.5689 - val_loss: 0.9002 - val_accuracy: 0.5570\n",
      "Epoch 3213/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8759 - accuracy: 0.5730 - val_loss: 0.9010 - val_accuracy: 0.5507\n",
      "Epoch 3214/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8754 - accuracy: 0.5696 - val_loss: 0.9226 - val_accuracy: 0.5397\n",
      "Epoch 3215/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8756 - accuracy: 0.5719 - val_loss: 0.9059 - val_accuracy: 0.5530\n",
      "Epoch 3216/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8756 - accuracy: 0.5711 - val_loss: 0.8996 - val_accuracy: 0.5537\n",
      "Epoch 3217/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8753 - accuracy: 0.5698 - val_loss: 0.9005 - val_accuracy: 0.5560\n",
      "Epoch 3218/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8754 - accuracy: 0.5711 - val_loss: 0.8997 - val_accuracy: 0.5503\n",
      "Epoch 3219/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8753 - accuracy: 0.5714 - val_loss: 0.9071 - val_accuracy: 0.5513\n",
      "Epoch 3220/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8754 - accuracy: 0.5681 - val_loss: 0.9017 - val_accuracy: 0.5537\n",
      "Epoch 3221/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8754 - accuracy: 0.5704 - val_loss: 0.9006 - val_accuracy: 0.5497\n",
      "Epoch 3222/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8754 - accuracy: 0.5735 - val_loss: 0.9035 - val_accuracy: 0.5530\n",
      "Epoch 3223/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8749 - accuracy: 0.5701 - val_loss: 0.9075 - val_accuracy: 0.5497\n",
      "Epoch 3224/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8755 - accuracy: 0.5707 - val_loss: 0.9000 - val_accuracy: 0.5497\n",
      "Epoch 3225/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8747 - accuracy: 0.5713 - val_loss: 0.8996 - val_accuracy: 0.5540\n",
      "Epoch 3226/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8758 - accuracy: 0.5719 - val_loss: 0.9155 - val_accuracy: 0.5470\n",
      "Epoch 3227/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8752 - accuracy: 0.5729 - val_loss: 0.9033 - val_accuracy: 0.5513\n",
      "Epoch 3228/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8757 - accuracy: 0.5731 - val_loss: 0.9006 - val_accuracy: 0.5557\n",
      "Epoch 3229/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8753 - accuracy: 0.5708 - val_loss: 0.9109 - val_accuracy: 0.5467\n",
      "Epoch 3230/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8769 - accuracy: 0.5686 - val_loss: 0.9123 - val_accuracy: 0.5480\n",
      "Epoch 3231/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8754 - accuracy: 0.5726 - val_loss: 0.9052 - val_accuracy: 0.5500\n",
      "Epoch 3232/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8747 - accuracy: 0.5694 - val_loss: 0.9015 - val_accuracy: 0.5543\n",
      "Epoch 3233/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8755 - accuracy: 0.5684 - val_loss: 0.9039 - val_accuracy: 0.5507\n",
      "Epoch 3234/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8757 - accuracy: 0.5679 - val_loss: 0.9075 - val_accuracy: 0.5550\n",
      "Epoch 3235/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8748 - accuracy: 0.5706 - val_loss: 0.9187 - val_accuracy: 0.5403\n",
      "Epoch 3236/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8744 - accuracy: 0.5714 - val_loss: 0.9069 - val_accuracy: 0.5493\n",
      "Epoch 3237/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8758 - accuracy: 0.5720 - val_loss: 0.9003 - val_accuracy: 0.5507\n",
      "Epoch 3238/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8756 - accuracy: 0.5670 - val_loss: 0.9005 - val_accuracy: 0.5537\n",
      "Epoch 3239/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8749 - accuracy: 0.5713 - val_loss: 0.9006 - val_accuracy: 0.5547\n",
      "Epoch 3240/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8754 - accuracy: 0.5703 - val_loss: 0.9078 - val_accuracy: 0.5477\n",
      "Epoch 3241/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8757 - accuracy: 0.5679 - val_loss: 0.9041 - val_accuracy: 0.5593\n",
      "Epoch 3242/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8744 - accuracy: 0.5751 - val_loss: 0.9014 - val_accuracy: 0.5567\n",
      "Epoch 3243/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8745 - accuracy: 0.5707 - val_loss: 0.9110 - val_accuracy: 0.5453\n",
      "Epoch 3244/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8746 - accuracy: 0.5723 - val_loss: 0.9007 - val_accuracy: 0.5573\n",
      "Epoch 3245/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8748 - accuracy: 0.5704 - val_loss: 0.9129 - val_accuracy: 0.5470\n",
      "Epoch 3246/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8751 - accuracy: 0.5721 - val_loss: 0.8996 - val_accuracy: 0.5563\n",
      "Epoch 3247/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8757 - accuracy: 0.5706 - val_loss: 0.9048 - val_accuracy: 0.5577\n",
      "Epoch 3248/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8751 - accuracy: 0.5704 - val_loss: 0.9066 - val_accuracy: 0.5510\n",
      "Epoch 3249/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8752 - accuracy: 0.5722 - val_loss: 0.8996 - val_accuracy: 0.5533\n",
      "Epoch 3250/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8749 - accuracy: 0.5741 - val_loss: 0.9017 - val_accuracy: 0.5553\n",
      "Epoch 3251/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8745 - accuracy: 0.5724 - val_loss: 0.9051 - val_accuracy: 0.5580\n",
      "Epoch 3252/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8757 - accuracy: 0.5685 - val_loss: 0.9129 - val_accuracy: 0.5437\n",
      "Epoch 3253/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8745 - accuracy: 0.5761 - val_loss: 0.9001 - val_accuracy: 0.5527\n",
      "Epoch 3254/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8748 - accuracy: 0.5722 - val_loss: 0.8997 - val_accuracy: 0.5480\n",
      "Epoch 3255/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8748 - accuracy: 0.5681 - val_loss: 0.9003 - val_accuracy: 0.5577\n",
      "Epoch 3256/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8741 - accuracy: 0.5709 - val_loss: 0.9029 - val_accuracy: 0.5523\n",
      "Epoch 3257/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8743 - accuracy: 0.5711 - val_loss: 0.9025 - val_accuracy: 0.5573\n",
      "Epoch 3258/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8741 - accuracy: 0.5720 - val_loss: 0.9009 - val_accuracy: 0.5563\n",
      "Epoch 3259/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8745 - accuracy: 0.5704 - val_loss: 0.9069 - val_accuracy: 0.5503\n",
      "Epoch 3260/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8750 - accuracy: 0.5714 - val_loss: 0.8995 - val_accuracy: 0.5533\n",
      "Epoch 3261/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8740 - accuracy: 0.5727 - val_loss: 0.9013 - val_accuracy: 0.5547\n",
      "Epoch 3262/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8745 - accuracy: 0.5727 - val_loss: 0.9044 - val_accuracy: 0.5457\n",
      "Epoch 3263/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8736 - accuracy: 0.5726 - val_loss: 0.9007 - val_accuracy: 0.5557\n",
      "Epoch 3264/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8738 - accuracy: 0.5714 - val_loss: 0.8997 - val_accuracy: 0.5550\n",
      "Epoch 3265/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8739 - accuracy: 0.5720 - val_loss: 0.9133 - val_accuracy: 0.5483\n",
      "Epoch 3266/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8748 - accuracy: 0.5714 - val_loss: 0.9047 - val_accuracy: 0.5433\n",
      "Epoch 3267/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8745 - accuracy: 0.5679 - val_loss: 0.9211 - val_accuracy: 0.5383\n",
      "Epoch 3268/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8748 - accuracy: 0.5695 - val_loss: 0.9005 - val_accuracy: 0.5563\n",
      "Epoch 3269/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8733 - accuracy: 0.5723 - val_loss: 0.9006 - val_accuracy: 0.5553\n",
      "Epoch 3270/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8739 - accuracy: 0.5713 - val_loss: 0.9029 - val_accuracy: 0.5540\n",
      "Epoch 3271/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8740 - accuracy: 0.5709 - val_loss: 0.9035 - val_accuracy: 0.5537\n",
      "Epoch 3272/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8747 - accuracy: 0.5728 - val_loss: 0.9006 - val_accuracy: 0.5527\n",
      "Epoch 3273/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8755 - accuracy: 0.5715 - val_loss: 0.9026 - val_accuracy: 0.5527\n",
      "Epoch 3274/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8743 - accuracy: 0.5704 - val_loss: 0.9327 - val_accuracy: 0.5287\n",
      "Epoch 3275/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8740 - accuracy: 0.5716 - val_loss: 0.9060 - val_accuracy: 0.5487\n",
      "Epoch 3276/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8737 - accuracy: 0.5719 - val_loss: 0.9027 - val_accuracy: 0.5513\n",
      "Epoch 3277/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8744 - accuracy: 0.5728 - val_loss: 0.9023 - val_accuracy: 0.5580\n",
      "Epoch 3278/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8749 - accuracy: 0.5719 - val_loss: 0.9038 - val_accuracy: 0.5513\n",
      "Epoch 3279/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8741 - accuracy: 0.5720 - val_loss: 0.9191 - val_accuracy: 0.5393\n",
      "Epoch 3280/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8737 - accuracy: 0.5735 - val_loss: 0.8992 - val_accuracy: 0.5523\n",
      "Epoch 3281/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.8757 - accuracy: 0.5709 - val_loss: 0.9004 - val_accuracy: 0.5533\n",
      "Epoch 3282/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8741 - accuracy: 0.5687 - val_loss: 0.8995 - val_accuracy: 0.5537\n",
      "Epoch 3283/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8746 - accuracy: 0.5729 - val_loss: 0.9024 - val_accuracy: 0.5563\n",
      "Epoch 3284/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8737 - accuracy: 0.5749 - val_loss: 0.9012 - val_accuracy: 0.5523\n",
      "Epoch 3285/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8742 - accuracy: 0.5731 - val_loss: 0.9127 - val_accuracy: 0.5470\n",
      "Epoch 3286/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8738 - accuracy: 0.5724 - val_loss: 0.9201 - val_accuracy: 0.5387\n",
      "Epoch 3287/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8745 - accuracy: 0.5704 - val_loss: 0.9027 - val_accuracy: 0.5517\n",
      "Epoch 3288/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8743 - accuracy: 0.5679 - val_loss: 0.9045 - val_accuracy: 0.5513\n",
      "Epoch 3289/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8744 - accuracy: 0.5679 - val_loss: 0.9015 - val_accuracy: 0.5523\n",
      "Epoch 3290/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8750 - accuracy: 0.5680 - val_loss: 0.9122 - val_accuracy: 0.5400\n",
      "Epoch 3291/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8746 - accuracy: 0.5666 - val_loss: 0.9093 - val_accuracy: 0.5490\n",
      "Epoch 3292/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8747 - accuracy: 0.5717 - val_loss: 0.9073 - val_accuracy: 0.5470\n",
      "Epoch 3293/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8737 - accuracy: 0.5712 - val_loss: 0.8998 - val_accuracy: 0.5570\n",
      "Epoch 3294/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8751 - accuracy: 0.5714 - val_loss: 0.9096 - val_accuracy: 0.5437\n",
      "Epoch 3295/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8733 - accuracy: 0.5704 - val_loss: 0.9253 - val_accuracy: 0.5390\n",
      "Epoch 3296/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8742 - accuracy: 0.5730 - val_loss: 0.9308 - val_accuracy: 0.5300\n",
      "Epoch 3297/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8740 - accuracy: 0.5719 - val_loss: 0.9002 - val_accuracy: 0.5547\n",
      "Epoch 3298/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8750 - accuracy: 0.5725 - val_loss: 0.9084 - val_accuracy: 0.5510\n",
      "Epoch 3299/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8744 - accuracy: 0.5716 - val_loss: 0.9050 - val_accuracy: 0.5610\n",
      "Epoch 3300/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8742 - accuracy: 0.5730 - val_loss: 0.9033 - val_accuracy: 0.5507\n",
      "Epoch 3301/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8736 - accuracy: 0.5698 - val_loss: 0.9013 - val_accuracy: 0.5570\n",
      "Epoch 3302/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8740 - accuracy: 0.5720 - val_loss: 0.8996 - val_accuracy: 0.5513\n",
      "Epoch 3303/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8742 - accuracy: 0.5715 - val_loss: 0.8992 - val_accuracy: 0.5543\n",
      "Epoch 3304/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8745 - accuracy: 0.5725 - val_loss: 0.9034 - val_accuracy: 0.5517\n",
      "Epoch 3305/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8736 - accuracy: 0.5703 - val_loss: 0.8999 - val_accuracy: 0.5553\n",
      "Epoch 3306/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8751 - accuracy: 0.5711 - val_loss: 0.9050 - val_accuracy: 0.5463\n",
      "Epoch 3307/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8739 - accuracy: 0.5693 - val_loss: 0.9128 - val_accuracy: 0.5467\n",
      "Epoch 3308/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8736 - accuracy: 0.5736 - val_loss: 0.9017 - val_accuracy: 0.5533\n",
      "Epoch 3309/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8739 - accuracy: 0.5722 - val_loss: 0.9275 - val_accuracy: 0.5340\n",
      "Epoch 3310/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8757 - accuracy: 0.5689 - val_loss: 0.9064 - val_accuracy: 0.5517\n",
      "Epoch 3311/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8742 - accuracy: 0.5739 - val_loss: 0.9030 - val_accuracy: 0.5520\n",
      "Epoch 3312/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8734 - accuracy: 0.5738 - val_loss: 0.9004 - val_accuracy: 0.5540\n",
      "Epoch 3313/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8743 - accuracy: 0.5676 - val_loss: 0.9031 - val_accuracy: 0.5557\n",
      "Epoch 3314/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8738 - accuracy: 0.5734 - val_loss: 0.8999 - val_accuracy: 0.5560\n",
      "Epoch 3315/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8745 - accuracy: 0.5689 - val_loss: 0.9058 - val_accuracy: 0.5420\n",
      "Epoch 3316/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8750 - accuracy: 0.5726 - val_loss: 0.8990 - val_accuracy: 0.5543\n",
      "Epoch 3317/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8739 - accuracy: 0.5722 - val_loss: 0.9628 - val_accuracy: 0.5200\n",
      "Epoch 3318/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8749 - accuracy: 0.5726 - val_loss: 0.9110 - val_accuracy: 0.5493\n",
      "Epoch 3319/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8734 - accuracy: 0.5734 - val_loss: 0.9040 - val_accuracy: 0.5523\n",
      "Epoch 3320/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8742 - accuracy: 0.5720 - val_loss: 0.8996 - val_accuracy: 0.5527\n",
      "Epoch 3321/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8753 - accuracy: 0.5715 - val_loss: 0.9003 - val_accuracy: 0.5533\n",
      "Epoch 3322/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8749 - accuracy: 0.5700 - val_loss: 0.8996 - val_accuracy: 0.5527\n",
      "Epoch 3323/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8739 - accuracy: 0.5694 - val_loss: 0.9011 - val_accuracy: 0.5493\n",
      "Epoch 3324/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8735 - accuracy: 0.5711 - val_loss: 0.9189 - val_accuracy: 0.5370\n",
      "Epoch 3325/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8741 - accuracy: 0.5700 - val_loss: 0.8991 - val_accuracy: 0.5557\n",
      "Epoch 3326/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8735 - accuracy: 0.5726 - val_loss: 0.9123 - val_accuracy: 0.5480\n",
      "Epoch 3327/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8738 - accuracy: 0.5694 - val_loss: 0.9002 - val_accuracy: 0.5577\n",
      "Epoch 3328/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8745 - accuracy: 0.5709 - val_loss: 0.8996 - val_accuracy: 0.5480\n",
      "Epoch 3329/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8743 - accuracy: 0.5759 - val_loss: 0.9002 - val_accuracy: 0.5537\n",
      "Epoch 3330/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8735 - accuracy: 0.5681 - val_loss: 0.9005 - val_accuracy: 0.5523\n",
      "Epoch 3331/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8727 - accuracy: 0.5735 - val_loss: 0.9019 - val_accuracy: 0.5547\n",
      "Epoch 3332/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8746 - accuracy: 0.5699 - val_loss: 0.9004 - val_accuracy: 0.5543\n",
      "Epoch 3333/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8747 - accuracy: 0.5709 - val_loss: 0.9009 - val_accuracy: 0.5530\n",
      "Epoch 3334/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8733 - accuracy: 0.5696 - val_loss: 0.9125 - val_accuracy: 0.5493\n",
      "Epoch 3335/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8750 - accuracy: 0.5671 - val_loss: 0.8993 - val_accuracy: 0.5547\n",
      "Epoch 3336/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8732 - accuracy: 0.5741 - val_loss: 0.8996 - val_accuracy: 0.5537\n",
      "Epoch 3337/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8747 - accuracy: 0.5691 - val_loss: 0.9070 - val_accuracy: 0.5423\n",
      "Epoch 3338/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8736 - accuracy: 0.5732 - val_loss: 0.9047 - val_accuracy: 0.5500\n",
      "Epoch 3339/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8751 - accuracy: 0.5714 - val_loss: 0.9125 - val_accuracy: 0.5500\n",
      "Epoch 3340/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8732 - accuracy: 0.5751 - val_loss: 0.9007 - val_accuracy: 0.5553\n",
      "Epoch 3341/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8734 - accuracy: 0.5747 - val_loss: 0.9018 - val_accuracy: 0.5530\n",
      "Epoch 3342/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8742 - accuracy: 0.5709 - val_loss: 0.9034 - val_accuracy: 0.5550\n",
      "Epoch 3343/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8725 - accuracy: 0.5734 - val_loss: 0.9093 - val_accuracy: 0.5507\n",
      "Epoch 3344/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8739 - accuracy: 0.5703 - val_loss: 0.9036 - val_accuracy: 0.5540\n",
      "Epoch 3345/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8739 - accuracy: 0.5704 - val_loss: 0.8998 - val_accuracy: 0.5527\n",
      "Epoch 3346/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8741 - accuracy: 0.5717 - val_loss: 0.9007 - val_accuracy: 0.5590\n",
      "Epoch 3347/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8742 - accuracy: 0.5706 - val_loss: 0.9011 - val_accuracy: 0.5520\n",
      "Epoch 3348/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8730 - accuracy: 0.5736 - val_loss: 0.9070 - val_accuracy: 0.5503\n",
      "Epoch 3349/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8737 - accuracy: 0.5706 - val_loss: 0.9004 - val_accuracy: 0.5543\n",
      "Epoch 3350/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8739 - accuracy: 0.5714 - val_loss: 0.9007 - val_accuracy: 0.5517\n",
      "Epoch 3351/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8742 - accuracy: 0.5691 - val_loss: 0.9041 - val_accuracy: 0.5563\n",
      "Epoch 3352/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8734 - accuracy: 0.5715 - val_loss: 0.9109 - val_accuracy: 0.5520\n",
      "Epoch 3353/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8740 - accuracy: 0.5709 - val_loss: 0.9004 - val_accuracy: 0.5553\n",
      "Epoch 3354/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8718 - accuracy: 0.5753 - val_loss: 0.9005 - val_accuracy: 0.5550\n",
      "Epoch 3355/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8745 - accuracy: 0.5717 - val_loss: 0.9020 - val_accuracy: 0.5587\n",
      "Epoch 3356/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8730 - accuracy: 0.5719 - val_loss: 0.9062 - val_accuracy: 0.5463\n",
      "Epoch 3357/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8732 - accuracy: 0.5743 - val_loss: 0.9001 - val_accuracy: 0.5580\n",
      "Epoch 3358/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8743 - accuracy: 0.5715 - val_loss: 0.9078 - val_accuracy: 0.5510\n",
      "Epoch 3359/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8738 - accuracy: 0.5708 - val_loss: 0.9108 - val_accuracy: 0.5543\n",
      "Epoch 3360/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8744 - accuracy: 0.5719 - val_loss: 0.9075 - val_accuracy: 0.5503\n",
      "Epoch 3361/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8739 - accuracy: 0.5704 - val_loss: 0.9145 - val_accuracy: 0.5383\n",
      "Epoch 3362/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8735 - accuracy: 0.5718 - val_loss: 0.9030 - val_accuracy: 0.5540\n",
      "Epoch 3363/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8724 - accuracy: 0.5723 - val_loss: 0.8992 - val_accuracy: 0.5537\n",
      "Epoch 3364/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8733 - accuracy: 0.5728 - val_loss: 0.9007 - val_accuracy: 0.5500\n",
      "Epoch 3365/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8750 - accuracy: 0.5691 - val_loss: 0.9080 - val_accuracy: 0.5517\n",
      "Epoch 3366/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8728 - accuracy: 0.5711 - val_loss: 0.8997 - val_accuracy: 0.5547\n",
      "Epoch 3367/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8734 - accuracy: 0.5692 - val_loss: 0.9085 - val_accuracy: 0.5503\n",
      "Epoch 3368/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8730 - accuracy: 0.5751 - val_loss: 0.9029 - val_accuracy: 0.5553\n",
      "Epoch 3369/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8735 - accuracy: 0.5708 - val_loss: 0.9082 - val_accuracy: 0.5520\n",
      "Epoch 3370/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8734 - accuracy: 0.5729 - val_loss: 0.9053 - val_accuracy: 0.5463\n",
      "Epoch 3371/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8740 - accuracy: 0.5736 - val_loss: 0.8995 - val_accuracy: 0.5567\n",
      "Epoch 3372/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8734 - accuracy: 0.5691 - val_loss: 0.8997 - val_accuracy: 0.5573\n",
      "Epoch 3373/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8738 - accuracy: 0.5705 - val_loss: 0.9050 - val_accuracy: 0.5557\n",
      "Epoch 3374/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8742 - accuracy: 0.5742 - val_loss: 0.9038 - val_accuracy: 0.5543\n",
      "Epoch 3375/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8728 - accuracy: 0.5719 - val_loss: 0.9004 - val_accuracy: 0.5550\n",
      "Epoch 3376/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8741 - accuracy: 0.5691 - val_loss: 0.9005 - val_accuracy: 0.5543\n",
      "Epoch 3377/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8739 - accuracy: 0.5731 - val_loss: 0.9000 - val_accuracy: 0.5507\n",
      "Epoch 3378/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8733 - accuracy: 0.5712 - val_loss: 0.9012 - val_accuracy: 0.5530\n",
      "Epoch 3379/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8747 - accuracy: 0.5683 - val_loss: 0.8993 - val_accuracy: 0.5537\n",
      "Epoch 3380/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8731 - accuracy: 0.5708 - val_loss: 0.8996 - val_accuracy: 0.5543\n",
      "Epoch 3381/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8725 - accuracy: 0.5742 - val_loss: 0.9015 - val_accuracy: 0.5567\n",
      "Epoch 3382/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8737 - accuracy: 0.5734 - val_loss: 0.9021 - val_accuracy: 0.5573\n",
      "Epoch 3383/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8733 - accuracy: 0.5706 - val_loss: 0.9035 - val_accuracy: 0.5543\n",
      "Epoch 3384/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8725 - accuracy: 0.5726 - val_loss: 0.9168 - val_accuracy: 0.5450\n",
      "Epoch 3385/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8736 - accuracy: 0.5718 - val_loss: 0.9311 - val_accuracy: 0.5360\n",
      "Epoch 3386/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8736 - accuracy: 0.5731 - val_loss: 0.9034 - val_accuracy: 0.5563\n",
      "Epoch 3387/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8747 - accuracy: 0.5694 - val_loss: 0.8993 - val_accuracy: 0.5537\n",
      "Epoch 3388/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8738 - accuracy: 0.5701 - val_loss: 0.9018 - val_accuracy: 0.5553\n",
      "Epoch 3389/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8723 - accuracy: 0.5730 - val_loss: 0.9053 - val_accuracy: 0.5483\n",
      "Epoch 3390/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8736 - accuracy: 0.5725 - val_loss: 0.9022 - val_accuracy: 0.5537\n",
      "Epoch 3391/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8732 - accuracy: 0.5706 - val_loss: 0.9136 - val_accuracy: 0.5397\n",
      "Epoch 3392/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8730 - accuracy: 0.5738 - val_loss: 0.9028 - val_accuracy: 0.5547\n",
      "Epoch 3393/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8728 - accuracy: 0.5753 - val_loss: 0.8996 - val_accuracy: 0.5523\n",
      "Epoch 3394/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8739 - accuracy: 0.5727 - val_loss: 0.8995 - val_accuracy: 0.5540\n",
      "Epoch 3395/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8739 - accuracy: 0.5693 - val_loss: 0.8992 - val_accuracy: 0.5547\n",
      "Epoch 3396/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8731 - accuracy: 0.5723 - val_loss: 0.9072 - val_accuracy: 0.5497\n",
      "Epoch 3397/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8730 - accuracy: 0.5714 - val_loss: 0.9000 - val_accuracy: 0.5553\n",
      "Epoch 3398/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8725 - accuracy: 0.5722 - val_loss: 0.9021 - val_accuracy: 0.5537\n",
      "Epoch 3399/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8728 - accuracy: 0.5735 - val_loss: 0.9120 - val_accuracy: 0.5360\n",
      "Epoch 3400/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8749 - accuracy: 0.5716 - val_loss: 0.9032 - val_accuracy: 0.5517\n",
      "Epoch 3401/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8732 - accuracy: 0.5734 - val_loss: 0.9113 - val_accuracy: 0.5410\n",
      "Epoch 3402/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8720 - accuracy: 0.5699 - val_loss: 0.9011 - val_accuracy: 0.5553\n",
      "Epoch 3403/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8742 - accuracy: 0.5733 - val_loss: 0.9004 - val_accuracy: 0.5560\n",
      "Epoch 3404/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8732 - accuracy: 0.5724 - val_loss: 0.9003 - val_accuracy: 0.5580\n",
      "Epoch 3405/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8744 - accuracy: 0.5723 - val_loss: 0.9013 - val_accuracy: 0.5570\n",
      "Epoch 3406/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8724 - accuracy: 0.5740 - val_loss: 0.9018 - val_accuracy: 0.5537\n",
      "Epoch 3407/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8735 - accuracy: 0.5751 - val_loss: 0.9052 - val_accuracy: 0.5510\n",
      "Epoch 3408/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8723 - accuracy: 0.5724 - val_loss: 0.8999 - val_accuracy: 0.5530\n",
      "Epoch 3409/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8724 - accuracy: 0.5739 - val_loss: 0.9241 - val_accuracy: 0.5363\n",
      "Epoch 3410/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8734 - accuracy: 0.5731 - val_loss: 0.9002 - val_accuracy: 0.5513\n",
      "Epoch 3411/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8725 - accuracy: 0.5726 - val_loss: 0.8992 - val_accuracy: 0.5533\n",
      "Epoch 3412/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8737 - accuracy: 0.5709 - val_loss: 0.9228 - val_accuracy: 0.5427\n",
      "Epoch 3413/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8728 - accuracy: 0.5704 - val_loss: 0.8993 - val_accuracy: 0.5547\n",
      "Epoch 3414/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8729 - accuracy: 0.5726 - val_loss: 0.9004 - val_accuracy: 0.5553\n",
      "Epoch 3415/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8735 - accuracy: 0.5696 - val_loss: 0.9009 - val_accuracy: 0.5567\n",
      "Epoch 3416/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8714 - accuracy: 0.5751 - val_loss: 0.8999 - val_accuracy: 0.5570\n",
      "Epoch 3417/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8733 - accuracy: 0.5730 - val_loss: 0.9057 - val_accuracy: 0.5543\n",
      "Epoch 3418/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8730 - accuracy: 0.5732 - val_loss: 0.9053 - val_accuracy: 0.5527\n",
      "Epoch 3419/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8736 - accuracy: 0.5673 - val_loss: 0.9075 - val_accuracy: 0.5530\n",
      "Epoch 3420/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8739 - accuracy: 0.5760 - val_loss: 0.9098 - val_accuracy: 0.5510\n",
      "Epoch 3421/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8733 - accuracy: 0.5696 - val_loss: 0.8994 - val_accuracy: 0.5593\n",
      "Epoch 3422/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8728 - accuracy: 0.5696 - val_loss: 0.9134 - val_accuracy: 0.5510\n",
      "Epoch 3423/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8733 - accuracy: 0.5716 - val_loss: 0.9010 - val_accuracy: 0.5570\n",
      "Epoch 3424/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8728 - accuracy: 0.5730 - val_loss: 0.9020 - val_accuracy: 0.5533\n",
      "Epoch 3425/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8738 - accuracy: 0.5706 - val_loss: 0.9006 - val_accuracy: 0.5600\n",
      "Epoch 3426/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8726 - accuracy: 0.5754 - val_loss: 0.8996 - val_accuracy: 0.5537\n",
      "Epoch 3427/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8736 - accuracy: 0.5727 - val_loss: 0.9069 - val_accuracy: 0.5517\n",
      "Epoch 3428/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8727 - accuracy: 0.5729 - val_loss: 0.9009 - val_accuracy: 0.5557\n",
      "Epoch 3429/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8720 - accuracy: 0.5744 - val_loss: 0.8994 - val_accuracy: 0.5553\n",
      "Epoch 3430/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8724 - accuracy: 0.5741 - val_loss: 0.9001 - val_accuracy: 0.5557\n",
      "Epoch 3431/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8727 - accuracy: 0.5713 - val_loss: 0.9150 - val_accuracy: 0.5440\n",
      "Epoch 3432/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8724 - accuracy: 0.5721 - val_loss: 0.8991 - val_accuracy: 0.5533\n",
      "Epoch 3433/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8732 - accuracy: 0.5758 - val_loss: 0.9006 - val_accuracy: 0.5523\n",
      "Epoch 3434/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8720 - accuracy: 0.5748 - val_loss: 0.9006 - val_accuracy: 0.5533\n",
      "Epoch 3435/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8731 - accuracy: 0.5701 - val_loss: 0.9391 - val_accuracy: 0.5253\n",
      "Epoch 3436/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8730 - accuracy: 0.5733 - val_loss: 0.9012 - val_accuracy: 0.5540\n",
      "Epoch 3437/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8728 - accuracy: 0.5747 - val_loss: 0.8995 - val_accuracy: 0.5563\n",
      "Epoch 3438/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8742 - accuracy: 0.5691 - val_loss: 0.9059 - val_accuracy: 0.5513\n",
      "Epoch 3439/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8738 - accuracy: 0.5704 - val_loss: 0.9454 - val_accuracy: 0.5227\n",
      "Epoch 3440/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8728 - accuracy: 0.5733 - val_loss: 0.8987 - val_accuracy: 0.5543\n",
      "Epoch 3441/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8726 - accuracy: 0.5711 - val_loss: 0.9024 - val_accuracy: 0.5533\n",
      "Epoch 3442/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8733 - accuracy: 0.5726 - val_loss: 0.9018 - val_accuracy: 0.5517\n",
      "Epoch 3443/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8722 - accuracy: 0.5704 - val_loss: 0.8995 - val_accuracy: 0.5563\n",
      "Epoch 3444/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8731 - accuracy: 0.5731 - val_loss: 0.9009 - val_accuracy: 0.5550\n",
      "Epoch 3445/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8725 - accuracy: 0.5736 - val_loss: 0.9019 - val_accuracy: 0.5497\n",
      "Epoch 3446/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8729 - accuracy: 0.5681 - val_loss: 0.9040 - val_accuracy: 0.5500\n",
      "Epoch 3447/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8720 - accuracy: 0.5706 - val_loss: 0.9043 - val_accuracy: 0.5570\n",
      "Epoch 3448/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8707 - accuracy: 0.5744 - val_loss: 0.9006 - val_accuracy: 0.5530\n",
      "Epoch 3449/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8711 - accuracy: 0.5714 - val_loss: 0.9140 - val_accuracy: 0.5487\n",
      "Epoch 3450/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8732 - accuracy: 0.5719 - val_loss: 0.9029 - val_accuracy: 0.5600\n",
      "Epoch 3451/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8722 - accuracy: 0.5726 - val_loss: 0.9033 - val_accuracy: 0.5540\n",
      "Epoch 3452/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8717 - accuracy: 0.5752 - val_loss: 0.8991 - val_accuracy: 0.5560\n",
      "Epoch 3453/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8718 - accuracy: 0.5694 - val_loss: 0.9073 - val_accuracy: 0.5423\n",
      "Epoch 3454/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8722 - accuracy: 0.5724 - val_loss: 0.8999 - val_accuracy: 0.5517\n",
      "Epoch 3455/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8716 - accuracy: 0.5761 - val_loss: 0.9017 - val_accuracy: 0.5580\n",
      "Epoch 3456/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8727 - accuracy: 0.5718 - val_loss: 0.9073 - val_accuracy: 0.5383\n",
      "Epoch 3457/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8723 - accuracy: 0.5712 - val_loss: 0.8988 - val_accuracy: 0.5550\n",
      "Epoch 3458/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8725 - accuracy: 0.5686 - val_loss: 0.9048 - val_accuracy: 0.5570\n",
      "Epoch 3459/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8712 - accuracy: 0.5732 - val_loss: 0.9061 - val_accuracy: 0.5493\n",
      "Epoch 3460/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8730 - accuracy: 0.5756 - val_loss: 0.9002 - val_accuracy: 0.5550\n",
      "Epoch 3461/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8717 - accuracy: 0.5715 - val_loss: 0.9008 - val_accuracy: 0.5540\n",
      "Epoch 3462/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8725 - accuracy: 0.5724 - val_loss: 0.9076 - val_accuracy: 0.5507\n",
      "Epoch 3463/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8719 - accuracy: 0.5729 - val_loss: 0.9002 - val_accuracy: 0.5537\n",
      "Epoch 3464/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8726 - accuracy: 0.5728 - val_loss: 0.9023 - val_accuracy: 0.5577\n",
      "Epoch 3465/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8726 - accuracy: 0.5731 - val_loss: 0.8993 - val_accuracy: 0.5547\n",
      "Epoch 3466/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8710 - accuracy: 0.5748 - val_loss: 0.9007 - val_accuracy: 0.5593\n",
      "Epoch 3467/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8714 - accuracy: 0.5756 - val_loss: 0.9016 - val_accuracy: 0.5597\n",
      "Epoch 3468/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8727 - accuracy: 0.5714 - val_loss: 0.9155 - val_accuracy: 0.5487\n",
      "Epoch 3469/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8721 - accuracy: 0.5736 - val_loss: 0.9005 - val_accuracy: 0.5510\n",
      "Epoch 3470/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8730 - accuracy: 0.5714 - val_loss: 0.9048 - val_accuracy: 0.5583\n",
      "Epoch 3471/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8718 - accuracy: 0.5753 - val_loss: 0.9038 - val_accuracy: 0.5617\n",
      "Epoch 3472/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8721 - accuracy: 0.5751 - val_loss: 0.9017 - val_accuracy: 0.5570\n",
      "Epoch 3473/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8731 - accuracy: 0.5702 - val_loss: 0.9028 - val_accuracy: 0.5490\n",
      "Epoch 3474/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8731 - accuracy: 0.5747 - val_loss: 0.8992 - val_accuracy: 0.5563\n",
      "Epoch 3475/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8716 - accuracy: 0.5735 - val_loss: 0.8997 - val_accuracy: 0.5553\n",
      "Epoch 3476/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8729 - accuracy: 0.5731 - val_loss: 0.9169 - val_accuracy: 0.5420\n",
      "Epoch 3477/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8717 - accuracy: 0.5737 - val_loss: 0.9008 - val_accuracy: 0.5547\n",
      "Epoch 3478/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8717 - accuracy: 0.5731 - val_loss: 0.9375 - val_accuracy: 0.5247\n",
      "Epoch 3479/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8711 - accuracy: 0.5744 - val_loss: 0.9002 - val_accuracy: 0.5537\n",
      "Epoch 3480/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8720 - accuracy: 0.5774 - val_loss: 0.9002 - val_accuracy: 0.5563\n",
      "Epoch 3481/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8728 - accuracy: 0.5718 - val_loss: 0.9041 - val_accuracy: 0.5543\n",
      "Epoch 3482/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8726 - accuracy: 0.5721 - val_loss: 0.9145 - val_accuracy: 0.5463\n",
      "Epoch 3483/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8733 - accuracy: 0.5711 - val_loss: 0.9006 - val_accuracy: 0.5577\n",
      "Epoch 3484/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8732 - accuracy: 0.5720 - val_loss: 0.8993 - val_accuracy: 0.5567\n",
      "Epoch 3485/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8715 - accuracy: 0.5746 - val_loss: 0.9060 - val_accuracy: 0.5577\n",
      "Epoch 3486/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8715 - accuracy: 0.5741 - val_loss: 0.9099 - val_accuracy: 0.5487\n",
      "Epoch 3487/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8725 - accuracy: 0.5749 - val_loss: 0.9036 - val_accuracy: 0.5557\n",
      "Epoch 3488/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8726 - accuracy: 0.5723 - val_loss: 0.9004 - val_accuracy: 0.5523\n",
      "Epoch 3489/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8721 - accuracy: 0.5775 - val_loss: 0.9064 - val_accuracy: 0.5467\n",
      "Epoch 3490/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8709 - accuracy: 0.5727 - val_loss: 0.9052 - val_accuracy: 0.5493\n",
      "Epoch 3491/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8717 - accuracy: 0.5769 - val_loss: 0.8990 - val_accuracy: 0.5513\n",
      "Epoch 3492/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8730 - accuracy: 0.5735 - val_loss: 0.9008 - val_accuracy: 0.5550\n",
      "Epoch 3493/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8725 - accuracy: 0.5742 - val_loss: 0.9006 - val_accuracy: 0.5483\n",
      "Epoch 3494/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8718 - accuracy: 0.5711 - val_loss: 0.9002 - val_accuracy: 0.5563\n",
      "Epoch 3495/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8724 - accuracy: 0.5731 - val_loss: 0.8999 - val_accuracy: 0.5570\n",
      "Epoch 3496/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8716 - accuracy: 0.5740 - val_loss: 0.8986 - val_accuracy: 0.5567\n",
      "Epoch 3497/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8717 - accuracy: 0.5738 - val_loss: 0.9373 - val_accuracy: 0.5257\n",
      "Epoch 3498/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8718 - accuracy: 0.5716 - val_loss: 0.9032 - val_accuracy: 0.5567\n",
      "Epoch 3499/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8716 - accuracy: 0.5740 - val_loss: 0.9003 - val_accuracy: 0.5563\n",
      "Epoch 3500/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8714 - accuracy: 0.5776 - val_loss: 0.9029 - val_accuracy: 0.5530\n",
      "Epoch 3501/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8725 - accuracy: 0.5689 - val_loss: 0.9016 - val_accuracy: 0.5577\n",
      "Epoch 3502/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8718 - accuracy: 0.5731 - val_loss: 0.9002 - val_accuracy: 0.5517\n",
      "Epoch 3503/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8718 - accuracy: 0.5721 - val_loss: 0.9226 - val_accuracy: 0.5370\n",
      "Epoch 3504/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8720 - accuracy: 0.5712 - val_loss: 0.9035 - val_accuracy: 0.5560\n",
      "Epoch 3505/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8725 - accuracy: 0.5708 - val_loss: 0.9129 - val_accuracy: 0.5513\n",
      "Epoch 3506/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8720 - accuracy: 0.5719 - val_loss: 0.8998 - val_accuracy: 0.5523\n",
      "Epoch 3507/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8713 - accuracy: 0.5766 - val_loss: 0.9016 - val_accuracy: 0.5557\n",
      "Epoch 3508/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8715 - accuracy: 0.5728 - val_loss: 0.9138 - val_accuracy: 0.5433\n",
      "Epoch 3509/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8707 - accuracy: 0.5743 - val_loss: 0.9005 - val_accuracy: 0.5543\n",
      "Epoch 3510/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8723 - accuracy: 0.5741 - val_loss: 0.8999 - val_accuracy: 0.5547\n",
      "Epoch 3511/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8700 - accuracy: 0.5764 - val_loss: 0.9120 - val_accuracy: 0.5520\n",
      "Epoch 3512/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8727 - accuracy: 0.5708 - val_loss: 0.9063 - val_accuracy: 0.5450\n",
      "Epoch 3513/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8726 - accuracy: 0.5716 - val_loss: 0.9003 - val_accuracy: 0.5560\n",
      "Epoch 3514/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8718 - accuracy: 0.5714 - val_loss: 0.9008 - val_accuracy: 0.5577\n",
      "Epoch 3515/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8710 - accuracy: 0.5728 - val_loss: 0.9047 - val_accuracy: 0.5520\n",
      "Epoch 3516/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8719 - accuracy: 0.5726 - val_loss: 0.9101 - val_accuracy: 0.5483\n",
      "Epoch 3517/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8722 - accuracy: 0.5766 - val_loss: 0.9046 - val_accuracy: 0.5510\n",
      "Epoch 3518/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8719 - accuracy: 0.5719 - val_loss: 0.9064 - val_accuracy: 0.5580\n",
      "Epoch 3519/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8711 - accuracy: 0.5738 - val_loss: 0.9062 - val_accuracy: 0.5443\n",
      "Epoch 3520/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8718 - accuracy: 0.5715 - val_loss: 0.9003 - val_accuracy: 0.5550\n",
      "Epoch 3521/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8716 - accuracy: 0.5774 - val_loss: 0.9063 - val_accuracy: 0.5583\n",
      "Epoch 3522/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8716 - accuracy: 0.5724 - val_loss: 0.9416 - val_accuracy: 0.5260\n",
      "Epoch 3523/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8700 - accuracy: 0.5782 - val_loss: 0.8996 - val_accuracy: 0.5533\n",
      "Epoch 3524/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8719 - accuracy: 0.5719 - val_loss: 0.9043 - val_accuracy: 0.5517\n",
      "Epoch 3525/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8709 - accuracy: 0.5741 - val_loss: 0.9009 - val_accuracy: 0.5560\n",
      "Epoch 3526/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8718 - accuracy: 0.5706 - val_loss: 0.9033 - val_accuracy: 0.5557\n",
      "Epoch 3527/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8713 - accuracy: 0.5763 - val_loss: 0.9053 - val_accuracy: 0.5563\n",
      "Epoch 3528/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8712 - accuracy: 0.5751 - val_loss: 0.9040 - val_accuracy: 0.5557\n",
      "Epoch 3529/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8720 - accuracy: 0.5726 - val_loss: 0.9210 - val_accuracy: 0.5450\n",
      "Epoch 3530/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8731 - accuracy: 0.5722 - val_loss: 0.9018 - val_accuracy: 0.5540\n",
      "Epoch 3531/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8718 - accuracy: 0.5701 - val_loss: 0.9030 - val_accuracy: 0.5613\n",
      "Epoch 3532/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8733 - accuracy: 0.5737 - val_loss: 0.9015 - val_accuracy: 0.5567\n",
      "Epoch 3533/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8713 - accuracy: 0.5724 - val_loss: 0.8993 - val_accuracy: 0.5587\n",
      "Epoch 3534/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8714 - accuracy: 0.5741 - val_loss: 0.8994 - val_accuracy: 0.5533\n",
      "Epoch 3535/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8736 - accuracy: 0.5695 - val_loss: 0.9048 - val_accuracy: 0.5580\n",
      "Epoch 3536/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8719 - accuracy: 0.5749 - val_loss: 0.9000 - val_accuracy: 0.5550\n",
      "Epoch 3537/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8731 - accuracy: 0.5752 - val_loss: 0.9042 - val_accuracy: 0.5543\n",
      "Epoch 3538/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8718 - accuracy: 0.5689 - val_loss: 0.8993 - val_accuracy: 0.5600\n",
      "Epoch 3539/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8711 - accuracy: 0.5722 - val_loss: 0.8990 - val_accuracy: 0.5553\n",
      "Epoch 3540/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8717 - accuracy: 0.5748 - val_loss: 0.9179 - val_accuracy: 0.5477\n",
      "Epoch 3541/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8708 - accuracy: 0.5731 - val_loss: 0.8999 - val_accuracy: 0.5537\n",
      "Epoch 3542/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8716 - accuracy: 0.5714 - val_loss: 0.9030 - val_accuracy: 0.5603\n",
      "Epoch 3543/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8725 - accuracy: 0.5729 - val_loss: 0.9042 - val_accuracy: 0.5567\n",
      "Epoch 3544/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8708 - accuracy: 0.5730 - val_loss: 0.9009 - val_accuracy: 0.5517\n",
      "Epoch 3545/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8727 - accuracy: 0.5718 - val_loss: 0.8991 - val_accuracy: 0.5593\n",
      "Epoch 3546/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8719 - accuracy: 0.5741 - val_loss: 0.9165 - val_accuracy: 0.5457\n",
      "Epoch 3547/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8720 - accuracy: 0.5731 - val_loss: 0.9083 - val_accuracy: 0.5530\n",
      "Epoch 3548/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8719 - accuracy: 0.5709 - val_loss: 0.9005 - val_accuracy: 0.5570\n",
      "Epoch 3549/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8718 - accuracy: 0.5733 - val_loss: 0.9060 - val_accuracy: 0.5550\n",
      "Epoch 3550/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8700 - accuracy: 0.5786 - val_loss: 0.9023 - val_accuracy: 0.5527\n",
      "Epoch 3551/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8705 - accuracy: 0.5705 - val_loss: 0.9053 - val_accuracy: 0.5527\n",
      "Epoch 3552/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8722 - accuracy: 0.5725 - val_loss: 0.9014 - val_accuracy: 0.5537\n",
      "Epoch 3553/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8722 - accuracy: 0.5716 - val_loss: 0.9170 - val_accuracy: 0.5453\n",
      "Epoch 3554/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8712 - accuracy: 0.5763 - val_loss: 0.9019 - val_accuracy: 0.5537\n",
      "Epoch 3555/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8720 - accuracy: 0.5767 - val_loss: 0.9111 - val_accuracy: 0.5523\n",
      "Epoch 3556/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8711 - accuracy: 0.5720 - val_loss: 0.9054 - val_accuracy: 0.5490\n",
      "Epoch 3557/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8722 - accuracy: 0.5744 - val_loss: 0.8993 - val_accuracy: 0.5553\n",
      "Epoch 3558/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8705 - accuracy: 0.5718 - val_loss: 0.9046 - val_accuracy: 0.5533\n",
      "Epoch 3559/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8708 - accuracy: 0.5719 - val_loss: 0.9168 - val_accuracy: 0.5467\n",
      "Epoch 3560/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8722 - accuracy: 0.5756 - val_loss: 0.9156 - val_accuracy: 0.5377\n",
      "Epoch 3561/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8707 - accuracy: 0.5732 - val_loss: 0.9047 - val_accuracy: 0.5590\n",
      "Epoch 3562/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8716 - accuracy: 0.5741 - val_loss: 0.9016 - val_accuracy: 0.5533\n",
      "Epoch 3563/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8717 - accuracy: 0.5754 - val_loss: 0.9047 - val_accuracy: 0.5547\n",
      "Epoch 3564/5500\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.8720 - accuracy: 0.5716 - val_loss: 0.9023 - val_accuracy: 0.5517\n",
      "Epoch 3565/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.8712 - accuracy: 0.5729 - val_loss: 0.9069 - val_accuracy: 0.5490\n",
      "Epoch 3566/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8706 - accuracy: 0.5702 - val_loss: 0.9015 - val_accuracy: 0.5510\n",
      "Epoch 3567/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8711 - accuracy: 0.5730 - val_loss: 0.9092 - val_accuracy: 0.5523\n",
      "Epoch 3568/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8722 - accuracy: 0.5741 - val_loss: 0.9036 - val_accuracy: 0.5540\n",
      "Epoch 3569/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8720 - accuracy: 0.5735 - val_loss: 0.9025 - val_accuracy: 0.5573\n",
      "Epoch 3570/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8717 - accuracy: 0.5749 - val_loss: 0.9018 - val_accuracy: 0.5550\n",
      "Epoch 3571/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8718 - accuracy: 0.5744 - val_loss: 0.9083 - val_accuracy: 0.5540\n",
      "Epoch 3572/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8702 - accuracy: 0.5773 - val_loss: 0.9047 - val_accuracy: 0.5570\n",
      "Epoch 3573/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8705 - accuracy: 0.5709 - val_loss: 0.8994 - val_accuracy: 0.5537\n",
      "Epoch 3574/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8719 - accuracy: 0.5764 - val_loss: 0.9070 - val_accuracy: 0.5490\n",
      "Epoch 3575/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8722 - accuracy: 0.5709 - val_loss: 0.9042 - val_accuracy: 0.5547\n",
      "Epoch 3576/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8718 - accuracy: 0.5730 - val_loss: 0.9017 - val_accuracy: 0.5567\n",
      "Epoch 3577/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8711 - accuracy: 0.5749 - val_loss: 0.9091 - val_accuracy: 0.5503\n",
      "Epoch 3578/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8719 - accuracy: 0.5735 - val_loss: 0.9035 - val_accuracy: 0.5550\n",
      "Epoch 3579/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8711 - accuracy: 0.5770 - val_loss: 0.9068 - val_accuracy: 0.5570\n",
      "Epoch 3580/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8707 - accuracy: 0.5734 - val_loss: 0.9170 - val_accuracy: 0.5473\n",
      "Epoch 3581/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8720 - accuracy: 0.5715 - val_loss: 0.9000 - val_accuracy: 0.5567\n",
      "Epoch 3582/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8707 - accuracy: 0.5748 - val_loss: 0.9041 - val_accuracy: 0.5580\n",
      "Epoch 3583/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8707 - accuracy: 0.5743 - val_loss: 0.9067 - val_accuracy: 0.5513\n",
      "Epoch 3584/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8705 - accuracy: 0.5737 - val_loss: 0.8990 - val_accuracy: 0.5610\n",
      "Epoch 3585/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8717 - accuracy: 0.5741 - val_loss: 0.9026 - val_accuracy: 0.5590\n",
      "Epoch 3586/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8730 - accuracy: 0.5720 - val_loss: 0.8987 - val_accuracy: 0.5630\n",
      "Epoch 3587/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8719 - accuracy: 0.5721 - val_loss: 0.9045 - val_accuracy: 0.5513\n",
      "Epoch 3588/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8705 - accuracy: 0.5753 - val_loss: 0.9061 - val_accuracy: 0.5530\n",
      "Epoch 3589/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8715 - accuracy: 0.5731 - val_loss: 0.9008 - val_accuracy: 0.5540\n",
      "Epoch 3590/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8715 - accuracy: 0.5716 - val_loss: 0.9014 - val_accuracy: 0.5557\n",
      "Epoch 3591/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8708 - accuracy: 0.5734 - val_loss: 0.8993 - val_accuracy: 0.5533\n",
      "Epoch 3592/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8709 - accuracy: 0.5750 - val_loss: 0.9039 - val_accuracy: 0.5607\n",
      "Epoch 3593/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8702 - accuracy: 0.5737 - val_loss: 0.9029 - val_accuracy: 0.5543\n",
      "Epoch 3594/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8712 - accuracy: 0.5750 - val_loss: 0.8997 - val_accuracy: 0.5557\n",
      "Epoch 3595/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8718 - accuracy: 0.5738 - val_loss: 0.9011 - val_accuracy: 0.5540\n",
      "Epoch 3596/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8714 - accuracy: 0.5752 - val_loss: 0.8998 - val_accuracy: 0.5537\n",
      "Epoch 3597/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8715 - accuracy: 0.5751 - val_loss: 0.9204 - val_accuracy: 0.5467\n",
      "Epoch 3598/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8711 - accuracy: 0.5723 - val_loss: 0.8999 - val_accuracy: 0.5607\n",
      "Epoch 3599/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8701 - accuracy: 0.5746 - val_loss: 0.9000 - val_accuracy: 0.5570\n",
      "Epoch 3600/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8705 - accuracy: 0.5729 - val_loss: 0.9008 - val_accuracy: 0.5553\n",
      "Epoch 3601/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8703 - accuracy: 0.5744 - val_loss: 0.8999 - val_accuracy: 0.5547\n",
      "Epoch 3602/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8724 - accuracy: 0.5774 - val_loss: 0.9137 - val_accuracy: 0.5487\n",
      "Epoch 3603/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8723 - accuracy: 0.5721 - val_loss: 0.9031 - val_accuracy: 0.5537\n",
      "Epoch 3604/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8718 - accuracy: 0.5749 - val_loss: 0.8997 - val_accuracy: 0.5590\n",
      "Epoch 3605/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8702 - accuracy: 0.5741 - val_loss: 0.9014 - val_accuracy: 0.5577\n",
      "Epoch 3606/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8700 - accuracy: 0.5764 - val_loss: 0.9030 - val_accuracy: 0.5590\n",
      "Epoch 3607/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8704 - accuracy: 0.5743 - val_loss: 0.9222 - val_accuracy: 0.5353\n",
      "Epoch 3608/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8705 - accuracy: 0.5738 - val_loss: 0.9213 - val_accuracy: 0.5450\n",
      "Epoch 3609/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8708 - accuracy: 0.5721 - val_loss: 0.9132 - val_accuracy: 0.5480\n",
      "Epoch 3610/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8700 - accuracy: 0.5721 - val_loss: 0.8990 - val_accuracy: 0.5593\n",
      "Epoch 3611/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8725 - accuracy: 0.5691 - val_loss: 0.9042 - val_accuracy: 0.5537\n",
      "Epoch 3612/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8693 - accuracy: 0.5751 - val_loss: 0.8986 - val_accuracy: 0.5577\n",
      "Epoch 3613/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8697 - accuracy: 0.5742 - val_loss: 0.9015 - val_accuracy: 0.5540\n",
      "Epoch 3614/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8704 - accuracy: 0.5765 - val_loss: 0.9318 - val_accuracy: 0.5307\n",
      "Epoch 3615/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8691 - accuracy: 0.5720 - val_loss: 0.9170 - val_accuracy: 0.5457\n",
      "Epoch 3616/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8705 - accuracy: 0.5734 - val_loss: 0.9016 - val_accuracy: 0.5557\n",
      "Epoch 3617/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8702 - accuracy: 0.5707 - val_loss: 0.9016 - val_accuracy: 0.5583\n",
      "Epoch 3618/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8698 - accuracy: 0.5786 - val_loss: 0.9019 - val_accuracy: 0.5520\n",
      "Epoch 3619/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8721 - accuracy: 0.5761 - val_loss: 0.9001 - val_accuracy: 0.5580\n",
      "Epoch 3620/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8710 - accuracy: 0.5739 - val_loss: 0.9001 - val_accuracy: 0.5553\n",
      "Epoch 3621/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8723 - accuracy: 0.5700 - val_loss: 0.8992 - val_accuracy: 0.5523\n",
      "Epoch 3622/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8705 - accuracy: 0.5744 - val_loss: 0.9192 - val_accuracy: 0.5443\n",
      "Epoch 3623/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8698 - accuracy: 0.5708 - val_loss: 0.9135 - val_accuracy: 0.5417\n",
      "Epoch 3624/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8715 - accuracy: 0.5773 - val_loss: 0.9207 - val_accuracy: 0.5413\n",
      "Epoch 3625/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8706 - accuracy: 0.5761 - val_loss: 0.9016 - val_accuracy: 0.5557\n",
      "Epoch 3626/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8702 - accuracy: 0.5748 - val_loss: 0.9129 - val_accuracy: 0.5493\n",
      "Epoch 3627/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8695 - accuracy: 0.5751 - val_loss: 0.9013 - val_accuracy: 0.5543\n",
      "Epoch 3628/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8704 - accuracy: 0.5749 - val_loss: 0.9041 - val_accuracy: 0.5527\n",
      "Epoch 3629/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8696 - accuracy: 0.5774 - val_loss: 0.9022 - val_accuracy: 0.5597\n",
      "Epoch 3630/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8718 - accuracy: 0.5736 - val_loss: 0.9167 - val_accuracy: 0.5340\n",
      "Epoch 3631/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8695 - accuracy: 0.5776 - val_loss: 0.9009 - val_accuracy: 0.5577\n",
      "Epoch 3632/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8717 - accuracy: 0.5691 - val_loss: 0.8987 - val_accuracy: 0.5597\n",
      "Epoch 3633/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8715 - accuracy: 0.5709 - val_loss: 0.9044 - val_accuracy: 0.5557\n",
      "Epoch 3634/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8700 - accuracy: 0.5749 - val_loss: 0.9092 - val_accuracy: 0.5510\n",
      "Epoch 3635/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8701 - accuracy: 0.5745 - val_loss: 0.9030 - val_accuracy: 0.5530\n",
      "Epoch 3636/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8713 - accuracy: 0.5706 - val_loss: 0.9065 - val_accuracy: 0.5520\n",
      "Epoch 3637/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8712 - accuracy: 0.5748 - val_loss: 0.9551 - val_accuracy: 0.5187\n",
      "Epoch 3638/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8711 - accuracy: 0.5696 - val_loss: 0.9058 - val_accuracy: 0.5530\n",
      "Epoch 3639/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8693 - accuracy: 0.5771 - val_loss: 0.9072 - val_accuracy: 0.5490\n",
      "Epoch 3640/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8703 - accuracy: 0.5740 - val_loss: 0.9049 - val_accuracy: 0.5520\n",
      "Epoch 3641/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8728 - accuracy: 0.5731 - val_loss: 0.9044 - val_accuracy: 0.5577\n",
      "Epoch 3642/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8691 - accuracy: 0.5752 - val_loss: 0.9022 - val_accuracy: 0.5550\n",
      "Epoch 3643/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8698 - accuracy: 0.5727 - val_loss: 0.9004 - val_accuracy: 0.5603\n",
      "Epoch 3644/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8715 - accuracy: 0.5737 - val_loss: 0.9107 - val_accuracy: 0.5560\n",
      "Epoch 3645/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8700 - accuracy: 0.5727 - val_loss: 0.9004 - val_accuracy: 0.5597\n",
      "Epoch 3646/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8691 - accuracy: 0.5788 - val_loss: 0.9001 - val_accuracy: 0.5553\n",
      "Epoch 3647/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8706 - accuracy: 0.5731 - val_loss: 0.9028 - val_accuracy: 0.5547\n",
      "Epoch 3648/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8698 - accuracy: 0.5709 - val_loss: 0.9327 - val_accuracy: 0.5303\n",
      "Epoch 3649/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8714 - accuracy: 0.5749 - val_loss: 0.8989 - val_accuracy: 0.5590\n",
      "Epoch 3650/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8693 - accuracy: 0.5784 - val_loss: 0.9008 - val_accuracy: 0.5577\n",
      "Epoch 3651/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8695 - accuracy: 0.5775 - val_loss: 0.9075 - val_accuracy: 0.5540\n",
      "Epoch 3652/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8713 - accuracy: 0.5715 - val_loss: 0.9009 - val_accuracy: 0.5543\n",
      "Epoch 3653/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8705 - accuracy: 0.5731 - val_loss: 0.9013 - val_accuracy: 0.5543\n",
      "Epoch 3654/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8694 - accuracy: 0.5731 - val_loss: 0.9061 - val_accuracy: 0.5500\n",
      "Epoch 3655/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8723 - accuracy: 0.5714 - val_loss: 0.9183 - val_accuracy: 0.5417\n",
      "Epoch 3656/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8701 - accuracy: 0.5708 - val_loss: 0.9002 - val_accuracy: 0.5533\n",
      "Epoch 3657/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8703 - accuracy: 0.5756 - val_loss: 0.8993 - val_accuracy: 0.5567\n",
      "Epoch 3658/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8708 - accuracy: 0.5743 - val_loss: 0.8991 - val_accuracy: 0.5580\n",
      "Epoch 3659/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8702 - accuracy: 0.5726 - val_loss: 0.9083 - val_accuracy: 0.5500\n",
      "Epoch 3660/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8688 - accuracy: 0.5758 - val_loss: 0.9054 - val_accuracy: 0.5497\n",
      "Epoch 3661/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8687 - accuracy: 0.5751 - val_loss: 0.9161 - val_accuracy: 0.5493\n",
      "Epoch 3662/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8700 - accuracy: 0.5727 - val_loss: 0.9256 - val_accuracy: 0.5337\n",
      "Epoch 3663/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8698 - accuracy: 0.5735 - val_loss: 0.8993 - val_accuracy: 0.5580\n",
      "Epoch 3664/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8698 - accuracy: 0.5753 - val_loss: 0.9062 - val_accuracy: 0.5517\n",
      "Epoch 3665/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8707 - accuracy: 0.5708 - val_loss: 0.9364 - val_accuracy: 0.5263\n",
      "Epoch 3666/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8712 - accuracy: 0.5714 - val_loss: 0.9152 - val_accuracy: 0.5413\n",
      "Epoch 3667/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8707 - accuracy: 0.5759 - val_loss: 0.8992 - val_accuracy: 0.5577\n",
      "Epoch 3668/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8708 - accuracy: 0.5719 - val_loss: 0.9007 - val_accuracy: 0.5547\n",
      "Epoch 3669/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5740 - val_loss: 0.9006 - val_accuracy: 0.5557\n",
      "Epoch 3670/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8707 - accuracy: 0.5729 - val_loss: 0.9075 - val_accuracy: 0.5483\n",
      "Epoch 3671/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8708 - accuracy: 0.5709 - val_loss: 0.9035 - val_accuracy: 0.5577\n",
      "Epoch 3672/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8698 - accuracy: 0.5774 - val_loss: 0.9178 - val_accuracy: 0.5440\n",
      "Epoch 3673/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8708 - accuracy: 0.5714 - val_loss: 0.8988 - val_accuracy: 0.5573\n",
      "Epoch 3674/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8704 - accuracy: 0.5724 - val_loss: 0.9057 - val_accuracy: 0.5593\n",
      "Epoch 3675/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8693 - accuracy: 0.5725 - val_loss: 0.8987 - val_accuracy: 0.5610\n",
      "Epoch 3676/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8697 - accuracy: 0.5763 - val_loss: 0.9060 - val_accuracy: 0.5467\n",
      "Epoch 3677/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8692 - accuracy: 0.5785 - val_loss: 0.9160 - val_accuracy: 0.5400\n",
      "Epoch 3678/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8705 - accuracy: 0.5765 - val_loss: 0.9040 - val_accuracy: 0.5577\n",
      "Epoch 3679/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8694 - accuracy: 0.5760 - val_loss: 0.8986 - val_accuracy: 0.5610\n",
      "Epoch 3680/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8700 - accuracy: 0.5785 - val_loss: 0.9075 - val_accuracy: 0.5533\n",
      "Epoch 3681/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8712 - accuracy: 0.5751 - val_loss: 0.9008 - val_accuracy: 0.5560\n",
      "Epoch 3682/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8706 - accuracy: 0.5749 - val_loss: 0.8993 - val_accuracy: 0.5550\n",
      "Epoch 3683/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8698 - accuracy: 0.5749 - val_loss: 0.9052 - val_accuracy: 0.5547\n",
      "Epoch 3684/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8701 - accuracy: 0.5756 - val_loss: 0.9021 - val_accuracy: 0.5603\n",
      "Epoch 3685/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8705 - accuracy: 0.5739 - val_loss: 0.9025 - val_accuracy: 0.5510\n",
      "Epoch 3686/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8694 - accuracy: 0.5717 - val_loss: 0.8999 - val_accuracy: 0.5603\n",
      "Epoch 3687/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8693 - accuracy: 0.5757 - val_loss: 0.9099 - val_accuracy: 0.5520\n",
      "Epoch 3688/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8710 - accuracy: 0.5701 - val_loss: 0.9008 - val_accuracy: 0.5590\n",
      "Epoch 3689/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8692 - accuracy: 0.5747 - val_loss: 0.9079 - val_accuracy: 0.5517\n",
      "Epoch 3690/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8700 - accuracy: 0.5746 - val_loss: 0.9105 - val_accuracy: 0.5503\n",
      "Epoch 3691/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8696 - accuracy: 0.5749 - val_loss: 0.9558 - val_accuracy: 0.5177\n",
      "Epoch 3692/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8699 - accuracy: 0.5718 - val_loss: 0.9054 - val_accuracy: 0.5527\n",
      "Epoch 3693/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8700 - accuracy: 0.5761 - val_loss: 0.8994 - val_accuracy: 0.5603\n",
      "Epoch 3694/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8696 - accuracy: 0.5750 - val_loss: 0.9068 - val_accuracy: 0.5520\n",
      "Epoch 3695/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8692 - accuracy: 0.5727 - val_loss: 0.9028 - val_accuracy: 0.5560\n",
      "Epoch 3696/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8700 - accuracy: 0.5749 - val_loss: 0.9050 - val_accuracy: 0.5553\n",
      "Epoch 3697/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8699 - accuracy: 0.5769 - val_loss: 0.9101 - val_accuracy: 0.5450\n",
      "Epoch 3698/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8692 - accuracy: 0.5762 - val_loss: 0.9095 - val_accuracy: 0.5470\n",
      "Epoch 3699/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8702 - accuracy: 0.5751 - val_loss: 0.8990 - val_accuracy: 0.5563\n",
      "Epoch 3700/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8687 - accuracy: 0.5766 - val_loss: 0.9063 - val_accuracy: 0.5563\n",
      "Epoch 3701/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8704 - accuracy: 0.5744 - val_loss: 0.9001 - val_accuracy: 0.5533\n",
      "Epoch 3702/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8706 - accuracy: 0.5754 - val_loss: 0.8992 - val_accuracy: 0.5607\n",
      "Epoch 3703/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8718 - accuracy: 0.5700 - val_loss: 0.9032 - val_accuracy: 0.5537\n",
      "Epoch 3704/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8698 - accuracy: 0.5777 - val_loss: 0.9108 - val_accuracy: 0.5530\n",
      "Epoch 3705/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8713 - accuracy: 0.5789 - val_loss: 0.9006 - val_accuracy: 0.5520\n",
      "Epoch 3706/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5781 - val_loss: 0.9023 - val_accuracy: 0.5527\n",
      "Epoch 3707/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8696 - accuracy: 0.5729 - val_loss: 0.9010 - val_accuracy: 0.5553\n",
      "Epoch 3708/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8680 - accuracy: 0.5774 - val_loss: 0.9028 - val_accuracy: 0.5517\n",
      "Epoch 3709/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8694 - accuracy: 0.5754 - val_loss: 0.8997 - val_accuracy: 0.5567\n",
      "Epoch 3710/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5751 - val_loss: 0.9001 - val_accuracy: 0.5577\n",
      "Epoch 3711/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8687 - accuracy: 0.5756 - val_loss: 0.9032 - val_accuracy: 0.5527\n",
      "Epoch 3712/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8713 - accuracy: 0.5721 - val_loss: 0.9085 - val_accuracy: 0.5537\n",
      "Epoch 3713/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8696 - accuracy: 0.5771 - val_loss: 0.8984 - val_accuracy: 0.5590\n",
      "Epoch 3714/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8707 - accuracy: 0.5738 - val_loss: 0.9049 - val_accuracy: 0.5547\n",
      "Epoch 3715/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8694 - accuracy: 0.5746 - val_loss: 0.9306 - val_accuracy: 0.5320\n",
      "Epoch 3716/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8701 - accuracy: 0.5711 - val_loss: 0.9022 - val_accuracy: 0.5560\n",
      "Epoch 3717/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8692 - accuracy: 0.5761 - val_loss: 0.9316 - val_accuracy: 0.5270\n",
      "Epoch 3718/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8702 - accuracy: 0.5746 - val_loss: 0.9022 - val_accuracy: 0.5573\n",
      "Epoch 3719/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8690 - accuracy: 0.5752 - val_loss: 0.9040 - val_accuracy: 0.5497\n",
      "Epoch 3720/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8697 - accuracy: 0.5725 - val_loss: 0.9011 - val_accuracy: 0.5563\n",
      "Epoch 3721/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8701 - accuracy: 0.5754 - val_loss: 0.9026 - val_accuracy: 0.5553\n",
      "Epoch 3722/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8705 - accuracy: 0.5741 - val_loss: 0.9003 - val_accuracy: 0.5593\n",
      "Epoch 3723/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8693 - accuracy: 0.5754 - val_loss: 0.8998 - val_accuracy: 0.5507\n",
      "Epoch 3724/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8691 - accuracy: 0.5755 - val_loss: 0.9130 - val_accuracy: 0.5420\n",
      "Epoch 3725/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8702 - accuracy: 0.5749 - val_loss: 0.9013 - val_accuracy: 0.5580\n",
      "Epoch 3726/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8685 - accuracy: 0.5760 - val_loss: 0.9315 - val_accuracy: 0.5263\n",
      "Epoch 3727/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8702 - accuracy: 0.5779 - val_loss: 0.9025 - val_accuracy: 0.5620\n",
      "Epoch 3728/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8686 - accuracy: 0.5731 - val_loss: 0.8993 - val_accuracy: 0.5563\n",
      "Epoch 3729/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8703 - accuracy: 0.5731 - val_loss: 0.8992 - val_accuracy: 0.5607\n",
      "Epoch 3730/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8707 - accuracy: 0.5702 - val_loss: 0.9007 - val_accuracy: 0.5623\n",
      "Epoch 3731/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8702 - accuracy: 0.5743 - val_loss: 0.9088 - val_accuracy: 0.5500\n",
      "Epoch 3732/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8681 - accuracy: 0.5764 - val_loss: 0.8981 - val_accuracy: 0.5570\n",
      "Epoch 3733/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8706 - accuracy: 0.5744 - val_loss: 0.9053 - val_accuracy: 0.5563\n",
      "Epoch 3734/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8701 - accuracy: 0.5751 - val_loss: 0.9125 - val_accuracy: 0.5503\n",
      "Epoch 3735/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8709 - accuracy: 0.5726 - val_loss: 0.8989 - val_accuracy: 0.5580\n",
      "Epoch 3736/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8711 - accuracy: 0.5716 - val_loss: 0.9054 - val_accuracy: 0.5557\n",
      "Epoch 3737/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8682 - accuracy: 0.5758 - val_loss: 0.8993 - val_accuracy: 0.5580\n",
      "Epoch 3738/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8688 - accuracy: 0.5753 - val_loss: 0.9013 - val_accuracy: 0.5563\n",
      "Epoch 3739/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8682 - accuracy: 0.5767 - val_loss: 0.9038 - val_accuracy: 0.5570\n",
      "Epoch 3740/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8687 - accuracy: 0.5744 - val_loss: 0.9244 - val_accuracy: 0.5383\n",
      "Epoch 3741/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8735 - accuracy: 0.5716 - val_loss: 0.9044 - val_accuracy: 0.5550\n",
      "Epoch 3742/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8694 - accuracy: 0.5714 - val_loss: 0.9143 - val_accuracy: 0.5430\n",
      "Epoch 3743/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8691 - accuracy: 0.5777 - val_loss: 0.9063 - val_accuracy: 0.5507\n",
      "Epoch 3744/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8681 - accuracy: 0.5770 - val_loss: 0.9008 - val_accuracy: 0.5547\n",
      "Epoch 3745/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8691 - accuracy: 0.5768 - val_loss: 0.8997 - val_accuracy: 0.5570\n",
      "Epoch 3746/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8694 - accuracy: 0.5735 - val_loss: 0.9011 - val_accuracy: 0.5583\n",
      "Epoch 3747/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8682 - accuracy: 0.5714 - val_loss: 0.9124 - val_accuracy: 0.5390\n",
      "Epoch 3748/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8696 - accuracy: 0.5733 - val_loss: 0.8998 - val_accuracy: 0.5567\n",
      "Epoch 3749/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8694 - accuracy: 0.5769 - val_loss: 0.9090 - val_accuracy: 0.5523\n",
      "Epoch 3750/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8702 - accuracy: 0.5729 - val_loss: 0.9264 - val_accuracy: 0.5417\n",
      "Epoch 3751/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8702 - accuracy: 0.5742 - val_loss: 0.9018 - val_accuracy: 0.5560\n",
      "Epoch 3752/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8688 - accuracy: 0.5755 - val_loss: 0.9128 - val_accuracy: 0.5417\n",
      "Epoch 3753/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8685 - accuracy: 0.5761 - val_loss: 0.9000 - val_accuracy: 0.5557\n",
      "Epoch 3754/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8712 - accuracy: 0.5759 - val_loss: 0.8984 - val_accuracy: 0.5590\n",
      "Epoch 3755/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8700 - accuracy: 0.5759 - val_loss: 0.9026 - val_accuracy: 0.5500\n",
      "Epoch 3756/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8702 - accuracy: 0.5780 - val_loss: 0.9050 - val_accuracy: 0.5520\n",
      "Epoch 3757/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8681 - accuracy: 0.5754 - val_loss: 0.8985 - val_accuracy: 0.5643\n",
      "Epoch 3758/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8697 - accuracy: 0.5746 - val_loss: 0.9059 - val_accuracy: 0.5537\n",
      "Epoch 3759/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8683 - accuracy: 0.5745 - val_loss: 0.8993 - val_accuracy: 0.5563\n",
      "Epoch 3760/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8688 - accuracy: 0.5769 - val_loss: 0.9042 - val_accuracy: 0.5553\n",
      "Epoch 3761/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8694 - accuracy: 0.5765 - val_loss: 0.9079 - val_accuracy: 0.5540\n",
      "Epoch 3762/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8696 - accuracy: 0.5754 - val_loss: 0.9123 - val_accuracy: 0.5437\n",
      "Epoch 3763/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8690 - accuracy: 0.5756 - val_loss: 0.9027 - val_accuracy: 0.5543\n",
      "Epoch 3764/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8696 - accuracy: 0.5738 - val_loss: 0.9027 - val_accuracy: 0.5573\n",
      "Epoch 3765/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8691 - accuracy: 0.5750 - val_loss: 0.9169 - val_accuracy: 0.5533\n",
      "Epoch 3766/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8712 - accuracy: 0.5726 - val_loss: 0.8994 - val_accuracy: 0.5610\n",
      "Epoch 3767/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8694 - accuracy: 0.5744 - val_loss: 0.9046 - val_accuracy: 0.5500\n",
      "Epoch 3768/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8687 - accuracy: 0.5744 - val_loss: 0.9029 - val_accuracy: 0.5527\n",
      "Epoch 3769/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5748 - val_loss: 0.9002 - val_accuracy: 0.5530\n",
      "Epoch 3770/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8677 - accuracy: 0.5779 - val_loss: 0.9114 - val_accuracy: 0.5503\n",
      "Epoch 3771/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8683 - accuracy: 0.5796 - val_loss: 0.9371 - val_accuracy: 0.5293\n",
      "Epoch 3772/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8685 - accuracy: 0.5751 - val_loss: 0.8990 - val_accuracy: 0.5553\n",
      "Epoch 3773/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8704 - accuracy: 0.5720 - val_loss: 0.9349 - val_accuracy: 0.5367\n",
      "Epoch 3774/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8695 - accuracy: 0.5729 - val_loss: 0.9085 - val_accuracy: 0.5527\n",
      "Epoch 3775/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8695 - accuracy: 0.5746 - val_loss: 0.9036 - val_accuracy: 0.5570\n",
      "Epoch 3776/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8687 - accuracy: 0.5755 - val_loss: 0.8998 - val_accuracy: 0.5547\n",
      "Epoch 3777/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8677 - accuracy: 0.5806 - val_loss: 0.9003 - val_accuracy: 0.5563\n",
      "Epoch 3778/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8673 - accuracy: 0.5793 - val_loss: 0.9391 - val_accuracy: 0.5293\n",
      "Epoch 3779/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8681 - accuracy: 0.5749 - val_loss: 0.8992 - val_accuracy: 0.5617\n",
      "Epoch 3780/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8692 - accuracy: 0.5739 - val_loss: 0.9080 - val_accuracy: 0.5467\n",
      "Epoch 3781/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8685 - accuracy: 0.5766 - val_loss: 0.9039 - val_accuracy: 0.5567\n",
      "Epoch 3782/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8691 - accuracy: 0.5750 - val_loss: 0.9126 - val_accuracy: 0.5477\n",
      "Epoch 3783/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8682 - accuracy: 0.5788 - val_loss: 0.8996 - val_accuracy: 0.5610\n",
      "Epoch 3784/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8683 - accuracy: 0.5752 - val_loss: 0.9013 - val_accuracy: 0.5520\n",
      "Epoch 3785/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8677 - accuracy: 0.5759 - val_loss: 0.8993 - val_accuracy: 0.5580\n",
      "Epoch 3786/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8698 - accuracy: 0.5753 - val_loss: 0.9068 - val_accuracy: 0.5563\n",
      "Epoch 3787/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8700 - accuracy: 0.5749 - val_loss: 0.9251 - val_accuracy: 0.5367\n",
      "Epoch 3788/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8681 - accuracy: 0.5766 - val_loss: 0.9015 - val_accuracy: 0.5510\n",
      "Epoch 3789/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8685 - accuracy: 0.5774 - val_loss: 0.9271 - val_accuracy: 0.5323\n",
      "Epoch 3790/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8675 - accuracy: 0.5796 - val_loss: 0.9007 - val_accuracy: 0.5570\n",
      "Epoch 3791/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8707 - accuracy: 0.5732 - val_loss: 0.9001 - val_accuracy: 0.5570\n",
      "Epoch 3792/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8703 - accuracy: 0.5715 - val_loss: 0.9023 - val_accuracy: 0.5527\n",
      "Epoch 3793/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8689 - accuracy: 0.5794 - val_loss: 0.9001 - val_accuracy: 0.5623\n",
      "Epoch 3794/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8679 - accuracy: 0.5759 - val_loss: 0.9000 - val_accuracy: 0.5633\n",
      "Epoch 3795/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8672 - accuracy: 0.5743 - val_loss: 0.8999 - val_accuracy: 0.5577\n",
      "Epoch 3796/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8697 - accuracy: 0.5739 - val_loss: 0.8998 - val_accuracy: 0.5563\n",
      "Epoch 3797/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8693 - accuracy: 0.5751 - val_loss: 0.9072 - val_accuracy: 0.5463\n",
      "Epoch 3798/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8683 - accuracy: 0.5766 - val_loss: 0.9002 - val_accuracy: 0.5550\n",
      "Epoch 3799/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8691 - accuracy: 0.5732 - val_loss: 0.8991 - val_accuracy: 0.5587\n",
      "Epoch 3800/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.8699 - accuracy: 0.5736 - val_loss: 0.9005 - val_accuracy: 0.5597\n",
      "Epoch 3801/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.8681 - accuracy: 0.5752 - val_loss: 0.9015 - val_accuracy: 0.5573\n",
      "Epoch 3802/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8666 - accuracy: 0.5790 - val_loss: 0.9044 - val_accuracy: 0.5570\n",
      "Epoch 3803/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8695 - accuracy: 0.5751 - val_loss: 0.9001 - val_accuracy: 0.5593\n",
      "Epoch 3804/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8700 - accuracy: 0.5740 - val_loss: 0.9072 - val_accuracy: 0.5550\n",
      "Epoch 3805/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8673 - accuracy: 0.5781 - val_loss: 0.9070 - val_accuracy: 0.5543\n",
      "Epoch 3806/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8700 - accuracy: 0.5744 - val_loss: 0.8991 - val_accuracy: 0.5557\n",
      "Epoch 3807/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8672 - accuracy: 0.5756 - val_loss: 0.8998 - val_accuracy: 0.5553\n",
      "Epoch 3808/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8685 - accuracy: 0.5750 - val_loss: 0.9037 - val_accuracy: 0.5587\n",
      "Epoch 3809/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8688 - accuracy: 0.5763 - val_loss: 0.9084 - val_accuracy: 0.5530\n",
      "Epoch 3810/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8684 - accuracy: 0.5764 - val_loss: 0.8989 - val_accuracy: 0.5583\n",
      "Epoch 3811/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8681 - accuracy: 0.5752 - val_loss: 0.9041 - val_accuracy: 0.5547\n",
      "Epoch 3812/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8681 - accuracy: 0.5769 - val_loss: 0.9039 - val_accuracy: 0.5570\n",
      "Epoch 3813/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8683 - accuracy: 0.5781 - val_loss: 0.8993 - val_accuracy: 0.5607\n",
      "Epoch 3814/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8687 - accuracy: 0.5711 - val_loss: 0.9013 - val_accuracy: 0.5583\n",
      "Epoch 3815/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8692 - accuracy: 0.5756 - val_loss: 0.8990 - val_accuracy: 0.5597\n",
      "Epoch 3816/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8695 - accuracy: 0.5743 - val_loss: 0.9021 - val_accuracy: 0.5567\n",
      "Epoch 3817/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8685 - accuracy: 0.5741 - val_loss: 0.8990 - val_accuracy: 0.5577\n",
      "Epoch 3818/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8696 - accuracy: 0.5743 - val_loss: 0.9017 - val_accuracy: 0.5537\n",
      "Epoch 3819/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8691 - accuracy: 0.5716 - val_loss: 0.9026 - val_accuracy: 0.5577\n",
      "Epoch 3820/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8675 - accuracy: 0.5754 - val_loss: 0.9009 - val_accuracy: 0.5593\n",
      "Epoch 3821/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8672 - accuracy: 0.5770 - val_loss: 0.9147 - val_accuracy: 0.5380\n",
      "Epoch 3822/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8680 - accuracy: 0.5749 - val_loss: 0.9047 - val_accuracy: 0.5580\n",
      "Epoch 3823/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8702 - accuracy: 0.5759 - val_loss: 0.9255 - val_accuracy: 0.5377\n",
      "Epoch 3824/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8685 - accuracy: 0.5756 - val_loss: 0.9050 - val_accuracy: 0.5530\n",
      "Epoch 3825/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8692 - accuracy: 0.5751 - val_loss: 0.9034 - val_accuracy: 0.5573\n",
      "Epoch 3826/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8694 - accuracy: 0.5708 - val_loss: 0.9017 - val_accuracy: 0.5557\n",
      "Epoch 3827/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8696 - accuracy: 0.5761 - val_loss: 0.9062 - val_accuracy: 0.5523\n",
      "Epoch 3828/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8681 - accuracy: 0.5784 - val_loss: 0.9336 - val_accuracy: 0.5277\n",
      "Epoch 3829/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8708 - accuracy: 0.5726 - val_loss: 0.9027 - val_accuracy: 0.5500\n",
      "Epoch 3830/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8677 - accuracy: 0.5761 - val_loss: 0.9132 - val_accuracy: 0.5420\n",
      "Epoch 3831/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5754 - val_loss: 0.8988 - val_accuracy: 0.5593\n",
      "Epoch 3832/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8679 - accuracy: 0.5757 - val_loss: 0.9008 - val_accuracy: 0.5587\n",
      "Epoch 3833/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5755 - val_loss: 0.9025 - val_accuracy: 0.5573\n",
      "Epoch 3834/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5744 - val_loss: 0.9156 - val_accuracy: 0.5373\n",
      "Epoch 3835/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8675 - accuracy: 0.5753 - val_loss: 0.9167 - val_accuracy: 0.5427\n",
      "Epoch 3836/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8686 - accuracy: 0.5723 - val_loss: 0.9076 - val_accuracy: 0.5533\n",
      "Epoch 3837/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8668 - accuracy: 0.5808 - val_loss: 0.9132 - val_accuracy: 0.5490\n",
      "Epoch 3838/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8690 - accuracy: 0.5759 - val_loss: 0.9007 - val_accuracy: 0.5563\n",
      "Epoch 3839/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8688 - accuracy: 0.5768 - val_loss: 0.9023 - val_accuracy: 0.5603\n",
      "Epoch 3840/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8675 - accuracy: 0.5747 - val_loss: 0.9201 - val_accuracy: 0.5530\n",
      "Epoch 3841/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8685 - accuracy: 0.5767 - val_loss: 0.9072 - val_accuracy: 0.5523\n",
      "Epoch 3842/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8692 - accuracy: 0.5778 - val_loss: 0.9029 - val_accuracy: 0.5517\n",
      "Epoch 3843/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8690 - accuracy: 0.5751 - val_loss: 0.9061 - val_accuracy: 0.5543\n",
      "Epoch 3844/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8689 - accuracy: 0.5769 - val_loss: 0.9058 - val_accuracy: 0.5490\n",
      "Epoch 3845/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8688 - accuracy: 0.5754 - val_loss: 0.9177 - val_accuracy: 0.5523\n",
      "Epoch 3846/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8678 - accuracy: 0.5777 - val_loss: 0.9373 - val_accuracy: 0.5280\n",
      "Epoch 3847/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8690 - accuracy: 0.5774 - val_loss: 0.9011 - val_accuracy: 0.5570\n",
      "Epoch 3848/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8683 - accuracy: 0.5740 - val_loss: 0.9008 - val_accuracy: 0.5587\n",
      "Epoch 3849/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8681 - accuracy: 0.5769 - val_loss: 0.9061 - val_accuracy: 0.5553\n",
      "Epoch 3850/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8678 - accuracy: 0.5755 - val_loss: 0.9010 - val_accuracy: 0.5623\n",
      "Epoch 3851/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8691 - accuracy: 0.5755 - val_loss: 0.9531 - val_accuracy: 0.5210\n",
      "Epoch 3852/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8684 - accuracy: 0.5745 - val_loss: 0.9079 - val_accuracy: 0.5530\n",
      "Epoch 3853/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8668 - accuracy: 0.5746 - val_loss: 0.8990 - val_accuracy: 0.5590\n",
      "Epoch 3854/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8692 - accuracy: 0.5769 - val_loss: 0.8989 - val_accuracy: 0.5577\n",
      "Epoch 3855/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8683 - accuracy: 0.5771 - val_loss: 0.9103 - val_accuracy: 0.5463\n",
      "Epoch 3856/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8681 - accuracy: 0.5721 - val_loss: 0.9042 - val_accuracy: 0.5490\n",
      "Epoch 3857/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8676 - accuracy: 0.5773 - val_loss: 0.8985 - val_accuracy: 0.5587\n",
      "Epoch 3858/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8664 - accuracy: 0.5749 - val_loss: 0.9023 - val_accuracy: 0.5533\n",
      "Epoch 3859/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8694 - accuracy: 0.5716 - val_loss: 0.8992 - val_accuracy: 0.5613\n",
      "Epoch 3860/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8685 - accuracy: 0.5777 - val_loss: 0.8989 - val_accuracy: 0.5603\n",
      "Epoch 3861/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8675 - accuracy: 0.5793 - val_loss: 0.9004 - val_accuracy: 0.5533\n",
      "Epoch 3862/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8683 - accuracy: 0.5761 - val_loss: 0.8990 - val_accuracy: 0.5577\n",
      "Epoch 3863/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8687 - accuracy: 0.5766 - val_loss: 0.8988 - val_accuracy: 0.5567\n",
      "Epoch 3864/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8682 - accuracy: 0.5774 - val_loss: 0.8985 - val_accuracy: 0.5583\n",
      "Epoch 3865/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8675 - accuracy: 0.5753 - val_loss: 0.9064 - val_accuracy: 0.5537\n",
      "Epoch 3866/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8698 - accuracy: 0.5734 - val_loss: 0.8990 - val_accuracy: 0.5603\n",
      "Epoch 3867/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5743 - val_loss: 0.9192 - val_accuracy: 0.5437\n",
      "Epoch 3868/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8677 - accuracy: 0.5752 - val_loss: 0.9027 - val_accuracy: 0.5547\n",
      "Epoch 3869/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8687 - accuracy: 0.5729 - val_loss: 0.8995 - val_accuracy: 0.5620\n",
      "Epoch 3870/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8676 - accuracy: 0.5777 - val_loss: 0.9083 - val_accuracy: 0.5533\n",
      "Epoch 3871/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8678 - accuracy: 0.5762 - val_loss: 0.9024 - val_accuracy: 0.5597\n",
      "Epoch 3872/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8684 - accuracy: 0.5804 - val_loss: 0.9009 - val_accuracy: 0.5557\n",
      "Epoch 3873/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8678 - accuracy: 0.5789 - val_loss: 0.9030 - val_accuracy: 0.5583\n",
      "Epoch 3874/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8690 - accuracy: 0.5779 - val_loss: 0.9002 - val_accuracy: 0.5560\n",
      "Epoch 3875/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8674 - accuracy: 0.5781 - val_loss: 0.9076 - val_accuracy: 0.5510\n",
      "Epoch 3876/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8682 - accuracy: 0.5778 - val_loss: 0.9377 - val_accuracy: 0.5350\n",
      "Epoch 3877/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8690 - accuracy: 0.5757 - val_loss: 0.9003 - val_accuracy: 0.5560\n",
      "Epoch 3878/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8676 - accuracy: 0.5783 - val_loss: 0.9126 - val_accuracy: 0.5383\n",
      "Epoch 3879/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8675 - accuracy: 0.5751 - val_loss: 0.8987 - val_accuracy: 0.5577\n",
      "Epoch 3880/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8667 - accuracy: 0.5756 - val_loss: 0.8997 - val_accuracy: 0.5587\n",
      "Epoch 3881/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8684 - accuracy: 0.5744 - val_loss: 0.9175 - val_accuracy: 0.5453\n",
      "Epoch 3882/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8665 - accuracy: 0.5792 - val_loss: 0.9047 - val_accuracy: 0.5563\n",
      "Epoch 3883/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8673 - accuracy: 0.5778 - val_loss: 0.8989 - val_accuracy: 0.5617\n",
      "Epoch 3884/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8672 - accuracy: 0.5783 - val_loss: 0.9008 - val_accuracy: 0.5553\n",
      "Epoch 3885/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8675 - accuracy: 0.5743 - val_loss: 0.9058 - val_accuracy: 0.5523\n",
      "Epoch 3886/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8682 - accuracy: 0.5780 - val_loss: 0.9062 - val_accuracy: 0.5583\n",
      "Epoch 3887/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8688 - accuracy: 0.5779 - val_loss: 0.9097 - val_accuracy: 0.5470\n",
      "Epoch 3888/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8686 - accuracy: 0.5779 - val_loss: 0.9003 - val_accuracy: 0.5603\n",
      "Epoch 3889/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8686 - accuracy: 0.5741 - val_loss: 0.9048 - val_accuracy: 0.5510\n",
      "Epoch 3890/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8678 - accuracy: 0.5766 - val_loss: 0.9037 - val_accuracy: 0.5517\n",
      "Epoch 3891/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8674 - accuracy: 0.5761 - val_loss: 0.8995 - val_accuracy: 0.5590\n",
      "Epoch 3892/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8675 - accuracy: 0.5777 - val_loss: 0.9118 - val_accuracy: 0.5513\n",
      "Epoch 3893/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8684 - accuracy: 0.5770 - val_loss: 0.8991 - val_accuracy: 0.5540\n",
      "Epoch 3894/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8665 - accuracy: 0.5772 - val_loss: 0.9017 - val_accuracy: 0.5577\n",
      "Epoch 3895/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8687 - accuracy: 0.5759 - val_loss: 0.8996 - val_accuracy: 0.5567\n",
      "Epoch 3896/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8679 - accuracy: 0.5787 - val_loss: 0.9011 - val_accuracy: 0.5630\n",
      "Epoch 3897/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8688 - accuracy: 0.5790 - val_loss: 0.9003 - val_accuracy: 0.5547\n",
      "Epoch 3898/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8690 - accuracy: 0.5773 - val_loss: 0.8997 - val_accuracy: 0.5627\n",
      "Epoch 3899/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8685 - accuracy: 0.5784 - val_loss: 0.9052 - val_accuracy: 0.5540\n",
      "Epoch 3900/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8689 - accuracy: 0.5764 - val_loss: 0.8998 - val_accuracy: 0.5627\n",
      "Epoch 3901/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8680 - accuracy: 0.5768 - val_loss: 0.9006 - val_accuracy: 0.5613\n",
      "Epoch 3902/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8683 - accuracy: 0.5786 - val_loss: 0.8995 - val_accuracy: 0.5600\n",
      "Epoch 3903/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8669 - accuracy: 0.5775 - val_loss: 0.9967 - val_accuracy: 0.5007\n",
      "Epoch 3904/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8680 - accuracy: 0.5743 - val_loss: 0.9026 - val_accuracy: 0.5567\n",
      "Epoch 3905/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8650 - accuracy: 0.5799 - val_loss: 0.8984 - val_accuracy: 0.5637\n",
      "Epoch 3906/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8669 - accuracy: 0.5781 - val_loss: 0.9018 - val_accuracy: 0.5540\n",
      "Epoch 3907/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8680 - accuracy: 0.5752 - val_loss: 0.8998 - val_accuracy: 0.5583\n",
      "Epoch 3908/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8691 - accuracy: 0.5756 - val_loss: 0.8993 - val_accuracy: 0.5607\n",
      "Epoch 3909/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8663 - accuracy: 0.5761 - val_loss: 0.9005 - val_accuracy: 0.5573\n",
      "Epoch 3910/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8665 - accuracy: 0.5786 - val_loss: 0.9026 - val_accuracy: 0.5570\n",
      "Epoch 3911/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8661 - accuracy: 0.5774 - val_loss: 0.8988 - val_accuracy: 0.5573\n",
      "Epoch 3912/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8660 - accuracy: 0.5781 - val_loss: 0.9092 - val_accuracy: 0.5453\n",
      "Epoch 3913/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8671 - accuracy: 0.5758 - val_loss: 0.8989 - val_accuracy: 0.5570\n",
      "Epoch 3914/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8668 - accuracy: 0.5741 - val_loss: 0.8985 - val_accuracy: 0.5587\n",
      "Epoch 3915/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8670 - accuracy: 0.5769 - val_loss: 0.9050 - val_accuracy: 0.5607\n",
      "Epoch 3916/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8683 - accuracy: 0.5764 - val_loss: 0.9084 - val_accuracy: 0.5540\n",
      "Epoch 3917/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8666 - accuracy: 0.5776 - val_loss: 0.9042 - val_accuracy: 0.5497\n",
      "Epoch 3918/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8667 - accuracy: 0.5791 - val_loss: 0.9030 - val_accuracy: 0.5550\n",
      "Epoch 3919/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8674 - accuracy: 0.5756 - val_loss: 0.9000 - val_accuracy: 0.5560\n",
      "Epoch 3920/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8681 - accuracy: 0.5707 - val_loss: 0.9002 - val_accuracy: 0.5533\n",
      "Epoch 3921/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8671 - accuracy: 0.5778 - val_loss: 0.9026 - val_accuracy: 0.5570\n",
      "Epoch 3922/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8682 - accuracy: 0.5774 - val_loss: 0.9012 - val_accuracy: 0.5597\n",
      "Epoch 3923/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8663 - accuracy: 0.5780 - val_loss: 0.9319 - val_accuracy: 0.5400\n",
      "Epoch 3924/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8685 - accuracy: 0.5755 - val_loss: 0.8988 - val_accuracy: 0.5610\n",
      "Epoch 3925/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8665 - accuracy: 0.5799 - val_loss: 0.8988 - val_accuracy: 0.5587\n",
      "Epoch 3926/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8670 - accuracy: 0.5761 - val_loss: 0.8998 - val_accuracy: 0.5580\n",
      "Epoch 3927/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8662 - accuracy: 0.5751 - val_loss: 0.9044 - val_accuracy: 0.5480\n",
      "Epoch 3928/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8682 - accuracy: 0.5759 - val_loss: 0.8998 - val_accuracy: 0.5593\n",
      "Epoch 3929/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8664 - accuracy: 0.5785 - val_loss: 0.8987 - val_accuracy: 0.5640\n",
      "Epoch 3930/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8691 - accuracy: 0.5740 - val_loss: 0.9156 - val_accuracy: 0.5560\n",
      "Epoch 3931/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8671 - accuracy: 0.5768 - val_loss: 0.8993 - val_accuracy: 0.5630\n",
      "Epoch 3932/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8662 - accuracy: 0.5811 - val_loss: 0.9042 - val_accuracy: 0.5610\n",
      "Epoch 3933/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8665 - accuracy: 0.5729 - val_loss: 0.9104 - val_accuracy: 0.5520\n",
      "Epoch 3934/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8658 - accuracy: 0.5778 - val_loss: 0.9047 - val_accuracy: 0.5560\n",
      "Epoch 3935/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8673 - accuracy: 0.5764 - val_loss: 0.9157 - val_accuracy: 0.5423\n",
      "Epoch 3936/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8684 - accuracy: 0.5743 - val_loss: 0.9059 - val_accuracy: 0.5513\n",
      "Epoch 3937/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8659 - accuracy: 0.5757 - val_loss: 0.9069 - val_accuracy: 0.5553\n",
      "Epoch 3938/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8681 - accuracy: 0.5762 - val_loss: 0.8996 - val_accuracy: 0.5593\n",
      "Epoch 3939/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8693 - accuracy: 0.5725 - val_loss: 0.9031 - val_accuracy: 0.5580\n",
      "Epoch 3940/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8667 - accuracy: 0.5775 - val_loss: 0.9052 - val_accuracy: 0.5523\n",
      "Epoch 3941/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8663 - accuracy: 0.5774 - val_loss: 0.9020 - val_accuracy: 0.5507\n",
      "Epoch 3942/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8669 - accuracy: 0.5785 - val_loss: 0.8994 - val_accuracy: 0.5587\n",
      "Epoch 3943/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8659 - accuracy: 0.5732 - val_loss: 0.8997 - val_accuracy: 0.5610\n",
      "Epoch 3944/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8675 - accuracy: 0.5759 - val_loss: 0.9204 - val_accuracy: 0.5513\n",
      "Epoch 3945/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8662 - accuracy: 0.5744 - val_loss: 0.9189 - val_accuracy: 0.5350\n",
      "Epoch 3946/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8665 - accuracy: 0.5816 - val_loss: 0.9092 - val_accuracy: 0.5537\n",
      "Epoch 3947/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8670 - accuracy: 0.5785 - val_loss: 0.9515 - val_accuracy: 0.5233\n",
      "Epoch 3948/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8679 - accuracy: 0.5762 - val_loss: 0.9063 - val_accuracy: 0.5560\n",
      "Epoch 3949/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8668 - accuracy: 0.5787 - val_loss: 0.9029 - val_accuracy: 0.5607\n",
      "Epoch 3950/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8677 - accuracy: 0.5743 - val_loss: 0.9679 - val_accuracy: 0.5113\n",
      "Epoch 3951/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8691 - accuracy: 0.5743 - val_loss: 0.9012 - val_accuracy: 0.5573\n",
      "Epoch 3952/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8658 - accuracy: 0.5771 - val_loss: 0.9135 - val_accuracy: 0.5480\n",
      "Epoch 3953/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8666 - accuracy: 0.5775 - val_loss: 0.9039 - val_accuracy: 0.5533\n",
      "Epoch 3954/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8684 - accuracy: 0.5768 - val_loss: 0.8989 - val_accuracy: 0.5620\n",
      "Epoch 3955/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8677 - accuracy: 0.5748 - val_loss: 0.9020 - val_accuracy: 0.5583\n",
      "Epoch 3956/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8650 - accuracy: 0.5717 - val_loss: 0.8999 - val_accuracy: 0.5600\n",
      "Epoch 3957/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8653 - accuracy: 0.5791 - val_loss: 0.9042 - val_accuracy: 0.5603\n",
      "Epoch 3958/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8681 - accuracy: 0.5788 - val_loss: 0.9007 - val_accuracy: 0.5580\n",
      "Epoch 3959/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8671 - accuracy: 0.5776 - val_loss: 0.9035 - val_accuracy: 0.5610\n",
      "Epoch 3960/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8661 - accuracy: 0.5793 - val_loss: 0.9473 - val_accuracy: 0.5307\n",
      "Epoch 3961/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8690 - accuracy: 0.5721 - val_loss: 0.9025 - val_accuracy: 0.5517\n",
      "Epoch 3962/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8662 - accuracy: 0.5826 - val_loss: 0.8991 - val_accuracy: 0.5543\n",
      "Epoch 3963/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8685 - accuracy: 0.5769 - val_loss: 0.9060 - val_accuracy: 0.5530\n",
      "Epoch 3964/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8665 - accuracy: 0.5758 - val_loss: 0.9063 - val_accuracy: 0.5550\n",
      "Epoch 3965/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8664 - accuracy: 0.5767 - val_loss: 0.9233 - val_accuracy: 0.5330\n",
      "Epoch 3966/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8665 - accuracy: 0.5772 - val_loss: 0.9002 - val_accuracy: 0.5577\n",
      "Epoch 3967/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8667 - accuracy: 0.5744 - val_loss: 0.9571 - val_accuracy: 0.5197\n",
      "Epoch 3968/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8677 - accuracy: 0.5767 - val_loss: 0.9029 - val_accuracy: 0.5547\n",
      "Epoch 3969/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8654 - accuracy: 0.5816 - val_loss: 0.9004 - val_accuracy: 0.5557\n",
      "Epoch 3970/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8653 - accuracy: 0.5782 - val_loss: 0.9032 - val_accuracy: 0.5513\n",
      "Epoch 3971/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8679 - accuracy: 0.5755 - val_loss: 0.9028 - val_accuracy: 0.5633\n",
      "Epoch 3972/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8675 - accuracy: 0.5769 - val_loss: 0.8998 - val_accuracy: 0.5600\n",
      "Epoch 3973/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8657 - accuracy: 0.5804 - val_loss: 0.9096 - val_accuracy: 0.5503\n",
      "Epoch 3974/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8681 - accuracy: 0.5767 - val_loss: 0.9016 - val_accuracy: 0.5583\n",
      "Epoch 3975/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8676 - accuracy: 0.5756 - val_loss: 0.9376 - val_accuracy: 0.5233\n",
      "Epoch 3976/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8668 - accuracy: 0.5740 - val_loss: 0.8985 - val_accuracy: 0.5587\n",
      "Epoch 3977/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8667 - accuracy: 0.5787 - val_loss: 0.9097 - val_accuracy: 0.5460\n",
      "Epoch 3978/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8659 - accuracy: 0.5777 - val_loss: 0.9305 - val_accuracy: 0.5370\n",
      "Epoch 3979/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8653 - accuracy: 0.5768 - val_loss: 0.9005 - val_accuracy: 0.5597\n",
      "Epoch 3980/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8673 - accuracy: 0.5743 - val_loss: 0.9135 - val_accuracy: 0.5557\n",
      "Epoch 3981/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8688 - accuracy: 0.5766 - val_loss: 0.9043 - val_accuracy: 0.5550\n",
      "Epoch 3982/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8667 - accuracy: 0.5743 - val_loss: 0.9005 - val_accuracy: 0.5603\n",
      "Epoch 3983/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8673 - accuracy: 0.5760 - val_loss: 0.9249 - val_accuracy: 0.5347\n",
      "Epoch 3984/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8659 - accuracy: 0.5806 - val_loss: 0.9027 - val_accuracy: 0.5563\n",
      "Epoch 3985/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8652 - accuracy: 0.5809 - val_loss: 0.8988 - val_accuracy: 0.5610\n",
      "Epoch 3986/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8676 - accuracy: 0.5763 - val_loss: 0.9061 - val_accuracy: 0.5570\n",
      "Epoch 3987/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8680 - accuracy: 0.5721 - val_loss: 0.9116 - val_accuracy: 0.5487\n",
      "Epoch 3988/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8661 - accuracy: 0.5753 - val_loss: 0.9436 - val_accuracy: 0.5263\n",
      "Epoch 3989/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 0.9035 - val_accuracy: 0.5513\n",
      "Epoch 3990/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8677 - accuracy: 0.5752 - val_loss: 0.8990 - val_accuracy: 0.5587\n",
      "Epoch 3991/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8675 - accuracy: 0.5771 - val_loss: 0.9051 - val_accuracy: 0.5557\n",
      "Epoch 3992/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8700 - accuracy: 0.5718 - val_loss: 0.9600 - val_accuracy: 0.5203\n",
      "Epoch 3993/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8667 - accuracy: 0.5776 - val_loss: 0.8979 - val_accuracy: 0.5623\n",
      "Epoch 3994/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8673 - accuracy: 0.5794 - val_loss: 0.9301 - val_accuracy: 0.5377\n",
      "Epoch 3995/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8663 - accuracy: 0.5796 - val_loss: 0.9015 - val_accuracy: 0.5530\n",
      "Epoch 3996/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8653 - accuracy: 0.5793 - val_loss: 0.9393 - val_accuracy: 0.5233\n",
      "Epoch 3997/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8655 - accuracy: 0.5804 - val_loss: 0.9030 - val_accuracy: 0.5607\n",
      "Epoch 3998/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8679 - accuracy: 0.5809 - val_loss: 0.8984 - val_accuracy: 0.5590\n",
      "Epoch 3999/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8658 - accuracy: 0.5746 - val_loss: 0.9009 - val_accuracy: 0.5550\n",
      "Epoch 4000/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8671 - accuracy: 0.5774 - val_loss: 0.9014 - val_accuracy: 0.5593\n",
      "Epoch 4001/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8666 - accuracy: 0.5780 - val_loss: 0.8987 - val_accuracy: 0.5583\n",
      "Epoch 4002/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8665 - accuracy: 0.5774 - val_loss: 0.9518 - val_accuracy: 0.5187\n",
      "Epoch 4003/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8665 - accuracy: 0.5811 - val_loss: 0.8993 - val_accuracy: 0.5593\n",
      "Epoch 4004/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8652 - accuracy: 0.5799 - val_loss: 0.9021 - val_accuracy: 0.5603\n",
      "Epoch 4005/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8663 - accuracy: 0.5805 - val_loss: 0.9003 - val_accuracy: 0.5547\n",
      "Epoch 4006/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8661 - accuracy: 0.5776 - val_loss: 0.9007 - val_accuracy: 0.5557\n",
      "Epoch 4007/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8683 - accuracy: 0.5751 - val_loss: 0.9030 - val_accuracy: 0.5513\n",
      "Epoch 4008/5500\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.8675 - accuracy: 0.5738 - val_loss: 0.9060 - val_accuracy: 0.5533\n",
      "Epoch 4009/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8661 - accuracy: 0.5778 - val_loss: 0.9047 - val_accuracy: 0.5520\n",
      "Epoch 4010/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8668 - accuracy: 0.5776 - val_loss: 0.9158 - val_accuracy: 0.5407\n",
      "Epoch 4011/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8671 - accuracy: 0.5762 - val_loss: 0.9049 - val_accuracy: 0.5630\n",
      "Epoch 4012/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8674 - accuracy: 0.5733 - val_loss: 0.9303 - val_accuracy: 0.5363\n",
      "Epoch 4013/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8656 - accuracy: 0.5821 - val_loss: 0.9035 - val_accuracy: 0.5520\n",
      "Epoch 4014/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8677 - accuracy: 0.5737 - val_loss: 0.8994 - val_accuracy: 0.5567\n",
      "Epoch 4015/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8663 - accuracy: 0.5799 - val_loss: 0.9030 - val_accuracy: 0.5560\n",
      "Epoch 4016/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8669 - accuracy: 0.5775 - val_loss: 0.9158 - val_accuracy: 0.5543\n",
      "Epoch 4017/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8670 - accuracy: 0.5757 - val_loss: 0.9184 - val_accuracy: 0.5347\n",
      "Epoch 4018/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8658 - accuracy: 0.5775 - val_loss: 0.9340 - val_accuracy: 0.5380\n",
      "Epoch 4019/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8669 - accuracy: 0.5762 - val_loss: 0.9032 - val_accuracy: 0.5583\n",
      "Epoch 4020/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8665 - accuracy: 0.5793 - val_loss: 0.8994 - val_accuracy: 0.5547\n",
      "Epoch 4021/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8685 - accuracy: 0.5780 - val_loss: 0.9525 - val_accuracy: 0.5210\n",
      "Epoch 4022/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8667 - accuracy: 0.5737 - val_loss: 0.8995 - val_accuracy: 0.5627\n",
      "Epoch 4023/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8665 - accuracy: 0.5761 - val_loss: 0.9364 - val_accuracy: 0.5297\n",
      "Epoch 4024/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8671 - accuracy: 0.5784 - val_loss: 0.8993 - val_accuracy: 0.5593\n",
      "Epoch 4025/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8667 - accuracy: 0.5767 - val_loss: 0.9251 - val_accuracy: 0.5363\n",
      "Epoch 4026/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8669 - accuracy: 0.5750 - val_loss: 0.9031 - val_accuracy: 0.5527\n",
      "Epoch 4027/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8662 - accuracy: 0.5764 - val_loss: 0.9073 - val_accuracy: 0.5530\n",
      "Epoch 4028/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8648 - accuracy: 0.5799 - val_loss: 0.9161 - val_accuracy: 0.5437\n",
      "Epoch 4029/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8666 - accuracy: 0.5766 - val_loss: 0.9051 - val_accuracy: 0.5497\n",
      "Epoch 4030/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8667 - accuracy: 0.5757 - val_loss: 0.9032 - val_accuracy: 0.5547\n",
      "Epoch 4031/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8658 - accuracy: 0.5812 - val_loss: 0.9031 - val_accuracy: 0.5570\n",
      "Epoch 4032/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8650 - accuracy: 0.5795 - val_loss: 0.9087 - val_accuracy: 0.5537\n",
      "Epoch 4033/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8670 - accuracy: 0.5729 - val_loss: 0.8985 - val_accuracy: 0.5647\n",
      "Epoch 4034/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8655 - accuracy: 0.5797 - val_loss: 0.9176 - val_accuracy: 0.5470\n",
      "Epoch 4035/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8647 - accuracy: 0.5811 - val_loss: 0.9199 - val_accuracy: 0.5420\n",
      "Epoch 4036/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8660 - accuracy: 0.5763 - val_loss: 0.9036 - val_accuracy: 0.5557\n",
      "Epoch 4037/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8665 - accuracy: 0.5758 - val_loss: 0.8989 - val_accuracy: 0.5623\n",
      "Epoch 4038/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8671 - accuracy: 0.5764 - val_loss: 0.9070 - val_accuracy: 0.5520\n",
      "Epoch 4039/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8671 - accuracy: 0.5759 - val_loss: 0.9012 - val_accuracy: 0.5543\n",
      "Epoch 4040/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8660 - accuracy: 0.5797 - val_loss: 0.9006 - val_accuracy: 0.5567\n",
      "Epoch 4041/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8659 - accuracy: 0.5780 - val_loss: 0.9234 - val_accuracy: 0.5410\n",
      "Epoch 4042/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8652 - accuracy: 0.5809 - val_loss: 0.9020 - val_accuracy: 0.5593\n",
      "Epoch 4043/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8667 - accuracy: 0.5821 - val_loss: 0.9486 - val_accuracy: 0.5243\n",
      "Epoch 4044/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8641 - accuracy: 0.5786 - val_loss: 0.9064 - val_accuracy: 0.5533\n",
      "Epoch 4045/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8647 - accuracy: 0.5774 - val_loss: 0.9015 - val_accuracy: 0.5543\n",
      "Epoch 4046/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8649 - accuracy: 0.5797 - val_loss: 0.8997 - val_accuracy: 0.5590\n",
      "Epoch 4047/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8648 - accuracy: 0.5785 - val_loss: 0.9056 - val_accuracy: 0.5527\n",
      "Epoch 4048/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8657 - accuracy: 0.5796 - val_loss: 0.9169 - val_accuracy: 0.5437\n",
      "Epoch 4049/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8679 - accuracy: 0.5726 - val_loss: 0.9084 - val_accuracy: 0.5493\n",
      "Epoch 4050/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8681 - accuracy: 0.5748 - val_loss: 0.9017 - val_accuracy: 0.5590\n",
      "Epoch 4051/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8650 - accuracy: 0.5769 - val_loss: 0.9005 - val_accuracy: 0.5580\n",
      "Epoch 4052/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8678 - accuracy: 0.5766 - val_loss: 0.9023 - val_accuracy: 0.5570\n",
      "Epoch 4053/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8658 - accuracy: 0.5771 - val_loss: 0.8995 - val_accuracy: 0.5583\n",
      "Epoch 4054/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8663 - accuracy: 0.5785 - val_loss: 0.8981 - val_accuracy: 0.5620\n",
      "Epoch 4055/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8664 - accuracy: 0.5764 - val_loss: 0.9053 - val_accuracy: 0.5517\n",
      "Epoch 4056/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8641 - accuracy: 0.5763 - val_loss: 0.9185 - val_accuracy: 0.5403\n",
      "Epoch 4057/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8664 - accuracy: 0.5781 - val_loss: 0.8992 - val_accuracy: 0.5600\n",
      "Epoch 4058/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8666 - accuracy: 0.5788 - val_loss: 0.9019 - val_accuracy: 0.5573\n",
      "Epoch 4059/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8641 - accuracy: 0.5786 - val_loss: 0.9059 - val_accuracy: 0.5553\n",
      "Epoch 4060/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8660 - accuracy: 0.5812 - val_loss: 0.9008 - val_accuracy: 0.5603\n",
      "Epoch 4061/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8661 - accuracy: 0.5788 - val_loss: 0.8999 - val_accuracy: 0.5587\n",
      "Epoch 4062/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8656 - accuracy: 0.5759 - val_loss: 0.8999 - val_accuracy: 0.5627\n",
      "Epoch 4063/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8635 - accuracy: 0.5785 - val_loss: 0.9035 - val_accuracy: 0.5557\n",
      "Epoch 4064/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8643 - accuracy: 0.5838 - val_loss: 0.9084 - val_accuracy: 0.5537\n",
      "Epoch 4065/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8656 - accuracy: 0.5773 - val_loss: 0.9612 - val_accuracy: 0.5173\n",
      "Epoch 4066/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8668 - accuracy: 0.5769 - val_loss: 0.9087 - val_accuracy: 0.5457\n",
      "Epoch 4067/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8669 - accuracy: 0.5778 - val_loss: 0.9119 - val_accuracy: 0.5500\n",
      "Epoch 4068/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8663 - accuracy: 0.5813 - val_loss: 0.9026 - val_accuracy: 0.5603\n",
      "Epoch 4069/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8647 - accuracy: 0.5746 - val_loss: 0.9105 - val_accuracy: 0.5537\n",
      "Epoch 4070/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8647 - accuracy: 0.5791 - val_loss: 0.9082 - val_accuracy: 0.5503\n",
      "Epoch 4071/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8661 - accuracy: 0.5783 - val_loss: 0.9049 - val_accuracy: 0.5540\n",
      "Epoch 4072/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8676 - accuracy: 0.5784 - val_loss: 0.9052 - val_accuracy: 0.5523\n",
      "Epoch 4073/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8663 - accuracy: 0.5758 - val_loss: 0.9105 - val_accuracy: 0.5513\n",
      "Epoch 4074/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8651 - accuracy: 0.5760 - val_loss: 0.9171 - val_accuracy: 0.5463\n",
      "Epoch 4075/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8641 - accuracy: 0.5784 - val_loss: 0.8995 - val_accuracy: 0.5593\n",
      "Epoch 4076/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8661 - accuracy: 0.5806 - val_loss: 0.9062 - val_accuracy: 0.5540\n",
      "Epoch 4077/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8659 - accuracy: 0.5779 - val_loss: 0.9015 - val_accuracy: 0.5580\n",
      "Epoch 4078/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8656 - accuracy: 0.5740 - val_loss: 0.8991 - val_accuracy: 0.5557\n",
      "Epoch 4079/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8668 - accuracy: 0.5763 - val_loss: 0.9036 - val_accuracy: 0.5550\n",
      "Epoch 4080/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8663 - accuracy: 0.5797 - val_loss: 0.8994 - val_accuracy: 0.5613\n",
      "Epoch 4081/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8656 - accuracy: 0.5759 - val_loss: 0.9283 - val_accuracy: 0.5350\n",
      "Epoch 4082/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8655 - accuracy: 0.5769 - val_loss: 0.9387 - val_accuracy: 0.5283\n",
      "Epoch 4083/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8667 - accuracy: 0.5755 - val_loss: 0.9040 - val_accuracy: 0.5510\n",
      "Epoch 4084/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8647 - accuracy: 0.5821 - val_loss: 0.8996 - val_accuracy: 0.5630\n",
      "Epoch 4085/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8659 - accuracy: 0.5745 - val_loss: 0.9155 - val_accuracy: 0.5513\n",
      "Epoch 4086/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8647 - accuracy: 0.5784 - val_loss: 0.8991 - val_accuracy: 0.5543\n",
      "Epoch 4087/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8650 - accuracy: 0.5744 - val_loss: 0.9036 - val_accuracy: 0.5560\n",
      "Epoch 4088/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8667 - accuracy: 0.5744 - val_loss: 0.8987 - val_accuracy: 0.5570\n",
      "Epoch 4089/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8675 - accuracy: 0.5803 - val_loss: 0.9075 - val_accuracy: 0.5503\n",
      "Epoch 4090/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8650 - accuracy: 0.5792 - val_loss: 0.9303 - val_accuracy: 0.5310\n",
      "Epoch 4091/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8640 - accuracy: 0.5809 - val_loss: 0.8985 - val_accuracy: 0.5570\n",
      "Epoch 4092/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8650 - accuracy: 0.5754 - val_loss: 0.9097 - val_accuracy: 0.5540\n",
      "Epoch 4093/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8649 - accuracy: 0.5767 - val_loss: 0.9094 - val_accuracy: 0.5527\n",
      "Epoch 4094/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8660 - accuracy: 0.5774 - val_loss: 0.9083 - val_accuracy: 0.5490\n",
      "Epoch 4095/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8677 - accuracy: 0.5763 - val_loss: 0.9160 - val_accuracy: 0.5513\n",
      "Epoch 4096/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8655 - accuracy: 0.5746 - val_loss: 0.9003 - val_accuracy: 0.5567\n",
      "Epoch 4097/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8654 - accuracy: 0.5734 - val_loss: 0.9207 - val_accuracy: 0.5453\n",
      "Epoch 4098/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8661 - accuracy: 0.5804 - val_loss: 0.9053 - val_accuracy: 0.5600\n",
      "Epoch 4099/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8650 - accuracy: 0.5786 - val_loss: 0.9210 - val_accuracy: 0.5330\n",
      "Epoch 4100/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8663 - accuracy: 0.5758 - val_loss: 0.9013 - val_accuracy: 0.5600\n",
      "Epoch 4101/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8652 - accuracy: 0.5811 - val_loss: 0.8987 - val_accuracy: 0.5603\n",
      "Epoch 4102/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8637 - accuracy: 0.5794 - val_loss: 0.8982 - val_accuracy: 0.5587\n",
      "Epoch 4103/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8653 - accuracy: 0.5816 - val_loss: 0.9015 - val_accuracy: 0.5550\n",
      "Epoch 4104/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8653 - accuracy: 0.5802 - val_loss: 0.9030 - val_accuracy: 0.5603\n",
      "Epoch 4105/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8654 - accuracy: 0.5770 - val_loss: 0.8991 - val_accuracy: 0.5597\n",
      "Epoch 4106/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8647 - accuracy: 0.5790 - val_loss: 0.9158 - val_accuracy: 0.5460\n",
      "Epoch 4107/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8655 - accuracy: 0.5784 - val_loss: 0.8991 - val_accuracy: 0.5633\n",
      "Epoch 4108/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8666 - accuracy: 0.5753 - val_loss: 0.9072 - val_accuracy: 0.5577\n",
      "Epoch 4109/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8661 - accuracy: 0.5798 - val_loss: 0.9100 - val_accuracy: 0.5517\n",
      "Epoch 4110/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8654 - accuracy: 0.5811 - val_loss: 0.9029 - val_accuracy: 0.5577\n",
      "Epoch 4111/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8661 - accuracy: 0.5804 - val_loss: 0.9105 - val_accuracy: 0.5483\n",
      "Epoch 4112/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8661 - accuracy: 0.5744 - val_loss: 0.9105 - val_accuracy: 0.5513\n",
      "Epoch 4113/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8638 - accuracy: 0.5811 - val_loss: 0.9017 - val_accuracy: 0.5567\n",
      "Epoch 4114/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8643 - accuracy: 0.5765 - val_loss: 0.9207 - val_accuracy: 0.5513\n",
      "Epoch 4115/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8645 - accuracy: 0.5796 - val_loss: 0.9102 - val_accuracy: 0.5500\n",
      "Epoch 4116/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8674 - accuracy: 0.5761 - val_loss: 0.9007 - val_accuracy: 0.5660\n",
      "Epoch 4117/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8631 - accuracy: 0.5830 - val_loss: 0.8998 - val_accuracy: 0.5633\n",
      "Epoch 4118/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8637 - accuracy: 0.5793 - val_loss: 0.9165 - val_accuracy: 0.5520\n",
      "Epoch 4119/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8641 - accuracy: 0.5761 - val_loss: 0.9172 - val_accuracy: 0.5437\n",
      "Epoch 4120/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8674 - accuracy: 0.5741 - val_loss: 0.9088 - val_accuracy: 0.5527\n",
      "Epoch 4121/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8659 - accuracy: 0.5728 - val_loss: 0.9127 - val_accuracy: 0.5493\n",
      "Epoch 4122/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8651 - accuracy: 0.5751 - val_loss: 0.8993 - val_accuracy: 0.5583\n",
      "Epoch 4123/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8637 - accuracy: 0.5796 - val_loss: 0.9181 - val_accuracy: 0.5473\n",
      "Epoch 4124/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8660 - accuracy: 0.5794 - val_loss: 0.8987 - val_accuracy: 0.5583\n",
      "Epoch 4125/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8670 - accuracy: 0.5743 - val_loss: 0.9193 - val_accuracy: 0.5363\n",
      "Epoch 4126/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8673 - accuracy: 0.5756 - val_loss: 0.9062 - val_accuracy: 0.5463\n",
      "Epoch 4127/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8667 - accuracy: 0.5783 - val_loss: 0.9136 - val_accuracy: 0.5507\n",
      "Epoch 4128/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8668 - accuracy: 0.5729 - val_loss: 0.9109 - val_accuracy: 0.5553\n",
      "Epoch 4129/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8648 - accuracy: 0.5791 - val_loss: 0.8982 - val_accuracy: 0.5600\n",
      "Epoch 4130/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.8650 - accuracy: 0.5784 - val_loss: 0.9027 - val_accuracy: 0.5597\n",
      "Epoch 4131/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8648 - accuracy: 0.5804 - val_loss: 0.9074 - val_accuracy: 0.5510\n",
      "Epoch 4132/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8643 - accuracy: 0.5771 - val_loss: 0.9253 - val_accuracy: 0.5303\n",
      "Epoch 4133/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8659 - accuracy: 0.5763 - val_loss: 0.9017 - val_accuracy: 0.5527\n",
      "Epoch 4134/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8660 - accuracy: 0.5755 - val_loss: 0.9037 - val_accuracy: 0.5583\n",
      "Epoch 4135/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8656 - accuracy: 0.5812 - val_loss: 0.9031 - val_accuracy: 0.5573\n",
      "Epoch 4136/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8643 - accuracy: 0.5817 - val_loss: 0.9136 - val_accuracy: 0.5420\n",
      "Epoch 4137/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8667 - accuracy: 0.5789 - val_loss: 0.9000 - val_accuracy: 0.5567\n",
      "Epoch 4138/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8642 - accuracy: 0.5782 - val_loss: 0.9063 - val_accuracy: 0.5570\n",
      "Epoch 4139/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8646 - accuracy: 0.5750 - val_loss: 0.9016 - val_accuracy: 0.5610\n",
      "Epoch 4140/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8647 - accuracy: 0.5797 - val_loss: 0.9019 - val_accuracy: 0.5653\n",
      "Epoch 4141/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8659 - accuracy: 0.5759 - val_loss: 0.8985 - val_accuracy: 0.5613\n",
      "Epoch 4142/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8647 - accuracy: 0.5807 - val_loss: 0.9109 - val_accuracy: 0.5517\n",
      "Epoch 4143/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8654 - accuracy: 0.5767 - val_loss: 0.9034 - val_accuracy: 0.5590\n",
      "Epoch 4144/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8652 - accuracy: 0.5780 - val_loss: 0.9129 - val_accuracy: 0.5507\n",
      "Epoch 4145/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8666 - accuracy: 0.5769 - val_loss: 0.8989 - val_accuracy: 0.5593\n",
      "Epoch 4146/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8631 - accuracy: 0.5784 - val_loss: 0.9006 - val_accuracy: 0.5640\n",
      "Epoch 4147/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8657 - accuracy: 0.5805 - val_loss: 0.9162 - val_accuracy: 0.5507\n",
      "Epoch 4148/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8625 - accuracy: 0.5844 - val_loss: 0.8974 - val_accuracy: 0.5613\n",
      "Epoch 4149/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8648 - accuracy: 0.5781 - val_loss: 0.9028 - val_accuracy: 0.5603\n",
      "Epoch 4150/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8654 - accuracy: 0.5823 - val_loss: 0.9106 - val_accuracy: 0.5540\n",
      "Epoch 4151/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8653 - accuracy: 0.5790 - val_loss: 0.9140 - val_accuracy: 0.5433\n",
      "Epoch 4152/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8643 - accuracy: 0.5796 - val_loss: 0.8985 - val_accuracy: 0.5553\n",
      "Epoch 4153/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8636 - accuracy: 0.5814 - val_loss: 0.9146 - val_accuracy: 0.5510\n",
      "Epoch 4154/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8652 - accuracy: 0.5775 - val_loss: 0.9012 - val_accuracy: 0.5640\n",
      "Epoch 4155/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8641 - accuracy: 0.5776 - val_loss: 0.8988 - val_accuracy: 0.5600\n",
      "Epoch 4156/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8653 - accuracy: 0.5786 - val_loss: 0.9578 - val_accuracy: 0.5240\n",
      "Epoch 4157/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8653 - accuracy: 0.5784 - val_loss: 0.9446 - val_accuracy: 0.5297\n",
      "Epoch 4158/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8664 - accuracy: 0.5755 - val_loss: 0.9014 - val_accuracy: 0.5590\n",
      "Epoch 4159/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8642 - accuracy: 0.5811 - val_loss: 0.9157 - val_accuracy: 0.5490\n",
      "Epoch 4160/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8642 - accuracy: 0.5787 - val_loss: 0.8990 - val_accuracy: 0.5637\n",
      "Epoch 4161/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8639 - accuracy: 0.5791 - val_loss: 0.9005 - val_accuracy: 0.5600\n",
      "Epoch 4162/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8654 - accuracy: 0.5779 - val_loss: 0.9008 - val_accuracy: 0.5567\n",
      "Epoch 4163/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8641 - accuracy: 0.5732 - val_loss: 0.9290 - val_accuracy: 0.5330\n",
      "Epoch 4164/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8656 - accuracy: 0.5803 - val_loss: 0.8987 - val_accuracy: 0.5623\n",
      "Epoch 4165/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8642 - accuracy: 0.5779 - val_loss: 0.8989 - val_accuracy: 0.5570\n",
      "Epoch 4166/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8661 - accuracy: 0.5764 - val_loss: 0.9327 - val_accuracy: 0.5360\n",
      "Epoch 4167/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8640 - accuracy: 0.5819 - val_loss: 0.9329 - val_accuracy: 0.5270\n",
      "Epoch 4168/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8646 - accuracy: 0.5811 - val_loss: 0.8994 - val_accuracy: 0.5593\n",
      "Epoch 4169/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8663 - accuracy: 0.5763 - val_loss: 0.8989 - val_accuracy: 0.5627\n",
      "Epoch 4170/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8655 - accuracy: 0.5791 - val_loss: 0.9403 - val_accuracy: 0.5307\n",
      "Epoch 4171/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8642 - accuracy: 0.5796 - val_loss: 0.9103 - val_accuracy: 0.5530\n",
      "Epoch 4172/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8653 - accuracy: 0.5794 - val_loss: 0.9027 - val_accuracy: 0.5543\n",
      "Epoch 4173/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8642 - accuracy: 0.5774 - val_loss: 0.9033 - val_accuracy: 0.5630\n",
      "Epoch 4174/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8653 - accuracy: 0.5739 - val_loss: 0.9582 - val_accuracy: 0.5147\n",
      "Epoch 4175/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8648 - accuracy: 0.5781 - val_loss: 0.9150 - val_accuracy: 0.5500\n",
      "Epoch 4176/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8620 - accuracy: 0.5823 - val_loss: 0.9049 - val_accuracy: 0.5533\n",
      "Epoch 4177/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8652 - accuracy: 0.5761 - val_loss: 0.9107 - val_accuracy: 0.5527\n",
      "Epoch 4178/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8668 - accuracy: 0.5769 - val_loss: 0.9005 - val_accuracy: 0.5560\n",
      "Epoch 4179/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8655 - accuracy: 0.5804 - val_loss: 0.9041 - val_accuracy: 0.5570\n",
      "Epoch 4180/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8647 - accuracy: 0.5815 - val_loss: 0.9031 - val_accuracy: 0.5583\n",
      "Epoch 4181/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8634 - accuracy: 0.5795 - val_loss: 0.9672 - val_accuracy: 0.5107\n",
      "Epoch 4182/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8670 - accuracy: 0.5756 - val_loss: 0.9129 - val_accuracy: 0.5507\n",
      "Epoch 4183/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8646 - accuracy: 0.5814 - val_loss: 0.9070 - val_accuracy: 0.5530\n",
      "Epoch 4184/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8645 - accuracy: 0.5782 - val_loss: 0.9439 - val_accuracy: 0.5287\n",
      "Epoch 4185/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8639 - accuracy: 0.5814 - val_loss: 0.9000 - val_accuracy: 0.5597\n",
      "Epoch 4186/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8628 - accuracy: 0.5819 - val_loss: 0.9199 - val_accuracy: 0.5507\n",
      "Epoch 4187/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8645 - accuracy: 0.5798 - val_loss: 0.9031 - val_accuracy: 0.5577\n",
      "Epoch 4188/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8661 - accuracy: 0.5754 - val_loss: 0.9013 - val_accuracy: 0.5617\n",
      "Epoch 4189/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8666 - accuracy: 0.5774 - val_loss: 0.9030 - val_accuracy: 0.5537\n",
      "Epoch 4190/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8634 - accuracy: 0.5790 - val_loss: 0.9012 - val_accuracy: 0.5533\n",
      "Epoch 4191/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8639 - accuracy: 0.5810 - val_loss: 0.8999 - val_accuracy: 0.5577\n",
      "Epoch 4192/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8642 - accuracy: 0.5825 - val_loss: 0.9051 - val_accuracy: 0.5560\n",
      "Epoch 4193/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8643 - accuracy: 0.5824 - val_loss: 0.9118 - val_accuracy: 0.5527\n",
      "Epoch 4194/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8648 - accuracy: 0.5779 - val_loss: 0.8985 - val_accuracy: 0.5627\n",
      "Epoch 4195/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8632 - accuracy: 0.5805 - val_loss: 0.9036 - val_accuracy: 0.5593\n",
      "Epoch 4196/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8650 - accuracy: 0.5802 - val_loss: 0.8999 - val_accuracy: 0.5587\n",
      "Epoch 4197/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8651 - accuracy: 0.5786 - val_loss: 0.9076 - val_accuracy: 0.5460\n",
      "Epoch 4198/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8656 - accuracy: 0.5746 - val_loss: 0.9022 - val_accuracy: 0.5603\n",
      "Epoch 4199/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8651 - accuracy: 0.5804 - val_loss: 0.9006 - val_accuracy: 0.5607\n",
      "Epoch 4200/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8658 - accuracy: 0.5754 - val_loss: 0.9003 - val_accuracy: 0.5627\n",
      "Epoch 4201/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8648 - accuracy: 0.5781 - val_loss: 0.9000 - val_accuracy: 0.5580\n",
      "Epoch 4202/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8654 - accuracy: 0.5811 - val_loss: 0.8993 - val_accuracy: 0.5603\n",
      "Epoch 4203/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8636 - accuracy: 0.5806 - val_loss: 0.9068 - val_accuracy: 0.5527\n",
      "Epoch 4204/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8639 - accuracy: 0.5770 - val_loss: 0.8990 - val_accuracy: 0.5633\n",
      "Epoch 4205/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8648 - accuracy: 0.5777 - val_loss: 0.8988 - val_accuracy: 0.5587\n",
      "Epoch 4206/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8651 - accuracy: 0.5789 - val_loss: 0.9083 - val_accuracy: 0.5537\n",
      "Epoch 4207/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8632 - accuracy: 0.5788 - val_loss: 0.9479 - val_accuracy: 0.5207\n",
      "Epoch 4208/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8660 - accuracy: 0.5761 - val_loss: 0.8985 - val_accuracy: 0.5620\n",
      "Epoch 4209/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8643 - accuracy: 0.5791 - val_loss: 0.9018 - val_accuracy: 0.5580\n",
      "Epoch 4210/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8632 - accuracy: 0.5811 - val_loss: 0.9244 - val_accuracy: 0.5430\n",
      "Epoch 4211/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8650 - accuracy: 0.5759 - val_loss: 0.9019 - val_accuracy: 0.5577\n",
      "Epoch 4212/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8642 - accuracy: 0.5791 - val_loss: 0.8989 - val_accuracy: 0.5607\n",
      "Epoch 4213/5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8637 - accuracy: 0.5807 - val_loss: 0.9001 - val_accuracy: 0.5573\n",
      "Epoch 4214/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8640 - accuracy: 0.5796 - val_loss: 0.9019 - val_accuracy: 0.5567\n",
      "Epoch 4215/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8641 - accuracy: 0.5806 - val_loss: 0.9055 - val_accuracy: 0.5503\n",
      "Epoch 4216/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8655 - accuracy: 0.5748 - val_loss: 0.9215 - val_accuracy: 0.5353\n",
      "Epoch 4217/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8632 - accuracy: 0.5792 - val_loss: 0.9153 - val_accuracy: 0.5423\n",
      "Epoch 4218/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8626 - accuracy: 0.5809 - val_loss: 0.9493 - val_accuracy: 0.5220\n",
      "Epoch 4219/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8660 - accuracy: 0.5750 - val_loss: 0.9004 - val_accuracy: 0.5530\n",
      "Epoch 4220/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8649 - accuracy: 0.5775 - val_loss: 0.9067 - val_accuracy: 0.5470\n",
      "Epoch 4221/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8655 - accuracy: 0.5759 - val_loss: 0.9114 - val_accuracy: 0.5517\n",
      "Epoch 4222/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8666 - accuracy: 0.5784 - val_loss: 0.9053 - val_accuracy: 0.5523\n",
      "Epoch 4223/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8658 - accuracy: 0.5776 - val_loss: 0.9106 - val_accuracy: 0.5537\n",
      "Epoch 4224/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8639 - accuracy: 0.5802 - val_loss: 0.9004 - val_accuracy: 0.5530\n",
      "Epoch 4225/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8651 - accuracy: 0.5784 - val_loss: 0.9545 - val_accuracy: 0.5290\n",
      "Epoch 4226/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8647 - accuracy: 0.5796 - val_loss: 0.9078 - val_accuracy: 0.5507\n",
      "Epoch 4227/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8631 - accuracy: 0.5800 - val_loss: 0.8983 - val_accuracy: 0.5620\n",
      "Epoch 4228/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8643 - accuracy: 0.5779 - val_loss: 0.9078 - val_accuracy: 0.5550\n",
      "Epoch 4229/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8619 - accuracy: 0.5806 - val_loss: 0.9320 - val_accuracy: 0.5340\n",
      "Epoch 4230/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8646 - accuracy: 0.5810 - val_loss: 0.8990 - val_accuracy: 0.5647\n",
      "Epoch 4231/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8641 - accuracy: 0.5825 - val_loss: 0.9012 - val_accuracy: 0.5620\n",
      "Epoch 4232/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8644 - accuracy: 0.5773 - val_loss: 0.9055 - val_accuracy: 0.5473\n",
      "Epoch 4233/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8638 - accuracy: 0.5812 - val_loss: 0.9116 - val_accuracy: 0.5410\n",
      "Epoch 4234/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8654 - accuracy: 0.5775 - val_loss: 0.9025 - val_accuracy: 0.5570\n",
      "Epoch 4235/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8639 - accuracy: 0.5794 - val_loss: 0.9057 - val_accuracy: 0.5577\n",
      "Epoch 4236/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8637 - accuracy: 0.5802 - val_loss: 0.9031 - val_accuracy: 0.5517\n",
      "Epoch 4237/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8639 - accuracy: 0.5788 - val_loss: 0.9001 - val_accuracy: 0.5580\n",
      "Epoch 4238/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8662 - accuracy: 0.5789 - val_loss: 0.9040 - val_accuracy: 0.5540\n",
      "Epoch 4239/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8633 - accuracy: 0.5814 - val_loss: 0.9245 - val_accuracy: 0.5363\n",
      "Epoch 4240/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8627 - accuracy: 0.5787 - val_loss: 0.9072 - val_accuracy: 0.5557\n",
      "Epoch 4241/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8621 - accuracy: 0.5848 - val_loss: 0.9008 - val_accuracy: 0.5603\n",
      "Epoch 4242/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8642 - accuracy: 0.5797 - val_loss: 0.9039 - val_accuracy: 0.5610\n",
      "Epoch 4243/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8614 - accuracy: 0.5853 - val_loss: 0.8989 - val_accuracy: 0.5613\n",
      "Epoch 4244/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8626 - accuracy: 0.5824 - val_loss: 0.8999 - val_accuracy: 0.5627\n",
      "Epoch 4245/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8628 - accuracy: 0.5788 - val_loss: 0.9099 - val_accuracy: 0.5493\n",
      "Epoch 4246/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8637 - accuracy: 0.5782 - val_loss: 0.9007 - val_accuracy: 0.5567\n",
      "Epoch 4247/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8654 - accuracy: 0.5756 - val_loss: 0.9400 - val_accuracy: 0.5283\n",
      "Epoch 4248/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8638 - accuracy: 0.5761 - val_loss: 0.9239 - val_accuracy: 0.5327\n",
      "Epoch 4249/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8633 - accuracy: 0.5811 - val_loss: 0.9051 - val_accuracy: 0.5493\n",
      "Epoch 4250/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8633 - accuracy: 0.5773 - val_loss: 0.9029 - val_accuracy: 0.5593\n",
      "Epoch 4251/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8632 - accuracy: 0.5773 - val_loss: 0.9054 - val_accuracy: 0.5597\n",
      "Epoch 4252/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8644 - accuracy: 0.5769 - val_loss: 0.9245 - val_accuracy: 0.5323\n",
      "Epoch 4253/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8632 - accuracy: 0.5793 - val_loss: 0.9101 - val_accuracy: 0.5547\n",
      "Epoch 4254/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8630 - accuracy: 0.5773 - val_loss: 0.9294 - val_accuracy: 0.5373\n",
      "Epoch 4255/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8640 - accuracy: 0.5814 - val_loss: 0.9018 - val_accuracy: 0.5597\n",
      "Epoch 4256/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8643 - accuracy: 0.5814 - val_loss: 0.9034 - val_accuracy: 0.5550\n",
      "Epoch 4257/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8625 - accuracy: 0.5784 - val_loss: 0.9051 - val_accuracy: 0.5490\n",
      "Epoch 4258/5500\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.8647 - accuracy: 0.57 - 0s 18us/step - loss: 0.8643 - accuracy: 0.5751 - val_loss: 0.9106 - val_accuracy: 0.5510\n",
      "Epoch 4259/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8620 - accuracy: 0.5777 - val_loss: 0.9008 - val_accuracy: 0.5550\n",
      "Epoch 4260/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8639 - accuracy: 0.5792 - val_loss: 0.9024 - val_accuracy: 0.5610\n",
      "Epoch 4261/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8631 - accuracy: 0.5777 - val_loss: 0.9004 - val_accuracy: 0.5610\n",
      "Epoch 4262/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8625 - accuracy: 0.5834 - val_loss: 0.9400 - val_accuracy: 0.5313\n",
      "Epoch 4263/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8653 - accuracy: 0.5743 - val_loss: 0.9090 - val_accuracy: 0.5557\n",
      "Epoch 4264/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8635 - accuracy: 0.5753 - val_loss: 0.9020 - val_accuracy: 0.5537\n",
      "Epoch 4265/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8631 - accuracy: 0.5803 - val_loss: 0.9127 - val_accuracy: 0.5470\n",
      "Epoch 4266/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8639 - accuracy: 0.5781 - val_loss: 0.9625 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4267/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8633 - accuracy: 0.5801 - val_loss: 0.9233 - val_accuracy: 0.5330\n",
      "Epoch 4268/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8637 - accuracy: 0.5780 - val_loss: 0.9045 - val_accuracy: 0.5507\n",
      "Epoch 4269/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8626 - accuracy: 0.5794 - val_loss: 0.9079 - val_accuracy: 0.5540\n",
      "Epoch 4270/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8651 - accuracy: 0.5799 - val_loss: 0.9069 - val_accuracy: 0.5573\n",
      "Epoch 4271/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8649 - accuracy: 0.5792 - val_loss: 0.9059 - val_accuracy: 0.5540\n",
      "Epoch 4272/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8630 - accuracy: 0.5779 - val_loss: 0.9235 - val_accuracy: 0.5460\n",
      "Epoch 4273/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8648 - accuracy: 0.5784 - val_loss: 0.9040 - val_accuracy: 0.5550\n",
      "Epoch 4274/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8645 - accuracy: 0.5755 - val_loss: 0.9004 - val_accuracy: 0.5610\n",
      "Epoch 4275/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8637 - accuracy: 0.5779 - val_loss: 0.9032 - val_accuracy: 0.5600\n",
      "Epoch 4276/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8625 - accuracy: 0.5828 - val_loss: 0.9003 - val_accuracy: 0.5607\n",
      "Epoch 4277/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8626 - accuracy: 0.5819 - val_loss: 0.8985 - val_accuracy: 0.5590\n",
      "Epoch 4278/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8646 - accuracy: 0.5789 - val_loss: 0.9020 - val_accuracy: 0.5587\n",
      "Epoch 4279/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8620 - accuracy: 0.5804 - val_loss: 0.8990 - val_accuracy: 0.5607\n",
      "Epoch 4280/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8626 - accuracy: 0.5793 - val_loss: 0.9182 - val_accuracy: 0.5433\n",
      "Epoch 4281/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8629 - accuracy: 0.5789 - val_loss: 0.9013 - val_accuracy: 0.5567\n",
      "Epoch 4282/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8633 - accuracy: 0.5807 - val_loss: 0.9020 - val_accuracy: 0.5587\n",
      "Epoch 4283/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8619 - accuracy: 0.5788 - val_loss: 0.9023 - val_accuracy: 0.5587\n",
      "Epoch 4284/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8628 - accuracy: 0.5821 - val_loss: 0.9102 - val_accuracy: 0.5497\n",
      "Epoch 4285/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8639 - accuracy: 0.5754 - val_loss: 0.9400 - val_accuracy: 0.5303\n",
      "Epoch 4286/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8634 - accuracy: 0.5780 - val_loss: 0.8992 - val_accuracy: 0.5620\n",
      "Epoch 4287/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8635 - accuracy: 0.5809 - val_loss: 0.8998 - val_accuracy: 0.5557\n",
      "Epoch 4288/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8638 - accuracy: 0.5824 - val_loss: 0.9301 - val_accuracy: 0.5410\n",
      "Epoch 4289/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8628 - accuracy: 0.5771 - val_loss: 0.9056 - val_accuracy: 0.5573\n",
      "Epoch 4290/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8647 - accuracy: 0.5752 - val_loss: 0.9018 - val_accuracy: 0.5613\n",
      "Epoch 4291/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8630 - accuracy: 0.5798 - val_loss: 0.9228 - val_accuracy: 0.5357\n",
      "Epoch 4292/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8634 - accuracy: 0.5780 - val_loss: 0.9112 - val_accuracy: 0.5550\n",
      "Epoch 4293/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8627 - accuracy: 0.5797 - val_loss: 0.9012 - val_accuracy: 0.5633\n",
      "Epoch 4294/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8638 - accuracy: 0.5794 - val_loss: 0.8998 - val_accuracy: 0.5610\n",
      "Epoch 4295/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8644 - accuracy: 0.5799 - val_loss: 0.9135 - val_accuracy: 0.5473\n",
      "Epoch 4296/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8622 - accuracy: 0.5824 - val_loss: 0.9039 - val_accuracy: 0.5547\n",
      "Epoch 4297/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8665 - accuracy: 0.5765 - val_loss: 0.9196 - val_accuracy: 0.5447\n",
      "Epoch 4298/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8615 - accuracy: 0.5815 - val_loss: 0.8997 - val_accuracy: 0.5627\n",
      "Epoch 4299/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8630 - accuracy: 0.5819 - val_loss: 0.8990 - val_accuracy: 0.5617\n",
      "Epoch 4300/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8633 - accuracy: 0.5790 - val_loss: 0.9178 - val_accuracy: 0.5440\n",
      "Epoch 4301/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8625 - accuracy: 0.5814 - val_loss: 0.8981 - val_accuracy: 0.5597\n",
      "Epoch 4302/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8645 - accuracy: 0.5814 - val_loss: 0.9000 - val_accuracy: 0.5623\n",
      "Epoch 4303/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8615 - accuracy: 0.5841 - val_loss: 0.9153 - val_accuracy: 0.5477\n",
      "Epoch 4304/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8649 - accuracy: 0.5823 - val_loss: 0.9051 - val_accuracy: 0.5570\n",
      "Epoch 4305/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8627 - accuracy: 0.5821 - val_loss: 0.9092 - val_accuracy: 0.5523\n",
      "Epoch 4306/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8661 - accuracy: 0.5811 - val_loss: 0.9337 - val_accuracy: 0.5350\n",
      "Epoch 4307/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8614 - accuracy: 0.5792 - val_loss: 0.9001 - val_accuracy: 0.5623\n",
      "Epoch 4308/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8626 - accuracy: 0.5803 - val_loss: 0.9156 - val_accuracy: 0.5403\n",
      "Epoch 4309/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8625 - accuracy: 0.5829 - val_loss: 0.9022 - val_accuracy: 0.5533\n",
      "Epoch 4310/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8622 - accuracy: 0.5799 - val_loss: 0.9143 - val_accuracy: 0.5457\n",
      "Epoch 4311/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8655 - accuracy: 0.5745 - val_loss: 0.8985 - val_accuracy: 0.5663\n",
      "Epoch 4312/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8601 - accuracy: 0.5812 - val_loss: 0.9067 - val_accuracy: 0.5583\n",
      "Epoch 4313/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8632 - accuracy: 0.5829 - val_loss: 0.9093 - val_accuracy: 0.5537\n",
      "Epoch 4314/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8629 - accuracy: 0.5761 - val_loss: 0.9076 - val_accuracy: 0.5517\n",
      "Epoch 4315/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8642 - accuracy: 0.5796 - val_loss: 0.9021 - val_accuracy: 0.5567\n",
      "Epoch 4316/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8618 - accuracy: 0.5814 - val_loss: 0.8980 - val_accuracy: 0.5647\n",
      "Epoch 4317/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8613 - accuracy: 0.5822 - val_loss: 0.9056 - val_accuracy: 0.5553\n",
      "Epoch 4318/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8643 - accuracy: 0.5783 - val_loss: 0.8999 - val_accuracy: 0.5607\n",
      "Epoch 4319/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8661 - accuracy: 0.5744 - val_loss: 0.9069 - val_accuracy: 0.5553\n",
      "Epoch 4320/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8638 - accuracy: 0.5791 - val_loss: 0.9060 - val_accuracy: 0.5437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4321/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8623 - accuracy: 0.5812 - val_loss: 0.9030 - val_accuracy: 0.5610\n",
      "Epoch 4322/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.8628 - accuracy: 0.5798 - val_loss: 0.9005 - val_accuracy: 0.5633\n",
      "Epoch 4323/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8620 - accuracy: 0.5794 - val_loss: 0.9011 - val_accuracy: 0.5583\n",
      "Epoch 4324/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8630 - accuracy: 0.5799 - val_loss: 0.9034 - val_accuracy: 0.5557\n",
      "Epoch 4325/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8631 - accuracy: 0.5792 - val_loss: 0.9042 - val_accuracy: 0.5537\n",
      "Epoch 4326/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8645 - accuracy: 0.5783 - val_loss: 0.8988 - val_accuracy: 0.5597\n",
      "Epoch 4327/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8623 - accuracy: 0.5764 - val_loss: 0.9000 - val_accuracy: 0.5570\n",
      "Epoch 4328/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8615 - accuracy: 0.5796 - val_loss: 0.9054 - val_accuracy: 0.5520\n",
      "Epoch 4329/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8614 - accuracy: 0.5825 - val_loss: 0.9392 - val_accuracy: 0.5313\n",
      "Epoch 4330/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8628 - accuracy: 0.5813 - val_loss: 0.9175 - val_accuracy: 0.5403\n",
      "Epoch 4331/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8639 - accuracy: 0.5771 - val_loss: 0.8985 - val_accuracy: 0.5613\n",
      "Epoch 4332/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8628 - accuracy: 0.5811 - val_loss: 0.9036 - val_accuracy: 0.5633\n",
      "Epoch 4333/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8624 - accuracy: 0.5800 - val_loss: 0.9109 - val_accuracy: 0.5530\n",
      "Epoch 4334/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8631 - accuracy: 0.5818 - val_loss: 0.9224 - val_accuracy: 0.5347\n",
      "Epoch 4335/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8623 - accuracy: 0.5776 - val_loss: 0.9011 - val_accuracy: 0.5553\n",
      "Epoch 4336/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8612 - accuracy: 0.5794 - val_loss: 0.8987 - val_accuracy: 0.5630\n",
      "Epoch 4337/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8649 - accuracy: 0.5766 - val_loss: 0.9025 - val_accuracy: 0.5533\n",
      "Epoch 4338/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8624 - accuracy: 0.5799 - val_loss: 0.9130 - val_accuracy: 0.5440\n",
      "Epoch 4339/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8647 - accuracy: 0.5736 - val_loss: 0.9055 - val_accuracy: 0.5523\n",
      "Epoch 4340/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8616 - accuracy: 0.5811 - val_loss: 0.9061 - val_accuracy: 0.5493\n",
      "Epoch 4341/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8640 - accuracy: 0.5791 - val_loss: 0.9152 - val_accuracy: 0.5540\n",
      "Epoch 4342/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8632 - accuracy: 0.5786 - val_loss: 0.8986 - val_accuracy: 0.5610\n",
      "Epoch 4343/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8618 - accuracy: 0.5849 - val_loss: 0.9074 - val_accuracy: 0.5553\n",
      "Epoch 4344/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8621 - accuracy: 0.5798 - val_loss: 0.8985 - val_accuracy: 0.5590\n",
      "Epoch 4345/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8619 - accuracy: 0.5818 - val_loss: 0.9003 - val_accuracy: 0.5557\n",
      "Epoch 4346/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8617 - accuracy: 0.5820 - val_loss: 0.9120 - val_accuracy: 0.5523\n",
      "Epoch 4347/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8631 - accuracy: 0.5801 - val_loss: 0.9179 - val_accuracy: 0.5480\n",
      "Epoch 4348/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8615 - accuracy: 0.5790 - val_loss: 0.8992 - val_accuracy: 0.5567\n",
      "Epoch 4349/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8614 - accuracy: 0.5834 - val_loss: 0.9089 - val_accuracy: 0.5553\n",
      "Epoch 4350/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8629 - accuracy: 0.5808 - val_loss: 0.9111 - val_accuracy: 0.5437\n",
      "Epoch 4351/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8617 - accuracy: 0.5822 - val_loss: 0.9018 - val_accuracy: 0.5547\n",
      "Epoch 4352/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8623 - accuracy: 0.5780 - val_loss: 0.8982 - val_accuracy: 0.5617\n",
      "Epoch 4353/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8612 - accuracy: 0.5814 - val_loss: 0.9033 - val_accuracy: 0.5540\n",
      "Epoch 4354/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8623 - accuracy: 0.5797 - val_loss: 0.8995 - val_accuracy: 0.5593\n",
      "Epoch 4355/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8650 - accuracy: 0.5794 - val_loss: 0.9034 - val_accuracy: 0.5593\n",
      "Epoch 4356/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8637 - accuracy: 0.5807 - val_loss: 0.9030 - val_accuracy: 0.5603\n",
      "Epoch 4357/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8611 - accuracy: 0.5792 - val_loss: 0.9011 - val_accuracy: 0.5627\n",
      "Epoch 4358/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8621 - accuracy: 0.5788 - val_loss: 0.9030 - val_accuracy: 0.5557\n",
      "Epoch 4359/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8622 - accuracy: 0.5795 - val_loss: 0.9023 - val_accuracy: 0.5517\n",
      "Epoch 4360/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8626 - accuracy: 0.5801 - val_loss: 0.9188 - val_accuracy: 0.5403\n",
      "Epoch 4361/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8637 - accuracy: 0.5784 - val_loss: 0.9116 - val_accuracy: 0.5510\n",
      "Epoch 4362/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8607 - accuracy: 0.5840 - val_loss: 0.9120 - val_accuracy: 0.5527\n",
      "Epoch 4363/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8618 - accuracy: 0.5796 - val_loss: 0.9089 - val_accuracy: 0.5530\n",
      "Epoch 4364/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8631 - accuracy: 0.5831 - val_loss: 0.9052 - val_accuracy: 0.5560\n",
      "Epoch 4365/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8615 - accuracy: 0.5809 - val_loss: 0.9213 - val_accuracy: 0.5337\n",
      "Epoch 4366/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8650 - accuracy: 0.5764 - val_loss: 0.9192 - val_accuracy: 0.5510\n",
      "Epoch 4367/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8630 - accuracy: 0.5789 - val_loss: 0.8992 - val_accuracy: 0.5593\n",
      "Epoch 4368/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8612 - accuracy: 0.5815 - val_loss: 0.9039 - val_accuracy: 0.5547\n",
      "Epoch 4369/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8601 - accuracy: 0.5826 - val_loss: 0.9013 - val_accuracy: 0.5640\n",
      "Epoch 4370/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8636 - accuracy: 0.5784 - val_loss: 0.9013 - val_accuracy: 0.5617\n",
      "Epoch 4371/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8639 - accuracy: 0.5811 - val_loss: 0.8988 - val_accuracy: 0.5607\n",
      "Epoch 4372/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8644 - accuracy: 0.5814 - val_loss: 0.8999 - val_accuracy: 0.5607\n",
      "Epoch 4373/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8631 - accuracy: 0.5800 - val_loss: 0.9027 - val_accuracy: 0.5607\n",
      "Epoch 4374/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8624 - accuracy: 0.5769 - val_loss: 0.8988 - val_accuracy: 0.5593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4375/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8621 - accuracy: 0.5819 - val_loss: 0.8998 - val_accuracy: 0.5647\n",
      "Epoch 4376/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8616 - accuracy: 0.5809 - val_loss: 0.9398 - val_accuracy: 0.5273\n",
      "Epoch 4377/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8606 - accuracy: 0.5840 - val_loss: 0.9052 - val_accuracy: 0.5570\n",
      "Epoch 4378/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8625 - accuracy: 0.5820 - val_loss: 0.9028 - val_accuracy: 0.5587\n",
      "Epoch 4379/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8627 - accuracy: 0.5755 - val_loss: 0.8992 - val_accuracy: 0.5583\n",
      "Epoch 4380/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8638 - accuracy: 0.5803 - val_loss: 0.9192 - val_accuracy: 0.5460\n",
      "Epoch 4381/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8610 - accuracy: 0.5790 - val_loss: 0.9026 - val_accuracy: 0.5610\n",
      "Epoch 4382/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8637 - accuracy: 0.5780 - val_loss: 0.9107 - val_accuracy: 0.5493\n",
      "Epoch 4383/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8629 - accuracy: 0.5779 - val_loss: 0.9000 - val_accuracy: 0.5647\n",
      "Epoch 4384/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8646 - accuracy: 0.5810 - val_loss: 0.9546 - val_accuracy: 0.5157\n",
      "Epoch 4385/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8633 - accuracy: 0.5818 - val_loss: 0.9011 - val_accuracy: 0.5637\n",
      "Epoch 4386/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8627 - accuracy: 0.5844 - val_loss: 0.9018 - val_accuracy: 0.5623\n",
      "Epoch 4387/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8621 - accuracy: 0.5764 - val_loss: 0.9002 - val_accuracy: 0.5637\n",
      "Epoch 4388/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8625 - accuracy: 0.5804 - val_loss: 0.9178 - val_accuracy: 0.5470\n",
      "Epoch 4389/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8616 - accuracy: 0.5801 - val_loss: 0.9032 - val_accuracy: 0.5527\n",
      "Epoch 4390/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8619 - accuracy: 0.5821 - val_loss: 0.9166 - val_accuracy: 0.5420\n",
      "Epoch 4391/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8625 - accuracy: 0.5783 - val_loss: 0.9008 - val_accuracy: 0.5580\n",
      "Epoch 4392/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8631 - accuracy: 0.5818 - val_loss: 0.9004 - val_accuracy: 0.5647\n",
      "Epoch 4393/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8611 - accuracy: 0.5816 - val_loss: 0.9053 - val_accuracy: 0.5517\n",
      "Epoch 4394/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8619 - accuracy: 0.5784 - val_loss: 0.9002 - val_accuracy: 0.5623\n",
      "Epoch 4395/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8622 - accuracy: 0.5799 - val_loss: 0.9921 - val_accuracy: 0.5120\n",
      "Epoch 4396/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8627 - accuracy: 0.5794 - val_loss: 0.9130 - val_accuracy: 0.5500\n",
      "Epoch 4397/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8618 - accuracy: 0.5799 - val_loss: 0.9239 - val_accuracy: 0.5317\n",
      "Epoch 4398/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8612 - accuracy: 0.5825 - val_loss: 0.8997 - val_accuracy: 0.5620\n",
      "Epoch 4399/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8628 - accuracy: 0.5781 - val_loss: 0.9004 - val_accuracy: 0.5617\n",
      "Epoch 4400/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8611 - accuracy: 0.5803 - val_loss: 0.9165 - val_accuracy: 0.5473\n",
      "Epoch 4401/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8611 - accuracy: 0.5816 - val_loss: 0.8984 - val_accuracy: 0.5610\n",
      "Epoch 4402/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8623 - accuracy: 0.5811 - val_loss: 0.9010 - val_accuracy: 0.5623\n",
      "Epoch 4403/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8627 - accuracy: 0.5818 - val_loss: 0.9085 - val_accuracy: 0.5513\n",
      "Epoch 4404/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8628 - accuracy: 0.5817 - val_loss: 0.9001 - val_accuracy: 0.5647\n",
      "Epoch 4405/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8623 - accuracy: 0.5815 - val_loss: 0.9022 - val_accuracy: 0.5593\n",
      "Epoch 4406/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8627 - accuracy: 0.5792 - val_loss: 0.9238 - val_accuracy: 0.5457\n",
      "Epoch 4407/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8648 - accuracy: 0.5742 - val_loss: 0.9008 - val_accuracy: 0.5553\n",
      "Epoch 4408/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8613 - accuracy: 0.5784 - val_loss: 0.9035 - val_accuracy: 0.5633\n",
      "Epoch 4409/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8635 - accuracy: 0.5794 - val_loss: 0.9055 - val_accuracy: 0.5583\n",
      "Epoch 4410/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8652 - accuracy: 0.5774 - val_loss: 0.9111 - val_accuracy: 0.5503\n",
      "Epoch 4411/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8602 - accuracy: 0.5800 - val_loss: 0.8993 - val_accuracy: 0.5613\n",
      "Epoch 4412/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8626 - accuracy: 0.5803 - val_loss: 0.9062 - val_accuracy: 0.5533\n",
      "Epoch 4413/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8633 - accuracy: 0.5782 - val_loss: 0.8985 - val_accuracy: 0.5590\n",
      "Epoch 4414/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8609 - accuracy: 0.5835 - val_loss: 0.9093 - val_accuracy: 0.5423\n",
      "Epoch 4415/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8615 - accuracy: 0.5772 - val_loss: 0.9034 - val_accuracy: 0.5597\n",
      "Epoch 4416/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8625 - accuracy: 0.5789 - val_loss: 0.9019 - val_accuracy: 0.5603\n",
      "Epoch 4417/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8615 - accuracy: 0.5797 - val_loss: 0.9574 - val_accuracy: 0.5237\n",
      "Epoch 4418/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8624 - accuracy: 0.5766 - val_loss: 0.8993 - val_accuracy: 0.5647\n",
      "Epoch 4419/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8630 - accuracy: 0.5759 - val_loss: 0.8986 - val_accuracy: 0.5633\n",
      "Epoch 4420/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8613 - accuracy: 0.5819 - val_loss: 0.8995 - val_accuracy: 0.5643\n",
      "Epoch 4421/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8600 - accuracy: 0.5831 - val_loss: 0.9077 - val_accuracy: 0.5530\n",
      "Epoch 4422/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8637 - accuracy: 0.5796 - val_loss: 0.8986 - val_accuracy: 0.5633\n",
      "Epoch 4423/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8636 - accuracy: 0.5816 - val_loss: 0.8995 - val_accuracy: 0.5603\n",
      "Epoch 4424/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8610 - accuracy: 0.5824 - val_loss: 0.9019 - val_accuracy: 0.5547\n",
      "Epoch 4425/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8629 - accuracy: 0.5784 - val_loss: 0.9014 - val_accuracy: 0.5560\n",
      "Epoch 4426/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8624 - accuracy: 0.5793 - val_loss: 0.9014 - val_accuracy: 0.5557\n",
      "Epoch 4427/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8615 - accuracy: 0.5834 - val_loss: 0.9156 - val_accuracy: 0.5493\n",
      "Epoch 4428/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8612 - accuracy: 0.5818 - val_loss: 0.9298 - val_accuracy: 0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4429/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8622 - accuracy: 0.5812 - val_loss: 0.8987 - val_accuracy: 0.5667\n",
      "Epoch 4430/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8622 - accuracy: 0.5834 - val_loss: 0.8993 - val_accuracy: 0.5630\n",
      "Epoch 4431/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8615 - accuracy: 0.5814 - val_loss: 0.8986 - val_accuracy: 0.5613\n",
      "Epoch 4432/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8626 - accuracy: 0.5809 - val_loss: 0.9086 - val_accuracy: 0.5497\n",
      "Epoch 4433/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8634 - accuracy: 0.5797 - val_loss: 0.9020 - val_accuracy: 0.5560\n",
      "Epoch 4434/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8635 - accuracy: 0.5809 - val_loss: 0.9177 - val_accuracy: 0.5430\n",
      "Epoch 4435/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8619 - accuracy: 0.5796 - val_loss: 0.8986 - val_accuracy: 0.5640\n",
      "Epoch 4436/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8602 - accuracy: 0.5816 - val_loss: 0.9054 - val_accuracy: 0.5547\n",
      "Epoch 4437/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8623 - accuracy: 0.5786 - val_loss: 0.9002 - val_accuracy: 0.5620\n",
      "Epoch 4438/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8620 - accuracy: 0.5821 - val_loss: 0.9362 - val_accuracy: 0.5360\n",
      "Epoch 4439/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8608 - accuracy: 0.5846 - val_loss: 0.9382 - val_accuracy: 0.5323\n",
      "Epoch 4440/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8601 - accuracy: 0.5806 - val_loss: 0.9001 - val_accuracy: 0.5660\n",
      "Epoch 4441/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8629 - accuracy: 0.5802 - val_loss: 0.9041 - val_accuracy: 0.5533\n",
      "Epoch 4442/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8629 - accuracy: 0.5781 - val_loss: 0.9411 - val_accuracy: 0.5247\n",
      "Epoch 4443/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8640 - accuracy: 0.5764 - val_loss: 0.9094 - val_accuracy: 0.5513\n",
      "Epoch 4444/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8606 - accuracy: 0.5819 - val_loss: 0.9717 - val_accuracy: 0.5223\n",
      "Epoch 4445/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8631 - accuracy: 0.5762 - val_loss: 0.9028 - val_accuracy: 0.5570\n",
      "Epoch 4446/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8615 - accuracy: 0.5801 - val_loss: 0.9044 - val_accuracy: 0.5607\n",
      "Epoch 4447/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8631 - accuracy: 0.5791 - val_loss: 0.9074 - val_accuracy: 0.5550\n",
      "Epoch 4448/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8602 - accuracy: 0.5841 - val_loss: 0.8990 - val_accuracy: 0.5640\n",
      "Epoch 4449/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8631 - accuracy: 0.5844 - val_loss: 0.9045 - val_accuracy: 0.5617\n",
      "Epoch 4450/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8613 - accuracy: 0.5837 - val_loss: 0.9119 - val_accuracy: 0.5517\n",
      "Epoch 4451/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8621 - accuracy: 0.5776 - val_loss: 0.9461 - val_accuracy: 0.5300\n",
      "Epoch 4452/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8607 - accuracy: 0.5859 - val_loss: 0.8991 - val_accuracy: 0.5603\n",
      "Epoch 4453/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8602 - accuracy: 0.5814 - val_loss: 0.9000 - val_accuracy: 0.5597\n",
      "Epoch 4454/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8615 - accuracy: 0.5794 - val_loss: 0.9122 - val_accuracy: 0.5527\n",
      "Epoch 4455/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8629 - accuracy: 0.5785 - val_loss: 0.9024 - val_accuracy: 0.5627\n",
      "Epoch 4456/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8619 - accuracy: 0.5764 - val_loss: 0.9011 - val_accuracy: 0.5617\n",
      "Epoch 4457/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8607 - accuracy: 0.5810 - val_loss: 0.9230 - val_accuracy: 0.5393\n",
      "Epoch 4458/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8602 - accuracy: 0.5851 - val_loss: 0.9106 - val_accuracy: 0.5470\n",
      "Epoch 4459/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8609 - accuracy: 0.5799 - val_loss: 0.9470 - val_accuracy: 0.5230\n",
      "Epoch 4460/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8620 - accuracy: 0.5808 - val_loss: 0.9032 - val_accuracy: 0.5547\n",
      "Epoch 4461/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8604 - accuracy: 0.5837 - val_loss: 0.9012 - val_accuracy: 0.5620\n",
      "Epoch 4462/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8617 - accuracy: 0.5786 - val_loss: 0.9013 - val_accuracy: 0.5627\n",
      "Epoch 4463/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8606 - accuracy: 0.5820 - val_loss: 0.9178 - val_accuracy: 0.5463\n",
      "Epoch 4464/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8594 - accuracy: 0.5799 - val_loss: 0.8988 - val_accuracy: 0.5623\n",
      "Epoch 4465/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8622 - accuracy: 0.5809 - val_loss: 0.9002 - val_accuracy: 0.5603\n",
      "Epoch 4466/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8627 - accuracy: 0.5810 - val_loss: 0.8989 - val_accuracy: 0.5607\n",
      "Epoch 4467/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8618 - accuracy: 0.5800 - val_loss: 0.9201 - val_accuracy: 0.5380\n",
      "Epoch 4468/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8604 - accuracy: 0.5808 - val_loss: 0.8978 - val_accuracy: 0.5607\n",
      "Epoch 4469/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8612 - accuracy: 0.5818 - val_loss: 0.9050 - val_accuracy: 0.5530\n",
      "Epoch 4470/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8625 - accuracy: 0.5785 - val_loss: 0.9068 - val_accuracy: 0.5537\n",
      "Epoch 4471/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8613 - accuracy: 0.5793 - val_loss: 0.9285 - val_accuracy: 0.5327\n",
      "Epoch 4472/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8601 - accuracy: 0.5829 - val_loss: 0.9056 - val_accuracy: 0.5537\n",
      "Epoch 4473/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8599 - accuracy: 0.5822 - val_loss: 0.9008 - val_accuracy: 0.5623\n",
      "Epoch 4474/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8602 - accuracy: 0.5829 - val_loss: 0.9172 - val_accuracy: 0.5387\n",
      "Epoch 4475/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8603 - accuracy: 0.5796 - val_loss: 0.8993 - val_accuracy: 0.5610\n",
      "Epoch 4476/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8617 - accuracy: 0.5808 - val_loss: 0.9014 - val_accuracy: 0.5633\n",
      "Epoch 4477/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8595 - accuracy: 0.5806 - val_loss: 0.9231 - val_accuracy: 0.5443\n",
      "Epoch 4478/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8617 - accuracy: 0.5797 - val_loss: 0.9081 - val_accuracy: 0.5530\n",
      "Epoch 4479/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8587 - accuracy: 0.5819 - val_loss: 0.9077 - val_accuracy: 0.5457\n",
      "Epoch 4480/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8612 - accuracy: 0.5786 - val_loss: 0.9028 - val_accuracy: 0.5587\n",
      "Epoch 4481/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8613 - accuracy: 0.5805 - val_loss: 0.9249 - val_accuracy: 0.5377\n",
      "Epoch 4482/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8603 - accuracy: 0.5833 - val_loss: 0.8988 - val_accuracy: 0.5630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4483/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8606 - accuracy: 0.5815 - val_loss: 0.9006 - val_accuracy: 0.5637\n",
      "Epoch 4484/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8632 - accuracy: 0.5789 - val_loss: 0.9000 - val_accuracy: 0.5630\n",
      "Epoch 4485/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8609 - accuracy: 0.5819 - val_loss: 0.9026 - val_accuracy: 0.5580\n",
      "Epoch 4486/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8616 - accuracy: 0.5769 - val_loss: 0.9017 - val_accuracy: 0.5560\n",
      "Epoch 4487/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8613 - accuracy: 0.5803 - val_loss: 0.9021 - val_accuracy: 0.5607\n",
      "Epoch 4488/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8631 - accuracy: 0.5761 - val_loss: 0.8997 - val_accuracy: 0.5600\n",
      "Epoch 4489/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8619 - accuracy: 0.5827 - val_loss: 0.9044 - val_accuracy: 0.5530\n",
      "Epoch 4490/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8621 - accuracy: 0.5794 - val_loss: 0.9114 - val_accuracy: 0.5530\n",
      "Epoch 4491/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8611 - accuracy: 0.5806 - val_loss: 0.9080 - val_accuracy: 0.5530\n",
      "Epoch 4492/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8597 - accuracy: 0.5838 - val_loss: 0.9014 - val_accuracy: 0.5620\n",
      "Epoch 4493/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8629 - accuracy: 0.5811 - val_loss: 0.9010 - val_accuracy: 0.5577\n",
      "Epoch 4494/5500\n",
      "14000/14000 [==============================] - 1s 37us/step - loss: 0.8601 - accuracy: 0.5836 - val_loss: 0.8991 - val_accuracy: 0.5600\n",
      "Epoch 4495/5500\n",
      "14000/14000 [==============================] - 0s 32us/step - loss: 0.8622 - accuracy: 0.5798 - val_loss: 0.9441 - val_accuracy: 0.5190\n",
      "Epoch 4496/5500\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.8607 - accuracy: 0.5799 - val_loss: 0.9006 - val_accuracy: 0.5627\n",
      "Epoch 4497/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.8634 - accuracy: 0.5809 - val_loss: 0.8994 - val_accuracy: 0.5603\n",
      "Epoch 4498/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8617 - accuracy: 0.5804 - val_loss: 0.9015 - val_accuracy: 0.5617\n",
      "Epoch 4499/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8621 - accuracy: 0.5779 - val_loss: 0.9052 - val_accuracy: 0.5517\n",
      "Epoch 4500/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8615 - accuracy: 0.5804 - val_loss: 0.9186 - val_accuracy: 0.5440\n",
      "Epoch 4501/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8619 - accuracy: 0.5813 - val_loss: 0.9005 - val_accuracy: 0.5607\n",
      "Epoch 4502/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8607 - accuracy: 0.5804 - val_loss: 0.9125 - val_accuracy: 0.5517\n",
      "Epoch 4503/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8594 - accuracy: 0.5803 - val_loss: 0.9184 - val_accuracy: 0.5407\n",
      "Epoch 4504/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8595 - accuracy: 0.5849 - val_loss: 0.9068 - val_accuracy: 0.5557\n",
      "Epoch 4505/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8624 - accuracy: 0.5844 - val_loss: 0.9072 - val_accuracy: 0.5570\n",
      "Epoch 4506/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8610 - accuracy: 0.5780 - val_loss: 0.8992 - val_accuracy: 0.5680\n",
      "Epoch 4507/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8600 - accuracy: 0.5848 - val_loss: 0.9424 - val_accuracy: 0.5300\n",
      "Epoch 4508/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8602 - accuracy: 0.5796 - val_loss: 0.8979 - val_accuracy: 0.5620\n",
      "Epoch 4509/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8631 - accuracy: 0.5756 - val_loss: 0.9002 - val_accuracy: 0.5553\n",
      "Epoch 4510/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8600 - accuracy: 0.5837 - val_loss: 0.9010 - val_accuracy: 0.5610\n",
      "Epoch 4511/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8613 - accuracy: 0.5809 - val_loss: 0.9095 - val_accuracy: 0.5533\n",
      "Epoch 4512/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8601 - accuracy: 0.5826 - val_loss: 0.9006 - val_accuracy: 0.5623\n",
      "Epoch 4513/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8606 - accuracy: 0.5794 - val_loss: 0.9052 - val_accuracy: 0.5550\n",
      "Epoch 4514/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8604 - accuracy: 0.5786 - val_loss: 0.9052 - val_accuracy: 0.5563\n",
      "Epoch 4515/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8599 - accuracy: 0.5813 - val_loss: 0.9012 - val_accuracy: 0.5633\n",
      "Epoch 4516/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8624 - accuracy: 0.5817 - val_loss: 0.9067 - val_accuracy: 0.5577\n",
      "Epoch 4517/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8582 - accuracy: 0.5831 - val_loss: 0.9076 - val_accuracy: 0.5463\n",
      "Epoch 4518/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8598 - accuracy: 0.5818 - val_loss: 0.9161 - val_accuracy: 0.5503\n",
      "Epoch 4519/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8600 - accuracy: 0.5837 - val_loss: 0.9009 - val_accuracy: 0.5627\n",
      "Epoch 4520/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8606 - accuracy: 0.5804 - val_loss: 0.9071 - val_accuracy: 0.5553\n",
      "Epoch 4521/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8603 - accuracy: 0.5789 - val_loss: 0.9003 - val_accuracy: 0.5603\n",
      "Epoch 4522/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8619 - accuracy: 0.5811 - val_loss: 0.9166 - val_accuracy: 0.5423\n",
      "Epoch 4523/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8594 - accuracy: 0.5849 - val_loss: 0.8999 - val_accuracy: 0.5600\n",
      "Epoch 4524/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8604 - accuracy: 0.5831 - val_loss: 0.9083 - val_accuracy: 0.5503\n",
      "Epoch 4525/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8595 - accuracy: 0.5839 - val_loss: 0.9502 - val_accuracy: 0.5287\n",
      "Epoch 4526/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8607 - accuracy: 0.5770 - val_loss: 0.9054 - val_accuracy: 0.5590\n",
      "Epoch 4527/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8600 - accuracy: 0.5814 - val_loss: 0.9117 - val_accuracy: 0.5510\n",
      "Epoch 4528/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8599 - accuracy: 0.5828 - val_loss: 0.9015 - val_accuracy: 0.5560\n",
      "Epoch 4529/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8603 - accuracy: 0.5839 - val_loss: 0.9101 - val_accuracy: 0.5493\n",
      "Epoch 4530/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8602 - accuracy: 0.5838 - val_loss: 0.9047 - val_accuracy: 0.5590\n",
      "Epoch 4531/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8607 - accuracy: 0.5808 - val_loss: 0.9214 - val_accuracy: 0.5463\n",
      "Epoch 4532/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8611 - accuracy: 0.5809 - val_loss: 0.8988 - val_accuracy: 0.5657\n",
      "Epoch 4533/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8583 - accuracy: 0.5831 - val_loss: 0.8978 - val_accuracy: 0.5667\n",
      "Epoch 4534/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8614 - accuracy: 0.5824 - val_loss: 0.9080 - val_accuracy: 0.5603\n",
      "Epoch 4535/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8601 - accuracy: 0.5809 - val_loss: 0.9024 - val_accuracy: 0.5577\n",
      "Epoch 4536/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8600 - accuracy: 0.5808 - val_loss: 0.9580 - val_accuracy: 0.5203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4537/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8606 - accuracy: 0.5812 - val_loss: 0.8991 - val_accuracy: 0.5630\n",
      "Epoch 4538/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8602 - accuracy: 0.5816 - val_loss: 0.9254 - val_accuracy: 0.5393\n",
      "Epoch 4539/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8622 - accuracy: 0.5801 - val_loss: 0.9009 - val_accuracy: 0.5623\n",
      "Epoch 4540/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8585 - accuracy: 0.5779 - val_loss: 0.9087 - val_accuracy: 0.5490\n",
      "Epoch 4541/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8605 - accuracy: 0.5826 - val_loss: 0.9059 - val_accuracy: 0.5520\n",
      "Epoch 4542/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8595 - accuracy: 0.5794 - val_loss: 0.9290 - val_accuracy: 0.5300\n",
      "Epoch 4543/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8595 - accuracy: 0.5810 - val_loss: 0.9057 - val_accuracy: 0.5523\n",
      "Epoch 4544/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8602 - accuracy: 0.5829 - val_loss: 0.8989 - val_accuracy: 0.5633\n",
      "Epoch 4545/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8608 - accuracy: 0.5794 - val_loss: 0.9078 - val_accuracy: 0.5537\n",
      "Epoch 4546/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8597 - accuracy: 0.5844 - val_loss: 0.9005 - val_accuracy: 0.5680\n",
      "Epoch 4547/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8600 - accuracy: 0.5782 - val_loss: 0.9001 - val_accuracy: 0.5610\n",
      "Epoch 4548/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8598 - accuracy: 0.5829 - val_loss: 0.9223 - val_accuracy: 0.5387\n",
      "Epoch 4549/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8601 - accuracy: 0.5806 - val_loss: 0.9043 - val_accuracy: 0.5580\n",
      "Epoch 4550/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8596 - accuracy: 0.5808 - val_loss: 0.8991 - val_accuracy: 0.5630\n",
      "Epoch 4551/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8626 - accuracy: 0.5812 - val_loss: 0.9148 - val_accuracy: 0.5570\n",
      "Epoch 4552/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8594 - accuracy: 0.5794 - val_loss: 0.9094 - val_accuracy: 0.5533\n",
      "Epoch 4553/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8591 - accuracy: 0.5833 - val_loss: 0.9064 - val_accuracy: 0.5573\n",
      "Epoch 4554/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8619 - accuracy: 0.5824 - val_loss: 0.9034 - val_accuracy: 0.5553\n",
      "Epoch 4555/5500\n",
      "14000/14000 [==============================] - 0s 27us/step - loss: 0.8577 - accuracy: 0.5831 - val_loss: 0.9134 - val_accuracy: 0.5487\n",
      "Epoch 4556/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8601 - accuracy: 0.5814 - val_loss: 0.9242 - val_accuracy: 0.5380\n",
      "Epoch 4557/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8581 - accuracy: 0.5839 - val_loss: 0.9077 - val_accuracy: 0.5443\n",
      "Epoch 4558/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8605 - accuracy: 0.5806 - val_loss: 0.9125 - val_accuracy: 0.5453\n",
      "Epoch 4559/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8598 - accuracy: 0.5834 - val_loss: 0.9037 - val_accuracy: 0.5583\n",
      "Epoch 4560/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8610 - accuracy: 0.5806 - val_loss: 0.9076 - val_accuracy: 0.5557\n",
      "Epoch 4561/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8599 - accuracy: 0.5804 - val_loss: 0.9096 - val_accuracy: 0.5557\n",
      "Epoch 4562/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8614 - accuracy: 0.5792 - val_loss: 0.9075 - val_accuracy: 0.5567\n",
      "Epoch 4563/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8591 - accuracy: 0.5836 - val_loss: 0.9292 - val_accuracy: 0.5410\n",
      "Epoch 4564/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8597 - accuracy: 0.5855 - val_loss: 0.9087 - val_accuracy: 0.5500\n",
      "Epoch 4565/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8611 - accuracy: 0.5789 - val_loss: 0.9047 - val_accuracy: 0.5557\n",
      "Epoch 4566/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8585 - accuracy: 0.5832 - val_loss: 0.9002 - val_accuracy: 0.5597\n",
      "Epoch 4567/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8605 - accuracy: 0.5797 - val_loss: 0.9367 - val_accuracy: 0.5327\n",
      "Epoch 4568/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8640 - accuracy: 0.5758 - val_loss: 0.9020 - val_accuracy: 0.5580\n",
      "Epoch 4569/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8601 - accuracy: 0.5831 - val_loss: 0.9011 - val_accuracy: 0.5533\n",
      "Epoch 4570/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8597 - accuracy: 0.5826 - val_loss: 0.9140 - val_accuracy: 0.5413\n",
      "Epoch 4571/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8612 - accuracy: 0.5779 - val_loss: 0.9023 - val_accuracy: 0.5527\n",
      "Epoch 4572/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8592 - accuracy: 0.5841 - val_loss: 0.8993 - val_accuracy: 0.5633\n",
      "Epoch 4573/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8604 - accuracy: 0.5833 - val_loss: 0.8982 - val_accuracy: 0.5607\n",
      "Epoch 4574/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8618 - accuracy: 0.5799 - val_loss: 0.8995 - val_accuracy: 0.5657\n",
      "Epoch 4575/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8619 - accuracy: 0.5807 - val_loss: 0.9037 - val_accuracy: 0.5550\n",
      "Epoch 4576/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8628 - accuracy: 0.5796 - val_loss: 0.9001 - val_accuracy: 0.5597\n",
      "Epoch 4577/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8603 - accuracy: 0.5785 - val_loss: 0.9045 - val_accuracy: 0.5553\n",
      "Epoch 4578/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8598 - accuracy: 0.5788 - val_loss: 0.9009 - val_accuracy: 0.5607\n",
      "Epoch 4579/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8604 - accuracy: 0.5832 - val_loss: 0.9831 - val_accuracy: 0.5010\n",
      "Epoch 4580/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8587 - accuracy: 0.5846 - val_loss: 0.9047 - val_accuracy: 0.5537\n",
      "Epoch 4581/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8593 - accuracy: 0.5818 - val_loss: 0.9146 - val_accuracy: 0.5483\n",
      "Epoch 4582/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8601 - accuracy: 0.5792 - val_loss: 0.9137 - val_accuracy: 0.5433\n",
      "Epoch 4583/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8589 - accuracy: 0.5817 - val_loss: 0.9402 - val_accuracy: 0.5270\n",
      "Epoch 4584/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8592 - accuracy: 0.5836 - val_loss: 0.9036 - val_accuracy: 0.5547\n",
      "Epoch 4585/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8602 - accuracy: 0.5830 - val_loss: 0.9062 - val_accuracy: 0.5480\n",
      "Epoch 4586/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8594 - accuracy: 0.5843 - val_loss: 0.9005 - val_accuracy: 0.5637\n",
      "Epoch 4587/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8607 - accuracy: 0.5803 - val_loss: 0.9040 - val_accuracy: 0.5577\n",
      "Epoch 4588/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8602 - accuracy: 0.5846 - val_loss: 0.9312 - val_accuracy: 0.5357\n",
      "Epoch 4589/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8591 - accuracy: 0.5796 - val_loss: 0.9048 - val_accuracy: 0.5583\n",
      "Epoch 4590/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8577 - accuracy: 0.5828 - val_loss: 0.9019 - val_accuracy: 0.5533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4591/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8598 - accuracy: 0.5786 - val_loss: 0.9025 - val_accuracy: 0.5580\n",
      "Epoch 4592/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8581 - accuracy: 0.5856 - val_loss: 0.8997 - val_accuracy: 0.5643\n",
      "Epoch 4593/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8598 - accuracy: 0.5783 - val_loss: 0.9293 - val_accuracy: 0.5350\n",
      "Epoch 4594/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8593 - accuracy: 0.5796 - val_loss: 0.9065 - val_accuracy: 0.5517\n",
      "Epoch 4595/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8604 - accuracy: 0.5787 - val_loss: 0.9001 - val_accuracy: 0.5613\n",
      "Epoch 4596/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8599 - accuracy: 0.5809 - val_loss: 0.8992 - val_accuracy: 0.5647\n",
      "Epoch 4597/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8589 - accuracy: 0.5826 - val_loss: 0.9348 - val_accuracy: 0.5307\n",
      "Epoch 4598/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8618 - accuracy: 0.5806 - val_loss: 0.9055 - val_accuracy: 0.5503\n",
      "Epoch 4599/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8579 - accuracy: 0.5799 - val_loss: 0.9195 - val_accuracy: 0.5383\n",
      "Epoch 4600/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8596 - accuracy: 0.5797 - val_loss: 0.9135 - val_accuracy: 0.5433\n",
      "Epoch 4601/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8602 - accuracy: 0.5803 - val_loss: 0.9250 - val_accuracy: 0.5460\n",
      "Epoch 4602/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8593 - accuracy: 0.5844 - val_loss: 0.9010 - val_accuracy: 0.5547\n",
      "Epoch 4603/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8605 - accuracy: 0.5807 - val_loss: 0.9006 - val_accuracy: 0.5607\n",
      "Epoch 4604/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8579 - accuracy: 0.5812 - val_loss: 0.8988 - val_accuracy: 0.5630\n",
      "Epoch 4605/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8601 - accuracy: 0.5814 - val_loss: 0.9145 - val_accuracy: 0.5480\n",
      "Epoch 4606/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8598 - accuracy: 0.5823 - val_loss: 0.9031 - val_accuracy: 0.5573\n",
      "Epoch 4607/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8576 - accuracy: 0.5846 - val_loss: 0.9000 - val_accuracy: 0.5647\n",
      "Epoch 4608/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8595 - accuracy: 0.5793 - val_loss: 0.9010 - val_accuracy: 0.5627\n",
      "Epoch 4609/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8600 - accuracy: 0.5799 - val_loss: 0.9045 - val_accuracy: 0.5540\n",
      "Epoch 4610/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8588 - accuracy: 0.5830 - val_loss: 0.9375 - val_accuracy: 0.5280\n",
      "Epoch 4611/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8592 - accuracy: 0.5834 - val_loss: 0.9049 - val_accuracy: 0.5563\n",
      "Epoch 4612/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8597 - accuracy: 0.5819 - val_loss: 0.8997 - val_accuracy: 0.5577\n",
      "Epoch 4613/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8571 - accuracy: 0.5840 - val_loss: 0.9209 - val_accuracy: 0.5333\n",
      "Epoch 4614/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8599 - accuracy: 0.5848 - val_loss: 0.9099 - val_accuracy: 0.5473\n",
      "Epoch 4615/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8582 - accuracy: 0.5851 - val_loss: 0.9028 - val_accuracy: 0.5610\n",
      "Epoch 4616/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8592 - accuracy: 0.5825 - val_loss: 0.9511 - val_accuracy: 0.5187\n",
      "Epoch 4617/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8617 - accuracy: 0.5809 - val_loss: 0.9196 - val_accuracy: 0.5427\n",
      "Epoch 4618/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8574 - accuracy: 0.5842 - val_loss: 0.9816 - val_accuracy: 0.5163\n",
      "Epoch 4619/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8603 - accuracy: 0.5835 - val_loss: 0.9014 - val_accuracy: 0.5607\n",
      "Epoch 4620/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8588 - accuracy: 0.5828 - val_loss: 0.9215 - val_accuracy: 0.5350\n",
      "Epoch 4621/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8603 - accuracy: 0.5822 - val_loss: 0.9288 - val_accuracy: 0.5377\n",
      "Epoch 4622/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8618 - accuracy: 0.5776 - val_loss: 0.9129 - val_accuracy: 0.5540\n",
      "Epoch 4623/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8585 - accuracy: 0.5853 - val_loss: 0.9150 - val_accuracy: 0.5553\n",
      "Epoch 4624/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8606 - accuracy: 0.5846 - val_loss: 0.9193 - val_accuracy: 0.5353\n",
      "Epoch 4625/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8596 - accuracy: 0.5856 - val_loss: 0.9425 - val_accuracy: 0.5227\n",
      "Epoch 4626/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8593 - accuracy: 0.5820 - val_loss: 0.8988 - val_accuracy: 0.5660\n",
      "Epoch 4627/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8607 - accuracy: 0.5801 - val_loss: 0.8979 - val_accuracy: 0.5613\n",
      "Epoch 4628/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8571 - accuracy: 0.5841 - val_loss: 0.9009 - val_accuracy: 0.5607\n",
      "Epoch 4629/5500\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.8586 - accuracy: 0.5822 - val_loss: 0.9043 - val_accuracy: 0.5627\n",
      "Epoch 4630/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8604 - accuracy: 0.5806 - val_loss: 0.8996 - val_accuracy: 0.5593\n",
      "Epoch 4631/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8599 - accuracy: 0.5804 - val_loss: 0.9174 - val_accuracy: 0.5497\n",
      "Epoch 4632/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8593 - accuracy: 0.5807 - val_loss: 0.9531 - val_accuracy: 0.5197\n",
      "Epoch 4633/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8602 - accuracy: 0.5814 - val_loss: 0.9342 - val_accuracy: 0.5467\n",
      "Epoch 4634/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8605 - accuracy: 0.5790 - val_loss: 0.9181 - val_accuracy: 0.5447\n",
      "Epoch 4635/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8597 - accuracy: 0.5840 - val_loss: 0.9147 - val_accuracy: 0.5513\n",
      "Epoch 4636/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8573 - accuracy: 0.5836 - val_loss: 0.9002 - val_accuracy: 0.5617\n",
      "Epoch 4637/5500\n",
      "14000/14000 [==============================] - 0s 28us/step - loss: 0.8600 - accuracy: 0.5799 - val_loss: 0.8984 - val_accuracy: 0.5653\n",
      "Epoch 4638/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8592 - accuracy: 0.5789 - val_loss: 0.9010 - val_accuracy: 0.5627\n",
      "Epoch 4639/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8589 - accuracy: 0.5787 - val_loss: 0.8991 - val_accuracy: 0.5573\n",
      "Epoch 4640/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8581 - accuracy: 0.5821 - val_loss: 0.9218 - val_accuracy: 0.5413\n",
      "Epoch 4641/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8589 - accuracy: 0.5860 - val_loss: 0.9519 - val_accuracy: 0.5217\n",
      "Epoch 4642/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8603 - accuracy: 0.5792 - val_loss: 0.9086 - val_accuracy: 0.5557\n",
      "Epoch 4643/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8568 - accuracy: 0.5846 - val_loss: 0.9020 - val_accuracy: 0.5553\n",
      "Epoch 4644/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8593 - accuracy: 0.5782 - val_loss: 0.8993 - val_accuracy: 0.5677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4645/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8588 - accuracy: 0.5825 - val_loss: 0.9017 - val_accuracy: 0.5570\n",
      "Epoch 4646/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8593 - accuracy: 0.5826 - val_loss: 0.9016 - val_accuracy: 0.5553\n",
      "Epoch 4647/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8590 - accuracy: 0.5800 - val_loss: 0.9080 - val_accuracy: 0.5543\n",
      "Epoch 4648/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8577 - accuracy: 0.5816 - val_loss: 0.9101 - val_accuracy: 0.5523\n",
      "Epoch 4649/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8616 - accuracy: 0.5808 - val_loss: 0.9032 - val_accuracy: 0.5643\n",
      "Epoch 4650/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8589 - accuracy: 0.5849 - val_loss: 0.9088 - val_accuracy: 0.5547\n",
      "Epoch 4651/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8612 - accuracy: 0.5769 - val_loss: 0.9386 - val_accuracy: 0.5227\n",
      "Epoch 4652/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8600 - accuracy: 0.5830 - val_loss: 0.9107 - val_accuracy: 0.5500\n",
      "Epoch 4653/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8586 - accuracy: 0.5824 - val_loss: 0.9024 - val_accuracy: 0.5607\n",
      "Epoch 4654/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8602 - accuracy: 0.5810 - val_loss: 0.9021 - val_accuracy: 0.5570\n",
      "Epoch 4655/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8579 - accuracy: 0.5843 - val_loss: 0.9036 - val_accuracy: 0.5567\n",
      "Epoch 4656/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8585 - accuracy: 0.5836 - val_loss: 0.9014 - val_accuracy: 0.5580\n",
      "Epoch 4657/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8593 - accuracy: 0.5841 - val_loss: 0.9688 - val_accuracy: 0.5147\n",
      "Epoch 4658/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8593 - accuracy: 0.5800 - val_loss: 0.9419 - val_accuracy: 0.5333\n",
      "Epoch 4659/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8596 - accuracy: 0.5848 - val_loss: 0.9030 - val_accuracy: 0.5557\n",
      "Epoch 4660/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8592 - accuracy: 0.5825 - val_loss: 0.9010 - val_accuracy: 0.5690\n",
      "Epoch 4661/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8592 - accuracy: 0.5798 - val_loss: 0.8997 - val_accuracy: 0.5660\n",
      "Epoch 4662/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8590 - accuracy: 0.5845 - val_loss: 0.9041 - val_accuracy: 0.5563\n",
      "Epoch 4663/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8576 - accuracy: 0.5831 - val_loss: 0.9005 - val_accuracy: 0.5590\n",
      "Epoch 4664/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8614 - accuracy: 0.5813 - val_loss: 0.9031 - val_accuracy: 0.5667\n",
      "Epoch 4665/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8586 - accuracy: 0.5814 - val_loss: 0.9091 - val_accuracy: 0.5500\n",
      "Epoch 4666/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8567 - accuracy: 0.5847 - val_loss: 0.9311 - val_accuracy: 0.5300\n",
      "Epoch 4667/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8590 - accuracy: 0.5798 - val_loss: 0.9119 - val_accuracy: 0.5467\n",
      "Epoch 4668/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8592 - accuracy: 0.5808 - val_loss: 0.9025 - val_accuracy: 0.5587\n",
      "Epoch 4669/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8589 - accuracy: 0.5802 - val_loss: 0.9386 - val_accuracy: 0.5333\n",
      "Epoch 4670/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8601 - accuracy: 0.5799 - val_loss: 0.9052 - val_accuracy: 0.5550\n",
      "Epoch 4671/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8587 - accuracy: 0.5851 - val_loss: 0.9071 - val_accuracy: 0.5553\n",
      "Epoch 4672/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8586 - accuracy: 0.5843 - val_loss: 0.9180 - val_accuracy: 0.5503\n",
      "Epoch 4673/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8616 - accuracy: 0.5784 - val_loss: 0.9045 - val_accuracy: 0.5607\n",
      "Epoch 4674/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8590 - accuracy: 0.5798 - val_loss: 0.9121 - val_accuracy: 0.5533\n",
      "Epoch 4675/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8590 - accuracy: 0.5848 - val_loss: 0.9062 - val_accuracy: 0.5637\n",
      "Epoch 4676/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8607 - accuracy: 0.5792 - val_loss: 0.9290 - val_accuracy: 0.5317\n",
      "Epoch 4677/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8579 - accuracy: 0.5814 - val_loss: 0.9127 - val_accuracy: 0.5457\n",
      "Epoch 4678/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8575 - accuracy: 0.5858 - val_loss: 0.9015 - val_accuracy: 0.5663\n",
      "Epoch 4679/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8565 - accuracy: 0.5833 - val_loss: 0.9147 - val_accuracy: 0.5487\n",
      "Epoch 4680/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8608 - accuracy: 0.5819 - val_loss: 0.9069 - val_accuracy: 0.5517\n",
      "Epoch 4681/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8600 - accuracy: 0.5816 - val_loss: 0.9553 - val_accuracy: 0.5157\n",
      "Epoch 4682/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8593 - accuracy: 0.5852 - val_loss: 0.9351 - val_accuracy: 0.5327\n",
      "Epoch 4683/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8598 - accuracy: 0.5790 - val_loss: 0.9490 - val_accuracy: 0.5260\n",
      "Epoch 4684/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8587 - accuracy: 0.5862 - val_loss: 0.9139 - val_accuracy: 0.5487\n",
      "Epoch 4685/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8570 - accuracy: 0.5819 - val_loss: 0.8990 - val_accuracy: 0.5643\n",
      "Epoch 4686/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8593 - accuracy: 0.5811 - val_loss: 0.8982 - val_accuracy: 0.5680\n",
      "Epoch 4687/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8599 - accuracy: 0.5802 - val_loss: 0.9049 - val_accuracy: 0.5553\n",
      "Epoch 4688/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8590 - accuracy: 0.5810 - val_loss: 0.9040 - val_accuracy: 0.5567\n",
      "Epoch 4689/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8559 - accuracy: 0.5834 - val_loss: 0.9010 - val_accuracy: 0.5607\n",
      "Epoch 4690/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8578 - accuracy: 0.5851 - val_loss: 0.9316 - val_accuracy: 0.5317\n",
      "Epoch 4691/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8580 - accuracy: 0.5795 - val_loss: 0.9002 - val_accuracy: 0.5650\n",
      "Epoch 4692/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8617 - accuracy: 0.5829 - val_loss: 0.9002 - val_accuracy: 0.5613\n",
      "Epoch 4693/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8604 - accuracy: 0.5792 - val_loss: 0.9129 - val_accuracy: 0.5473\n",
      "Epoch 4694/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8571 - accuracy: 0.5844 - val_loss: 0.8985 - val_accuracy: 0.5603\n",
      "Epoch 4695/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8580 - accuracy: 0.5829 - val_loss: 0.8986 - val_accuracy: 0.5643\n",
      "Epoch 4696/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8579 - accuracy: 0.5826 - val_loss: 0.9028 - val_accuracy: 0.5573\n",
      "Epoch 4697/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8583 - accuracy: 0.5823 - val_loss: 0.9269 - val_accuracy: 0.5353\n",
      "Epoch 4698/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8596 - accuracy: 0.5815 - val_loss: 0.9038 - val_accuracy: 0.5573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4699/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8575 - accuracy: 0.5855 - val_loss: 0.9184 - val_accuracy: 0.5427\n",
      "Epoch 4700/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8581 - accuracy: 0.5819 - val_loss: 0.9056 - val_accuracy: 0.5527\n",
      "Epoch 4701/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8574 - accuracy: 0.5852 - val_loss: 0.8997 - val_accuracy: 0.5633\n",
      "Epoch 4702/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8551 - accuracy: 0.5842 - val_loss: 0.9016 - val_accuracy: 0.5637\n",
      "Epoch 4703/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8589 - accuracy: 0.5807 - val_loss: 0.9493 - val_accuracy: 0.5300\n",
      "Epoch 4704/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8583 - accuracy: 0.5811 - val_loss: 0.9090 - val_accuracy: 0.5533\n",
      "Epoch 4705/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8586 - accuracy: 0.5827 - val_loss: 0.9024 - val_accuracy: 0.5587\n",
      "Epoch 4706/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8579 - accuracy: 0.5844 - val_loss: 0.9072 - val_accuracy: 0.5580\n",
      "Epoch 4707/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8581 - accuracy: 0.5826 - val_loss: 0.9091 - val_accuracy: 0.5547\n",
      "Epoch 4708/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8564 - accuracy: 0.5863 - val_loss: 0.9969 - val_accuracy: 0.5040\n",
      "Epoch 4709/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8590 - accuracy: 0.5848 - val_loss: 0.9002 - val_accuracy: 0.5677\n",
      "Epoch 4710/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8588 - accuracy: 0.5832 - val_loss: 0.9500 - val_accuracy: 0.5223\n",
      "Epoch 4711/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8578 - accuracy: 0.5804 - val_loss: 0.9003 - val_accuracy: 0.5610\n",
      "Epoch 4712/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8568 - accuracy: 0.5837 - val_loss: 0.9104 - val_accuracy: 0.5483\n",
      "Epoch 4713/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8592 - accuracy: 0.5790 - val_loss: 0.8978 - val_accuracy: 0.5627\n",
      "Epoch 4714/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8570 - accuracy: 0.5836 - val_loss: 0.8988 - val_accuracy: 0.5667\n",
      "Epoch 4715/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8573 - accuracy: 0.5846 - val_loss: 0.9055 - val_accuracy: 0.5537\n",
      "Epoch 4716/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8564 - accuracy: 0.5855 - val_loss: 0.9018 - val_accuracy: 0.5547\n",
      "Epoch 4717/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8578 - accuracy: 0.5823 - val_loss: 0.9277 - val_accuracy: 0.5393\n",
      "Epoch 4718/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8593 - accuracy: 0.5813 - val_loss: 0.9001 - val_accuracy: 0.5623\n",
      "Epoch 4719/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8590 - accuracy: 0.5844 - val_loss: 0.9292 - val_accuracy: 0.5367\n",
      "Epoch 4720/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8592 - accuracy: 0.5831 - val_loss: 0.9160 - val_accuracy: 0.5447\n",
      "Epoch 4721/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8582 - accuracy: 0.5846 - val_loss: 0.9014 - val_accuracy: 0.5580\n",
      "Epoch 4722/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8587 - accuracy: 0.5824 - val_loss: 0.9167 - val_accuracy: 0.5473\n",
      "Epoch 4723/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8562 - accuracy: 0.5875 - val_loss: 0.9038 - val_accuracy: 0.5633\n",
      "Epoch 4724/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8567 - accuracy: 0.5842 - val_loss: 0.9103 - val_accuracy: 0.5630\n",
      "Epoch 4725/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8600 - accuracy: 0.5802 - val_loss: 0.9005 - val_accuracy: 0.5630\n",
      "Epoch 4726/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8591 - accuracy: 0.5860 - val_loss: 0.9004 - val_accuracy: 0.5600\n",
      "Epoch 4727/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8558 - accuracy: 0.5861 - val_loss: 0.9024 - val_accuracy: 0.5560\n",
      "Epoch 4728/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8578 - accuracy: 0.5834 - val_loss: 0.8988 - val_accuracy: 0.5600\n",
      "Epoch 4729/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8618 - accuracy: 0.5772 - val_loss: 0.9035 - val_accuracy: 0.5563\n",
      "Epoch 4730/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8590 - accuracy: 0.5832 - val_loss: 0.9101 - val_accuracy: 0.5497\n",
      "Epoch 4731/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8580 - accuracy: 0.5853 - val_loss: 0.9561 - val_accuracy: 0.5137\n",
      "Epoch 4732/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8572 - accuracy: 0.5816 - val_loss: 0.9064 - val_accuracy: 0.5547\n",
      "Epoch 4733/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8580 - accuracy: 0.5818 - val_loss: 0.8992 - val_accuracy: 0.5627\n",
      "Epoch 4734/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8586 - accuracy: 0.5816 - val_loss: 0.9190 - val_accuracy: 0.5403\n",
      "Epoch 4735/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8558 - accuracy: 0.5874 - val_loss: 0.9008 - val_accuracy: 0.5687\n",
      "Epoch 4736/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8566 - accuracy: 0.5821 - val_loss: 0.9062 - val_accuracy: 0.5583\n",
      "Epoch 4737/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8581 - accuracy: 0.5849 - val_loss: 0.9023 - val_accuracy: 0.5537\n",
      "Epoch 4738/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8586 - accuracy: 0.5841 - val_loss: 0.9121 - val_accuracy: 0.5493\n",
      "Epoch 4739/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8601 - accuracy: 0.5844 - val_loss: 0.9402 - val_accuracy: 0.5230\n",
      "Epoch 4740/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8574 - accuracy: 0.5888 - val_loss: 0.9022 - val_accuracy: 0.5683\n",
      "Epoch 4741/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8571 - accuracy: 0.5834 - val_loss: 0.9040 - val_accuracy: 0.5633\n",
      "Epoch 4742/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8570 - accuracy: 0.5859 - val_loss: 0.9107 - val_accuracy: 0.5500\n",
      "Epoch 4743/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8563 - accuracy: 0.5835 - val_loss: 0.9099 - val_accuracy: 0.5527\n",
      "Epoch 4744/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8572 - accuracy: 0.5825 - val_loss: 0.9012 - val_accuracy: 0.5603\n",
      "Epoch 4745/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8559 - accuracy: 0.5856 - val_loss: 0.9117 - val_accuracy: 0.5570\n",
      "Epoch 4746/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8589 - accuracy: 0.5837 - val_loss: 0.8991 - val_accuracy: 0.5673\n",
      "Epoch 4747/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8592 - accuracy: 0.5824 - val_loss: 0.9018 - val_accuracy: 0.5623\n",
      "Epoch 4748/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8571 - accuracy: 0.5789 - val_loss: 0.9010 - val_accuracy: 0.5647\n",
      "Epoch 4749/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8595 - accuracy: 0.5811 - val_loss: 0.9198 - val_accuracy: 0.5387\n",
      "Epoch 4750/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8596 - accuracy: 0.5771 - val_loss: 0.9007 - val_accuracy: 0.5670\n",
      "Epoch 4751/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8567 - accuracy: 0.5837 - val_loss: 0.9070 - val_accuracy: 0.5590\n",
      "Epoch 4752/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8599 - accuracy: 0.5824 - val_loss: 0.9301 - val_accuracy: 0.5390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4753/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8544 - accuracy: 0.5882 - val_loss: 0.9076 - val_accuracy: 0.5550\n",
      "Epoch 4754/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8577 - accuracy: 0.5828 - val_loss: 0.9759 - val_accuracy: 0.5170\n",
      "Epoch 4755/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8573 - accuracy: 0.5826 - val_loss: 0.9207 - val_accuracy: 0.5423\n",
      "Epoch 4756/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8566 - accuracy: 0.5826 - val_loss: 0.9246 - val_accuracy: 0.5333\n",
      "Epoch 4757/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8593 - accuracy: 0.5781 - val_loss: 0.9179 - val_accuracy: 0.5513\n",
      "Epoch 4758/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8559 - accuracy: 0.5836 - val_loss: 0.9219 - val_accuracy: 0.5383\n",
      "Epoch 4759/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8584 - accuracy: 0.5846 - val_loss: 0.9094 - val_accuracy: 0.5527\n",
      "Epoch 4760/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8584 - accuracy: 0.5849 - val_loss: 0.9019 - val_accuracy: 0.5577\n",
      "Epoch 4761/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8594 - accuracy: 0.5828 - val_loss: 0.9001 - val_accuracy: 0.5633\n",
      "Epoch 4762/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8582 - accuracy: 0.5829 - val_loss: 0.9014 - val_accuracy: 0.5590\n",
      "Epoch 4763/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8574 - accuracy: 0.5850 - val_loss: 0.9013 - val_accuracy: 0.5613\n",
      "Epoch 4764/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8570 - accuracy: 0.5836 - val_loss: 0.9007 - val_accuracy: 0.5637\n",
      "Epoch 4765/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8586 - accuracy: 0.5814 - val_loss: 0.9048 - val_accuracy: 0.5603\n",
      "Epoch 4766/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8570 - accuracy: 0.5855 - val_loss: 0.9037 - val_accuracy: 0.5590\n",
      "Epoch 4767/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8568 - accuracy: 0.5812 - val_loss: 0.8989 - val_accuracy: 0.5647\n",
      "Epoch 4768/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8575 - accuracy: 0.5817 - val_loss: 0.9089 - val_accuracy: 0.5520\n",
      "Epoch 4769/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8587 - accuracy: 0.5835 - val_loss: 0.9289 - val_accuracy: 0.5383\n",
      "Epoch 4770/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8561 - accuracy: 0.5851 - val_loss: 0.9171 - val_accuracy: 0.5510\n",
      "Epoch 4771/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8561 - accuracy: 0.5864 - val_loss: 0.9056 - val_accuracy: 0.5607\n",
      "Epoch 4772/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8564 - accuracy: 0.5849 - val_loss: 0.9545 - val_accuracy: 0.5300\n",
      "Epoch 4773/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8584 - accuracy: 0.5824 - val_loss: 0.9154 - val_accuracy: 0.5433\n",
      "Epoch 4774/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8570 - accuracy: 0.5819 - val_loss: 0.9223 - val_accuracy: 0.5423\n",
      "Epoch 4775/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8562 - accuracy: 0.5846 - val_loss: 0.9119 - val_accuracy: 0.5480\n",
      "Epoch 4776/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8601 - accuracy: 0.5822 - val_loss: 0.9191 - val_accuracy: 0.5357\n",
      "Epoch 4777/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8565 - accuracy: 0.5832 - val_loss: 0.9170 - val_accuracy: 0.5407\n",
      "Epoch 4778/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8558 - accuracy: 0.5850 - val_loss: 0.9017 - val_accuracy: 0.5627\n",
      "Epoch 4779/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8579 - accuracy: 0.5809 - val_loss: 0.9199 - val_accuracy: 0.5373\n",
      "Epoch 4780/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8580 - accuracy: 0.5821 - val_loss: 0.9005 - val_accuracy: 0.5590\n",
      "Epoch 4781/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8577 - accuracy: 0.5834 - val_loss: 0.9127 - val_accuracy: 0.5473\n",
      "Epoch 4782/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8571 - accuracy: 0.5857 - val_loss: 0.9029 - val_accuracy: 0.5593\n",
      "Epoch 4783/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8580 - accuracy: 0.5855 - val_loss: 0.8994 - val_accuracy: 0.5613\n",
      "Epoch 4784/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8585 - accuracy: 0.5803 - val_loss: 0.9023 - val_accuracy: 0.5597\n",
      "Epoch 4785/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8566 - accuracy: 0.5845 - val_loss: 0.9026 - val_accuracy: 0.5620\n",
      "Epoch 4786/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8594 - accuracy: 0.5838 - val_loss: 0.9027 - val_accuracy: 0.5590\n",
      "Epoch 4787/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8541 - accuracy: 0.5884 - val_loss: 0.9483 - val_accuracy: 0.5303\n",
      "Epoch 4788/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8573 - accuracy: 0.5830 - val_loss: 0.9055 - val_accuracy: 0.5550\n",
      "Epoch 4789/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8566 - accuracy: 0.5851 - val_loss: 0.9005 - val_accuracy: 0.5660\n",
      "Epoch 4790/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8552 - accuracy: 0.5846 - val_loss: 0.9227 - val_accuracy: 0.5363\n",
      "Epoch 4791/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8569 - accuracy: 0.5819 - val_loss: 0.8989 - val_accuracy: 0.5677\n",
      "Epoch 4792/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8559 - accuracy: 0.5836 - val_loss: 0.9068 - val_accuracy: 0.5567\n",
      "Epoch 4793/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8551 - accuracy: 0.5846 - val_loss: 0.9081 - val_accuracy: 0.5540\n",
      "Epoch 4794/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8575 - accuracy: 0.5836 - val_loss: 0.9051 - val_accuracy: 0.5587\n",
      "Epoch 4795/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8573 - accuracy: 0.5832 - val_loss: 0.9471 - val_accuracy: 0.5230\n",
      "Epoch 4796/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8577 - accuracy: 0.5795 - val_loss: 0.8992 - val_accuracy: 0.5653\n",
      "Epoch 4797/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8582 - accuracy: 0.5819 - val_loss: 0.9114 - val_accuracy: 0.5530\n",
      "Epoch 4798/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8577 - accuracy: 0.5811 - val_loss: 0.9127 - val_accuracy: 0.5487\n",
      "Epoch 4799/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8568 - accuracy: 0.5831 - val_loss: 0.9440 - val_accuracy: 0.5143\n",
      "Epoch 4800/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8588 - accuracy: 0.5816 - val_loss: 0.9593 - val_accuracy: 0.5077\n",
      "Epoch 4801/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8583 - accuracy: 0.5834 - val_loss: 0.9005 - val_accuracy: 0.5703\n",
      "Epoch 4802/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8585 - accuracy: 0.5788 - val_loss: 0.9024 - val_accuracy: 0.5630\n",
      "Epoch 4803/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8574 - accuracy: 0.5789 - val_loss: 0.9172 - val_accuracy: 0.5460\n",
      "Epoch 4804/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8562 - accuracy: 0.5837 - val_loss: 0.9004 - val_accuracy: 0.5647\n",
      "Epoch 4805/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8583 - accuracy: 0.5823 - val_loss: 0.9171 - val_accuracy: 0.5403\n",
      "Epoch 4806/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8565 - accuracy: 0.5850 - val_loss: 0.9279 - val_accuracy: 0.5383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4807/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8586 - accuracy: 0.5791 - val_loss: 0.9039 - val_accuracy: 0.5600\n",
      "Epoch 4808/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8580 - accuracy: 0.5832 - val_loss: 0.8979 - val_accuracy: 0.5660\n",
      "Epoch 4809/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8560 - accuracy: 0.5874 - val_loss: 0.9153 - val_accuracy: 0.5467\n",
      "Epoch 4810/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8561 - accuracy: 0.5856 - val_loss: 0.9063 - val_accuracy: 0.5600\n",
      "Epoch 4811/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8557 - accuracy: 0.5848 - val_loss: 0.8991 - val_accuracy: 0.5693\n",
      "Epoch 4812/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8577 - accuracy: 0.5797 - val_loss: 0.8998 - val_accuracy: 0.5647\n",
      "Epoch 4813/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8572 - accuracy: 0.5841 - val_loss: 0.9388 - val_accuracy: 0.5223\n",
      "Epoch 4814/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8563 - accuracy: 0.5831 - val_loss: 0.8990 - val_accuracy: 0.5640\n",
      "Epoch 4815/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8589 - accuracy: 0.5815 - val_loss: 0.9008 - val_accuracy: 0.5590\n",
      "Epoch 4816/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8552 - accuracy: 0.5891 - val_loss: 0.9030 - val_accuracy: 0.5580\n",
      "Epoch 4817/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8546 - accuracy: 0.5840 - val_loss: 0.9336 - val_accuracy: 0.5343\n",
      "Epoch 4818/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8568 - accuracy: 0.5836 - val_loss: 0.9082 - val_accuracy: 0.5503\n",
      "Epoch 4819/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8577 - accuracy: 0.5834 - val_loss: 0.9004 - val_accuracy: 0.5600\n",
      "Epoch 4820/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8592 - accuracy: 0.5804 - val_loss: 0.9020 - val_accuracy: 0.5580\n",
      "Epoch 4821/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8574 - accuracy: 0.5830 - val_loss: 0.9267 - val_accuracy: 0.5350\n",
      "Epoch 4822/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8574 - accuracy: 0.5829 - val_loss: 0.9052 - val_accuracy: 0.5597\n",
      "Epoch 4823/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8585 - accuracy: 0.5839 - val_loss: 0.9042 - val_accuracy: 0.5573\n",
      "Epoch 4824/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8591 - accuracy: 0.5824 - val_loss: 0.9338 - val_accuracy: 0.5287\n",
      "Epoch 4825/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8577 - accuracy: 0.5859 - val_loss: 0.9081 - val_accuracy: 0.5500\n",
      "Epoch 4826/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8579 - accuracy: 0.5820 - val_loss: 0.9178 - val_accuracy: 0.5403\n",
      "Epoch 4827/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8566 - accuracy: 0.5857 - val_loss: 0.9057 - val_accuracy: 0.5567\n",
      "Epoch 4828/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8566 - accuracy: 0.5846 - val_loss: 0.8994 - val_accuracy: 0.5580\n",
      "Epoch 4829/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8548 - accuracy: 0.5876 - val_loss: 0.9184 - val_accuracy: 0.5433\n",
      "Epoch 4830/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8569 - accuracy: 0.5816 - val_loss: 0.9356 - val_accuracy: 0.5273\n",
      "Epoch 4831/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8566 - accuracy: 0.5852 - val_loss: 0.9136 - val_accuracy: 0.5470\n",
      "Epoch 4832/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8563 - accuracy: 0.5835 - val_loss: 0.9044 - val_accuracy: 0.5600\n",
      "Epoch 4833/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8572 - accuracy: 0.5852 - val_loss: 0.9004 - val_accuracy: 0.5683\n",
      "Epoch 4834/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8590 - accuracy: 0.5806 - val_loss: 0.9354 - val_accuracy: 0.5320\n",
      "Epoch 4835/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8560 - accuracy: 0.5844 - val_loss: 0.9095 - val_accuracy: 0.5520\n",
      "Epoch 4836/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8577 - accuracy: 0.5819 - val_loss: 0.9208 - val_accuracy: 0.5403\n",
      "Epoch 4837/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8552 - accuracy: 0.5863 - val_loss: 0.8999 - val_accuracy: 0.5597\n",
      "Epoch 4838/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8552 - accuracy: 0.5867 - val_loss: 0.9028 - val_accuracy: 0.5577\n",
      "Epoch 4839/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8561 - accuracy: 0.5831 - val_loss: 0.9032 - val_accuracy: 0.5590\n",
      "Epoch 4840/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8604 - accuracy: 0.5756 - val_loss: 0.9028 - val_accuracy: 0.5573\n",
      "Epoch 4841/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8556 - accuracy: 0.5879 - val_loss: 0.9073 - val_accuracy: 0.5563\n",
      "Epoch 4842/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8541 - accuracy: 0.5858 - val_loss: 0.9076 - val_accuracy: 0.5507\n",
      "Epoch 4843/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8544 - accuracy: 0.5866 - val_loss: 0.9017 - val_accuracy: 0.5647\n",
      "Epoch 4844/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8582 - accuracy: 0.5841 - val_loss: 0.9099 - val_accuracy: 0.5580\n",
      "Epoch 4845/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8554 - accuracy: 0.5864 - val_loss: 0.8997 - val_accuracy: 0.5597\n",
      "Epoch 4846/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8559 - accuracy: 0.5849 - val_loss: 0.9121 - val_accuracy: 0.5453\n",
      "Epoch 4847/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8554 - accuracy: 0.5840 - val_loss: 0.9083 - val_accuracy: 0.5513\n",
      "Epoch 4848/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8559 - accuracy: 0.5816 - val_loss: 0.9008 - val_accuracy: 0.5620\n",
      "Epoch 4849/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8575 - accuracy: 0.5848 - val_loss: 0.9139 - val_accuracy: 0.5393\n",
      "Epoch 4850/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8562 - accuracy: 0.5841 - val_loss: 0.9047 - val_accuracy: 0.5623\n",
      "Epoch 4851/5500\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8553 - accuracy: 0.5874 - val_loss: 0.9226 - val_accuracy: 0.5420\n",
      "Epoch 4852/5500\n",
      "14000/14000 [==============================] - 1s 37us/step - loss: 0.8556 - accuracy: 0.5832 - val_loss: 0.9356 - val_accuracy: 0.5370\n",
      "Epoch 4853/5500\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.8609 - accuracy: 0.5779 - val_loss: 0.9007 - val_accuracy: 0.5550\n",
      "Epoch 4854/5500\n",
      "14000/14000 [==============================] - 0s 35us/step - loss: 0.8566 - accuracy: 0.5889 - val_loss: 0.8999 - val_accuracy: 0.5607\n",
      "Epoch 4855/5500\n",
      "14000/14000 [==============================] - 1s 36us/step - loss: 0.8568 - accuracy: 0.5841 - val_loss: 0.8986 - val_accuracy: 0.5667\n",
      "Epoch 4856/5500\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.8564 - accuracy: 0.5814 - val_loss: 0.9112 - val_accuracy: 0.5463\n",
      "Epoch 4857/5500\n",
      "14000/14000 [==============================] - 0s 36us/step - loss: 0.8572 - accuracy: 0.5847 - val_loss: 0.9244 - val_accuracy: 0.5400\n",
      "Epoch 4858/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8528 - accuracy: 0.5928 - val_loss: 0.9080 - val_accuracy: 0.5560\n",
      "Epoch 4859/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8548 - accuracy: 0.5869 - val_loss: 0.9032 - val_accuracy: 0.5617\n",
      "Epoch 4860/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8541 - accuracy: 0.5840 - val_loss: 0.8978 - val_accuracy: 0.5683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4861/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8571 - accuracy: 0.5829 - val_loss: 0.9137 - val_accuracy: 0.5477\n",
      "Epoch 4862/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8561 - accuracy: 0.5861 - val_loss: 0.9054 - val_accuracy: 0.5543\n",
      "Epoch 4863/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8575 - accuracy: 0.5826 - val_loss: 0.9141 - val_accuracy: 0.5447\n",
      "Epoch 4864/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8567 - accuracy: 0.5829 - val_loss: 0.9153 - val_accuracy: 0.5487\n",
      "Epoch 4865/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8563 - accuracy: 0.5845 - val_loss: 0.8979 - val_accuracy: 0.5683\n",
      "Epoch 4866/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8537 - accuracy: 0.5862 - val_loss: 0.9585 - val_accuracy: 0.5233\n",
      "Epoch 4867/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8568 - accuracy: 0.5806 - val_loss: 0.9027 - val_accuracy: 0.5683\n",
      "Epoch 4868/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8574 - accuracy: 0.5815 - val_loss: 0.9141 - val_accuracy: 0.5453\n",
      "Epoch 4869/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8536 - accuracy: 0.5845 - val_loss: 0.9072 - val_accuracy: 0.5487\n",
      "Epoch 4870/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8572 - accuracy: 0.5846 - val_loss: 0.9074 - val_accuracy: 0.5550\n",
      "Epoch 4871/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8568 - accuracy: 0.5821 - val_loss: 0.9034 - val_accuracy: 0.5580\n",
      "Epoch 4872/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8555 - accuracy: 0.5856 - val_loss: 0.9019 - val_accuracy: 0.5660\n",
      "Epoch 4873/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8553 - accuracy: 0.5821 - val_loss: 0.9013 - val_accuracy: 0.5620\n",
      "Epoch 4874/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8580 - accuracy: 0.5838 - val_loss: 0.9019 - val_accuracy: 0.5623\n",
      "Epoch 4875/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8600 - accuracy: 0.5796 - val_loss: 0.9041 - val_accuracy: 0.5580\n",
      "Epoch 4876/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8544 - accuracy: 0.5836 - val_loss: 0.9232 - val_accuracy: 0.5340\n",
      "Epoch 4877/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8539 - accuracy: 0.5894 - val_loss: 0.9117 - val_accuracy: 0.5563\n",
      "Epoch 4878/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8563 - accuracy: 0.5827 - val_loss: 0.8996 - val_accuracy: 0.5607\n",
      "Epoch 4879/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8560 - accuracy: 0.5801 - val_loss: 0.9232 - val_accuracy: 0.5410\n",
      "Epoch 4880/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8562 - accuracy: 0.5827 - val_loss: 0.9219 - val_accuracy: 0.5353\n",
      "Epoch 4881/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8531 - accuracy: 0.5878 - val_loss: 0.9170 - val_accuracy: 0.5500\n",
      "Epoch 4882/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8574 - accuracy: 0.5849 - val_loss: 0.9112 - val_accuracy: 0.5477\n",
      "Epoch 4883/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8562 - accuracy: 0.5827 - val_loss: 0.9119 - val_accuracy: 0.5500\n",
      "Epoch 4884/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8534 - accuracy: 0.5834 - val_loss: 0.9028 - val_accuracy: 0.5617\n",
      "Epoch 4885/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8581 - accuracy: 0.5806 - val_loss: 0.9265 - val_accuracy: 0.5330\n",
      "Epoch 4886/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8561 - accuracy: 0.5817 - val_loss: 0.8996 - val_accuracy: 0.5630\n",
      "Epoch 4887/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8557 - accuracy: 0.5870 - val_loss: 0.9059 - val_accuracy: 0.5567\n",
      "Epoch 4888/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8541 - accuracy: 0.5861 - val_loss: 0.9157 - val_accuracy: 0.5507\n",
      "Epoch 4889/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8534 - accuracy: 0.5903 - val_loss: 0.9219 - val_accuracy: 0.5430\n",
      "Epoch 4890/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8571 - accuracy: 0.5816 - val_loss: 0.9128 - val_accuracy: 0.5483\n",
      "Epoch 4891/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8560 - accuracy: 0.5838 - val_loss: 0.9140 - val_accuracy: 0.5490\n",
      "Epoch 4892/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8591 - accuracy: 0.5832 - val_loss: 0.9116 - val_accuracy: 0.5523\n",
      "Epoch 4893/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8592 - accuracy: 0.5821 - val_loss: 0.9016 - val_accuracy: 0.5623\n",
      "Epoch 4894/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8569 - accuracy: 0.5861 - val_loss: 0.9060 - val_accuracy: 0.5573\n",
      "Epoch 4895/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8560 - accuracy: 0.5823 - val_loss: 0.8996 - val_accuracy: 0.5680\n",
      "Epoch 4896/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8557 - accuracy: 0.5829 - val_loss: 0.9016 - val_accuracy: 0.5613\n",
      "Epoch 4897/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8567 - accuracy: 0.5841 - val_loss: 0.9044 - val_accuracy: 0.5647\n",
      "Epoch 4898/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8550 - accuracy: 0.5824 - val_loss: 0.9211 - val_accuracy: 0.5390\n",
      "Epoch 4899/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8546 - accuracy: 0.5894 - val_loss: 0.9000 - val_accuracy: 0.5590\n",
      "Epoch 4900/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8589 - accuracy: 0.5829 - val_loss: 0.9192 - val_accuracy: 0.5333\n",
      "Epoch 4901/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8556 - accuracy: 0.5828 - val_loss: 0.9681 - val_accuracy: 0.5097\n",
      "Epoch 4902/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8575 - accuracy: 0.5787 - val_loss: 0.9053 - val_accuracy: 0.5580\n",
      "Epoch 4903/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8576 - accuracy: 0.5791 - val_loss: 0.9031 - val_accuracy: 0.5563\n",
      "Epoch 4904/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8557 - accuracy: 0.5859 - val_loss: 0.9012 - val_accuracy: 0.5587\n",
      "Epoch 4905/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8583 - accuracy: 0.5804 - val_loss: 0.9073 - val_accuracy: 0.5510\n",
      "Epoch 4906/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8574 - accuracy: 0.5825 - val_loss: 0.8996 - val_accuracy: 0.5697\n",
      "Epoch 4907/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8534 - accuracy: 0.5885 - val_loss: 0.9041 - val_accuracy: 0.5607\n",
      "Epoch 4908/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8552 - accuracy: 0.5866 - val_loss: 0.9060 - val_accuracy: 0.5523\n",
      "Epoch 4909/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8573 - accuracy: 0.5844 - val_loss: 0.9057 - val_accuracy: 0.5570\n",
      "Epoch 4910/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8554 - accuracy: 0.5850 - val_loss: 0.9134 - val_accuracy: 0.5443\n",
      "Epoch 4911/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8553 - accuracy: 0.5844 - val_loss: 0.9007 - val_accuracy: 0.5600\n",
      "Epoch 4912/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8574 - accuracy: 0.5884 - val_loss: 0.9133 - val_accuracy: 0.5433\n",
      "Epoch 4913/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8563 - accuracy: 0.5807 - val_loss: 0.9010 - val_accuracy: 0.5603\n",
      "Epoch 4914/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8547 - accuracy: 0.5849 - val_loss: 0.8993 - val_accuracy: 0.5633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4915/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8550 - accuracy: 0.5839 - val_loss: 0.9201 - val_accuracy: 0.5487\n",
      "Epoch 4916/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8563 - accuracy: 0.5846 - val_loss: 0.9030 - val_accuracy: 0.5603\n",
      "Epoch 4917/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8553 - accuracy: 0.5854 - val_loss: 0.9060 - val_accuracy: 0.5550\n",
      "Epoch 4918/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8569 - accuracy: 0.5823 - val_loss: 0.9044 - val_accuracy: 0.5623\n",
      "Epoch 4919/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8556 - accuracy: 0.5836 - val_loss: 0.9047 - val_accuracy: 0.5573\n",
      "Epoch 4920/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8563 - accuracy: 0.5844 - val_loss: 0.9015 - val_accuracy: 0.5570\n",
      "Epoch 4921/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8561 - accuracy: 0.5843 - val_loss: 0.9117 - val_accuracy: 0.5550\n",
      "Epoch 4922/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8546 - accuracy: 0.5865 - val_loss: 0.9421 - val_accuracy: 0.5183\n",
      "Epoch 4923/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8551 - accuracy: 0.5846 - val_loss: 0.8990 - val_accuracy: 0.5670\n",
      "Epoch 4924/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8564 - accuracy: 0.5820 - val_loss: 0.9119 - val_accuracy: 0.5537\n",
      "Epoch 4925/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8542 - accuracy: 0.5853 - val_loss: 0.9055 - val_accuracy: 0.5573\n",
      "Epoch 4926/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8549 - accuracy: 0.5844 - val_loss: 0.9258 - val_accuracy: 0.5313\n",
      "Epoch 4927/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8566 - accuracy: 0.5851 - val_loss: 0.8993 - val_accuracy: 0.5700\n",
      "Epoch 4928/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8551 - accuracy: 0.5844 - val_loss: 0.9103 - val_accuracy: 0.5503\n",
      "Epoch 4929/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8545 - accuracy: 0.5883 - val_loss: 0.9048 - val_accuracy: 0.5587\n",
      "Epoch 4930/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8582 - accuracy: 0.5824 - val_loss: 0.9178 - val_accuracy: 0.5460\n",
      "Epoch 4931/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8543 - accuracy: 0.5860 - val_loss: 0.8993 - val_accuracy: 0.5700\n",
      "Epoch 4932/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8541 - accuracy: 0.5854 - val_loss: 0.9031 - val_accuracy: 0.5687\n",
      "Epoch 4933/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8529 - accuracy: 0.5861 - val_loss: 0.9014 - val_accuracy: 0.5587\n",
      "Epoch 4934/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8548 - accuracy: 0.5812 - val_loss: 0.9291 - val_accuracy: 0.5393\n",
      "Epoch 4935/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8558 - accuracy: 0.5819 - val_loss: 0.9083 - val_accuracy: 0.5587\n",
      "Epoch 4936/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8552 - accuracy: 0.5826 - val_loss: 0.9007 - val_accuracy: 0.5590\n",
      "Epoch 4937/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8556 - accuracy: 0.5860 - val_loss: 0.9142 - val_accuracy: 0.5577\n",
      "Epoch 4938/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8571 - accuracy: 0.5854 - val_loss: 0.9116 - val_accuracy: 0.5503\n",
      "Epoch 4939/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8565 - accuracy: 0.5825 - val_loss: 0.8999 - val_accuracy: 0.5633\n",
      "Epoch 4940/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8563 - accuracy: 0.5835 - val_loss: 0.9094 - val_accuracy: 0.5580\n",
      "Epoch 4941/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8540 - accuracy: 0.5854 - val_loss: 0.9029 - val_accuracy: 0.5577\n",
      "Epoch 4942/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8556 - accuracy: 0.5864 - val_loss: 0.9076 - val_accuracy: 0.5547\n",
      "Epoch 4943/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8571 - accuracy: 0.5796 - val_loss: 0.9060 - val_accuracy: 0.5550\n",
      "Epoch 4944/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8551 - accuracy: 0.5826 - val_loss: 0.9005 - val_accuracy: 0.5620\n",
      "Epoch 4945/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8543 - accuracy: 0.5841 - val_loss: 0.9001 - val_accuracy: 0.5720\n",
      "Epoch 4946/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8551 - accuracy: 0.5824 - val_loss: 0.8994 - val_accuracy: 0.5647\n",
      "Epoch 4947/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8552 - accuracy: 0.5861 - val_loss: 0.9359 - val_accuracy: 0.5277\n",
      "Epoch 4948/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8571 - accuracy: 0.5829 - val_loss: 0.9057 - val_accuracy: 0.5580\n",
      "Epoch 4949/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8572 - accuracy: 0.5787 - val_loss: 0.9039 - val_accuracy: 0.5667\n",
      "Epoch 4950/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8546 - accuracy: 0.5876 - val_loss: 0.9280 - val_accuracy: 0.5353\n",
      "Epoch 4951/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8554 - accuracy: 0.5872 - val_loss: 0.9171 - val_accuracy: 0.5480\n",
      "Epoch 4952/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8550 - accuracy: 0.5904 - val_loss: 0.8992 - val_accuracy: 0.5657\n",
      "Epoch 4953/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8538 - accuracy: 0.5874 - val_loss: 0.8994 - val_accuracy: 0.5700\n",
      "Epoch 4954/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8570 - accuracy: 0.5834 - val_loss: 0.9277 - val_accuracy: 0.5377\n",
      "Epoch 4955/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8550 - accuracy: 0.5866 - val_loss: 0.9533 - val_accuracy: 0.5220\n",
      "Epoch 4956/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8559 - accuracy: 0.5845 - val_loss: 0.9255 - val_accuracy: 0.5330\n",
      "Epoch 4957/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8531 - accuracy: 0.5897 - val_loss: 0.9009 - val_accuracy: 0.5590\n",
      "Epoch 4958/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8547 - accuracy: 0.5845 - val_loss: 0.9090 - val_accuracy: 0.5503\n",
      "Epoch 4959/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8532 - accuracy: 0.5879 - val_loss: 0.9019 - val_accuracy: 0.5613\n",
      "Epoch 4960/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8564 - accuracy: 0.5843 - val_loss: 0.9013 - val_accuracy: 0.5613\n",
      "Epoch 4961/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8552 - accuracy: 0.5881 - val_loss: 0.9092 - val_accuracy: 0.5527\n",
      "Epoch 4962/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8528 - accuracy: 0.5874 - val_loss: 0.9041 - val_accuracy: 0.5533\n",
      "Epoch 4963/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8535 - accuracy: 0.5882 - val_loss: 0.9110 - val_accuracy: 0.5477\n",
      "Epoch 4964/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8539 - accuracy: 0.5865 - val_loss: 0.9210 - val_accuracy: 0.5383\n",
      "Epoch 4965/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8557 - accuracy: 0.5896 - val_loss: 0.9402 - val_accuracy: 0.5290\n",
      "Epoch 4966/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8526 - accuracy: 0.5866 - val_loss: 0.9017 - val_accuracy: 0.5603\n",
      "Epoch 4967/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8538 - accuracy: 0.5886 - val_loss: 0.9521 - val_accuracy: 0.5240\n",
      "Epoch 4968/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8540 - accuracy: 0.5880 - val_loss: 0.9090 - val_accuracy: 0.5563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4969/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8557 - accuracy: 0.5886 - val_loss: 0.9141 - val_accuracy: 0.5503\n",
      "Epoch 4970/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8520 - accuracy: 0.5881 - val_loss: 0.8984 - val_accuracy: 0.5663\n",
      "Epoch 4971/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8544 - accuracy: 0.5866 - val_loss: 0.9029 - val_accuracy: 0.5593\n",
      "Epoch 4972/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8527 - accuracy: 0.5872 - val_loss: 0.8996 - val_accuracy: 0.5677\n",
      "Epoch 4973/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8507 - accuracy: 0.5884 - val_loss: 0.9048 - val_accuracy: 0.5540\n",
      "Epoch 4974/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8546 - accuracy: 0.5861 - val_loss: 0.9128 - val_accuracy: 0.5477\n",
      "Epoch 4975/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8547 - accuracy: 0.5863 - val_loss: 0.9023 - val_accuracy: 0.5607\n",
      "Epoch 4976/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8553 - accuracy: 0.5889 - val_loss: 0.9059 - val_accuracy: 0.5603\n",
      "Epoch 4977/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8558 - accuracy: 0.5862 - val_loss: 0.9170 - val_accuracy: 0.5420\n",
      "Epoch 4978/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8578 - accuracy: 0.5804 - val_loss: 0.9031 - val_accuracy: 0.5600\n",
      "Epoch 4979/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8525 - accuracy: 0.5881 - val_loss: 0.9016 - val_accuracy: 0.5607\n",
      "Epoch 4980/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8541 - accuracy: 0.5845 - val_loss: 0.9005 - val_accuracy: 0.5593\n",
      "Epoch 4981/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8551 - accuracy: 0.5841 - val_loss: 0.8982 - val_accuracy: 0.5690\n",
      "Epoch 4982/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8556 - accuracy: 0.5822 - val_loss: 0.8982 - val_accuracy: 0.5667\n",
      "Epoch 4983/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8544 - accuracy: 0.5891 - val_loss: 0.9301 - val_accuracy: 0.5277\n",
      "Epoch 4984/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8533 - accuracy: 0.5861 - val_loss: 0.8991 - val_accuracy: 0.5660\n",
      "Epoch 4985/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8537 - accuracy: 0.5894 - val_loss: 0.9080 - val_accuracy: 0.5540\n",
      "Epoch 4986/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8529 - accuracy: 0.5873 - val_loss: 0.9452 - val_accuracy: 0.5317\n",
      "Epoch 4987/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8539 - accuracy: 0.5861 - val_loss: 0.8988 - val_accuracy: 0.5693\n",
      "Epoch 4988/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8545 - accuracy: 0.5863 - val_loss: 0.9006 - val_accuracy: 0.5630\n",
      "Epoch 4989/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8537 - accuracy: 0.5851 - val_loss: 0.8980 - val_accuracy: 0.5733\n",
      "Epoch 4990/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8552 - accuracy: 0.5832 - val_loss: 0.9105 - val_accuracy: 0.5520\n",
      "Epoch 4991/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8550 - accuracy: 0.5871 - val_loss: 0.9042 - val_accuracy: 0.5597\n",
      "Epoch 4992/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8559 - accuracy: 0.5846 - val_loss: 0.9080 - val_accuracy: 0.5547\n",
      "Epoch 4993/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8539 - accuracy: 0.5874 - val_loss: 0.8993 - val_accuracy: 0.5580\n",
      "Epoch 4994/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8550 - accuracy: 0.5819 - val_loss: 0.9022 - val_accuracy: 0.5603\n",
      "Epoch 4995/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8529 - accuracy: 0.5848 - val_loss: 0.9134 - val_accuracy: 0.5497\n",
      "Epoch 4996/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8578 - accuracy: 0.5831 - val_loss: 0.8992 - val_accuracy: 0.5687\n",
      "Epoch 4997/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8561 - accuracy: 0.5834 - val_loss: 0.9582 - val_accuracy: 0.5213\n",
      "Epoch 4998/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8556 - accuracy: 0.5868 - val_loss: 0.9531 - val_accuracy: 0.5320\n",
      "Epoch 4999/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8536 - accuracy: 0.5833 - val_loss: 0.9026 - val_accuracy: 0.5600\n",
      "Epoch 5000/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8549 - accuracy: 0.5841 - val_loss: 0.8994 - val_accuracy: 0.5670\n",
      "Epoch 5001/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8529 - accuracy: 0.5884 - val_loss: 0.9144 - val_accuracy: 0.5517\n",
      "Epoch 5002/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8556 - accuracy: 0.5868 - val_loss: 0.9181 - val_accuracy: 0.5423\n",
      "Epoch 5003/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8549 - accuracy: 0.5830 - val_loss: 0.8990 - val_accuracy: 0.5663\n",
      "Epoch 5004/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8560 - accuracy: 0.5827 - val_loss: 0.9063 - val_accuracy: 0.5543\n",
      "Epoch 5005/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8557 - accuracy: 0.5824 - val_loss: 0.9133 - val_accuracy: 0.5443\n",
      "Epoch 5006/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8566 - accuracy: 0.5840 - val_loss: 0.9076 - val_accuracy: 0.5543\n",
      "Epoch 5007/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8524 - accuracy: 0.5854 - val_loss: 0.9054 - val_accuracy: 0.5627\n",
      "Epoch 5008/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8516 - accuracy: 0.5847 - val_loss: 0.9024 - val_accuracy: 0.5697\n",
      "Epoch 5009/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8544 - accuracy: 0.5849 - val_loss: 0.9091 - val_accuracy: 0.5520\n",
      "Epoch 5010/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8531 - accuracy: 0.5852 - val_loss: 0.9005 - val_accuracy: 0.5600\n",
      "Epoch 5011/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8546 - accuracy: 0.5855 - val_loss: 0.9363 - val_accuracy: 0.5257\n",
      "Epoch 5012/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8551 - accuracy: 0.5851 - val_loss: 0.9012 - val_accuracy: 0.5620\n",
      "Epoch 5013/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8523 - accuracy: 0.5882 - val_loss: 0.8998 - val_accuracy: 0.5603\n",
      "Epoch 5014/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8545 - accuracy: 0.5834 - val_loss: 0.9008 - val_accuracy: 0.5580\n",
      "Epoch 5015/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8556 - accuracy: 0.5854 - val_loss: 0.9044 - val_accuracy: 0.5607\n",
      "Epoch 5016/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8538 - accuracy: 0.5859 - val_loss: 0.9307 - val_accuracy: 0.5403\n",
      "Epoch 5017/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8572 - accuracy: 0.5825 - val_loss: 0.9082 - val_accuracy: 0.5500\n",
      "Epoch 5018/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8540 - accuracy: 0.5872 - val_loss: 0.9367 - val_accuracy: 0.5317\n",
      "Epoch 5019/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8535 - accuracy: 0.5900 - val_loss: 0.9141 - val_accuracy: 0.5493\n",
      "Epoch 5020/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8537 - accuracy: 0.5846 - val_loss: 0.9118 - val_accuracy: 0.5483\n",
      "Epoch 5021/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8537 - accuracy: 0.5866 - val_loss: 0.9243 - val_accuracy: 0.5287\n",
      "Epoch 5022/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8531 - accuracy: 0.5861 - val_loss: 0.8984 - val_accuracy: 0.5660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5023/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8533 - accuracy: 0.5864 - val_loss: 0.9164 - val_accuracy: 0.5423\n",
      "Epoch 5024/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8536 - accuracy: 0.5855 - val_loss: 0.9016 - val_accuracy: 0.5627\n",
      "Epoch 5025/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8527 - accuracy: 0.5844 - val_loss: 0.8995 - val_accuracy: 0.5690\n",
      "Epoch 5026/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8525 - accuracy: 0.5897 - val_loss: 0.9113 - val_accuracy: 0.5467\n",
      "Epoch 5027/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8537 - accuracy: 0.5878 - val_loss: 0.9008 - val_accuracy: 0.5597\n",
      "Epoch 5028/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8536 - accuracy: 0.5886 - val_loss: 0.9135 - val_accuracy: 0.5483\n",
      "Epoch 5029/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8529 - accuracy: 0.5871 - val_loss: 0.8974 - val_accuracy: 0.5657\n",
      "Epoch 5030/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8545 - accuracy: 0.5879 - val_loss: 0.9025 - val_accuracy: 0.5567\n",
      "Epoch 5031/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8529 - accuracy: 0.5866 - val_loss: 0.9032 - val_accuracy: 0.5580\n",
      "Epoch 5032/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8555 - accuracy: 0.5876 - val_loss: 0.9069 - val_accuracy: 0.5547\n",
      "Epoch 5033/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8541 - accuracy: 0.5871 - val_loss: 0.9169 - val_accuracy: 0.5487\n",
      "Epoch 5034/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8534 - accuracy: 0.5894 - val_loss: 0.9004 - val_accuracy: 0.5633\n",
      "Epoch 5035/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8555 - accuracy: 0.5814 - val_loss: 0.9036 - val_accuracy: 0.5707\n",
      "Epoch 5036/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8549 - accuracy: 0.5829 - val_loss: 0.9038 - val_accuracy: 0.5577\n",
      "Epoch 5037/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8514 - accuracy: 0.5860 - val_loss: 0.9041 - val_accuracy: 0.5627\n",
      "Epoch 5038/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8539 - accuracy: 0.5831 - val_loss: 0.9014 - val_accuracy: 0.5610\n",
      "Epoch 5039/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8549 - accuracy: 0.5843 - val_loss: 0.8992 - val_accuracy: 0.5650\n",
      "Epoch 5040/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8500 - accuracy: 0.5866 - val_loss: 0.9062 - val_accuracy: 0.5553\n",
      "Epoch 5041/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8539 - accuracy: 0.5841 - val_loss: 0.9025 - val_accuracy: 0.5577\n",
      "Epoch 5042/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8549 - accuracy: 0.5826 - val_loss: 0.9077 - val_accuracy: 0.5520\n",
      "Epoch 5043/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8540 - accuracy: 0.5886 - val_loss: 0.9066 - val_accuracy: 0.5580\n",
      "Epoch 5044/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8566 - accuracy: 0.5823 - val_loss: 0.9067 - val_accuracy: 0.5597\n",
      "Epoch 5045/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8543 - accuracy: 0.5861 - val_loss: 0.9091 - val_accuracy: 0.5537\n",
      "Epoch 5046/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8543 - accuracy: 0.5851 - val_loss: 0.9051 - val_accuracy: 0.5600\n",
      "Epoch 5047/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8540 - accuracy: 0.5819 - val_loss: 0.9194 - val_accuracy: 0.5430\n",
      "Epoch 5048/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8532 - accuracy: 0.5854 - val_loss: 0.8985 - val_accuracy: 0.5707\n",
      "Epoch 5049/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8539 - accuracy: 0.5855 - val_loss: 0.9194 - val_accuracy: 0.5357\n",
      "Epoch 5050/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8549 - accuracy: 0.5827 - val_loss: 0.9014 - val_accuracy: 0.5590\n",
      "Epoch 5051/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8548 - accuracy: 0.5848 - val_loss: 0.8992 - val_accuracy: 0.5660\n",
      "Epoch 5052/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8522 - accuracy: 0.5896 - val_loss: 0.9033 - val_accuracy: 0.5577\n",
      "Epoch 5053/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8546 - accuracy: 0.5846 - val_loss: 0.9083 - val_accuracy: 0.5573\n",
      "Epoch 5054/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8531 - accuracy: 0.5868 - val_loss: 0.9209 - val_accuracy: 0.5437\n",
      "Epoch 5055/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8554 - accuracy: 0.5834 - val_loss: 0.8991 - val_accuracy: 0.5613\n",
      "Epoch 5056/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8522 - accuracy: 0.5874 - val_loss: 0.9033 - val_accuracy: 0.5597\n",
      "Epoch 5057/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8535 - accuracy: 0.5813 - val_loss: 0.8991 - val_accuracy: 0.5707\n",
      "Epoch 5058/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8530 - accuracy: 0.5841 - val_loss: 0.9070 - val_accuracy: 0.5543\n",
      "Epoch 5059/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8540 - accuracy: 0.5835 - val_loss: 0.8991 - val_accuracy: 0.5660\n",
      "Epoch 5060/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8542 - accuracy: 0.5828 - val_loss: 0.9029 - val_accuracy: 0.5587\n",
      "Epoch 5061/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8539 - accuracy: 0.5869 - val_loss: 0.9180 - val_accuracy: 0.5437\n",
      "Epoch 5062/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8519 - accuracy: 0.5849 - val_loss: 0.9527 - val_accuracy: 0.5243\n",
      "Epoch 5063/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8560 - accuracy: 0.5817 - val_loss: 0.9032 - val_accuracy: 0.5550\n",
      "Epoch 5064/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8524 - accuracy: 0.5882 - val_loss: 0.9082 - val_accuracy: 0.5543\n",
      "Epoch 5065/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8523 - accuracy: 0.5896 - val_loss: 0.9077 - val_accuracy: 0.5557\n",
      "Epoch 5066/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8530 - accuracy: 0.5879 - val_loss: 0.9009 - val_accuracy: 0.5607\n",
      "Epoch 5067/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8526 - accuracy: 0.5829 - val_loss: 0.9226 - val_accuracy: 0.5397\n",
      "Epoch 5068/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8587 - accuracy: 0.5834 - val_loss: 0.9001 - val_accuracy: 0.5640\n",
      "Epoch 5069/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8523 - accuracy: 0.5918 - val_loss: 0.9002 - val_accuracy: 0.5690\n",
      "Epoch 5070/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8542 - accuracy: 0.5842 - val_loss: 0.9783 - val_accuracy: 0.5163\n",
      "Epoch 5071/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8520 - accuracy: 0.5874 - val_loss: 0.9236 - val_accuracy: 0.5410\n",
      "Epoch 5072/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8533 - accuracy: 0.5819 - val_loss: 0.9190 - val_accuracy: 0.5427\n",
      "Epoch 5073/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8539 - accuracy: 0.5857 - val_loss: 0.9290 - val_accuracy: 0.5327\n",
      "Epoch 5074/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8543 - accuracy: 0.5861 - val_loss: 0.9011 - val_accuracy: 0.5543\n",
      "Epoch 5075/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8506 - accuracy: 0.5889 - val_loss: 0.9040 - val_accuracy: 0.5613\n",
      "Epoch 5076/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8550 - accuracy: 0.5835 - val_loss: 0.9048 - val_accuracy: 0.5593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5077/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8543 - accuracy: 0.5834 - val_loss: 0.9137 - val_accuracy: 0.5457\n",
      "Epoch 5078/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8526 - accuracy: 0.5860 - val_loss: 0.8989 - val_accuracy: 0.5643\n",
      "Epoch 5079/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8555 - accuracy: 0.5832 - val_loss: 0.9044 - val_accuracy: 0.5517\n",
      "Epoch 5080/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8511 - accuracy: 0.5850 - val_loss: 0.9407 - val_accuracy: 0.5213\n",
      "Epoch 5081/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8504 - accuracy: 0.5905 - val_loss: 0.9014 - val_accuracy: 0.5633\n",
      "Epoch 5082/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8531 - accuracy: 0.5839 - val_loss: 0.9027 - val_accuracy: 0.5583\n",
      "Epoch 5083/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8526 - accuracy: 0.5831 - val_loss: 0.9078 - val_accuracy: 0.5567\n",
      "Epoch 5084/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8526 - accuracy: 0.5886 - val_loss: 0.9119 - val_accuracy: 0.5473\n",
      "Epoch 5085/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8516 - accuracy: 0.5847 - val_loss: 0.9179 - val_accuracy: 0.5390\n",
      "Epoch 5086/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8544 - accuracy: 0.5854 - val_loss: 0.8991 - val_accuracy: 0.5613\n",
      "Epoch 5087/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8517 - accuracy: 0.5866 - val_loss: 0.8985 - val_accuracy: 0.5707\n",
      "Epoch 5088/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8523 - accuracy: 0.5846 - val_loss: 0.9505 - val_accuracy: 0.5240\n",
      "Epoch 5089/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8544 - accuracy: 0.5844 - val_loss: 0.9246 - val_accuracy: 0.5337\n",
      "Epoch 5090/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8509 - accuracy: 0.5901 - val_loss: 0.9060 - val_accuracy: 0.5507\n",
      "Epoch 5091/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8530 - accuracy: 0.5867 - val_loss: 0.9054 - val_accuracy: 0.5573\n",
      "Epoch 5092/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8534 - accuracy: 0.5850 - val_loss: 0.9053 - val_accuracy: 0.5557\n",
      "Epoch 5093/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8508 - accuracy: 0.5892 - val_loss: 0.9008 - val_accuracy: 0.5643\n",
      "Epoch 5094/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8530 - accuracy: 0.5826 - val_loss: 0.9175 - val_accuracy: 0.5470\n",
      "Epoch 5095/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8541 - accuracy: 0.5823 - val_loss: 0.9220 - val_accuracy: 0.5470\n",
      "Epoch 5096/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8537 - accuracy: 0.5876 - val_loss: 0.9050 - val_accuracy: 0.5610\n",
      "Epoch 5097/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8540 - accuracy: 0.5866 - val_loss: 0.9064 - val_accuracy: 0.5660\n",
      "Epoch 5098/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8546 - accuracy: 0.5852 - val_loss: 0.9071 - val_accuracy: 0.5593\n",
      "Epoch 5099/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8530 - accuracy: 0.5849 - val_loss: 0.9003 - val_accuracy: 0.5613\n",
      "Epoch 5100/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8546 - accuracy: 0.5834 - val_loss: 0.9197 - val_accuracy: 0.5437\n",
      "Epoch 5101/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8527 - accuracy: 0.5836 - val_loss: 0.9009 - val_accuracy: 0.5607\n",
      "Epoch 5102/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8517 - accuracy: 0.5863 - val_loss: 0.8996 - val_accuracy: 0.5663\n",
      "Epoch 5103/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8549 - accuracy: 0.5820 - val_loss: 0.9232 - val_accuracy: 0.5397\n",
      "Epoch 5104/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8519 - accuracy: 0.5874 - val_loss: 0.9086 - val_accuracy: 0.5500\n",
      "Epoch 5105/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8529 - accuracy: 0.5848 - val_loss: 0.9031 - val_accuracy: 0.5593\n",
      "Epoch 5106/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8540 - accuracy: 0.5871 - val_loss: 0.9045 - val_accuracy: 0.5550\n",
      "Epoch 5107/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8530 - accuracy: 0.5869 - val_loss: 0.8994 - val_accuracy: 0.5713\n",
      "Epoch 5108/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8537 - accuracy: 0.5851 - val_loss: 0.9080 - val_accuracy: 0.5540\n",
      "Epoch 5109/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8514 - accuracy: 0.5851 - val_loss: 0.9038 - val_accuracy: 0.5563\n",
      "Epoch 5110/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8534 - accuracy: 0.5841 - val_loss: 0.9398 - val_accuracy: 0.5337\n",
      "Epoch 5111/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8538 - accuracy: 0.5831 - val_loss: 0.9009 - val_accuracy: 0.5677\n",
      "Epoch 5112/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8529 - accuracy: 0.5921 - val_loss: 0.8995 - val_accuracy: 0.5630\n",
      "Epoch 5113/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8529 - accuracy: 0.5885 - val_loss: 0.9242 - val_accuracy: 0.5380\n",
      "Epoch 5114/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8482 - accuracy: 0.5926 - val_loss: 0.9047 - val_accuracy: 0.5557\n",
      "Epoch 5115/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8516 - accuracy: 0.5854 - val_loss: 0.8988 - val_accuracy: 0.5703\n",
      "Epoch 5116/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8527 - accuracy: 0.5889 - val_loss: 0.9872 - val_accuracy: 0.5083\n",
      "Epoch 5117/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8540 - accuracy: 0.5836 - val_loss: 0.9110 - val_accuracy: 0.5493\n",
      "Epoch 5118/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8518 - accuracy: 0.5881 - val_loss: 0.9008 - val_accuracy: 0.5640\n",
      "Epoch 5119/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8523 - accuracy: 0.5842 - val_loss: 0.9169 - val_accuracy: 0.5483\n",
      "Epoch 5120/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8526 - accuracy: 0.5866 - val_loss: 0.9021 - val_accuracy: 0.5633\n",
      "Epoch 5121/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8533 - accuracy: 0.5844 - val_loss: 0.9127 - val_accuracy: 0.5450\n",
      "Epoch 5122/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8567 - accuracy: 0.5835 - val_loss: 0.9018 - val_accuracy: 0.5657\n",
      "Epoch 5123/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8507 - accuracy: 0.5844 - val_loss: 0.9044 - val_accuracy: 0.5553\n",
      "Epoch 5124/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8520 - accuracy: 0.5866 - val_loss: 0.9005 - val_accuracy: 0.5707\n",
      "Epoch 5125/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8534 - accuracy: 0.5871 - val_loss: 0.9293 - val_accuracy: 0.5393\n",
      "Epoch 5126/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8512 - accuracy: 0.5876 - val_loss: 0.8995 - val_accuracy: 0.5607\n",
      "Epoch 5127/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8501 - accuracy: 0.5870 - val_loss: 0.9230 - val_accuracy: 0.5397\n",
      "Epoch 5128/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8524 - accuracy: 0.5870 - val_loss: 0.9038 - val_accuracy: 0.5587\n",
      "Epoch 5129/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8542 - accuracy: 0.5888 - val_loss: 0.9676 - val_accuracy: 0.5033\n",
      "Epoch 5130/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8538 - accuracy: 0.5872 - val_loss: 0.9124 - val_accuracy: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5131/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8517 - accuracy: 0.5872 - val_loss: 0.9244 - val_accuracy: 0.5523\n",
      "Epoch 5132/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8508 - accuracy: 0.5869 - val_loss: 0.9020 - val_accuracy: 0.5587\n",
      "Epoch 5133/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8524 - accuracy: 0.5855 - val_loss: 0.9019 - val_accuracy: 0.5647\n",
      "Epoch 5134/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8519 - accuracy: 0.5861 - val_loss: 0.9117 - val_accuracy: 0.5540\n",
      "Epoch 5135/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8513 - accuracy: 0.5868 - val_loss: 0.9021 - val_accuracy: 0.5570\n",
      "Epoch 5136/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8536 - accuracy: 0.5856 - val_loss: 0.9155 - val_accuracy: 0.5460\n",
      "Epoch 5137/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8519 - accuracy: 0.5822 - val_loss: 0.9009 - val_accuracy: 0.5647\n",
      "Epoch 5138/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8527 - accuracy: 0.5879 - val_loss: 0.9030 - val_accuracy: 0.5630\n",
      "Epoch 5139/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8525 - accuracy: 0.5846 - val_loss: 0.8994 - val_accuracy: 0.5667\n",
      "Epoch 5140/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8497 - accuracy: 0.5874 - val_loss: 0.9058 - val_accuracy: 0.5563\n",
      "Epoch 5141/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8530 - accuracy: 0.5854 - val_loss: 0.8997 - val_accuracy: 0.5633\n",
      "Epoch 5142/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8524 - accuracy: 0.5851 - val_loss: 0.9067 - val_accuracy: 0.5547\n",
      "Epoch 5143/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8535 - accuracy: 0.5879 - val_loss: 0.9320 - val_accuracy: 0.5337\n",
      "Epoch 5144/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8547 - accuracy: 0.5858 - val_loss: 0.9355 - val_accuracy: 0.5230\n",
      "Epoch 5145/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8494 - accuracy: 0.5906 - val_loss: 0.9128 - val_accuracy: 0.5473\n",
      "Epoch 5146/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8523 - accuracy: 0.5901 - val_loss: 0.8998 - val_accuracy: 0.5687\n",
      "Epoch 5147/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8544 - accuracy: 0.5828 - val_loss: 0.9009 - val_accuracy: 0.5603\n",
      "Epoch 5148/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8535 - accuracy: 0.5861 - val_loss: 0.9076 - val_accuracy: 0.5557\n",
      "Epoch 5149/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8536 - accuracy: 0.5854 - val_loss: 0.8985 - val_accuracy: 0.5627\n",
      "Epoch 5150/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8530 - accuracy: 0.5857 - val_loss: 0.9435 - val_accuracy: 0.5327\n",
      "Epoch 5151/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8548 - accuracy: 0.5826 - val_loss: 0.8992 - val_accuracy: 0.5690\n",
      "Epoch 5152/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8503 - accuracy: 0.5898 - val_loss: 0.9143 - val_accuracy: 0.5420\n",
      "Epoch 5153/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8505 - accuracy: 0.5888 - val_loss: 0.9015 - val_accuracy: 0.5713\n",
      "Epoch 5154/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8533 - accuracy: 0.5866 - val_loss: 0.9255 - val_accuracy: 0.5363\n",
      "Epoch 5155/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8529 - accuracy: 0.5837 - val_loss: 0.9042 - val_accuracy: 0.5630\n",
      "Epoch 5156/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8522 - accuracy: 0.5891 - val_loss: 0.9043 - val_accuracy: 0.5527\n",
      "Epoch 5157/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8521 - accuracy: 0.5884 - val_loss: 0.8995 - val_accuracy: 0.5623\n",
      "Epoch 5158/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8528 - accuracy: 0.5861 - val_loss: 0.9105 - val_accuracy: 0.5473\n",
      "Epoch 5159/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8529 - accuracy: 0.5851 - val_loss: 0.8992 - val_accuracy: 0.5697\n",
      "Epoch 5160/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8529 - accuracy: 0.5858 - val_loss: 0.9127 - val_accuracy: 0.5500\n",
      "Epoch 5161/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8544 - accuracy: 0.5847 - val_loss: 0.9041 - val_accuracy: 0.5590\n",
      "Epoch 5162/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8528 - accuracy: 0.5855 - val_loss: 0.9165 - val_accuracy: 0.5497\n",
      "Epoch 5163/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8506 - accuracy: 0.5906 - val_loss: 0.9304 - val_accuracy: 0.5303\n",
      "Epoch 5164/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8510 - accuracy: 0.5916 - val_loss: 0.8990 - val_accuracy: 0.5677\n",
      "Epoch 5165/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8521 - accuracy: 0.5904 - val_loss: 0.9004 - val_accuracy: 0.5637\n",
      "Epoch 5166/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8538 - accuracy: 0.5819 - val_loss: 0.9093 - val_accuracy: 0.5477\n",
      "Epoch 5167/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8512 - accuracy: 0.5891 - val_loss: 0.9049 - val_accuracy: 0.5527\n",
      "Epoch 5168/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8501 - accuracy: 0.5846 - val_loss: 0.9077 - val_accuracy: 0.5503\n",
      "Epoch 5169/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8517 - accuracy: 0.5889 - val_loss: 0.9334 - val_accuracy: 0.5400\n",
      "Epoch 5170/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8529 - accuracy: 0.5892 - val_loss: 0.9011 - val_accuracy: 0.5660\n",
      "Epoch 5171/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8514 - accuracy: 0.5846 - val_loss: 0.9486 - val_accuracy: 0.5203\n",
      "Epoch 5172/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8530 - accuracy: 0.5876 - val_loss: 0.9068 - val_accuracy: 0.5563\n",
      "Epoch 5173/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8508 - accuracy: 0.5888 - val_loss: 0.9204 - val_accuracy: 0.5483\n",
      "Epoch 5174/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8524 - accuracy: 0.5872 - val_loss: 0.9195 - val_accuracy: 0.5427\n",
      "Epoch 5175/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8489 - accuracy: 0.5880 - val_loss: 0.9032 - val_accuracy: 0.5610\n",
      "Epoch 5176/5500\n",
      "14000/14000 [==============================] - 0s 24us/step - loss: 0.8522 - accuracy: 0.5916 - val_loss: 0.9048 - val_accuracy: 0.5583\n",
      "Epoch 5177/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8507 - accuracy: 0.5875 - val_loss: 0.9069 - val_accuracy: 0.5577\n",
      "Epoch 5178/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8532 - accuracy: 0.5874 - val_loss: 0.9015 - val_accuracy: 0.5613\n",
      "Epoch 5179/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8583 - accuracy: 0.5834 - val_loss: 0.9021 - val_accuracy: 0.5613\n",
      "Epoch 5180/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8523 - accuracy: 0.5870 - val_loss: 0.9041 - val_accuracy: 0.5560\n",
      "Epoch 5181/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8510 - accuracy: 0.5915 - val_loss: 0.9004 - val_accuracy: 0.5673\n",
      "Epoch 5182/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8525 - accuracy: 0.5854 - val_loss: 0.9087 - val_accuracy: 0.5600\n",
      "Epoch 5183/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8544 - accuracy: 0.5827 - val_loss: 0.9045 - val_accuracy: 0.5573\n",
      "Epoch 5184/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8544 - accuracy: 0.5878 - val_loss: 0.9180 - val_accuracy: 0.5427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5185/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8512 - accuracy: 0.5865 - val_loss: 0.9286 - val_accuracy: 0.5360\n",
      "Epoch 5186/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8532 - accuracy: 0.5890 - val_loss: 0.9461 - val_accuracy: 0.5193\n",
      "Epoch 5187/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8513 - accuracy: 0.5865 - val_loss: 0.9097 - val_accuracy: 0.5510\n",
      "Epoch 5188/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8523 - accuracy: 0.5851 - val_loss: 0.9137 - val_accuracy: 0.5523\n",
      "Epoch 5189/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8505 - accuracy: 0.5863 - val_loss: 0.9014 - val_accuracy: 0.5663\n",
      "Epoch 5190/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8487 - accuracy: 0.5882 - val_loss: 0.9026 - val_accuracy: 0.5597\n",
      "Epoch 5191/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8535 - accuracy: 0.5829 - val_loss: 0.9018 - val_accuracy: 0.5607\n",
      "Epoch 5192/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8513 - accuracy: 0.5906 - val_loss: 0.9195 - val_accuracy: 0.5390\n",
      "Epoch 5193/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8520 - accuracy: 0.5840 - val_loss: 0.9139 - val_accuracy: 0.5503\n",
      "Epoch 5194/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8501 - accuracy: 0.5875 - val_loss: 0.9122 - val_accuracy: 0.5490\n",
      "Epoch 5195/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8503 - accuracy: 0.5853 - val_loss: 0.9029 - val_accuracy: 0.5587\n",
      "Epoch 5196/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8507 - accuracy: 0.5892 - val_loss: 0.9144 - val_accuracy: 0.5550\n",
      "Epoch 5197/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8537 - accuracy: 0.5897 - val_loss: 0.9097 - val_accuracy: 0.5480\n",
      "Epoch 5198/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8504 - accuracy: 0.5873 - val_loss: 0.9086 - val_accuracy: 0.5510\n",
      "Epoch 5199/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8541 - accuracy: 0.5836 - val_loss: 0.9011 - val_accuracy: 0.5620\n",
      "Epoch 5200/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8517 - accuracy: 0.5872 - val_loss: 0.9029 - val_accuracy: 0.5563\n",
      "Epoch 5201/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8510 - accuracy: 0.5854 - val_loss: 0.9002 - val_accuracy: 0.5637\n",
      "Epoch 5202/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8519 - accuracy: 0.5881 - val_loss: 0.9487 - val_accuracy: 0.5300\n",
      "Epoch 5203/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8526 - accuracy: 0.5893 - val_loss: 0.9046 - val_accuracy: 0.5567\n",
      "Epoch 5204/5500\n",
      "14000/14000 [==============================] - 0s 25us/step - loss: 0.8504 - accuracy: 0.5906 - val_loss: 0.9105 - val_accuracy: 0.5517\n",
      "Epoch 5205/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8517 - accuracy: 0.5853 - val_loss: 0.9029 - val_accuracy: 0.5600\n",
      "Epoch 5206/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8501 - accuracy: 0.5901 - val_loss: 0.9033 - val_accuracy: 0.5583\n",
      "Epoch 5207/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8526 - accuracy: 0.5891 - val_loss: 0.9172 - val_accuracy: 0.5403\n",
      "Epoch 5208/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8513 - accuracy: 0.5874 - val_loss: 0.8989 - val_accuracy: 0.5637\n",
      "Epoch 5209/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8532 - accuracy: 0.5864 - val_loss: 0.9363 - val_accuracy: 0.5303\n",
      "Epoch 5210/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8495 - accuracy: 0.5871 - val_loss: 0.9027 - val_accuracy: 0.5567\n",
      "Epoch 5211/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8527 - accuracy: 0.5874 - val_loss: 0.9005 - val_accuracy: 0.5613\n",
      "Epoch 5212/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8511 - accuracy: 0.5895 - val_loss: 0.8999 - val_accuracy: 0.5677\n",
      "Epoch 5213/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8520 - accuracy: 0.5874 - val_loss: 0.9070 - val_accuracy: 0.5550\n",
      "Epoch 5214/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8502 - accuracy: 0.5905 - val_loss: 0.9477 - val_accuracy: 0.5270\n",
      "Epoch 5215/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8509 - accuracy: 0.5902 - val_loss: 0.9328 - val_accuracy: 0.5403\n",
      "Epoch 5216/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8513 - accuracy: 0.5882 - val_loss: 0.9001 - val_accuracy: 0.5607\n",
      "Epoch 5217/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8519 - accuracy: 0.5887 - val_loss: 0.9009 - val_accuracy: 0.5583\n",
      "Epoch 5218/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8516 - accuracy: 0.5858 - val_loss: 0.9126 - val_accuracy: 0.5513\n",
      "Epoch 5219/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8508 - accuracy: 0.5852 - val_loss: 0.9071 - val_accuracy: 0.5550\n",
      "Epoch 5220/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8518 - accuracy: 0.5862 - val_loss: 0.9146 - val_accuracy: 0.5500\n",
      "Epoch 5221/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8517 - accuracy: 0.5846 - val_loss: 0.9061 - val_accuracy: 0.5543\n",
      "Epoch 5222/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8517 - accuracy: 0.5901 - val_loss: 0.9220 - val_accuracy: 0.5397\n",
      "Epoch 5223/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8521 - accuracy: 0.5869 - val_loss: 0.9120 - val_accuracy: 0.5530\n",
      "Epoch 5224/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8501 - accuracy: 0.5894 - val_loss: 0.9029 - val_accuracy: 0.5633\n",
      "Epoch 5225/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8514 - accuracy: 0.5880 - val_loss: 0.9021 - val_accuracy: 0.5660\n",
      "Epoch 5226/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8545 - accuracy: 0.5874 - val_loss: 0.9054 - val_accuracy: 0.5573\n",
      "Epoch 5227/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8519 - accuracy: 0.5851 - val_loss: 0.9008 - val_accuracy: 0.5660\n",
      "Epoch 5228/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8530 - accuracy: 0.5869 - val_loss: 0.9009 - val_accuracy: 0.5590\n",
      "Epoch 5229/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8521 - accuracy: 0.5887 - val_loss: 0.9050 - val_accuracy: 0.5573\n",
      "Epoch 5230/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8492 - accuracy: 0.5872 - val_loss: 0.9015 - val_accuracy: 0.5567\n",
      "Epoch 5231/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8496 - accuracy: 0.5910 - val_loss: 0.9142 - val_accuracy: 0.5493\n",
      "Epoch 5232/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8511 - accuracy: 0.5886 - val_loss: 0.9405 - val_accuracy: 0.5287\n",
      "Epoch 5233/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8533 - accuracy: 0.5876 - val_loss: 0.9003 - val_accuracy: 0.5650\n",
      "Epoch 5234/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8524 - accuracy: 0.5873 - val_loss: 0.9237 - val_accuracy: 0.5360\n",
      "Epoch 5235/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8499 - accuracy: 0.5896 - val_loss: 0.9069 - val_accuracy: 0.5603\n",
      "Epoch 5236/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8496 - accuracy: 0.5843 - val_loss: 0.9098 - val_accuracy: 0.5493\n",
      "Epoch 5237/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8519 - accuracy: 0.5868 - val_loss: 0.9038 - val_accuracy: 0.5607\n",
      "Epoch 5238/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8500 - accuracy: 0.5916 - val_loss: 0.9004 - val_accuracy: 0.5597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5239/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8522 - accuracy: 0.5832 - val_loss: 0.9100 - val_accuracy: 0.5487\n",
      "Epoch 5240/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8509 - accuracy: 0.5838 - val_loss: 0.9035 - val_accuracy: 0.5623\n",
      "Epoch 5241/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8498 - accuracy: 0.5921 - val_loss: 0.9296 - val_accuracy: 0.5400\n",
      "Epoch 5242/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8518 - accuracy: 0.5881 - val_loss: 0.9140 - val_accuracy: 0.5437\n",
      "Epoch 5243/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8492 - accuracy: 0.5888 - val_loss: 0.9061 - val_accuracy: 0.5610\n",
      "Epoch 5244/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8511 - accuracy: 0.5869 - val_loss: 0.9354 - val_accuracy: 0.5293\n",
      "Epoch 5245/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8497 - accuracy: 0.5881 - val_loss: 0.9059 - val_accuracy: 0.5530\n",
      "Epoch 5246/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8505 - accuracy: 0.5889 - val_loss: 0.9060 - val_accuracy: 0.5587\n",
      "Epoch 5247/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8505 - accuracy: 0.5906 - val_loss: 0.9039 - val_accuracy: 0.5650\n",
      "Epoch 5248/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8496 - accuracy: 0.5898 - val_loss: 0.9205 - val_accuracy: 0.5520\n",
      "Epoch 5249/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8505 - accuracy: 0.5860 - val_loss: 0.9095 - val_accuracy: 0.5513\n",
      "Epoch 5250/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8519 - accuracy: 0.5897 - val_loss: 0.9009 - val_accuracy: 0.5607\n",
      "Epoch 5251/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8521 - accuracy: 0.5844 - val_loss: 0.8997 - val_accuracy: 0.5607\n",
      "Epoch 5252/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8509 - accuracy: 0.5877 - val_loss: 0.9188 - val_accuracy: 0.5453\n",
      "Epoch 5253/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8518 - accuracy: 0.5894 - val_loss: 0.9342 - val_accuracy: 0.5343\n",
      "Epoch 5254/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8510 - accuracy: 0.5849 - val_loss: 0.9043 - val_accuracy: 0.5617\n",
      "Epoch 5255/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8510 - accuracy: 0.5880 - val_loss: 0.9022 - val_accuracy: 0.5597\n",
      "Epoch 5256/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8497 - accuracy: 0.5909 - val_loss: 0.9006 - val_accuracy: 0.5670\n",
      "Epoch 5257/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8515 - accuracy: 0.5831 - val_loss: 0.9127 - val_accuracy: 0.5493\n",
      "Epoch 5258/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8495 - accuracy: 0.5849 - val_loss: 0.9159 - val_accuracy: 0.5473\n",
      "Epoch 5259/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8513 - accuracy: 0.5883 - val_loss: 0.9041 - val_accuracy: 0.5540\n",
      "Epoch 5260/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8520 - accuracy: 0.5862 - val_loss: 0.9019 - val_accuracy: 0.5607\n",
      "Epoch 5261/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8520 - accuracy: 0.5864 - val_loss: 0.9036 - val_accuracy: 0.5590\n",
      "Epoch 5262/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8526 - accuracy: 0.5846 - val_loss: 0.9019 - val_accuracy: 0.5673\n",
      "Epoch 5263/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8505 - accuracy: 0.5861 - val_loss: 0.9019 - val_accuracy: 0.5710\n",
      "Epoch 5264/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8489 - accuracy: 0.5929 - val_loss: 0.9245 - val_accuracy: 0.5293\n",
      "Epoch 5265/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8511 - accuracy: 0.5870 - val_loss: 0.9226 - val_accuracy: 0.5410\n",
      "Epoch 5266/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8508 - accuracy: 0.5850 - val_loss: 0.9014 - val_accuracy: 0.5600\n",
      "Epoch 5267/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8477 - accuracy: 0.5881 - val_loss: 0.9031 - val_accuracy: 0.5610\n",
      "Epoch 5268/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8488 - accuracy: 0.5876 - val_loss: 0.9155 - val_accuracy: 0.5437\n",
      "Epoch 5269/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8516 - accuracy: 0.5874 - val_loss: 0.9225 - val_accuracy: 0.5377\n",
      "Epoch 5270/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8510 - accuracy: 0.5863 - val_loss: 0.9021 - val_accuracy: 0.5577\n",
      "Epoch 5271/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8501 - accuracy: 0.5864 - val_loss: 0.9126 - val_accuracy: 0.5487\n",
      "Epoch 5272/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8506 - accuracy: 0.5904 - val_loss: 0.9087 - val_accuracy: 0.5530\n",
      "Epoch 5273/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8486 - accuracy: 0.5866 - val_loss: 0.9052 - val_accuracy: 0.5547\n",
      "Epoch 5274/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8500 - accuracy: 0.5871 - val_loss: 0.9049 - val_accuracy: 0.5587\n",
      "Epoch 5275/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8534 - accuracy: 0.5868 - val_loss: 0.9141 - val_accuracy: 0.5453\n",
      "Epoch 5276/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8532 - accuracy: 0.5866 - val_loss: 0.9112 - val_accuracy: 0.5520\n",
      "Epoch 5277/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8517 - accuracy: 0.5888 - val_loss: 0.9024 - val_accuracy: 0.5653\n",
      "Epoch 5278/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8520 - accuracy: 0.5856 - val_loss: 0.9047 - val_accuracy: 0.5583\n",
      "Epoch 5279/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8491 - accuracy: 0.5940 - val_loss: 0.9097 - val_accuracy: 0.5473\n",
      "Epoch 5280/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8481 - accuracy: 0.5936 - val_loss: 0.9070 - val_accuracy: 0.5533\n",
      "Epoch 5281/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8478 - accuracy: 0.5890 - val_loss: 0.8998 - val_accuracy: 0.5713\n",
      "Epoch 5282/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8517 - accuracy: 0.5871 - val_loss: 0.9054 - val_accuracy: 0.5607\n",
      "Epoch 5283/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8516 - accuracy: 0.5857 - val_loss: 0.9112 - val_accuracy: 0.5497\n",
      "Epoch 5284/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8492 - accuracy: 0.5894 - val_loss: 0.9083 - val_accuracy: 0.5560\n",
      "Epoch 5285/5500\n",
      "14000/14000 [==============================] - 0s 29us/step - loss: 0.8512 - accuracy: 0.5860 - val_loss: 0.9187 - val_accuracy: 0.5527\n",
      "Epoch 5286/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8514 - accuracy: 0.5890 - val_loss: 0.9775 - val_accuracy: 0.5133\n",
      "Epoch 5287/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8493 - accuracy: 0.5884 - val_loss: 0.9031 - val_accuracy: 0.5690\n",
      "Epoch 5288/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8505 - accuracy: 0.5859 - val_loss: 0.9050 - val_accuracy: 0.5610\n",
      "Epoch 5289/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8505 - accuracy: 0.5896 - val_loss: 0.8995 - val_accuracy: 0.5670\n",
      "Epoch 5290/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8497 - accuracy: 0.5876 - val_loss: 0.9324 - val_accuracy: 0.5340\n",
      "Epoch 5291/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8514 - accuracy: 0.5866 - val_loss: 0.8996 - val_accuracy: 0.5640\n",
      "Epoch 5292/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8501 - accuracy: 0.5896 - val_loss: 0.9147 - val_accuracy: 0.5513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5293/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8519 - accuracy: 0.5871 - val_loss: 0.9140 - val_accuracy: 0.5507\n",
      "Epoch 5294/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8544 - accuracy: 0.5859 - val_loss: 0.9063 - val_accuracy: 0.5583\n",
      "Epoch 5295/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8512 - accuracy: 0.5904 - val_loss: 0.9024 - val_accuracy: 0.5613\n",
      "Epoch 5296/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8478 - accuracy: 0.5897 - val_loss: 0.9074 - val_accuracy: 0.5553\n",
      "Epoch 5297/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8508 - accuracy: 0.5853 - val_loss: 0.9044 - val_accuracy: 0.5587\n",
      "Epoch 5298/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8523 - accuracy: 0.5814 - val_loss: 0.9045 - val_accuracy: 0.5600\n",
      "Epoch 5299/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8487 - accuracy: 0.5880 - val_loss: 0.9150 - val_accuracy: 0.5623\n",
      "Epoch 5300/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8526 - accuracy: 0.5906 - val_loss: 0.9123 - val_accuracy: 0.5507\n",
      "Epoch 5301/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8510 - accuracy: 0.5868 - val_loss: 0.9007 - val_accuracy: 0.5693\n",
      "Epoch 5302/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8489 - accuracy: 0.5889 - val_loss: 0.9096 - val_accuracy: 0.5510\n",
      "Epoch 5303/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8496 - accuracy: 0.5890 - val_loss: 0.9025 - val_accuracy: 0.5643\n",
      "Epoch 5304/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8517 - accuracy: 0.5848 - val_loss: 0.9042 - val_accuracy: 0.5590\n",
      "Epoch 5305/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8504 - accuracy: 0.5871 - val_loss: 0.9311 - val_accuracy: 0.5297\n",
      "Epoch 5306/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8464 - accuracy: 0.5914 - val_loss: 0.9394 - val_accuracy: 0.5333\n",
      "Epoch 5307/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8520 - accuracy: 0.5856 - val_loss: 0.9155 - val_accuracy: 0.5457\n",
      "Epoch 5308/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8476 - accuracy: 0.5946 - val_loss: 0.9041 - val_accuracy: 0.5580\n",
      "Epoch 5309/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8494 - accuracy: 0.5924 - val_loss: 0.9084 - val_accuracy: 0.5573\n",
      "Epoch 5310/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8503 - accuracy: 0.5895 - val_loss: 0.9839 - val_accuracy: 0.5050\n",
      "Epoch 5311/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8495 - accuracy: 0.5867 - val_loss: 0.9052 - val_accuracy: 0.5623\n",
      "Epoch 5312/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8492 - accuracy: 0.5851 - val_loss: 0.9041 - val_accuracy: 0.5633\n",
      "Epoch 5313/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8485 - accuracy: 0.5848 - val_loss: 0.9114 - val_accuracy: 0.5520\n",
      "Epoch 5314/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8491 - accuracy: 0.5872 - val_loss: 0.9052 - val_accuracy: 0.5560\n",
      "Epoch 5315/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8509 - accuracy: 0.5879 - val_loss: 0.9336 - val_accuracy: 0.5287\n",
      "Epoch 5316/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8514 - accuracy: 0.5871 - val_loss: 0.9216 - val_accuracy: 0.5323\n",
      "Epoch 5317/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8498 - accuracy: 0.5897 - val_loss: 0.9386 - val_accuracy: 0.5307\n",
      "Epoch 5318/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8490 - accuracy: 0.5924 - val_loss: 0.9017 - val_accuracy: 0.5663\n",
      "Epoch 5319/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8494 - accuracy: 0.5877 - val_loss: 0.9033 - val_accuracy: 0.5607\n",
      "Epoch 5320/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8500 - accuracy: 0.5896 - val_loss: 0.9005 - val_accuracy: 0.5633\n",
      "Epoch 5321/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8507 - accuracy: 0.5884 - val_loss: 0.9006 - val_accuracy: 0.5663\n",
      "Epoch 5322/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8488 - accuracy: 0.5918 - val_loss: 0.8998 - val_accuracy: 0.5643\n",
      "Epoch 5323/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8526 - accuracy: 0.5854 - val_loss: 0.9076 - val_accuracy: 0.5527\n",
      "Epoch 5324/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8505 - accuracy: 0.5849 - val_loss: 0.9009 - val_accuracy: 0.5647\n",
      "Epoch 5325/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8489 - accuracy: 0.5899 - val_loss: 0.9002 - val_accuracy: 0.5653\n",
      "Epoch 5326/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8484 - accuracy: 0.5881 - val_loss: 0.9163 - val_accuracy: 0.5523\n",
      "Epoch 5327/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8505 - accuracy: 0.5882 - val_loss: 0.9002 - val_accuracy: 0.5677\n",
      "Epoch 5328/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8495 - accuracy: 0.5892 - val_loss: 0.9241 - val_accuracy: 0.5537\n",
      "Epoch 5329/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8515 - accuracy: 0.5879 - val_loss: 0.9169 - val_accuracy: 0.5457\n",
      "Epoch 5330/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8480 - accuracy: 0.5914 - val_loss: 0.9138 - val_accuracy: 0.5480\n",
      "Epoch 5331/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8515 - accuracy: 0.5853 - val_loss: 0.9360 - val_accuracy: 0.5343\n",
      "Epoch 5332/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8491 - accuracy: 0.5916 - val_loss: 0.9032 - val_accuracy: 0.5597\n",
      "Epoch 5333/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8535 - accuracy: 0.5865 - val_loss: 0.9000 - val_accuracy: 0.5663\n",
      "Epoch 5334/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8499 - accuracy: 0.5888 - val_loss: 0.9137 - val_accuracy: 0.5487\n",
      "Epoch 5335/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8503 - accuracy: 0.5896 - val_loss: 0.9053 - val_accuracy: 0.5570\n",
      "Epoch 5336/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8456 - accuracy: 0.5938 - val_loss: 0.9061 - val_accuracy: 0.5607\n",
      "Epoch 5337/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8501 - accuracy: 0.5906 - val_loss: 0.9003 - val_accuracy: 0.5650\n",
      "Epoch 5338/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8520 - accuracy: 0.5851 - val_loss: 0.9175 - val_accuracy: 0.5413\n",
      "Epoch 5339/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8518 - accuracy: 0.5889 - val_loss: 0.9009 - val_accuracy: 0.5673\n",
      "Epoch 5340/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8494 - accuracy: 0.5916 - val_loss: 0.9254 - val_accuracy: 0.5367\n",
      "Epoch 5341/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8526 - accuracy: 0.5866 - val_loss: 0.9126 - val_accuracy: 0.5533\n",
      "Epoch 5342/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8483 - accuracy: 0.5934 - val_loss: 0.9027 - val_accuracy: 0.5660\n",
      "Epoch 5343/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8485 - accuracy: 0.5912 - val_loss: 0.9040 - val_accuracy: 0.5610\n",
      "Epoch 5344/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8500 - accuracy: 0.5892 - val_loss: 0.9151 - val_accuracy: 0.5470\n",
      "Epoch 5345/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8495 - accuracy: 0.5906 - val_loss: 0.9365 - val_accuracy: 0.5197\n",
      "Epoch 5346/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8495 - accuracy: 0.5881 - val_loss: 0.9027 - val_accuracy: 0.5630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5347/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8501 - accuracy: 0.5891 - val_loss: 0.9095 - val_accuracy: 0.5477\n",
      "Epoch 5348/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8490 - accuracy: 0.5892 - val_loss: 0.9205 - val_accuracy: 0.5380\n",
      "Epoch 5349/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8476 - accuracy: 0.5912 - val_loss: 0.9103 - val_accuracy: 0.5550\n",
      "Epoch 5350/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8497 - accuracy: 0.5854 - val_loss: 0.9115 - val_accuracy: 0.5587\n",
      "Epoch 5351/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8490 - accuracy: 0.5885 - val_loss: 0.9113 - val_accuracy: 0.5500\n",
      "Epoch 5352/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8485 - accuracy: 0.5876 - val_loss: 0.9031 - val_accuracy: 0.5600\n",
      "Epoch 5353/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8498 - accuracy: 0.5847 - val_loss: 0.9026 - val_accuracy: 0.5613\n",
      "Epoch 5354/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8512 - accuracy: 0.5894 - val_loss: 0.9035 - val_accuracy: 0.5583\n",
      "Epoch 5355/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8511 - accuracy: 0.5869 - val_loss: 0.9031 - val_accuracy: 0.5557\n",
      "Epoch 5356/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8483 - accuracy: 0.5898 - val_loss: 0.9067 - val_accuracy: 0.5533\n",
      "Epoch 5357/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8531 - accuracy: 0.5849 - val_loss: 0.9108 - val_accuracy: 0.5520\n",
      "Epoch 5358/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8488 - accuracy: 0.5904 - val_loss: 0.9128 - val_accuracy: 0.5460\n",
      "Epoch 5359/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8471 - accuracy: 0.5923 - val_loss: 0.9093 - val_accuracy: 0.5593\n",
      "Epoch 5360/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8500 - accuracy: 0.5903 - val_loss: 0.9064 - val_accuracy: 0.5493\n",
      "Epoch 5361/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8499 - accuracy: 0.5874 - val_loss: 0.9212 - val_accuracy: 0.5513\n",
      "Epoch 5362/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8463 - accuracy: 0.5896 - val_loss: 0.9082 - val_accuracy: 0.5533\n",
      "Epoch 5363/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8471 - accuracy: 0.5866 - val_loss: 0.9353 - val_accuracy: 0.5360\n",
      "Epoch 5364/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8495 - accuracy: 0.5906 - val_loss: 0.9056 - val_accuracy: 0.5553\n",
      "Epoch 5365/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8502 - accuracy: 0.5882 - val_loss: 0.9120 - val_accuracy: 0.5487\n",
      "Epoch 5366/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8486 - accuracy: 0.5869 - val_loss: 0.9389 - val_accuracy: 0.5363\n",
      "Epoch 5367/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8472 - accuracy: 0.5908 - val_loss: 0.9072 - val_accuracy: 0.5633\n",
      "Epoch 5368/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8505 - accuracy: 0.5914 - val_loss: 0.9205 - val_accuracy: 0.5367\n",
      "Epoch 5369/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8518 - accuracy: 0.5874 - val_loss: 0.9022 - val_accuracy: 0.5570\n",
      "Epoch 5370/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8470 - accuracy: 0.5891 - val_loss: 0.9121 - val_accuracy: 0.5553\n",
      "Epoch 5371/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8499 - accuracy: 0.5866 - val_loss: 0.9111 - val_accuracy: 0.5583\n",
      "Epoch 5372/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8498 - accuracy: 0.5899 - val_loss: 0.9183 - val_accuracy: 0.5530\n",
      "Epoch 5373/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8480 - accuracy: 0.5908 - val_loss: 0.9034 - val_accuracy: 0.5580\n",
      "Epoch 5374/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8477 - accuracy: 0.5890 - val_loss: 0.9297 - val_accuracy: 0.5353\n",
      "Epoch 5375/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8496 - accuracy: 0.5841 - val_loss: 0.9162 - val_accuracy: 0.5443\n",
      "Epoch 5376/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8495 - accuracy: 0.5911 - val_loss: 0.9029 - val_accuracy: 0.5580\n",
      "Epoch 5377/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8488 - accuracy: 0.5902 - val_loss: 0.9275 - val_accuracy: 0.5350\n",
      "Epoch 5378/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8490 - accuracy: 0.5878 - val_loss: 0.9021 - val_accuracy: 0.5680\n",
      "Epoch 5379/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8488 - accuracy: 0.5897 - val_loss: 0.8996 - val_accuracy: 0.5653\n",
      "Epoch 5380/5500\n",
      "14000/14000 [==============================] - 0s 23us/step - loss: 0.8511 - accuracy: 0.5846 - val_loss: 0.9027 - val_accuracy: 0.5577\n",
      "Epoch 5381/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8507 - accuracy: 0.5885 - val_loss: 0.9013 - val_accuracy: 0.5587\n",
      "Epoch 5382/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8504 - accuracy: 0.5925 - val_loss: 0.9100 - val_accuracy: 0.5563\n",
      "Epoch 5383/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8492 - accuracy: 0.5888 - val_loss: 0.9028 - val_accuracy: 0.5547\n",
      "Epoch 5384/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8488 - accuracy: 0.5881 - val_loss: 0.9633 - val_accuracy: 0.5250\n",
      "Epoch 5385/5500\n",
      "14000/14000 [==============================] - 0s 26us/step - loss: 0.8489 - accuracy: 0.5865 - val_loss: 0.9169 - val_accuracy: 0.5363\n",
      "Epoch 5386/5500\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.8493 - accuracy: 0.5909 - val_loss: 0.9180 - val_accuracy: 0.5423\n",
      "Epoch 5387/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8485 - accuracy: 0.5859 - val_loss: 0.9293 - val_accuracy: 0.5310\n",
      "Epoch 5388/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8502 - accuracy: 0.5865 - val_loss: 0.9254 - val_accuracy: 0.5397\n",
      "Epoch 5389/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8497 - accuracy: 0.5894 - val_loss: 0.9874 - val_accuracy: 0.5070\n",
      "Epoch 5390/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8482 - accuracy: 0.5909 - val_loss: 0.9072 - val_accuracy: 0.5543\n",
      "Epoch 5391/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8480 - accuracy: 0.5940 - val_loss: 0.9383 - val_accuracy: 0.5297\n",
      "Epoch 5392/5500\n",
      "14000/14000 [==============================] - 0s 17us/step - loss: 0.8478 - accuracy: 0.5858 - val_loss: 0.9021 - val_accuracy: 0.5600\n",
      "Epoch 5393/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8478 - accuracy: 0.5889 - val_loss: 0.9090 - val_accuracy: 0.5627\n",
      "Epoch 5394/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8477 - accuracy: 0.5883 - val_loss: 0.9006 - val_accuracy: 0.5677\n",
      "Epoch 5395/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8491 - accuracy: 0.5880 - val_loss: 0.9018 - val_accuracy: 0.5613\n",
      "Epoch 5396/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8530 - accuracy: 0.5844 - val_loss: 0.9070 - val_accuracy: 0.5607\n",
      "Epoch 5397/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8515 - accuracy: 0.5878 - val_loss: 0.9371 - val_accuracy: 0.5310\n",
      "Epoch 5398/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8527 - accuracy: 0.5877 - val_loss: 0.9092 - val_accuracy: 0.5537\n",
      "Epoch 5399/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8481 - accuracy: 0.5874 - val_loss: 0.8993 - val_accuracy: 0.5690\n",
      "Epoch 5400/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8497 - accuracy: 0.5876 - val_loss: 0.9063 - val_accuracy: 0.5597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5401/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8495 - accuracy: 0.5917 - val_loss: 0.9020 - val_accuracy: 0.5603\n",
      "Epoch 5402/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8505 - accuracy: 0.5864 - val_loss: 0.9224 - val_accuracy: 0.5477\n",
      "Epoch 5403/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8452 - accuracy: 0.5926 - val_loss: 0.9009 - val_accuracy: 0.5687\n",
      "Epoch 5404/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8482 - accuracy: 0.5862 - val_loss: 0.9673 - val_accuracy: 0.5240\n",
      "Epoch 5405/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8494 - accuracy: 0.5914 - val_loss: 0.9136 - val_accuracy: 0.5607\n",
      "Epoch 5406/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8477 - accuracy: 0.5891 - val_loss: 0.9147 - val_accuracy: 0.5437\n",
      "Epoch 5407/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8500 - accuracy: 0.5904 - val_loss: 0.9067 - val_accuracy: 0.5527\n",
      "Epoch 5408/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8488 - accuracy: 0.5895 - val_loss: 0.9106 - val_accuracy: 0.5477\n",
      "Epoch 5409/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8479 - accuracy: 0.5906 - val_loss: 0.9325 - val_accuracy: 0.5360\n",
      "Epoch 5410/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8483 - accuracy: 0.5886 - val_loss: 0.9017 - val_accuracy: 0.5670\n",
      "Epoch 5411/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8504 - accuracy: 0.5860 - val_loss: 0.9260 - val_accuracy: 0.5330\n",
      "Epoch 5412/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8457 - accuracy: 0.5944 - val_loss: 0.9035 - val_accuracy: 0.5607\n",
      "Epoch 5413/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8471 - accuracy: 0.5931 - val_loss: 0.9099 - val_accuracy: 0.5523\n",
      "Epoch 5414/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8484 - accuracy: 0.5904 - val_loss: 0.9072 - val_accuracy: 0.5490\n",
      "Epoch 5415/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8483 - accuracy: 0.5891 - val_loss: 0.9837 - val_accuracy: 0.5080\n",
      "Epoch 5416/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8455 - accuracy: 0.5951 - val_loss: 0.9014 - val_accuracy: 0.5680\n",
      "Epoch 5417/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8485 - accuracy: 0.5911 - val_loss: 0.9002 - val_accuracy: 0.5657\n",
      "Epoch 5418/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8507 - accuracy: 0.5866 - val_loss: 0.9012 - val_accuracy: 0.5633\n",
      "Epoch 5419/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8519 - accuracy: 0.5829 - val_loss: 0.9205 - val_accuracy: 0.5380\n",
      "Epoch 5420/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8476 - accuracy: 0.5940 - val_loss: 0.9311 - val_accuracy: 0.5390\n",
      "Epoch 5421/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8472 - accuracy: 0.5881 - val_loss: 0.9071 - val_accuracy: 0.5540\n",
      "Epoch 5422/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8508 - accuracy: 0.5844 - val_loss: 0.9054 - val_accuracy: 0.5603\n",
      "Epoch 5423/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8473 - accuracy: 0.5928 - val_loss: 0.9565 - val_accuracy: 0.5253\n",
      "Epoch 5424/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8503 - accuracy: 0.5843 - val_loss: 0.9021 - val_accuracy: 0.5607\n",
      "Epoch 5425/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8481 - accuracy: 0.5887 - val_loss: 0.9060 - val_accuracy: 0.5620\n",
      "Epoch 5426/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8478 - accuracy: 0.5935 - val_loss: 0.9390 - val_accuracy: 0.5263\n",
      "Epoch 5427/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8483 - accuracy: 0.5919 - val_loss: 0.9057 - val_accuracy: 0.5570\n",
      "Epoch 5428/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8498 - accuracy: 0.5891 - val_loss: 0.9028 - val_accuracy: 0.5610\n",
      "Epoch 5429/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8485 - accuracy: 0.5900 - val_loss: 0.9063 - val_accuracy: 0.5590\n",
      "Epoch 5430/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8499 - accuracy: 0.5852 - val_loss: 0.9446 - val_accuracy: 0.5280\n",
      "Epoch 5431/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8473 - accuracy: 0.5924 - val_loss: 0.9081 - val_accuracy: 0.5563\n",
      "Epoch 5432/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8474 - accuracy: 0.5893 - val_loss: 0.9002 - val_accuracy: 0.5633\n",
      "Epoch 5433/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8462 - accuracy: 0.5917 - val_loss: 0.9118 - val_accuracy: 0.5507\n",
      "Epoch 5434/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8463 - accuracy: 0.5904 - val_loss: 0.9066 - val_accuracy: 0.5570\n",
      "Epoch 5435/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8510 - accuracy: 0.5798 - val_loss: 0.9048 - val_accuracy: 0.5587\n",
      "Epoch 5436/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8492 - accuracy: 0.5858 - val_loss: 0.9111 - val_accuracy: 0.5533\n",
      "Epoch 5437/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8498 - accuracy: 0.5906 - val_loss: 0.9055 - val_accuracy: 0.5640\n",
      "Epoch 5438/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8477 - accuracy: 0.5919 - val_loss: 0.9175 - val_accuracy: 0.5657\n",
      "Epoch 5439/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8486 - accuracy: 0.5920 - val_loss: 0.8998 - val_accuracy: 0.5607\n",
      "Epoch 5440/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8475 - accuracy: 0.5879 - val_loss: 0.9141 - val_accuracy: 0.5457\n",
      "Epoch 5441/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8471 - accuracy: 0.5905 - val_loss: 0.9038 - val_accuracy: 0.5597\n",
      "Epoch 5442/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8484 - accuracy: 0.5854 - val_loss: 0.9447 - val_accuracy: 0.5320\n",
      "Epoch 5443/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8484 - accuracy: 0.5881 - val_loss: 0.9063 - val_accuracy: 0.5590\n",
      "Epoch 5444/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8464 - accuracy: 0.5912 - val_loss: 0.9280 - val_accuracy: 0.5323\n",
      "Epoch 5445/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8473 - accuracy: 0.5915 - val_loss: 0.9033 - val_accuracy: 0.5660\n",
      "Epoch 5446/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8479 - accuracy: 0.5856 - val_loss: 0.9453 - val_accuracy: 0.5287\n",
      "Epoch 5447/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8477 - accuracy: 0.5900 - val_loss: 0.9277 - val_accuracy: 0.5363\n",
      "Epoch 5448/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8466 - accuracy: 0.5900 - val_loss: 0.9020 - val_accuracy: 0.5660\n",
      "Epoch 5449/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8484 - accuracy: 0.5890 - val_loss: 0.9138 - val_accuracy: 0.5447\n",
      "Epoch 5450/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8457 - accuracy: 0.5944 - val_loss: 0.9247 - val_accuracy: 0.5390\n",
      "Epoch 5451/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8482 - accuracy: 0.5907 - val_loss: 0.9137 - val_accuracy: 0.5457\n",
      "Epoch 5452/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8493 - accuracy: 0.5875 - val_loss: 0.9126 - val_accuracy: 0.5483\n",
      "Epoch 5453/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8489 - accuracy: 0.5885 - val_loss: 0.9080 - val_accuracy: 0.5493\n",
      "Epoch 5454/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8538 - accuracy: 0.5855 - val_loss: 0.9077 - val_accuracy: 0.5523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5455/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8519 - accuracy: 0.5862 - val_loss: 0.9042 - val_accuracy: 0.5620\n",
      "Epoch 5456/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8503 - accuracy: 0.5854 - val_loss: 0.9067 - val_accuracy: 0.5577\n",
      "Epoch 5457/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8493 - accuracy: 0.5906 - val_loss: 0.9000 - val_accuracy: 0.5650\n",
      "Epoch 5458/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8472 - accuracy: 0.5910 - val_loss: 0.9141 - val_accuracy: 0.5523\n",
      "Epoch 5459/5500\n",
      "14000/14000 [==============================] - 0s 17us/step - loss: 0.8457 - accuracy: 0.5909 - val_loss: 0.9118 - val_accuracy: 0.5553\n",
      "Epoch 5460/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8507 - accuracy: 0.5885 - val_loss: 0.9370 - val_accuracy: 0.5230\n",
      "Epoch 5461/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8477 - accuracy: 0.5895 - val_loss: 0.9082 - val_accuracy: 0.5527\n",
      "Epoch 5462/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8481 - accuracy: 0.5914 - val_loss: 0.9081 - val_accuracy: 0.5560\n",
      "Epoch 5463/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8523 - accuracy: 0.5869 - val_loss: 0.9021 - val_accuracy: 0.5603\n",
      "Epoch 5464/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8483 - accuracy: 0.5894 - val_loss: 0.9057 - val_accuracy: 0.5537\n",
      "Epoch 5465/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8460 - accuracy: 0.5911 - val_loss: 0.9006 - val_accuracy: 0.5653\n",
      "Epoch 5466/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8462 - accuracy: 0.5907 - val_loss: 0.9092 - val_accuracy: 0.5577\n",
      "Epoch 5467/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8484 - accuracy: 0.5863 - val_loss: 0.9053 - val_accuracy: 0.5580\n",
      "Epoch 5468/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8467 - accuracy: 0.5885 - val_loss: 0.9087 - val_accuracy: 0.5490\n",
      "Epoch 5469/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8463 - accuracy: 0.5938 - val_loss: 0.9113 - val_accuracy: 0.5590\n",
      "Epoch 5470/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8478 - accuracy: 0.5934 - val_loss: 0.9207 - val_accuracy: 0.5413\n",
      "Epoch 5471/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8470 - accuracy: 0.5882 - val_loss: 0.9167 - val_accuracy: 0.5390\n",
      "Epoch 5472/5500\n",
      "14000/14000 [==============================] - 0s 20us/step - loss: 0.8466 - accuracy: 0.5890 - val_loss: 0.9037 - val_accuracy: 0.5617\n",
      "Epoch 5473/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8478 - accuracy: 0.5902 - val_loss: 0.9236 - val_accuracy: 0.5400\n",
      "Epoch 5474/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8482 - accuracy: 0.5854 - val_loss: 0.9555 - val_accuracy: 0.5193\n",
      "Epoch 5475/5500\n",
      "14000/14000 [==============================] - 0s 21us/step - loss: 0.8500 - accuracy: 0.5886 - val_loss: 0.9421 - val_accuracy: 0.5243\n",
      "Epoch 5476/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8465 - accuracy: 0.5927 - val_loss: 0.9032 - val_accuracy: 0.5597\n",
      "Epoch 5477/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8479 - accuracy: 0.5920 - val_loss: 0.9240 - val_accuracy: 0.5403\n",
      "Epoch 5478/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8462 - accuracy: 0.5901 - val_loss: 0.9147 - val_accuracy: 0.5463\n",
      "Epoch 5479/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8499 - accuracy: 0.5871 - val_loss: 0.9141 - val_accuracy: 0.5470\n",
      "Epoch 5480/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8451 - accuracy: 0.5889 - val_loss: 0.9005 - val_accuracy: 0.5693\n",
      "Epoch 5481/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8483 - accuracy: 0.5891 - val_loss: 0.9267 - val_accuracy: 0.5380\n",
      "Epoch 5482/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8507 - accuracy: 0.5880 - val_loss: 0.9071 - val_accuracy: 0.5620\n",
      "Epoch 5483/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8477 - accuracy: 0.5881 - val_loss: 0.9210 - val_accuracy: 0.5477\n",
      "Epoch 5484/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8466 - accuracy: 0.5933 - val_loss: 0.9157 - val_accuracy: 0.5520\n",
      "Epoch 5485/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8479 - accuracy: 0.5864 - val_loss: 0.9016 - val_accuracy: 0.5607\n",
      "Epoch 5486/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8497 - accuracy: 0.5830 - val_loss: 0.9097 - val_accuracy: 0.5613\n",
      "Epoch 5487/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8451 - accuracy: 0.5911 - val_loss: 0.9151 - val_accuracy: 0.5440\n",
      "Epoch 5488/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8489 - accuracy: 0.5926 - val_loss: 0.9108 - val_accuracy: 0.5537\n",
      "Epoch 5489/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8464 - accuracy: 0.5925 - val_loss: 0.9103 - val_accuracy: 0.5537\n",
      "Epoch 5490/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8449 - accuracy: 0.5934 - val_loss: 0.9002 - val_accuracy: 0.5660\n",
      "Epoch 5491/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8474 - accuracy: 0.5886 - val_loss: 0.9550 - val_accuracy: 0.5103\n",
      "Epoch 5492/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8491 - accuracy: 0.5926 - val_loss: 0.9100 - val_accuracy: 0.5603\n",
      "Epoch 5493/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8453 - accuracy: 0.5898 - val_loss: 0.9041 - val_accuracy: 0.5573\n",
      "Epoch 5494/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8470 - accuracy: 0.5896 - val_loss: 0.9021 - val_accuracy: 0.5600\n",
      "Epoch 5495/5500\n",
      "14000/14000 [==============================] - 0s 22us/step - loss: 0.8462 - accuracy: 0.5879 - val_loss: 0.9081 - val_accuracy: 0.5617\n",
      "Epoch 5496/5500\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.8502 - accuracy: 0.5858 - val_loss: 0.9017 - val_accuracy: 0.5687\n",
      "Epoch 5497/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8457 - accuracy: 0.5899 - val_loss: 0.9319 - val_accuracy: 0.5310\n",
      "Epoch 5498/5500\n",
      "14000/14000 [==============================] - 0s 19us/step - loss: 0.8483 - accuracy: 0.5884 - val_loss: 0.9357 - val_accuracy: 0.5333\n",
      "Epoch 5499/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8502 - accuracy: 0.5891 - val_loss: 0.9337 - val_accuracy: 0.5250\n",
      "Epoch 5500/5500\n",
      "14000/14000 [==============================] - 0s 18us/step - loss: 0.8490 - accuracy: 0.5893 - val_loss: 1.0438 - val_accuracy: 0.5013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "analysis = model.fit(X_train, y_train, batch_size=batch_size,epochs=5500,verbose=1,validation_data=(X_valid, y_valid))\n",
    "trainTime = (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.980625597635903  minutes\n"
     ]
    }
   ],
   "source": [
    "print(trainTime/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9853634064992269\n",
      "Test accuracy: 0.5253333449363708\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])      # this is the categorical_crossentropy\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(np.round(y_pred),axis=1) # Choose the prediction with the highest probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_pred_one_hot = to_categorical(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score =  0.5079510013898016\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-Score = \", f1_score(y_test, y_pred_one_hot, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABssAAAJOCAYAAADxrDkyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VPW9//H3hwSISUQh0WpdAq1aFwTEiLW4g4hcr7a2VSlYhGIqWOu123XpvXq9127WqrUFSy2oEEWu/qxLqV5xqXtLRMCqRamCIi4Q9p2Ez++P75zMmclMMtkIIa/n43EeM+ec7/me70xmgfOZz+dr7i4AAAAAAAAAAACgM+rS3gMAAAAAAAAAAAAA2gvBMgAAAAAAAAAAAHRaBMsAAAAAAAAAAADQaREsAwAAAAAAAAAAQKdFsAwAAAAAAAAAAACdFsEyAAAAAAAAAAAAdFoEywAAAADsVGaWZ2YbzOzg1mzbnszsEDPzNuh3qJktia0vMrOTcmnbjHPdaWbXNPd4AAAAAOio8tt7AAAAAAB2bWa2IbZaKGmrpNrE+rfdvbIp/bl7raTi1m7bGbj7F1qjHzMbL2m0u58a63t8a/QNAAAAAB0NwTIAAAAADXL3umBVInNpvLvPydbezPLdvWZnjA1oDK9HAAAAAI2hDCMAAACAFjGz/zGz+83sPjNbL2m0mZ1gZq+Y2Roz+8jMfm1mXRPt883Mzax3Yn1GYv+fzWy9mb1sZn2a2jax/ywze9vM1prZ7Wb2opldnGXcuYzx22a22MxWm9mvY8fmmdktZlZtZv+UNLyB5+fHZjYzbdtvzexXifvjzeytxOP5ZyLrK1tfy8zs1MT9QjObnhjbG5KOzXDedxP9vmFm5yS2Hy3pN5JOSpS4XBl7bq+PHX9p4rFXm9kfzWz/XJ6bpjzP0XjMbI6ZrTKzj83sR7Hz/EfiOVlnZlVm9tlMJS/N7IXo75x4Pp9LnGeVpB+b2aFm9kzisaxMPG97xY4vSzzGFYn9t5lZQWLMR8Ta7W9mm8ysJNvjBQAAANDxECwDAAAA0Bq+IuleSXtJul9SjaQrJJVKGqwQTPp2A8d/Q9J/SOol6X1J/93Utma2r6RZkn6YOO97kgY10E8uYxyhEIQ6RiEIODSxfYKkYZL6J85xfgPnuVfS2WZWlBhnvqSvJ7ZL0ieS/kVSD0mXSLrdzPo10F/kBkkHSfpcYpxj0va/nXhce0m6UdK9ZvYZd39d0nckPe/uxe5emt6xmQ1L9P81SQdIWi4pvdxmtucmXdbnORGwmiPpUUn7SzpM0rOJ436YOP9wSXtLGi9pS0NPSMyXJL0laR9JP5dkkv4ncY4jFZ6z/0iMIV/SnyQtltRb4Tmd5e5bFF5Po2P9fkPSE+5eneM4AAAAAHQABMsAAAAAtIYX3P1Rd9/h7pvdfa67/9Xda9z9XUlTJJ3SwPEPuHuVu29XCMoMaEbbsyXNd/eHE/tukbQyWyc5jvGn7r7W3ZcoBHGic50v6RZ3X5YInPysgfO8K+nvks5NbDpD0hp3r0rsf9Td3/XgaUlPSTqpgccfOV/S/7j7andfqpAtFj/vLHf/KPE3uVfSEknlOfQrSaMk3enu8xNBo6sknWJmB8baZHtuUjTyPJ8j6QN3v83dt7r7Onf/W2LfeEnXuPs7iccw391X5Tj+9919srvXJl6Pb7v7U+6+zd0/VXhtRGM4QSGQ9+/uvjHR/sXEvrslfcPMLLF+kaTpOY4BAAAAQAdBsAwAAABAa/ggvmJmh5vZnxJl9dYpZCnVy2CK+Th2f5Ok4mwNG2j72fg43N0lLcvWSY5jzOlckpY2MF4pZJGNTNz/hmJZWmZ2tpn9NVGGcI1CxlpDz1Vk/4bGYGYXm9mCRCnBNZIOz7FfKTy+uv7cfZ2k1QpZZpGc/maNPM8HKWR0ZXKQpH/mON506a/H/cxslpl9mBjDXWljWOLutemdJIJmNZJONLO+kg5WyEIDAAAAsBshWAYAAACgNXja+u8UsqkOcfcekv5ToRReW/pIUl3mUyIb6IDszVs0xo8UgiyRgxtpf7+koYnMrHOVKMFoZntIekDSTyV9xt33lvR/OY7j42xjMLPPSZqsUC6yJNHvP2L9pv+90i2XVBbrb09JPSV9mMO40jX0PH8g6fNZjsu2b2NiTIWxbfultUl/fD+XtFXS0YkxXJw2hjIzy8syjnsUSjFepFCecWuWdgAAAAA6KIJlAAAAANrCnpLWStpoZkeo4fnKWstjkgaa2b8m5qG6QmHOqrYY4yxJ/2ZmB5hZiaR/b6ixu38i6QVJ0yQtcvd3Eru6S+omaYWkWjM7W9KQJozhGjPb28wOVpiHLFKsEDBaoRA3HK+QWRb5RNKBZtY1S9/3SfqWmfUzs+4Kwbzn3T1rpl4DGnqeH5F0sJl9x8y6mVkPM4vmmbtT0v+Y2ectGGBmvRSChB8rzJOWZ2YVigX2GhjDRklrzewgST+I7XtZUrWkn5hZoZntYWaDY/unK8yd9g2FwBkAAACA3QzBMgAAAABt4fuSxkhar5BZdH9bnzARkLpA0q8Ugh+fl/SaQkZRa49xssLcYq9LmquQHdaYeyUNTdxGY14j6UpJD0lapRCUeSzHMVynkOG2RNKfFQvkuPtCSb+W9LdEm8Ml/TV27JOS3pH0iZnFyylGxz+uUC7xocTxByvMY9YcWZ9nd1+rMIfbVyV9KultJecSu0nSHxWe53UKc50VJMprXiLpGoU56Q5Je2yZXCdpkELQ7hFJD8bGUKMw390RCllm7yv8HaL9SxT+ztvc/aUmPnYAAAAAHYCF/2cAAAAAwO4lUVZvuaSvufvz7T0edFxmdo+kd939+vYeCwAAAIDWl9/eAwAAAACA1mJmwxXK6m2RdLWkGoXsKqBZEvO/nSvp6PYeCwAAAIC20aIyjGY23MwWmdliM7sqw/6DzewZM3vNzBaa2YjYvqsTxy0yszNbMg4AAAAASDhR0rsK5fmGS/qyu2crwwg0yMx+KmmBpJ+4+/vtPR4AAAAAbaPZZRgTJU3eVqgvv0yhTv9Id38z1maKpNfcfbKZHSlptrv3Tty/T6Fm/GclzZF0mLvXtujRAAAAAAAAAAAAAE3QksyyQZIWu/u77r5N0kyF0hRxLqlH4v5eCvMFKNFuprtvdff3JC1O9AcAAAAAAAAAAADsNC2Zs+wASR/E1pdJOj6tzfWS/s/MLpdUJGlo7NhX0o49INNJzKxCUoUkFRUVHXv44Ye3YMgAAAAAAAAAAADoiF599dWV7r5Pa/fbkmCZZdiWXtNxpKS73P1mMztB0nQz65vjsWGj+xRJUySpvLzcq6qqWjBkAAAAAAAAAAAAdERmtrQt+m1JsGyZpINi6wcqWWYx8i2FSbXl7i+bWYGk0hyPBQAAAAAAAAAAANpUS+YsmyvpUDPrY2bdJF0o6ZG0Nu9LGiJJZnaEpAJJKxLtLjSz7mbWR9Khkv7WgrEAAAAAAAAAAAAATdbszDJ3rzGz70h6QlKepKnu/oaZ3SCpyt0fkfR9Sb83sysVyixe7O4u6Q0zmyXpTUk1ki5z99qWPhgAAAAAAAAAAACgKSzErjoG5iwDAAAAAAAAAGD3sX37di1btkxbtmxp76FgF1JQUKADDzxQXbt2TdluZq+6e3lrn68lc5YBAAAAAAAAAAA027Jly7Tnnnuqd+/eMrP2Hg52Ae6u6upqLVu2TH369Nkp52zJnGUAAAAAAAAAAADNtmXLFpWUlBAoQx0zU0lJyU7NNiRYBgAAAAAAAAAA2g2BMqTb2a8JgmUAAAAAAAAAAADotAiWAQAAAAAAAACATqm6uloDBgzQgAEDtN9+++mAAw6oW9+2bVtOfYwdO1aLFi1qsM1vf/tbVVZWtsaQ0Qby23sAAAAAAAAAAAAAuaislK69Vnr/fengg6Ubb5RGjWp+fyUlJZo/f74k6frrr1dxcbF+8IMfpLRxd7m7unTJnH80bdq0Rs9z2WWXNX+Q7aSmpkb5+Z0jjERmGQAAAAAAAAAA2OVVVkoVFdLSpZJ7uK2oCNtb2+LFi9W3b19deumlGjhwoD766CNVVFSovLxcRx11lG644Ya6tieeeKLmz5+vmpoa7b333rrqqqvUv39/nXDCCfr0008lST/+8Y9166231rW/6qqrNGjQIH3hC1/QSy+9JEnauHGjvvrVr6p///4aOXKkysvL6wJ5cdddd52OO+64uvG5uyTp7bff1umnn67+/ftr4MCBWrJkiSTpJz/5iY4++mj1799f1157bcqYJenjjz/WIYccIkm68847deGFF+rss8/WWWedpXXr1un000/XwIED1a9fPz322GN145g2bZr69eun/v37a+zYsVqzZo0+97nPqaamRpK0Zs0a9enTR7W1ta32d2krBMsAAAAAAAAAAMAu79prpU2bUrdt2hS2t4U333xT3/rWt/Taa6/pgAMO0M9+9jNVVVVpwYIFevLJJ/Xmm2/WO2bt2rU65ZRTtGDBAp1wwgmaOnVqxr7dXX/7299000031QXebr/9du23335asGCBrrrqKr322msZj73iiis0d+5cvf7661q7dq0ef/xxSdLIkSN15ZVXasGCBXrppZe077776tFHH9Wf//xn/e1vf9OCBQv0/e9/v9HH/fLLL2v69Ol68skntccee+jhhx/WvHnzNGfOHF155ZWSpAULFujnP/+5nn32WS1YsEA333yz9t57bw0ePLhuPPfee6/OP/985eXlNf5ktzOCZQAAAAAAAAAAYJf3/vtN295Sn//853XcccfVrd93330aOHCgBg4cqLfeeitjsGyPPfbQWWedJUk69thj67K70p133nn12rzwwgu68MILJUn9+/fXUUcdlfHYp556SoMGDVL//v31l7/8RW+88YZWr16tlStX6l//9V8lSQUFBSosLNScOXM0btw47bHHHpKkXr16Nfq4hw0bpp49e0oKQb1///d/V79+/TRs2DB98MEHWrlypZ5++mldcMEFdf1Ft+PHj68rSzlt2jSNHTu20fPtCgiWAQAAAAAAAACAXd7BBzdte0sVFRXV3X/nnXd022236emnn9bChQs1fPhwbdmypd4x3bp1q7ufl5dXV5IwXffu3eu1icopNmTTpk36zne+o4ceekgLFy7UuHHj6sZhZvXau3vG7fn5+dqxY4ck1Xsc8cd9zz33aO3atZo3b57mz5+v0tJSbdmyJWu/p5xyit5++20988wz6tq1qw4//PBGH9OugGAZAAAAAAAAAADY5d14o1RYmLqtsDBsb2vr1q3TnnvuqR49euijjz7SE0880ernOPHEEzVr1ixJ0uuvv54xc23z5s3q0qWLSktLtX79ej344IOSpJ49e6q0tFSPPvqopBAA27Rpk4YNG6Y//OEP2rx5syRp1apVkqTevXvr1VdflSQ98MADWce0du1a7bvvvsrPz9eTTz6pDz/8UJI0dOhQzZw5s66/6FaSRo8erVGjRnWYrDKJYBkAAAAAAAAAAOgARo2SpkyRysoks3A7ZUrY3tYGDhyoI488Un379tUll1yiwYMHt/o5Lr/8cn344Yfq16+fbr75ZvXt21d77bVXSpuSkhKNGTNGffv21Ve+8hUdf/zxdfsqKyt18803q1+/fjrxxBO1YsUKnX322Ro+fLjKy8s1YMAA3XLLLZKkH/7wh7rtttv0pS99SatXr846posuukgvvfSSysvL9b//+7869NBDJUn9+vXTj370I5188skaMGCAfvjDH9YdM2rUKK1du1YXXHBBaz49bcpySevbVZSXl3tVVVV7DwMAAAAAAAAAALSCt956S0cccUR7D2OXUFNTo5qaGhUUFOidd97RsGHD9M477yg/P7+9h9YkM2fO1BNPPFE3d1lzZXptmNmr7l7eoo4z6FjPMAAAAAAAAAAAwG5ow4YNGjJkiGpqauTu+t3vftfhAmUTJkzQnDlz9Pjjj7f3UJqkYz3LAAAAAAAAAAAAu6G99967bh6xjmry5MntPYRmYc4yAAAAAAAAAAAAdFoEywAAAAAAAAAAANBpESwDAAAAAAAAAABAp0WwDAAAAAAAAAAAAJ0WwTIAAAAAAAAAANApnXrqqXriiSdStt16662aOHFig8cVFxdLkpYvX66vfe1rWfuuqqpqsJ9bb71VmzZtqlsfMWKE1qxZk8vQ0YoIlgEAAAAAAAAAgE5p5MiRmjlzZsq2mTNnauTIkTkd/9nPflYPPPBAs8+fHiybPXu29t5772b3t7O5u3bs2NHew2gxgmUAAAAAAAAAAKBT+trXvqbHHntMW7dulSQtWbJEy5cv14knnqgNGzZoyJAhGjhwoI4++mg9/PDD9Y5fsmSJ+vbtK0navHmzLrzwQvXr108XXHCBNm/eXNduwoQJKi8v11FHHaXrrrtOkvTrX/9ay5cv12mnnabTTjtNktS7d2+tXLlSkvSrX/1Kffv2Vd++fXXrrbfWne+II47QJZdcoqOOOkrDhg1LOU/k0Ucf1fHHH69jjjlGQ4cO1SeffCJJ2rBhg8aOHaujjz5a/fr104MPPihJevzxxzVw4ED1799fQ4YMkSRdf/31+uUvf1nXZ9++fbVkyZK6MUycOFEDBw7UBx98kPHxSdLcuXP1pS99Sf3799egQYO0fv16nXTSSZo/f35dm8GDB2vhwoVN+ru1tvyWHGxmwyXdJilP0p3u/rO0/bdIOi2xWihpX3ffO7GvVtLriX3vu/s5LRkLAAAAAAAAAADouP7t36RYDKVVDBggJeJMGZWUlGjQoEF6/PHHde6552rmzJm64IILZGYqKCjQQw89pB49emjlypX64he/qHPOOUdmlrGvyZMnq7CwUAsXLtTChQs1cODAun033nijevXqpdraWg0ZMkQLFy7Ud7/7Xf3qV7/SM888o9LS0pS+Xn31VU2bNk1//etf5e46/vjjdcopp6hnz5565513dN999+n3v/+9zj//fD344IMaPXp0yvEnnniiXnnlFZmZ7rzzTv3iF7/QzTffrP/+7//WXnvtpddfD+GZ1atXa8WKFbrkkkv03HPPqU+fPlq1alWjz+uiRYs0bdo0TZo0KevjO/zww3XBBRfo/vvv13HHHad169Zpjz320Pjx43XXXXfp1ltv1dtvv62tW7eqX79+jZ6zLTU7s8zM8iT9VtJZko6UNNLMjoy3cfcr3X2Auw+QdLuk/xfbvTnaR6AMAAAAAAAAAAC0h3gpxngJRnfXNddco379+mno0KH68MMP6zK0Mnnuuefqglb9+vVLCQDNmjVLAwcO1DHHHKM33nhDb775ZoNjeuGFF/SVr3xFRUVFKi4u1nnnnafnn39ektSnTx8NGDBAknTsscdqyZIl9Y5ftmyZzjzzTB199NG66aab9MYbb0iS5syZo8suu6yuXc+ePfXKK6/o5JNPVp8+fSRJvXr1anBsklRWVqYvfvGLDT6+RYsWaf/999dxxx0nSerRo4fy8/P19a9/XY899pi2b9+uqVOn6uKLL270fG2tJZllgyQtdvd3JcnMZko6V1K2v/BISddl2QcAAAAAAAAAADqxhjLA2tKXv/xlfe9739O8efO0efPmuoywyspKrVixQq+++qq6du2q3r17a8uWLQ32lSnr7L333tMvf/lLzZ07Vz179tTFF1/caD/unnVf9+7d6+7n5eVlLMN4+eWX63vf+57OOeccPfvss7r++uvr+k0fY6ZtkpSfn58yH1l8zEVFRY0+vmz9FhYW6owzztDDDz+sWbNmqaqqKutj3VlaMmfZAZI+iK0vS2yrx8zKJPWR9HRsc4GZVZnZK2b25WwnMbOKRLuqFStWtGC4AAAAAAAAAAAAqYqLi3Xqqadq3LhxdVllkrR27Vrtu+++6tq1q5555hktXbq0wX5OPvlkVVZWSpL+/ve/183DtW7dOhUVFWmvvfbSJ598oj//+c91x+y5555av359xr7++Mc/atOmTdq4caMeeughnXTSSTk/prVr1+qAA0LI5u67767bPmzYMP3mN7+pW1+9erVOOOEE/eUvf9F7770nSXVlGHv37q158+ZJkubNm1e3P122x3f44Ydr+fLlmjt3riRp/fr1qqmpkSSNHz9e3/3ud3XcccfllMnW1loSLMtUlDNbqPNCSQ+4e21s28HuXi7pG5JuNbPPZzrQ3ae4e7m7l++zzz4tGC4AAAAAAAAAAEB9I0eO1IIFC3ThhRfWbRs1apSqqqpUXl6uyspKHX744Q32MWHCBG3YsEH9+vXTL37xCw0aNEiS1L9/fx1zzDE66qijNG7cOA0ePLjumIqKCp111lk67bTTUvoaOHCgLr74Yg0aNEjHH3+8xo8fr2OOOSbnx3P99dfr61//uk466aSU+dB+/OMfa/Xq1erbt6/69++vZ555Rvvss4+mTJmi8847T/3799cFF1wgSfrqV7+qVatWacCAAZo8ebIOO+ywjOfK9vi6deum+++/X5dffrn69++vM844oy477dhjj1WPHj00duzYnB9TW7KGUvkaPNDsBEnXu/uZifWrJcndf5qh7WuSLnP3l7L0dZekx9z9gYbOWV5e7rtCOh4AAAAAAAAAAGi5t956S0cccUR7DwM72fLly3XqqafqH//4h7p0yZzXlem1YWavJhKxWlVLMsvmSjrUzPqYWTeF7LFH0huZ2Rck9ZT0cmxbTzPrnrhfKmmwss91BgAAAAAAAAAAgN3APffco+OPP1433nhj1kDZzpbf3APdvcbMviPpCUl5kqa6+xtmdoOkKnePAmcjJc301BS2IyT9zsx2KATsfubuBMsAAAAAAAAAAAB2Y9/85jf1zW9+s72HkaLZwTJJcvfZkmanbfvPtPXrMxz3kqSjW3JuAAAAAAAAAADQ8bm7zKy9h4FdSHOnEGuuXSO/DQAAAAAAAAAAdDoFBQWqrq7e6cER7LrcXdXV1SooKNhp52xRZhkAAAAAAAAAAEBzHXjggVq2bJlWrFjR3kPBLqSgoEAHHnjgTjsfwTIAAAAAAAAAANAuunbtqj59+rT3MNDJUYYRAAAAAAAAAAAAnRbBMgAAAAAAAAAAAHRaBMsAAAAAAAAAAADQaREsAwAAAAAAAAAAQKdFsAwAAAAAAAAAAACdFsEyAAAAAAAAAAAAdFoEywAAAAAAAAAAANBpESwDAAAAAAAAAABAp0WwDAAAAAAAAAAAAJ0WwTIAAAAAAAAAAAB0WgTLAAAAAAAAAAAA0GkRLAMAAAAAAAAAAECnRbAMAAAAAAAAAAAAnRbBMgAAAAAAAAAAAHRaBMsAAAAAAAAAAADQaREsAwAAAAAAAAAAQKdFsAwAAAAAAAAAAACdFsEyAAAAAAAAAAAAdFoEywAAAAAAAAAAANBptShYZmbDzWyRmS02s6sy7L/FzOYnlrfNbE1s3xgzeyexjGnJOAAAAAAAAAAAAIDmyG/ugWaWJ+m3ks6QtEzSXDN7xN3fjNq4+5Wx9pdLOiZxv5ek6ySVS3JJryaOXd3c8QAAAAAAAAAAAABN1ZLMskGSFrv7u+6+TdJMSec20H6kpPsS98+U9KS7r0oEyJ6UNLwFYwEAAAAAAAAAAACarCXBsgMkfRBbX5bYVo+ZlUnqI+npZhxbYWZVZla1YsWKFgwXAAAAAAAAAAAASNWSYJll2OZZ2l4o6QF3r23qse4+xd3L3b18n332acYwAQAAAAAAAAAAgMxaEixbJumg2PqBkpZnaXuhkiUYm3osAAAAAAAAAAAA0CZaEiybK+lQM+tjZt0UAmKPpDcysy9I6inp5djmJyQNM7OeZtZT0rDENgAAAAAAAAAAAGCnyW/uge5eY2bfUQhy5Uma6u5vmNkNkqrcPQqcjZQ00909duwqM/tvhYCbJN3g7quaOxYAAAAAAAAAAACgOSwWw9rllZeXe1VVVXsPAwAAAAAAAAAAADuZmb3q7uWt3W9LyjACAAAAAAAAAAAAHRrBMgAAAAAAAAAAAHRaBMsAAAAAAAAAAADQaREsAwAAAAAAAAAAQKdFsAwAAAAAAAAAAACdFsEyAAAAAAAAAAAAdFoEywAAAAAAAAAAANBpESwDAAAAAAAAAABAp0WwDAAAAAAAAAAAAJ0WwTIAAAAAAAAAAAB0WgTLAAAAAAAAAAAAsNNVVkq9e0tduoTbysqG90ulvdpiHATLAAAAAAAAAAAAkFVjQa2G2qVvmzgx3JpJF10kLV0quYfb0aPD9vz8zPulsj5t8fjM3dui3zZRXl7uVVVV7T0MAAAAAAAAAACA3VJlpXTttdL770sHHyyNGCHdfbe0aVOyTWGhNGVKuB+17dVLWr9e2rYttT+zEOxqHeVyr7LW6i1CZhkAAAAAAAAAAEAnUVkplZaGIJZZuB9lilVWSmPHpmZzTZ6cGiiTwvro0WGJ2lZX1w+USa0ZKGs7BMsAAAAAAAAAAAB2Aw2VS4yCZKNHh8BWpLpaGjMm7L/iCmn79p096vZHGUYAAAAAAAAAAIAOaOJE6Y47Okb2VuugDCMAAAAAAAAAAMBO0VCWVnP7a6j8YXxf9+5SXl5yPb7suWdoP3RoKJHYeQJlbYdgGQAAAAAAAAAA6FQaC4RVVkoVFalzd1VUNBwwi/dZWhqWqP+JE8NcYOnlD0ePDgGw9NKI27ZJO3ZkPs+GDaH9U08177GjPsowAgAAAAAAAACATiMKhG3alNxmFoJi0W1DysqkG2+UXnxRmjJFqq1t2/EijjKMAAAAAAAAAABgN5Yt4yt9+8SJ9bO4zKT8/GSJw+h++jJ6dGqgTEoGyHLJL1q6NPQxeTKBst0FwTIAAAAAAAAAANBqcilxmC0gNnZsaunDsWNDYCy9JOLkycn16upkCcMoeFVdTSALuSNYBgAAAAAAAABAJ9NYQKu5/Rx1VMi6yjbXV6aAWHzeru3bU/vfvj0ExtIzwYDW1KJgmZkNN7NFZrbYzK7K0uZ8M3vTzN4ws3tj22vNbH5ieaQl4wAAAAAAAAAAALnJFLD65jdD6cLGyh/Gt5eW1g+Mvflm/fNt2tRwQAzIXW1NW/RqnksBzkwHmuVJelvSGZKWSZoraaS7vxlrc6iCLQNzAAAgAElEQVSkWZJOd/fVZravu3+a2LfB3Yubcs7y8nKvqqpq1ngBAAAAAAAAAOhsKiulK65IlilsiiOPzBz8AnY2M+nSS6XJk+1Vdy9v7f5bklk2SNJid3/X3bdJminp3LQ2l0j6rbuvlqQoUAYAAAAAAAAAAJomU5bXxIlSfn4IJkRLfr40dGgy86s5gTKJQBnaRl6eNGFCyEacMUMqKUnuKypKruflhduyMmn6dGnSpLYbU0uCZQdI+iC2viyxLe4wSYeZ2Ytm9oqZDY/tKzCzqsT2L2c7iZlVJNpVrVixogXDBQAAAAAAAACgdUSBqyg4Zdbw3F/x9l26JANbxcUhqNVQP5WVUvfu9Usejh4d5vOqrU09V22t9NRTzQ+SAZmYhduSkhDUipSUhKBXFPwqLMzeR1mZVFOTDHyNGiWtXBmOdZc2bEiu19SE2yVLQru21JIyjF+XdKa7j0+sXyRpkLtfHmvzmKTtks6XdKCk5yX1dfc1ZvZZd19uZp+T9LSkIe7+z4bOSRlGAAAAAAAAAEB7q6yUKirCXFyZdOki7diRzJAhaIWOoKxMuvHGcP/aa0NANi8vBF+jfbkErbKV/iwslKZMaVngy2zXK8O4TNJBsfUDJS3P0OZhd9/u7u9JWiTpUEly9+WJ23clPSvpmBaMBQAAAAAAAADQSWUqT9jU40pLw9JYH5WV0pgx2QNlUgiUSSFYQKAM7WXChLBE5QyzGTIkNYNr1Khwv7nZXVG22IwZIchmFm5bGihrSy3JLMuX9LakIZI+lDRX0jfc/Y1Ym+GSRrr7GDMrlfSapAGSdkja5O5bE9tflnSuuzdYAZXMMgAAAAAAAABA3MSJ0h13hAv6cSUl0m23hfuZslyAXV1xcShLGGV3ZRPtzyULrLIyZI29/7508MG5Z4vtKna5zDJ3r5H0HUlPSHpL0ix3f8PMbjCzcxLNnpBUbWZvSnpG0g/dvVrSEZKqzGxBYvvPGguUAQAAAAAAAAB2fc3J1srURzSPV/rcXvG+KivDnF2ZckKqq8OcXqNHEyhD+yoslI48sv72bt1C5lf6HF9mYfv69anZXemZWtE8YdH+XLLAoqyxHTt2zlxgHUWzM8vaA5llAAAAAAAAAND+smWnNDaXVybduoWL/FHpQqCj6d49BHNXrQrvhxEjpNmzM78/sr1vOnK2187UVpllBMsAAAAAAAAAoANp7MJ6fH+vXmFbdBG/uRfhJ04M8w01VApuwgRp1iyyuLBr6tIlt4CsWcjOipc0POQQ6emns5f6JLC18+xyZRgBAAAAAAAAAM0TL1XY1PKEFRXS0qXhwv3SpWE9KklYWhrKDkb7q6vDErW96KIQBDCT8vOloUPD+c3CWKKSh1GbaJk8ueFAmRTaEChDazKThgypX6awqUpKpHvuydzPkCHh/REtO3bUL2k4Z440fXr9EogrVxIo210QLAMAAAAAAACAFso0T1cUkDJLDYhlCniNHh2OyRY0i/ofPbp+icNNm0IQ7KKLGg9WRcEAKQS/nnoqnD/aF6EkItqLWbgtKwsBqjlzQlZjFKgqKQlL+v2ysszzfxUWJrO/4v1EAa85c3IbF3N97d4owwgAAAAAAAAAGWQqdyhJV1yRDEoVFYXbjRtb77zdu0tbt7Zef0Bbi0oWRoqLpTvuSA0o9e6dDMxmOn7HjtaZr4v5v3ZvlGEEAAAAAAAA0OE1tfxgLu2zZXXFywrGs7YmTkxmfOXnh/WohGG89GC8nGGU/TV6dGr21saNrRsokwiUoePo0iVkc0UlC6Nl/fr6Aaoo2JzJjh2tl7FFBhiag8wyAAAAAAAAADtFVH4wXkawsFAaM0aaPbt+Jki29lOmJC+AZ2oDoHFFRSFAHM/2ysuTTj1Vmj8/GRTu0iUEnkpKwvqqVc3P2CotzVwqtKwsBLaAxrRVZhnBMgAAAAAAAAAtFi991qtX2JZ+UT1bGTaz1PmyunaVevTIPv9W/MJ6tovvQGcxYYI0eHDy/VdY2Hi2Y3rQeWfJJQAONIQyjAAAAAAAAADaRbayhfHSh+PGJUsWVleHJSpfWFERjsk2X1H67/m3b284ALZ0abJUIoEydGQlJWExC0HgGTOSpQxnzAjbzEKbbt1Sjy0sDG0mTUotPbhhQ+qxZWUhoBZfb6/g1KhR4dy7wliAODLLAAAAAAAAgE4kngEWZX1J0hVXJANPJSXSbbeFC9hDh0pPPVW/n6g0G4AgypCSUt9PkeLikPHV3BKGmd67BJnQ2ZBZBgAAAAAAALSDeAZV795hfVc8f6Z20TazsN1MGj06mQG2dGlYv+ii1Av71dVhu1nmQJlEoAy7vry8zNu7dAmZVvEMrsLC1DZm9dvEs7yi+buic8QzpEaNklauTB4bLevXh/fNkiXNC3LFs8ea2weAzMgsAwAAAAAAQKfQlKyMqG1U7i9+Ca015tfJlt0V3zZihDRrVuYyg9EcRZmyV4COrqQkvK7z8qTa2rC+ZUtyHq4o81FKfQ9E2Y5lZU3PuiJrC+gY2iqzjGAZAAAAAAAAdnuVlWHerE2bktuyBb0qK8P8W9u2NdznhAlhrqDomGyBq27dpJoaMrGAxsTLfwJAJpRhBAAAAAAAAJrp2mtTA2VSWL/22nA/XsLwm99sPFAmSZMnS3vuKU2cKI0dmz3Da9s2AmXoHLp2DUHk9JKGUgiEzZiRLGkYlTGM71u5kkAZgPZBsAwAAAAAAAA7XbZ5uJoyP1hlpVRcHMokRks0L1f82IkTQznFTKIyi/F5vJoS2NqwIQTNtm/P/RigrRUXh6BVPCDVVF27huPNQlnDTEGw9DbTpoVsyylTkvN7lZXVD4Slz+lFkAxAe6MMIwAAAAAAAFKkz90zYoQ0e3bT5/LJ1k+2wBWAzLp2DeU8ozm7ItF8etHcXtnm6spUWrRbN2nq1HA/mp8vl36Y1wtAe2LOMhEsAwAAAAAAHV97X2yOn79Xr7Bt1ark/WylBOPSL9CXlEjr1+dWuhBAZgUFoZxnFFDOFLhqyedHe3/2AEBrYM4yAAAAAACANtbUEoC5to1MnChddFGy3N/SpVJFRW7Hpp+ze/fU8oNmUmlpWOLlCNOXeLnB6uqwxO/nIvrtdW1tuK2uJlCG3VeXLtKQISF4lU1UanDGDCk/P3Vffn7DJRHz8sL+zZtDCcMlS8J7rKYm3C5Zklq+cMmSUCo0vj0XLTkWAHZ3BMsAAAAAAAAUAlEVFdkDWZWVyUBUetApl6BXZaV0xx3JQFNk06bQl1n9+bcaCnRlCk7FA14dqJgQ0OpKSkLgyj3cxufPSg9cxdtmWmprpTlzpLvvzn5cFHwaNUq6667U8911VwiCxefoii81NWE/AKD9UIYRAAAAAADsMlqjxFh6+bIRI6RZs5JBpKKiUO5s1arUc/TunXkuraivpsrLk049VVq8mDm6gFx16xYysTZtSm4rLJSmTAnv04kTw/3a2vAeq6iQBg+mvCAAdBbMWSaCZQAAAAAA7MqaG+iKB7miubAiXbtKPXrUD2zFjwHQvkpKpPPPT861lUk84CWFoFd6pmXURiL4BQDIjDnLAAAAAABAs+bJamof6eUGS0sbLy9YWlq/LOFFF4Xje/cOF8Z7904tKdilS8jwio6T6pcO3L49OadWVOpw6NDkvF8Amq9bt/A+lEKW1pAh2efVksK+CRNSSwzOmBHKC8bn2spU+jAeKJNC++nTM7dhbi0AwM5GZhkAAAAAAB1ENKdWtvJkufYxdmwIQkW6dpWmTUtmbKXvl8LF7F69QuAqXuLwkEOkp55q+WMD0DRRCcI776z/fj3ySOmaa6Qrrmi8/CgAAB3JLplZZmbDzWyRmS02s6uytDnfzN40szfM7N7Y9jFm9k5iGdOScQAAAAAA0F5yydJqSSZY/PgxY1IDZVJYHz06BLOGDm24D7PQNv3C+vbtyT4y7ZdCpkh00T2av2vpUgJlQFN16RICXXEFBeHWrH57s/oZXyUl0t13h+ysadPqZ3q98UYIhK1cmcz02rAhrJOtBQBAfc3OLDOzPElvSzpD0jJJcyWNdPc3Y20OlTRL0unuvtrM9nX3T82sl6QqSeWSXNKrko5199UNnZPMMgAAAABAczRnLq1cjsk2586YMdKsWcngUrqSEum228L96By9eklbtkgbNzb/cQLYdZSVhc8NKffPn+bO+wcAQGfRVpllLQmWnSDpenc/M7F+tSS5+09jbX4h6W13vzPt2JGSTnX3byfWfyfpWXe/r6FzEiwDAAAAgI6vJReDcz023q5XL2n9emnbtuR+M+nSS6XBg1P7GzGi4SCXFEqZbd4csjMAdGxlZeF9P3ly7sd06RLe/9Gxs2cT3AIAYGfZFcswHiDpg9j6ssS2uMMkHWZmL5rZK2Y2vAnHSpLMrMLMqsysasWKFS0YLgAAAACgKXItH5ipXbzsX35+uO3dO2RiVVSE8n3u4baiImyP2kdLfn7YHp2juDiUCIwfG5UOTF/i7aqrUwNlUtg+eXL9/iZPbjhQJoXMLwJlQO6i0oBDhmTeH5UeTC9NGDdkSLKc4IwZ9csOzpiRWqYwXdeuUrduqdsKC0Nwa9IkacKE5Pnz8sL5Cgvrt58xI5QhdQ+lDCdNCreUNgQAoGNrSbAsQxVlpaep5Us6VNKpkkZKutPM9s7x2LDRfYq7l7t7+T777NOC4QIAAABA22jpnFRt0f/EickgVTzo1Nh5ioszB5yiwFRxcWqb7t3rtxszRho3LtyXUue3mjw585xbkycn20dqa8P2aCyUJwR2PUOGhIBVJmVlyaDSqFHSnDn1g1ITJoRAk7tUU5M9GDZnTrLfUaPqB6jS5+dK72PaNGnq1NRtU6Ykg1uTJiXPX1MTzjdlSvb2AABg99LWZRjvkPSKu9+VWH9K0lWSDhFlGAEAAAB0UI2V+JNCQGnjxuaX5aqslK64ovEsp7hoHqwXX2y8pFhRkVRQEPo3S51zC8DuLy8vZHUOHhxu04PYUsjEmjo1+fmVrQxqZWX9PgoLCS4BAIDWtyuWYZwr6VAz62Nm3SRdKOmRtDZ/lHSaJJlZqUJZxnclPSFpmJn1NLOekoYltgEAAADYRbV19tTOHEdlpVRamsyOKi2Vhg5NZmLFywBG5QOj80QXhRsq8SdJGzZkLhWYlxfOFc/OylZGsCmBMim0Hz06t7l3Nm5M9k+gDNg1RKUGo6woKVmiMBddu4Zjs2VnRVlXUfbUpEkhmBVlUEnJrK+ystRAmZQ5oyvaThYWAADoyJqdWSZJZjZC0q2S8iRNdfcbzewGSVXu/oiZmaSbJQ2XVCvpRnefmTh2nKRrEl3d6O7TGjsfmWUAAADAzpNL9pSUzE6YNCn3/qKMBClzlkJDfWTKXjjhBOnZZ0PZPrOQNbVhQxhbbW24cBv1PXFibsEkAGjMkCHS4sWZP9eWLs2ctdmlS+Y570pKQhnBTKLPz0x9RuvxzzkAAIDdVVtllrUoWLazESwDAABAumwlodrbzhhX/OJpelBIyn7+9PJ+0YXbsjJpxAhp9uzsF3mbo3t3aevWph2Tnx/OHc11FaFcIIDWZCadfnrmgFdDZVDNpEsvbf6PBFpSsnBX/d4DAADYGXbFMowAAABAu0ovh7d0aVhPL8vXUNm+9H0TJ+beNlv5v8pKaezY1HFFZfgaOm7ixNB3VIZvzz0zj2fixGSZvqVLw7FRUCk6V7Qv/fxdutQv7xdlOCxdGjKuoj5bKyjV1ECZFMqDpQfKJAJlAEIG1oQJ4TZ9e6YShCUlYUm/X1YmTZ8uzZlTv7TgqFEhyysqWZhe0nD69MYDZVLmsoUtLVmYrRQiAAAAmo/MMgAAgA5kd/81eVMfX+/eycBOXFlZuIAY9TluXObygSUl2UsL5qJrV6lHD2nVqtTxFheH+aAaEmVzFRVJmzdnLskFADtbUZG0fXvzPxfTxTNLi4qkgoIQrI+yYaPbbFmj0efp7vidBwAAgKYjswwAAKCTi4I+8WyhceOyZynl2md61lK0zSyUwmssGypbv6WlyQyp0tJkhlS83+LiZJt4plQ8G2rPPcP4SkvDEh/r++9nPn9UQjDKosp20be6umUXhLdvD32kZ281FiiTksGxjRsJlAFoWwUFqVlVUghSSeHHBVE2lnuY62/q1PpZWfFj0rOzMmVzRdu3bEntO8rWqqlJvZ0+vf6x7uEHDWRQAQAAoK2RWQYAADqthrKYGstwam6GV1OPi89JlU1JSbj4mOvj6dUrbMs2D0tjSkqkAQOkp5+unwUQZUsBAIKCgpBZVViYWyBdkoYMkebPr/85HX3Gpmdlpc9ZSFAJAAAAu6u2yiwjWAYAADq8ykrpiiuSFxVLSqTbbms48CWFua02bUr2YyZdeqk0eHD9ffFye716SWvW1J9PKbqIGf0CP700XzS/VrzfbLp1a70SWACApou+S6TU75h4CdWGgl/p30VS9u+j3bm8LgAAANCaCJaJYBkAAE3RmnNbtTSLaunS+r96lxrPdMo2fwnZSwCAXGQKaHXrJn3rW9Ls2cnvtREjUtfbKlsYAAAAQMsQLBPBMgDA7qcpF9ka+jV6ejBqxAjp7rtTM5gKC6UpU5LHNHbOeKArW9CqIdF4AAAdS/Q9Mnt2wyVg00XfFfHvjJIS6fzz638npcvPl045JbW8a3GxdMcd4X6m76OionAbBcMyZXJJBLQAAACA3QnBMhEsAwC0rfSLac35lXkuc0Y1dOExCmhFJfviZZ/aSpcu4SIlJf8AYNcXBZ/+8IfMn9vR/lmzkt8fRUVh3qxMpWF3VhCpNb5jAQAAAIBgmQiWAUBn09KLeLmUAIzvyzV7Kt5HLsGsgoIwB1b81/IAgN1TLllZRUXS1q1STU3u/eYyFyPBJgAAAAC7O4JlIlgGALub5mZORRci77mn/jwkAIBdX/Q5fscduf+IoKQk3Gb6zsjLk049VXr22fDjh7w8qaIi/FBh7Fhp+/bMfebnpwaszKRLL5UmTUoNRvXqJa1f33gGblmZtGRJ6rZsQa1s34HRDzeiH2YQAAMAAACApLYKlnVp7Q4BAO2vslLq3TuU1+vdO6w35djS0nCxLtPSvXu4CJlt/557Zt+Xvowe3bwSg0uXSpMnEygDgOYqKZG6dWu9vmbMCAGe+DJjRjLAFVdYGIJAkyZJO3akti8rC98PZWX1+1y5MmRWFRbW7+/uu6U5c0Lgyz3cTpoUAk3TptUfR5cu0oQJ0l13pZ5z+vRwnBSOXbIkjHHlSmnq1GTbTM9f9LjSxftZsiQZ/Bo1KvSb/rinTw+PId4WAAAAANC2CJYBwC4sPXBVWlo/8DVxYrjolx6EWro0XGxbujSsNxbkKijILYC1bVu44JfNhg2t89gBoKPp3j0EUaJgSqZAkZTcF7UrKsrcrksj/1I3CwGfKNjSmChAFAWe4sGfsrKwL1s/xcXhNi8v3MaDWStXZg7qZAsGRfMyZmqfKaiU3mbKlNz6Sx9HPPBWW5sMpjV2zkzjy/T8ZRuHu3T99dI//5nc9vHHIVMt18e9s7z8snTYYa3zXV5TI737bsv76az+3/8Lr6133mnvkez6PvlEWru29ft9773sWam7mjVrpE8/be9RAAAAdGwEywCglTSWzRXfX1zccOAqW+ZVdXXYFm8zeXJuJawaC3Jt3dqMBw0Au4goEDRhQvhszCQK9KTfZlNSkgwgpWc7ZcqC2rIlBFGiYEp6gCaeIRVvt2FDasCrW7cQXLnnHunAA8O2z362/liiLKgo2BI/x5/+FIIxmQJEkfQgzaRJ9fuJlmXLpCeeSGZuNSWo09rBoEz9nXOONHNmy/ptjXFksmyZ9F//JZ19dnLb/vtLRx1Vv617KNcYee65EAhoa7W10kknSV/6UgjOLFiQuV2PHuG5TlddXT/AdvXV0uc/Hx5/Qz78MLyuFiwI/6ZpqY8/Du/FtrBiRXj/3X13y/p5/vkwzsi2bdI11yQDqJJ0333h9rXX6h//8svhea2tbfz5bciKFdLAgU0Lao4eLV12WXgeMo0tbuFC6R//yL6/oddaY7ZulR55JNzfb7/wb+x08+ZJ8+eHMqiZgl61tdLJJ0tPPll/3yefSJ/7nPT97zdvfJJ0883S4sXNP74pDjxQ+sxnds652sLw4dKDD7b3KAAAQKfn7h1mOfbYYx0AmmrGDPeyMnezcDtjRuq2khL3oqLUy4JFRWG7FNpkvnTIwsLCsvss3buHzz0z927dsrcrLg638c/GLl3CbfpnaXFx6mduY2MoKXGvqAj316xp+HO8qZ/7jbU/8MBw3gMPdJ8+3X3TptQxpPvkE/f77nMfNy7z/o8/bvic2Tz8cBhHeXlYv+22sD5+fO59fPJJOGbYMPfFi93feMN9+3b3FSty7+ODD9znzXOvrQ39nX126HP58tyOr6lx//TT1Ofh5ZdDXyNHuv/lL/WPeeKJcI53363f17/8i/v//V9y2y23hLbf+lZYj15DN93kfvHF7rffnmyb7W+xYIH773/vvueemcdzyy3uV1/tvmVL9sf5uc+5n3NOcr262v0HP3C/9dbktiVLkuNbvjyMMVq/+Wb3005znznT/aKL3H/3u7B97tzk4yoocN+xI9nfxo3ua9cm1996K7SLHsPGjcnnIvLRR2HbT3/q/o9/1H8c0WsmWqqqUve/+KL7//5vcn/UZ0RyP+CA1GMGDAjbX301rO/YUf9vsXZtaHPKKal9p3v5Zffhw8PrOF1pqfuoUaljOfZY97/9Laz/27+Fba+/Hh7DLbe4P/ig+6RJ2f+2V1+d+jeMPw+S+xe/mPm4uKVLw2tMcv+P/3Bfvdp98+bkGPffP9n2N78J277wheT79KtfDdtmzUrtd+XK5Osies4++KDx8VRXh7YzZoTXSvzvfemlyXaZ/k7R9tmzU4+78cawb9Ei98mTU9tXVWX+m+7YkXztRPufeSa8T7Zvd3/qqfAabsx3vxuOfeml7K+d+Fjvuiv5PGzdGu5Hr/vS0vrHLlwY9h11VONjyWTNmuR3yiefhPde/H3sHv7WL72UXH/uOfdly8J7afjw+n2uW+e+YUPm8zX0/mmOJ58M/f3zn63XZ9z27e433BAek3vrjz/uzjvD92BLvfxy075Hm2LVquTrsiG33RbeK7ubZ59NvhYAAMiFpCr31o8/tXqHbbkQLAM6hvhF0by8cFtW5j5hQjIAFV0UjS5gpgevogu26Rdeo4uxmbazsLCwdLSloMB9yJDcg/JRID89+B//bI2W7t2Tn8HpS9euyQBX167h9p13Ui/UTJvmftBBYd/++4fzrFvnvm1b/c/9VavCbW1tCJBku+AxY4Z7YWHmMd1zT2hz9NFhff5896efDoGSSG1tuJCazXvvud9xR2og4dprkxebf/lL9yuuCP2nXziLj+X220MQRAoXN2++OTzGP/0pbHvqqdT2cVdfndyeHnDIZONG9xdecP/FL9wffTR5bN++yQvzkvsll4SL5N/+tvtnPhMu9j/1VLjg+JvfhADIwQeHC+wffJD5tSOFAEFDY1m/PlysjY77r/9K7WfRotD20Ufdx45NrruHC70VFe5z5oRxRsf84Q/hdSG577FHuO3dO3lc9BxHr7cZM8LjWrMmPJZrr00dw3XXpa6PG5f5NbV6dfI5vf/+8Njir/H09jfdFJ7nt95K3T98ePj7b97sfv754SL6pk3hcUZtPvkkeXE9WjZsCOdbtCi5bfDght/jF1yQ/Hvv2JHcfuml4f08bpz7fvuFbZ9+Gt4nUTBo7NjweI86KqwXFycfa3ThO9Nr9v3364/j5JPDMf/5n+4/+Un9/VEgZOTI8HfP1O8xx4RtL7zgPnVqCGxK4bV+1VXh/iuv1O97xIgQ0HjvPffjjw+B4732Cvv+/vdk/6++mgwARcvBB6euz5uX22fryJHhc+ugg5IBail8ti5b5n7SSfWP2bYtvMbOOy81iLxuXXiMmc4TBcGj9YULQ6D0xhtT2735Zv1g2U9/6n799Zn7vemm1GByutWr3UePDm0HDsz8944+b6L36G9/G14b//hH+EydOrX+cdddF/rv1Susz56d+f31pS+FYOXLL6c+xvT+hg5N3l+xIrxn4/s//TTZ/7BhYdvjj6c+D/HP//ixd96Z3HbGGeHvt3Rp6ms3+ixavTr52hkwIOzbti35vDRk3rzwutx33+T78MtfDveffz61bfR9N3t2eA2lPx/Rd2v88fTsmfm80TG1teHzYujQ8DkVueaa8FrLVfR6iYKMkaefDs/l179eP6i5cGH4LMxkzZowtsi994b+J05MHX82772XfM015ccjUd9m2fe/+274N8j69Y3306dP086dKylzgDQu+h49/PD6+7Zvd//5z8Nnc/S3if4ttmOH+69/nflvM2NG6g8otm0LgavW8OCDYbzV1Q23ix7Xv/xL5v2LFoX3KtDWXngh+aMWALs+gmVOsAxojlx+XR8PbpFFxcLC0lGXI490z8/PvK9nz7C/qX1Gn4kHHxwuFObymRldnJLcDz003I8uPkruDz0Utu3YES5mLF2avCglJT+rf/WrsH7cccl9r7yS7FsKFx8rKsIv+vfbL2Sj/PnPyf0vvBB+sT9pUjIQcdBB2S+4DhwY+t+8OZlpFQXTovOeeWbIzNi+PVz4GjkybI8yI6LFPVzkXbQoPNbDDnM/9dRwoSv6XorGJLmfe27ygrgUAltS+OX5mjXhYsvPfha2HX54yEyIAjU7diSzDKIlPVMmfpE2WqLsnXhQIn1JDzJkWqIMlPTtt9+eGkzK5BvfyO21WFHhfsgh9bf37p36d4qes4b62rEjBGWKisLFtAULkn/Hxpbf/a7+Y3VPZlFkWs4/3/3001O3lZS49+8f/m4XXpi6b/r0EICQ3E84oenv2/hYu3dP3TZ4cDIzp6El23sk27L33pm39+uXGnQGiF4AACAASURBVMxrzudQc5e99kq+zgYNSt03cWIyqDB9etP7ji50py+33ebeo0f2AGauS0NBxQcfzPx+a+kyalTzj/3xj0Og4J57MgfW4svWrbn1ee654fZHPwoZkLmO5bnnwnfFggXhfbluXXgdtsVr7Oqr3f/619RtV16ZvEievkQ/0pCSmaTZlmzf52PGND4u9/pB4Og7PNsx0Xde9Nw//3y4P2CA+1lnhc+raP9559XPSty+Pfk9c8QRqX2feWbq+rx5IRCWy3N82WXJQEF8W/oPVzI9b488Un9/Ng89FIK87uHHMlH7O+9MjnX8+NSxPfBAaL9jR2qQOQqOrFwZvsuvvDL5PrnvvvqfR7W1yfvjxmXOlLzrrtRjoszRdJs2pQbl0h/7p5+mBoeioL4UgvNxtbWpAcGo3TnnhNsrrggB/PfeS74esmX+NSbqOz2TNO7DD0Ob/fZLbqupCf9mi//NpOS/p3bsCD8ikkIWdfSDo9ra8KMMKTWQ+MMfNvz8ZlJbmznAEH1/v/hi9mNfeCH5HZSenRyJ//2OOCI877/+dfi3dXPs2BH+fRYFE6uqwudRU/vIJQM2ajt5cmrwe/Hi8Fjir5f0/ubPD9/V6RmpTRnjCy80//jm2LYt/Js40w/rdnWLF4fX2f9n77zDrSiSNl59LzlIEAQlZ0VREUQFFFFUgooJFDEgSlTMooiggogRxSzmgAEz5sS65lXUNeHiYgAxYlwjF2S+P4r+pqdPz0xPOon39zz9nHMm9PSkPjP1dlUddVSyej79NNrABLBh8dZb3oEsIBkQyxyIZaA88fOokt/TfqlFQUFBUUsUgbxePa/wPmOGv5cQEY80l95Ca9c6znnnufNat3acDh28HiOqoaVFC/6UhrU2bbzGfN0QRcReF9dey143+rz+/d1wX2qRYcLkCHC1vPOO+71dO/58+21+qa+ocEc5S08Qtdx9t/v9449z57/2GntrmY5bgwb8wiy9OdTwZERskIh7vtu0cT2m/MratebpjpM7LcigrRqE77/fO+/ll831qUWKX6ZzQ+QaBBs2jGZI1kuHDnbG17Dy8sv+8yZNYuPgokVsVHr/fTaQ+B1rUxk/PnkbZVGFjDhilG7kvvtu8z2pFj0Mpyru6eX2293vnTqlt9+yqOJ1uRc15KNejjvO3mBfbEUOJiiWMm1a4dtQiHLqqTwIIs66uodumuWgg3K99aSHVJrb+eor7tvHjXNFBlMZODD9fWzWzOv1ZVqmQQPHOeUU73yVNWt40Mj//ufO1/+Xunbl/y5T/Xfe6RURZWnRguvWn3M228xu3zp0cNs3YQI/b91zT+5yTz3FAtKXX7JxXi6z226uMVLdn7VrXRHJ77ipyHP6xx/mATd6+fBD9/v553vr+uADFuqOOorFxLlzHeexx8ztUKmqYuHbcVyv8c0249/r1rnHVB+wJIvq+avWL4U3fZuDB/PvRx91p8n/ZOmdqTNqFM+/7TbvdFm3Gmr0/fe9XrD69WFCbaO+L3po3ptuYk9yFX0ZOahMD+P80Ufh3oUSKfiuWuU48+d7wxLrSA/qfv1YcJbipSw//8z3EhF73Eqkx64aFnfNGlf8evxxfsfwQwqoSYWbfv34OVYyezYPxDNx+eW8zUsu8U6X93JWYV3TQHrMy4GDt93Ggy3XruX9fecdu3o22ij3Po7Lf/6D8KSljN73yIGchxyS7XZvvTXXM71cgVjmQCwD2eHnfaWHttLDX02YAI8sFBQUbxGC+wa9/9h4Y7ucTabSrBkLNAsW8Iu2fEn6+28eKX3mmV6PnEaN+FO+ZMlSrRqHFurfn18A5PRly/yNXVddxS9FEybwC3e3bryuFLOuvjq47X36sEeROnLXpjRvzqOc1Wmqh5VfCRvRXyrl/fdd44NeZCizfBcZgiqt4jiFP84oxVnUvqtDh8K3p5yLrUchSnApVL9cDKVUQqNPnlye/ztz57InQ9AyCxe63x3HfY40LasLWjLsq6kMH57dft19N4cDlL/DRFmTWLlwIQtd8rea50+ir+M4fK0MGxa9zTNnen9//jkLM3o4UVVElOdDr0uKL9Ire9kyN2xoy5Y8T32W9yt6GGMi9rrcZx/vtO++c3NbEnnFMvUd4/vvedrVV7uil1qP9NqTg8yIvN5yQcdf9ZhTUdfR96VGDY4AID3D5PSVK/n3ggXuNN0zXuYbVevr1Ys99jt2dIWoqioWi1TRSi4vvWh33tnrsS156y27AQV9+7rXvX5NqOFniVicVwfO+TF9Os+fPt07fe1aDt/89tv8zhgUMvybb/zPmQk5SGHcOO90KaL16+ed/umn9gJlFM49lz16Ve67j58p1fDun3zC14/j5IplckCoev86Dgsekyb5e8/JZX/4gbcZxpo1XpFUr0v3eLXlr7/4fX3hQm7rzTfnet36cdddrkj3zDNeL+UorFvHNgxbL0zJt9/6h/QtFeRAzhUr3GnSe1GG8/3kk+AQ2nH44APext57p1tvsQKxzIFYtqEzYYKbe6Wykn+r7L577kMHBCwUlA2jyHtdvedr1vQPi+VX5CjB7793Q3BNnMiJ34k4fIm6fOvW3tHkW2/NowO//NJxTj/dHekqMY2+TVJOPtk83ZRfBqW0yv77F74NerERK1FQUFBQUIq19O9f+DYUSwnyOi2WoopbcYsM6asXafzNx35cc030dcaM8Qo9RK74QcReA6efnl4be/XKFd+uu46Pkfo+tXhxcHjqSZM495hpnpqX9bPPvOE31TJoEAtZp5/uFYLV82XKyatHXnCc3EF0jz3mfjeJZWrZaiueLwfvDRvGv1WvvGOP9a4zZYrXRhX1PNx5J+cwVAXVr77iaA1qJABVzF27lsUNKYQMHMhi5uzZPP+007xt+sc/vNscMYKnf/FFbng4Ncyuvk8PPpgrdKn9iuk47LJL7vTmzXm7VVV87k891UmM2gY1vywRDxzVl/v7b29UkLvvdsN4//67tz45yOi++7z5eWXOTvlb5uBUxRKdv/9mT2giFlL89mPdOvYQVPPuBvHww+7579iR8xkSueGIg/j3v3nZ4cO9bbD1rFOR4YyHDuVBw2reWcfh/Zoxg/Nmq6jn68gj7bc3cyYPMAjKb63y3Xds91Hvn7SQzxtqW6RYRsTivYygkybynt1++3TrLVYgljkQy4oJmzxYfstKbyyEGkRBKb2i5prwm9ewIY9yPeooc76JGjX4s1UrDpmnLyMEe9XI35tv7p2vhmTbYgt+Yfn6a36R+OsvfuhSl5F5j6IU+UAZVmzFuBo1vEnkUVBQUFBQUFBQUFAKV/xy65VC6dXL9dbJsqxb50asICrswKmwsMEnnuj97TjByw8cyNE5/OZ368Z1yOtkv/34t5pvVy9S6Ik7cFENQy3LvfcGh/qWZZddvKHWpeB2wAFe+5wulsmQcETsBafyxhve46kf05493TChjuO9JtW8qWobHYcFCpmX01QWLeJr7Y03WESbPZvf6Z94gudLIcePoGtg/nwWunTvSr1IG4X0OJP1SaHSFBr21FNzp+m5i7/8ksXwCRO83qiTJvHn2Wfn7ocMHSo9pFWeeornqaKM3oZTTuFPuT2Zn1JHj4Kje72a8g+++qp7nPzaJosufK1cydNl6F2/9ktWrQr2UlPXkfltg1CXtxESHYdFZSmsff65f35HmUZBDVmq2rhM+6eyZAlH5lHFXZXvvjPnPpMhg3v1stufuNx5p+MceGC227ABYpkDsSzfTJjg9dKQ30sl1AYKSrkXIfghtG3b6F6UTZu63xs1ckdOBdWjC0N6rirTCL98l6FD+UWm0O1AQUFBQUFBQUFBQUHJqlx/feHbUExl0CDvb9UjKE5p1IgHY8rfnTtn13b5Di7zjKVdvvzSzamnip+moqKKZUReTyq1yPCburejRJ320kv2+Wh793Y9r/Ry9tksnixZ4vXKUsPG69tOWhzHDT+reqIFlY8+8h5TNaypX9GP80UX8af0bpSoXnNNmvC0f/4ztz7pYXnSSfzZrJl7bKZMYRFSCpFq+ekn7+/TTmMvMHWfJk/meWPH8nYWLOB2rlvn5kBUixRX//yTvxNxaNkbb3Q9z/R15sxxc2tusQWHuFRZujQ3xzeRm5P6uefMNm912fPO88779ls3xPZvv/G0zz/n3zK0qemekchj/sILfK089ph/vuagtqk5B597jsM7vv02z+vbl6fffTe39Y473PyVO+7Inp4zZ5rrV3noIcc5/HDvtIULWej7/ntzyNGgtjsO54c++mg+p1nmKoRY5kAsM6HnxEFBQUFBQUFBQcktfqGYirHg2Q4FJX658EKEjUVBQUFBSV522KHwbUijNG3qOMccY7fsG29wRJShQx3n/vvtt6Hn5iPiEJFSsIhTeve2X7ZdO2+OQiJzPsAk5fffHefgg6Ot06gRi4gTJnBOuyTb328/95z88EPufMcJPmcnnOB+9wuDqhZdeJMeanJbupimlk8+8Z/nOP73luPYn4u77uLcgkFeimq9Oup86dH300+c70tGQyJyxdhXXuHfO+7oXV/muZP8/LMbNlX3eDWVL7/MDVEp56l570zrSuFML+q9o7JqVW5ITbmc6iWn1/fww+489b7SkZ5tQcf/H//gKFQqv/zCQqCao1GyejV7l/75Z+68ohTLiGggES0lomVEdIZh/igiWkVE/15fjlHm/a1MX2izvQ1VLFNzdaGgoOSvIOcdSikVPSG7zf/Gr78WR86KatX4/y5JHXrYEtOoOpQNu/zwA4deKXQ7bErz5oVvAwpKqZY77igtcRwFBQUFBaXUy5135k674YbCtmnNmvTrtPEMy7LICEEPPpg777vvOOpQPtphExo0ToljEzB5sJnqrary5n1T5595Jk+bMyd33ZNPZtuK9Pzcaafc9SVJPFrff5/r+Phjd1qHDvwZVXTu08f9/ssv7HG2bp0balMNZ2naj6DjKL38iNzwn2vWOM7o0f65YX/7jbev1q2iruc47O326qv8XdqrZs/mnGyTJjnOFVfIurIRyyooJkKISiK6mogGEVFXIhohhOhqWPRex3G2XV9uVKb/qUzfN247yoH584maNCESwlyuvZbo778L3UoAklO9unl648b5bYctjlPoFhQfbdqkU89pp6VTTzFw3HFE111H9OGH3ukDB7rfN9vM/e44ROvWpd+O888nGj3a/b16dfDyH3xAVK8eUbt26bfFlk6d+PPJJ+Ot37Ej0QEHEJ15JtHhh3vn7bJLsraVGm3bxlvvxRdTbUZm7Lxz8joqK4neeSd5PfmgIvYTenZ062a/7NlnE510UrzttG8fb70ssN2H227Lth0gGhUVRDVrFroVGxbjxhW6BQAAAArJihW508aMyX87VObOTb/OX35Jv84orFrFnwcckDvv4IOJPv88P+3Ya69s6j333OjrfPZZ+DLXXENUo4b/8+HatfxZo0buvDlz2CZ/1FH8++23iV55xVxPmA0miKFDiY49lqhzZ3faJ5/wZ9R3jY8/dr+PGME2q2eeIVq+nKfVrUt0xx1EL7zgXW/mTKKlS/3r/esvon/9y/29++5Ef/5JtHgx0c03E/3jH+b16tXjY3vXXe60tWvZLvb220Svv+5Odxyi/fcn6t2bn+nvvZenT5lCtMMORFdeSXT88XxOsyLJq3gvIlrmOM6njuNUEdE9RDQ0nWaVLvPns8GqooI/588n2nJLfyFMCKLDDiP64YdCtxyUA0IQdeiQO10VqdTORqdxYzbqV1Z6p/ftS3TjjdyRffFF7nqtW9u1b80a8/Qff7RbH2THokXu97lziX7+mei33/iPqk0bossu4++ff060zz6563/yCdGtt7q/772X6JZb+PuIEUSvveZd/sADvb9nz+bPF17gB9DnnuPf3bvzg8F//sNteuUVok024QfBBg28dZxzTvA+Pvhg7rQ99wxex4Yrr2QjUfv2fK9JQ2/z5vxZrRrRsmXedYTgh4W6dd1pW23lfh82jGj48OhtadKEP887j+9jU39AxA8ZW27pX0+9eubpV10VvU1B/PYbf3bpwp/PPx/tpaqykuiBB4hmzfJOHzEifN099rDfThpccEG29VerFm+9tIQJeb1nRbNmrli/ww7R12/fnmijjYhq1063XVkwY0bu/7AffoNQdNIY6BDlGjvnnPiDAsaO5Re1YmDOnPBlrruO6Igjsm9LITAZYkqByspwsezQQ/PTlg0Fv+cNAAAAGwZnnlnoFuRy6qmFbkF+8RMqsuD337OpN8ymY+Kjj8KXOfZY9/vRRxONH++dL22VNsLb6tVsI1X597/ZLjF/fvj6fnz6aXoCkBRViYieeII/r7/eu8wRRxAtXOidNn060eab+9c7axbRffd5p+29t91739q1RCNHur+rV+dn9h49WHCTvPqq+91xWIgzoZ7TtEkilrUgItVsvnL9NJ0DhRDvCSHuF0K0UqbXEkIsFkK8LoTYz28jQoix65dbvEo920XIxIksfC1fzid0+XL+vWRJoVsGNhQcxx15oKKKVOvWsdBg4scfib76KteT8eWXiY45hoW2Vq1y1zONIgIuHToQDR4cfb0pU4LnqyLjkUeywOT3x3bvvUS77cbfBw3Knd+/v2sInTSJhSgp5Hz+OdGJJ7rL3nYbC2OHHOJOa9+e/ySJeHTJ8OFEBx3EhrYLLyTacUeihx5yl2/UyLv9iRP5+u3Xjw3aUqyprOQ/8S5duE29exN9+y3RPfd4PS8GDCCaNs1b50svud//9z+i7bbL3e/jjnO/f/tt7vwDDvAfNUTkNbbVqkVUVcX3CpHXsGwyaP/yC9H335vrHTqU6Iwz/LdroqLC9YaU21ZFukcfJWralL+ro5VM+AnbBx0UrU1hyJFjzZrx5267sdCns/HG5vX9BAUbo50Q4cvY0K+f3XITJ/ILjLw+0iauJ1JaHkx+/ythVKtmFrJ1TjyRR7n9/rvrkVi/vt02Fi3i/0YpUhc73brZnxf5n6x6spq47rpkbSKKHuWgqiredioqcu/PI47IfTHLgj32ILr//mjrqC99pUCUgRhJxeVCCSgVFeH3ut9L/fTp3t/PP59Om7KgRQsezGRLlp7kpoFUAAAAAADFxs035wpHl13GtvtLL41XZ/fubCuZNCl5+9JG2oZUe5wkynMkEQ9gnzfPO23RIqKrr47XNhO//ppeXXFJYiIxmZn0oGWPElFbx3G2JqLniEh1HGztOE5PIjqUiC4XQhhfpxzHmec4Tk/HcXo2lVa+AjB/Po9QDPIQu/bagjUPaEjDdI0apTGKHESjRw9/r5i77jKPhN52W6KttzavI71adO6+275Nt97Ko0lMbLkl0eOPs5Bx443mZXSOPJJowgSiIUO8gspNN7l/dqrgdM01LFL5japp147FtG++IXrkEfMy77zD9YeJCI0acfv047PxxkRPP+2OTqlXj0fXSGPufsqwCH0bqocVkWso1r3HVNQwmePH5xqXO3Z0v9ev7worqgeMatwx/cUIEezhYRIIZLtUgcxUR61aXEw4jp2Yo7ZfCHfbJkP73nsTXXKJt41++IllUtRKizFjuC2qUdN0rLbYgmjUqNzpfudG9yjYaafYTQzkscdYDLahZk2iXXc1n5s4XoQ6tp5IOmmJZZdeSvTww9HXa9iQwyzIKOV+9OnDx7BOHXfahAl22+jf3/1eCuF1Hcf+vMg+pKqK+18/0hCHdbFs7Njg5ePed/K5WmXbbb1ivTqAI02uuMId+GFLMYbMDEK9h8KI67EqadmSBZ18Y+NZ5ieW6evJgUbFyBVXRLsX/Pq/nj2TtyVoFHIUBgxIp540sY2gQZTd8wYAAAAAsiUo8k4pk/R5XsXPnqmGV0yKaXB/vknyereSiFQfk5ZE9JW6gOM4PziOIyN23kBEPZR5X63//JSIXiCi7gnakgnz57OxV4ZKjDtCFuQfaeitqvK6c4LsSCpKmrx6TAL05ZezG+4777CQ9NJLHLpv2TKin37i8GsPPJBreO3SxfVWUsOhtWvHBu+zz87dVt26nAfKhiOPJNpmG/O8O+5wv8uOv3lzojfecAWaTTZxl2nQgMW3Vq24bRtvzELcf/7DOak++8wNa/jCCyxaqcavESN4pMyUKW6ItVq1uC9r1oxFnMGDWTRbuJC3QcRhANWcVzYsXszu4pI99ww2xN15J58zfRnd0N+zJ3sd3Xmnf12q59X22/Onmv9OilVSHJPGV90IK73DTMZkIYIFO5O3mr59v7rDsHFl79vXG3JQHShgQoZpbNky+bazQr8WdtrJP3Ss34PfKafw5/LlHBLkxReje+rZMGSIfd8XFC4v6HhffLFd/UEGe3l/+K0XdM/OmuXNuedHZSV7RKrMmJG7nD44QYbiDCLMyzYKMh59VtiGRQwiilgm4+JXVdl7fvmFsvBDGsF33537vIkT7dY77LBo25GY9j0tT9AwKiujC89hy+czJI4NXU0Zpn2I83Kt5ppwHKKVK6M/WyTF5J2o49fv5kP8DBt4EnfwQ1wmT+Yw63pI40KQ9b2uhwG3IUq/nq++CmRLWuIvAAAAUGj++qs46ypmkrwOvElEnYQQ7YQQNYjoECLyRLsUQmyq/NyXiD5aP72REKLm+u9NiKgPERU0WOHEieZcYlnFYQUgCbYj4//8kwUWIv8XvZYtOfTivfey4f2ZZ9x506f7j/ZXvXbuvdc7on3PPVmwnD+fw9+pIWy+/tpbzzHHcIerikUS03ZVr53HHuM29+vHoX4aNsxdXo4Gragg2nln/j5sGIfzmjmTQ3N17OiNjbzjjvy5bh0baWUE2LPOco+H47gGIfVYSE48kbf95JMcVlAiRYz27dmA/fHH7DXz1FNE//0vb/Pnn3Pr22Yb18jcsqXbxn79vOEQiXhUx9ixLPTJddQ2ELGn2777smfSkCG527OlR49oYX1GjuRz1qIFC3VffWXOgycEX39BeZBOP909F/I8q2EHKyv52gszDM+f715XUjhU2Xxzdll//nkOA0nEHmWOYxad9FCIcbG9z1VvsilTiE4+mXOoSUaPdkNUDhrE92ucxLn5QjcSTpvmFWtuvtn97mfUlAJW69Zs/KtWzT1O48axeGZr/Fq+PNizoFs3u7xf0oBm8nYIErM23dR/norfsfj7bzf0o8mDraKC70M/+vaN741lMhqOG+cNkWrzwG07aMGGKMmomzYluv129763Qb0+Tfz4o3/4VRVbY7kMvVxVFTwaUoasPPdc7rejIAcUbLQR0VtvEe2yC//2uzZlfxzXaGyzXlYegpWV4WKJfJaQhC1vejYpJH368POGDWH/Y6ZBTVOnut/lecrqfG2xBT/L6FRWhm/TL7xv1mLHt9+yl7/j8CAvnVq17O//qMfVb/mKCn6emTyZ89bmC9NAuahiZdOm/oPVTPhd00GeskHPC2kO5ih2svLoTZPXXkvHM2CLLZLXUQjuucf8LgMAAAAAe2KLZY7jrCWi44joaWIRbIHjOB8KIWYIIeRry/FCiA+FEO8S0fFENGr99C2IaPH66f8gogscx8m7WKZ6jiGEYjyCvCok+gtfKT58+oVKKwQyL8mnn+bmeZHeRs8/zy/EtWq5L51t2phDZN11Fxu8hg9nA+Yee7iGLjVh/R13uHFoTzmF6N13+YGciMMj9e5NdNJJLHw8/TS/jB56KBvoVEOzLn60a+caj6UBSo5G79CBY/+qhIV90nnqKf488EDOhbRkCRu2O3dm8Us1iqxaxWLe3Lks3sn2NGnCx3PmTG/d06fzMX355dztXnYZG9n1PDJNmrDnmwyF2LAht6l7dxbd0jbS3Hkn53lp0ybdetNgn3342gvzcopCo0auJ5jj8LWnh4AKOsZ77un9La/X/fbjumQM6iADlR6Gcffd3XlqjjMdKYDKOmyMYGroRSH4frv0Um+fddNNroePEHyvx8nbJPNEZU2SUf01avh7Tcjj1LYt39vz5tkZflq3Dg6TKIQ5V6QfZ53FgpH0Kr3ttnSST/sZV9VcdqbzXlkZ7D2ZBD8PIVsBkMiciyuJ4b137+D1jz7a/V6tGtHhh3vFPcnw4ebQvmH5KRs18jfSS6J4lkmqqvha9fPCrFmT69XzMZlo2zZ4/rBh7P3sl8jd9n/Mz2gdtP4tt/A9Pn58sAhl6q9sDOo2Ypn+7BUmbMT1vJ8yJVm/+/rr5ukVFfy8MW0a/w8Hif1hYpnJ61Q9fll7KVdUmM9XRYV323ryciJ+dvWrU+eqq+K1z4Q6OKxhQ6LvvvPOb948/55lkmrVvN7qaeH3H7rJJrnhY6M+Bw8bFm3Ql+nYfvstR2Twe0YLEsv8BnOoOXFLiaBBaoW6LqPw99/xnhFk9BHJiSf6h+kvRg46iAdCHnxwskGQWVIM3noIkwoAAMCGRIEmHMd5wnGczo7jdHAcZ9b6adMdx1m4/vsUx3G2dBxnG8dx+juO85/10191HKfb+undHMe5KfmuRGPLLUvTc6x9ezbcLFzIuV7SoF8/DkskBYsJE4heeYVDhIwaxflYvv2WDa5VVTyqWPLWW7zur7+ycPLll/yQ+scf/JK+bh17N61ezQaO554j+vBDojffdI3BS5fyyMrVq7nIF5VFi3jEuePwdD00yEYb8QummsNC5Zhj2IA5Zw6PoP39dzaCLV/ufyxML0k77+zdxuzZ5nVljP0TTuA2++XHkvm0gnI4fPwxH9MBA9ijReaGGjCAH4SJWGRSQ2ctWcLG9qoqfy+IoUP5/KxaxWLXDTew14DOZ5+xZ5iamP2ww9gDs6qKw4LVqcMP5FVVLDxVVvKx9hM+1LizjzzCL5GVld6cT7ffztu45Rb2BtpzT6K33+bj+e23RCtWRMu1QcTibFUVi2XVqgWLtU2a8Etir168PTWknx9Dh3rD6XzzDbcziAMOcMPhZU3jxv73UGQTUAAAIABJREFUSLki+0bdQCmNfs2bcxjPF17IXVc1BMybl5uPqn9/ruekk/y3r3qWLVnC4igR95VBYSXnzfNenzYv+wccEJynLAp6To6jjnK/L1zoeqlmjS7oBBkr9Dwrf/xB9P775mWPPJI/hw3jz802i57QNiq6EZSIjYPXXef2L1tvzefObySwreHQdP4ffZQ/pdHY5NVmU796LURBiNwR3roRO4xrrvGf1759br7DpMgQgwcfTPTss/xdhrBVkxnfe6/ZazXIqGozwIjILJbNnJk7YEMlTICLgrxH1PaoVFTw/RRHdLchqC8bNYqfIzffnJ8dVaOgmlBb9ZKX2BgQVXFohx3Clydy76EXXzTP79Il3nV6/vl2Xqt+dOtmni7bO2MG9+1BfUCYcTwsZGbWOQIffNDcfnWQwOWXe/N7SoYMMa9r2udjj/Vvg59obIueL9VPADSRxfHNIgxlUL/YuXOy7dvmeJXo/RuRK2D6hWtW2//RR5wrjig4skKa+UHySdAghCjnplAetevWRb8vGjVyPfAlu+zi/zxZjMycGT5Yp9AUQ4jSUssxCjYMbJ83AQD5o0Qf4+LTokVwuKFC0KYNC0EjR5rnr1vHOT2qV/caf/fZhw03w4bxS/itt7KXyz33sFdB375s9P/1Vx4lXLs2i1Vt2/JD5NNP8+iaPfbg+r77jujzz12R55tvvO2Q+Qa22463K18cKit5NJYqetSu7Xb6crlRo9z5qoFTf0m6/noeZa96FNWowSHXdt2Vw8cQEf3yC382auQu99VXbCxt3tw1TKhGbZmMUIbsO+UUFnfOOIPo1Vd5BPuiRe6+S8Hk99/ZiD1kCI9MHjmSDYCdO7NgeN99LEj8+adrjHzrLfZYPP54Nna88QYbm3v3ZrFw2205j8Wxx7Ig9N57vE+DB7sPk9JQJ0M2TZ7sfciToZSeecY1soeFFquoYKGmSRN/QS/oRV2v3zaU2aOPurli9t2Xy5VXepdp29b1XtPDRJnCNNqSRg4ZW8LyUIDsufBCNgLqHqHNmrEQu9de/p4t6nVvGpDQrJmbE9GP44/ne/2UU7z9U5jRUQg2uh1+uNnIuffe3NfI/wFpDJDCQ9KX0J492QhUty639eabuQ984gmu29QnLF0aPvL2mWdyPfZGjvT/L1bv199/dwXyceP4f0711NPDRQUd465d7Q0oJ5zgrdtW5NBp2pT/z/RcXiqyzUOG8H+FmgMwiGbNvCGsTPu+9978Ka8RG3Fj4UI2AMprsG1bNsJ8/71XLLJBCM63qOfviyKWBXnF1q3Lz0d+1/7TT0cXkbbbLvc6EcJ9LlC9m03/Leoxrl7d7S/228+bLzMIXSx79VV+npPe3Do33mgWA1Si9A/6/qveq0F07MihcJP2RULYh75Ur/srrnCfK0zn/aCDOERgkHAl63vvPXuPbLm/JmFLPrP+9BP/J+nXfu3awbl1bfPQmfC73/XzE3S+wgz+Yf9rWYtlnTub/5sqK91j7fcM2KoVL9O+PQ8Sk6jHQxVg/dAHmiTlvPPYc7JQxDEmmwZiqAQ9h7dty//1jRvz4MhLLuHnDr969GewKOLIgQcGD7rzG8h2zz3u++rmm7vHKOj+KAUvLBNpiXz5Ekbq1vUOfo7TZ9ata76Gqldne8Q773ind+pkH8o2XxSDEJUljRqZw9ZGpVTvS1De4LoEoPjYYMZWzJ/PDxGFEsp2392b60gtn3/uL5QR8QP5Rhv5h3G57z42IBKxMeaee/j3McewGNKnD4uEjRtzGIxevVjImj7dFcqIeBt+4onOmDFe8StN6tXLDb1HxH8i0niitvuSS1hs/N//2ADeoUP4CN5ly3hE+IgR7Dl2zz3soXHAAe5o5EcfZYGmWjUOUXXmmW4In1ateHuLF/M5lJ47tWt7X6COO45DIi5bxoabPn34OuzVi40Ye+3F8zbaiMVNv1GuMgygut9B01Xat2ePuQULgo9J1lRWhr9MA5AGFRX+/eWoUXYh4JJ44zVowP85qlAWxOzZ7OVJxB6cP/3EYvo227BgI+dVVJhDwtoasm2oU4e93z74wN2mug0ib9jizp3DjfS699f11/M2Fi0KXm/HHb1GrR139OanI0qnT9FHmU+axN6zBx3kHoftt7d/SddDO158sdmDV54v9QVpyRKzx3v37rntlHmBDj+cP4OMhdJoHPYy1r49n8+ttnKntW7N10EcLyIhcg1vUcSy/v3Nhltbw+iee4bn57r+evd7XA86FdUoLL0xW7RgL3E/YXnsWPYaP+MMHkgyZIhX7NlpJz53hx5qDrN49NHugJI0xAn9/Nj2MUEe0xMm8HOpDJN68cX+y1ZU8OAoG/yuaZmjTUWIcO90WV+3brm5PtV6JDIfJFHwtVq9un9bf/3V/a575ycRy/y2F0UsO/DA4G2ECSvyWspSNDO1YZdd+NwMGeK+Y61cyQNCdEziuETNv6ZjG75WjdJgw4gR4cdVnpe0cpap3m1RxbIhQ8y5x1TCBJg6ddx3t6BBZ6Z8q1GPQdD++c3Tw6Hq2zSFdC5VD5a0BhjmS7z57Tfv7zhhGNW8tjqm8L26N2gQakqDMPbckwfbnnyy/ToS/XgX4/WX5Jrw+z+OSjEeF5AeaiSjUqKUrsuoeY8BKFVK6LaMjwy5mC/atGFDoCqIPfdc/rZf7vz4oxtaiogfns4802wYsaVVKw6VVrcuG0gcxx2RnwQhOCRiIUd7VVay4d4kQAIAcvnhB87lly/OOMMb/kWGrhGCvdSkAVr2I7rxLmkYRmkYkQLjyJFuXgFZp2qw1Ue833+/Ky6acnfooXhsBlr89BN73gYhcwomZcECryf1FVfwMbnvPm8IwbCQQldcwecmamhH9f+hZk2zMf/tt3MHPEyaxOf+kEP4ty5wqHlH1HP8ww/e5aQR85dfXHHQRJzcQ37h0ZKGDJTHSBfw1HxjtowdywLOgAHsTZmE77/33odt2rD46OcRJmnShL3KZ8/mMMV16pjXEcLrWRmFsOcQ1VDod66D6jjvPNcz3LTcLruw8P/hh7ytoDx9UZ6ZbJ79pOe9jQHVZnSv3OacOW4+SKJwYdckfDlObq4clTCxTL2XevXyzvM7jn5imd43//KLVzg3Efa/k7VnmV8batXiULuPPeaKWi1amHPmmMKMSoKuRb+IB0884c2LEyd/kI0nehwcJzdE6dNP8/0ZVLf+TKQuox7jRx91/5NUbJ5PbMRHUwjsdevCj8f8+XZtCZpnyiUrtyv7THXwqxRU/O5vPYKLH19/bbccUTo52HWxLKh/KkZUscw2T3rQ/aaecxllJ0q/FhRK2sR22/H/aVT0e6AYPVXK3fsNFB45gLBQBIVsDqIY71c/sgrBDkCxUfZimRA8UjtNJkzw9xKz8RQDyWjUCB5KAIDsaNw4v6E7bZEv5+edZzZsx30JHTKER+DLHBwq0nAUJJTUqOEabBs14vyWb7zBBp4XX4w32rVhQ7MXneTbb805ieISJ3yqnvNu0qR4Bo4wo4vtedWvWTWs2OjRPKhk+nRvLsbnnnNH8wd5sBMlF8vatmXv9WHD2MhsG27SxMUXE511lpsDVHLddTw9Kh9+6IY9ToIuAlZWclhLk2fhq68Gh1pTxU4VW1G8bVvv7yRhGG2YOtX1pjXdu7aetkTRhP/LLw9fJsozo822a9TgY6Qb7k3H2EaElJhCT0qxbNCg3Dyq33zjFQvlYC8Z+pGIPXJ1/MQyXaywGckvj5efcGTTb7Ro4Z/v1oao/32LF3v7H/16VwXCoLr95vXty/e3Cdt+z9Zw5nevBnnQ9+vn/a2HSTbVqQuxfu3be283z3IY+v/ls89y365f5/vv73439S0219hee7GH0LnnxjunOnLARseO3jb06uXWsdNO3P/7iSWm5w7Ts6fff4EJv3v2gw/sB+7qXoBxB2IVShhR+8Sbb3Zznnfv7ub91qmstPvfiyN816plP6BXHrM4x67cPcvyMfCimFmxIjhvbTGi5yzOB7ZRCbIiLFWDH8V4v6oEvZMDUK4U+W2ZjLQe0mrV8nqKRR0hBAAAAMRFGqX8whgdeih/brtt/PpnzMg1UBGZwzAScXhINfyiKqqNHs1hC5s3d72/zj47Xtv82GSTwj+4hxn/w0JvyWeUMANA2Hx57Js25RH++nQiNu7PmpU7QjyKl5LJINm/PwuifrnMZBu++IIHLr37rjvaPkmen4YN2Wig3xPVqpWOMWGnneIJBLYeYmFeRrffnis4z53LOVX9wjCG0bYt0TnneK9DiW6QN7UpbLoJ/T40hczyG/zw9decrzfutnVMxg5VuAoahLFypVmwlWKZSQTWje3yPD3zDNdHZA6Nqe/j1VezB4aac23ECP+2qvgZePSwoEHH9aOPWLCeONE7ffLkZG3wo0cPzsvoh2psiyOsBK3jt13dczmqZ9lPP9kZCfV8iH7L6OjtTmMUfKtW3t8dOpg9TqN4xfrRsCHnz9xyy+D6bK+lVq1YCJMed7LP1NffZx/zKHzT8xZR8nxhfvvWtav9M6IpdHKabUmCKS+kyn33eb0669Rx+8mvv/Z6UKoEhWFU8XsmDqKy0v66kscsjbxxhTS++z0fJ7km9AFAGxqtWoV7esfBNjdrHExhnNVBeaa+0fbZw49Cey9WVcVbLyh3bTEwbpz7vdDCdaHf/8GGQ9mKZUncQ3XPsT//hKcYAACAwjBoENEJJ/gP1Bg2jP+rwowIcdBDDEmOP54NRRJTuEaVc85hoeTcc9NLHl8IHMd9YfAzdhERLV/OoRPTYLvtcqetWOF+HzCA86XMm+cd9Zz2C6N6DTRsyILIokUsiI4ZY15HtqFly1yvNRtDTqFfem144IH8bs/2mOjL6carww/PzXd6/PGcY1C/3484gj0WwsLbCMHCuKkvCvO6UjFdG7b7/dJLHOFBZcECotNOyxXSmjTJzT2TRAQwtfGCC9zvb7zhDdtIxJ64ROxdVadObh0yjLxN/y6PZ506XJ8tu+/OYrY0QIwZ44oA8n3Kb/vyXOntfuIJb5uCjCv16/P1dcop9nlpbr6Z6JNPvG2IS1DOsjhiWRpGats6ZNsbNvR696lte/JJ9/uYMeF1N2jgzcVnas+4ceH5/3Rmz2YxPipyX/zCW5muLTW0NZF9aM0o526ffVxvTDUctt4e00ATGQ759NO903VBXQ5K0vPo+uUSNIUZJeJ9tt03vQ22xy4IU063MHbdlb3h/dpiQj9O1aq5/wfffOPfv+ueZbrXusR2/5cu5ZzqMqVDWLulSJxELNOvu7TDunXsaP+8Y8qtmpQHH0yvrk8/ZfHpttvSqzMf7Ldf+nXqz0tpYuqb9YF8NutEoZDvDTvtFM2zTB10qudeLDbUZ8A4kUaiPi8AUAyUpVjWokV0F9hq1VzvMXiOAQAAKBaqVeNQY3FCBSbFdhStDLURNEJx661zDR+lyBVXsPAX5BXUunWyZORvvkn08sv8LKMav6QBXB2RX60a50nTw26lPapYFULnz7cLR5RGuKtix2RUe+st9rjLgqhGdCK+XqN48ukvwh06cP6qMG9JE19+ycWWo4825xkO8gRSqV8/tx9q25boootyj51uTLz33mT5eUznRjV6brutV4S44ALXM9iPiRN5pHKUUGxhRPEsqlWLvb70nIl6XX4hwKIYVdq35+tMGmUGDfJfds893eWS9iVBbbTtw4JyfkUx/g0cyJ9xcpap66jbVD3Opk0LP15C5Iq6RCz2Ss4+m0P7PfJIcF2SgQM5P2vPnnbL6+0hyg0feeml/Kmev0mTWOi94QZzHWHE/d8MCocddH3pgxh0oUoORNFzkfk9awX187bHICgMY9C1rIqyRN4+K04en2bNiPbd1zvtlFN4P8L6TVW8lKGm5W8Tqlh2+eXsoWbC9hh27sxtlTnWw9aTz29pPhdlkQPJT0TU8btOgvYvbEBIlFy3pv9x9Vpq144HnR1xhH2dhUSKrqWG6TpQr0uTt/26dURr18bfZiE9Kisqgm3Qc+Z4f6v9/2+/+Q92KAYeeICjxkRBvQ/T9GBMIzcnyC9BOdGLmbITyyZOJPrqK/vld9iBO/I1a+A9BgAAAKjYGjzHjyd65ZVcw0Y5UqMGC39JOfhg/jTl+unZk8O36Uard9/lkGU2BBklHn+cQ1IF0aWL97e8Bq66imjw4ORtkHTtaldXsfDCC3ytq6xYwd6Eku22c0OQBiFfJKMINHGMaVGvVxme8+KLWbRNwmabcbFhm22IbrzR9UK8/HI2fNv0LbY5YVT0Yzl8ePQ6VNIw0pjyiQWFb1SNUbaiTFj4QL2erl3dUcFduvB8ec1Kw5dfHjTZb6ghfGxp2ZLoP/8xz1MNbmkL72GeZTK3nDpPFY2StOeOO/hTXktz5xK9/z6HyZR07uwKiWpOGL/rT9+fqO2THoeqoayykg3Otv/5at6xtJCGe/Xaato0PIxXWp5lKqo44zfPBl3giHqu0ti3uDnLmjVzPe3OPZfooYfs2hWF3r25T5k/P3g5Nfyr2n/6tWPYMPd7UNjErAzxfoMOopCGZ1mQl1GUZzW/d4ag/Xv+efv6wzBtRw5EKEWC+hCZN7EYietZpl67psFTQUS9h5LkS9WpqMi9zmT0AJXmzXPzhK9eHV2MMqEODkiTP/90z53tYNCrr86mLcUoci9aFDw/i+g/fuhh+IuBQuQvTIOyE8uiKs2vv55NOwAAAIBS58ILeUSjGirChBCuARHYMW0a0c8/54aBC2Ljje1HHga9MA4ebM7tpPLuu0S//+7+lsaPMGHHNt8PEXtgvfRS8DLFRr9+udd6q1bxcrBNnMjeRSefbL9O1NwncTjwQKIff+TQUGrOrbTp0cP9ftppRP/4h3f+CSew4Tusb/njj9zcY2FkuV9hSC+LqOdICuxE2RhEbAzteg6yMM8yufyOO0Zvh2po69zZv61JDfFBhsig8KF+bUhiUJfrSmPhoEGcp0ZO/9e/iN57j2jUKM5Tpuaw8QuXl/T4mP4rwvZx7lz/eXHvPf08tWnD09T+Qd1X1RPOljQ8y/TjHddzMag9cfLlxQ3DGCa6vP02/5epOdGOPtobDcHUrrCwY6b7Mql4aApv2KUL0ZQp8eqTqPm0TJ7UcgDITTcFRzAy1R9noAFRvGs5KLz4rFn29cQJpde2bXoeVKbjWEiPI0nUiAPSTtmpkztNDzE7bZpXeBk1KlbTMsHU96nPLiZvQf3akQNIJBdeGLzNqH2EnxdpHLp2zT3+JjHzkEPYC1pl9Wqi66+Pn5tPXiNZCvry2Nr2l6qoleagpmKMTGLKD6yiDnjKgt12c79nGV62GI99mpE3dIrgbyM99MTQfsiHQF3RBwAAAIBLmzYcRiarkWobMhUV7ijsLEj6QFuzpjfGvHzpDXsRe+op11M/bNnttss1zlx7rdfoVs5Ur845a2rWNM/fdNPc3DT6eU0SNpCI6J13iL74Ine6Hh4sC5580h1ZPHBg/G3Wrh0t4fdPP3lHsf/3v/4eTETsmaeG2fND3iNh93Xc3A1XXEG0ahXR//5nFgdtDZRxjCnSyCzbLutQxbI5c4imTnV/R2lTEgollk2dysLP8OHpiVNyXemx1bAhf8rjXKuW21/IeRK/kctJj49JLAkTUIJCLsmQqnHzLwZNV8+l3yh9W0Epiqdp0P9jFLHMT3RWp/t54Cxblk7o46ieZd27sweBLhSG3RPqc6UeRtoP230w3dPHHcf7oubqvPRSPp5CmEVwvS6/0OQXX8xhF4nMntSyzp13Jpowwb/dpv2z/W9Lw7MsyEM7yMM5rC0mTN4PYevZDkoyHce4/WCa4kPU//4ddiB65hmvQGQSmHThRaJHiFCZPj37wWqm86k+sz72WG6kiqBrYPx4osmTg7cZ5Xxdfz0P5Ana5l13caoeG+bODb7Ogrbz11/8LGsTlcKE3G6WYoY8tjVrRrcLhOVh1EXRIOLsY9BAgDSwCW+dJWp/v/nmRGeemc12TPtRiDQhKqpQmDZlJZZdd134MhMmcOx/x/H/YwEAAADAhsXjjxMtXFjoVhQvtmJZzZquWBDn5WD8eDY8xV2/nPjqK6L77/dO04+JLrTpL+Nhx3DbbdMNQxOFRo0K45HasKH3uHXsGGxUevddon/+k6h/fzujbpgRIa6AVK0aj16tXz9ZsvSwa8LUvvbtic4/3w03aPIsO+kkovPO885X6+ra1S4UixwhLb0xwiiUWNa2LYcpbdQoWBiIc74vvpho5UrX89gmJPJZZ3GYXB3TPkTJP2jq89MwIKcppEa5BmzFsijGOykkmMKKyXMWFMZujz14oIh+TLp140/Z5hYt2DBkCmvZoUM6/5m6KBJU5/ffe3/7CU5h7dJDGxMl+1868UT+VPtreW7Utpx8spsL1q/tKn7zKiuJLrkk/JqOY1CNe5+oxtOTTopXR1z82iwHUxBxSOuoqOGuu3SJJ4hHPZ6yrgcfjLYeEUcOUNcLEwxM7LGHt18Ju4Z22MH9HtTn7L8/Ud++0dsTBZPAqoYl3GQTfvdSCTo/p54avs0ofaC894MYMcI+PKLfwDc/1H396y/+jNuH689kJqLk/SPyPk84jje8tqmdQX12mHgfNdxmPlFzDfthc95q1WKxWO0H00K/b849N/1tEIX/R11+uf+6+RiEmTZlJZaF/fnVrh3s+g4AAACADZPBg8PDTZYCWQkftmIZkZ3RCcQjShjG777jcIqlQClcK4sWBedFbtSIxSI9nKSODGtnMmSlmbMmKmFG4ilT3JH9useLn0eMKu58+KFdku+77+aBCy1b2u2TNCTGHV0aVSxr1Yo/1RHypjCMatiyqVOJRo+2b1NlpdeQJ+v8+2//dapVIzrqKP4uQ33qbZNESVtg6nPieK1E4fbb+VM15gadp7SENz2fzqpVRD/8EL7e7NnsWXTIIf5tC+q7t9mGB4qoXHSRew00bsx9i/Qq69OH6Ndfw9ulol4HQc86tmJZzZr+xtcgLzMT+sj0e+9lcT4uxx7Lx93kKZXEA8DPs8wWv7qDnpn8tqVPD/Isi5Mv5rTToq8j8RP11XC6psEQch9sRJE2baKFWrX5bzX9h8hzHuTV5ieS7LuvV9iW5yRNo7F+3m3DdpqOh81xl4QdeyFYZDjtNG8/robhTeqJG3eZqKRVZ1A9aihfEwcdlHwbQd5VpmczGSVEovZ/pu0895x//XGE4jTJOmeYzf/Kn3/y/7YpV3lSkjwDRQ0PG0SvXu4gHz1f33vvpbedfFE2YllYolcizmkAAAAAAFCuvP46hzZJmyhiWb555BGiW2+Nvl4S75xCEea1ov5u2jQ3VFuxko9wfflg6tTc/Fo6I0cSvf9+evlZJLYGnbB72OZc6J5jfp4kJsNXWM6qhg1zjflq/a1be40+cp4estSWqNfeTTexoCcNAnr75HfVUH/eebmGgyhII2uQIZGI+zTH8YbgMV0Xaig6222rpPE/EHS9Hn4478dLL6Vv/LT1LCNiT06b8E2NGrFnkcmzTBIkMNpcg1Onej1go4aasxWvdKNmlDCY6rwoYpl+3IcPj+6lYYvftRul34tKWIi0OGJZGLaCtp9wc8EFduub8uMk/T/fdddc8Vjn0kv50/TsFzcMowylqeKXl9PEuHHB/+vynGT5vGN735nug6AwnDqmcKMqM2ey8H7RRf55wUxtiDp4Jc4yQZj68KwGc0W5TsPyVdt4lgXNMwnq6vLdu7v/DX6eZUFh4ZMMsBk1yuxNbUv//rkejFGwOf9hz0RqHVl4dOrPKVGuWVPoT7/9ads2uC4h3Gf8AQO882wG80YZVKZuMyuK0OQRDz3ZpU65vIQDAAAAAPjRogXRkCHp13viifzwvOuu4cvm27Ns332Jjjwy2jqffeYN6VMq2B7TUvDUIsq2nTVqZDOC05YDDjBPF4Joq63858Vhjz3c8KUm1O35GfRNoRP90MUwvd1SpDWFL3ryyeAccWEsX+71flG3/fjj6eakNp2PjTbK9SAyGSizCDMYJpYFrRuXOGEYe/fmZR5+mOiTT7zzpDE5am7KOEbUrbf2X2enndijSRWH0uyPZHsPPZTo6KPZ+0wnTHQOwnQOgtZXxaesxDI/Q31UscwPtZ4XXuCcm7aEHeMkYRjDhIOw9U3bluGsbPuRuDnL/I697bV4xBHe39OmRe/7pMekul5YHXKwk+nZL8iQH7RfprCBUQSa887jPM9h9Qd5CEdFHqc5c3LD60a9lqMMggi7vtTz17y5fR1R+vmhQ/lTFXyTDuT44w/OJRy03SyJMzhBnR+n//JDPZZXX83C9IQJLPaY6gq6JqJ4lpm8m8PumSCvpf32S/4uEPQsQRTt2G63HefKs+HSS+3yVupeoUmvWdP6CxZwSPqgZYXg3H3vvmufY1Jy1VXJBpVlQdmIZTLOKwAAAAAASJfevfllxSaRr03YKZv1s6RtW/YaKDX0Y4rBYP789hvnfSoEf/7JL5ZRiXtNzpvn5rdSkcK59Ehp25ZztJno3p0/bbyOwsSyTTclWryY6IYbctetXz84R5xK1Ot78ODoOamTjmSPslxcbHKW+ZG0bSYDWFidTZvy/8XQobnhjw4+mO9N1TMvCJv2H3wwf+rehf/8J3txmupzHKIvviD6/fdo24pK7dpEN95o9qgM8hSOEy4wzJPkgQf8l5s7lz/1Ach+dV52WXDb4oplY8YELyvp1y+64BrUFhuxTPbPquH0tde8eaLibNs0P6oXkm6Mtn3+qqjg8MK6qK231fa/yXGi99sy/GFaEQyE8AqYDRu6xvK4OctsRAh9GellvuuunPtKijpRQ6gGIffnpJOIli2zXy9q/1FVFb7siy8SDRvmbZfkwQeJLrzQOy3Is2zRIr63grj55txtmdolQycH8dJLXCorc9uV1v9Cr178KQcdmq7FpN6rQffyGYFKAAAgAElEQVRO1Lr1/qh1a05pVK1adLE1SvQP/VrbY49wsSzoecLUVnWwZNizep8+PMgriKj/16ogGOT0U1HBbV26NLh+20Eu8hoMwyQuDhtmzvOn3381aviLi0Eew3Geb7OmbMSyIHbfvdAtAAAAAADYMAiLvW9LqXhH5ZMg46rpd7GTZXurVzePFM8HtWrFCzvzyCPptmPcOKKffnJD+ASFOOnenZc99NDwevUcWqZ7tUcPuxGxhSZpjhS/5aL0X1Ls8TtetmEYsyCL/GR168Zfd8mS3PQLW23FfYmeB7Bhw1wvTvW8VK8eHDoxCfr532ijbOv3m6aiCkJ6SKTjj+f5ujeonwHUlBtJrT9ILNND1arbmDfPvL246NuWv3WPKL/l1f+ozp3ZoH7lle40Gw+BsPPSoIH/OkH/kdKT6KqriDp18s5T79vhw/3rqKzkwQ1BOX1+/tnNTzdnjv9ykqT9VNJnv+HDib780u1Xe/RILkKo67/6avCyEnkO/vEPorvucsWys87yLudXX1zkwBnZHt3jTJ0XNo2I78/q1YnOOSd42WbN3IEw+nW7//5Ekyfn1qsj1+vfP/fe8ruXg8Syf/+b6O23c7ej07evf3i8IBFo++1ZqDj7bHeanutL0qcPP2NJj7g0sRHLoorQUYW3oGcF0zVow48/stCcpjfmZZex8CfDfYeF/N1zz1wxSv8Py/J9dZNNwsO7632uX3s22sgcblbnlVfs2kbEIVfDtisJOtYQywpEULJBAAAAAACQHknDMMqXklLMKZY1+jGdNs1uuWKn1NqbFbbhvCRhYqMQLBgcdxx7h44dG7y8bY67MM+ytLGpPwvhNV+eZVddRbRqFXshmUjiWUbEo5LDRib7kYVYFgd5frfYwk7Qta1PZ9iwbPJ+xmlLVKKIZUuXEv3yS3idcbx8wsSy667LXT4JukgahNyWHibX9hz07Rt/EIBpP19+2RXLTMcsqF2vvcZ5ao891n9b//53cC6qqVOD20zkFfP69w9fXrZ5//2JvvnGO+/II/3F8rTuAxmKV/XY8LvGwsKTmnKWSYG9enWizz/PFdQeeMBsbK6o4H1UjctEHBI2LqZcTldf7X5//XWzh1ZUsYyIQ/CFrW9z3QYRZfCKbFeQWLbNNv5ekX5t1AcM6HVOnuxeN088QbRmjVdIvOUW/z4p7BnLJgzjjBnR15fznn46ePsqaYplcZEC89q18evQ22obAjEI/f00jid4mkQRE088MXyZdu3s61PfK8KeF4Lub7/7cfBg729TxIqsKAuxTB9dBgAAAAAACkNSsaxfPx6lGfeBeN48DgFX7jgO0cknF7oVIG2EyA0nZ7NOEM2bs/HOJoyqDfLlNWtBW4Z8CQqtmNQI8ccfyesOWs7GaFitWnCYM+nFEza62I/OneOvmzQkWlLSNjKF1bdgQTZ5P+O0JYg450X9b65Tx9/bTfW6itJGP4Esa0Pim2+y2GyDnzHf5rlFXWeLLezbF0STJvFDVzdt6h8CUtYZ5F3tODyQQuW116KFTDPVqR5L/T/n1ls5DKuJXXbhz6BcN23bunWbqFbNHXBl0/f+9ZcbBtJE0Dnp1o2oTZtcseyAA3hwShDffx/etjD22ccsvqj7vcMO5hDNUe45k2BoQhfJ4xBFZDPdy2n8X+kCpL5P554bvJ/VqxM1bmxeNwy/5dX7SB0kJ73YbDzLOnZkL6kVK8K9qcLqCgvDeMstufP98vnJuq6/3t8LMEgMCrtmdK+wOEKu7oGu15HkPMs+PGoOPxXbgVRCmEMppoXtgB0TfvugX4dBYSvTpizEsqARMUnCPAAAAAAAgGgkFcsqKniUZtyEzGPGcNidcuaEE8zTBw7k/Ax6gnJQOqxbR3T//YVuRTDXXkv02WeusT2rUbMbbcT9ycSJ2dRPZC/E6aNb/ZYLmhaXww7j45CW2GnDIYfwZ7F4fabtOZh1yNoo9ZuWDRulX716bh6VKJ5lQciQezbLmgjzLEubOnXsc2olEctU3niDc32lgWnbQR46fvlgTEQ99jvuyN5ffthc1/r+2IY6nTKF82517Zrs+dGmbbaYwjCGLWuDeo+ZSBJC2uZaDgqBqH83iWX167NotN9+7jR1ftz+1bSe9HKR9Z9zDv8nyutKzbMqBNFBB8Xbth/6cVQ9S5OIA5JevcLzs/nlepL7Gnad3nUX0W238fdWrezuySSeZaNG5c7fe29zXaedxp9jx7q5c3Xiepb17k101FHeaXGuTV2UjiqW+c2/806io48m+vhjd7BAFKRXqq1Y5pdvLi2yEMt0sZOIBV8ZsjnL/SkLsWzFCv9511+fv3YAAAAAAGzoJBXLQDCOQ3T55eZ5G2/Mz8VRjGkARKVGDR7hXwz3+sSJRPXqxc8DcuGF/i/p6n49/rj/i3459nX77sufhc47l5VnWVZiWRyPDRN+ITlVBg703/abb+YuH+d+TUMsS4s06jSFblN/B21DvRfq1eNcX0lRPbFUgq7TfIcJVbExyuqecjJnZhgVFfFzG0lUT7k0rhcbsSyKoGbLxx+HL2MThjnKPL/6pAiirlOrFtH06WzsV+tM2r+a1nvySRZSZZ7Fs88muuMObsN//+uNMiYE0X332W0rDc/xNM75sce6oQHDQmGG4bfciBFeT+JXXgn3LkviWWbLW2/xM1gYcXOWXXaZnRddUsL23e+8tmzJ8zp1Mi+jRpk488zc+VHz2V5wQfgyfsJsEG3a8GfY/eDXzvr1OQS2CdPAoVat7J6RklIWYpl0c9WpW9c/wSIAAAAAAEifuCGFwIbH1Kn8IrTttoVuCYiDHP3evHnh2rDllkS//uoa0uJgkyckzvrFTpAR6fff+bPcorQU07kaO5ZHlU+fnjsvjkip7lvPnrnzk4plUTzXbLax667B87t0Cc8pFRVZh41ATuTu0223ZZe/L6pnWSHp0iV4vuPkL5elzpo1RJdc4m2LjqlN0junU6fceUEhCPXzlua5kuEmg0gyKCqKWBYkBurTkh4LUw62Ll2Izj/fvP2OHaN5esUhiVgm59vmpUvaftv3rm7dvHnWorYlzLMsbfzEsrBtmubrXp1xrlV1nSTeWkHbnjkzOCQtEdHBB/OnTX9BFO7R2qYN0TXXBC9z5ZW502yfLWQOOp3//c8V3HT86hw2jCPJXHpp8DaTUNZmjEKPhAMAAAAA2NCQyeSzzmcESp8BAzi8it8LFChu2rUjuvFGogceKHRLsiENsazYjN2Sjz8Ojs4i89wU2ktVhj9K+72+EOflmWe8Hl916vD9Y+r/4oyaTisMY5Q6/dYJWk+GAHv2Wc4ZJdGFmHr1eL6tZ5Jt24j8PcvC1ssC03nx84Ajys+Iej/q1cud9q9/efN+yfaZ8mmlhem4+Bmtw87d+PE8OMBkrFXXPfJIDsfrJxBF5f77iS6+ONo6p53GIXKffprDIJqwuc/jPJ9nJZbddBN/duvGAwiSkNYgvf/+l+ibb8KXszn3f/1F9OKLdtsNqu/DD4keecQ7LexcDxwY3+s+iLQ8y2yvEz+xrH373Gmq95SpTWGCvx9+4f0XLw737NLzg9rcS37HRg05fOyx3He1ahW8fX0bd99tnm8j/JkGx9kOkp02LTcyytNPB6/j156aNTkUY9yUDTYk6k6EEAOFEEuFEMuEEGcY5o8SQqwSQvx7fTlGmXekEOK/60tAZORwfvwx2nQAAAAAAJANs2dzWI208wYAAIqPo4/O9mVVsmQJ0cqV2W9HJYlYVkweTCY6dQo+b/vuS/Tcc8E53fLBRRdxUXPjJKGQ52WPPcweX5KFC9kDYZ99/PO7BFFosSxs2erViebM4TwyRGyYk55jb7/NocGyIswLKB8hZU3GTzUMo2po9Gvna6/Z5Wfr1o0/8+EZ2qsXUf/+/F0Ivn4vusjr5VUIttmGP9U+zM/bzE88Ur2qbr2Vw/H6EVWAP/BAolNPjbZO48Zs6N5zT3MuH7UdUcUyvf1TpvCnFLezEss6d+bPjTZKfv/5rd+5c7Q8cB07ujlCTUJNlHbWrOl/rnT69fOf17WrGx7Ztj1PPkn08MN225Y8/zzR6NH8/cwzvaE2g7aXpmfZokU8uESyxRbm5UzizOmnE737Lr+DbrVVem169VUuOttsEy6WDRni/W3r9WrixBO960QRvuU2ZE5afSCKTRvWrAmv349atXJzbu+5Z/A6hXxms7xtcxFCVBLR1US0BxGtJKI3hRALHcdZoi16r+M4x2nrNiais4moJxE5RPTW+nV/itOWxo2JfvjBPB0AAAAAAOSPunWJJk8udCsAAOWEn7EkS5KIZdJYbRt+KW0eeohowYL46wtBtPvu6bUnLvXqsTdF2mTlWZak3h12MBvj0sJWEIoSetGmDknjxkQnnWRevnv3eNuJ2o6oYpkMb2UjUNm2QSfovOjtlLmNwrjlFqIJE8LDeKWN47ABO4t7VkU9VgMHsieQziabuMfvn/+0q7dmTaLVq93fQWEY9bYUqxexCZOIqrf/+ON58JsUekzhGOOIZXXrumF+g7YfB7/ztHQp/x/KsHVRCMqX5be9uPsyYgTfu88+G299la5d4623226up+isWeZlsh4gJMV3yXXXcZ46HZOnKxF7xOu56848M1k/XqOG61XVuTPR+++784LEsmrV7AaP6sdvzJjobYyyjZ9/doVwvzaYMIllWQ42KaRYlsSzrBcRLXMc51PHcaqI6B4isnXy3IuInnUc58f1AtmzRDQwZB0AAAAAAAAAAFTYcFwbAkle0nfZhWj5cqLDDkuvPVHYbz+iu+4qzLaLmVI0bAdxzTXuNZaFZ5k6ct/Pq0Gvv5g49FA2Gh9/PP/2O/9ShJJeLpLp09kzY2BGliohgr0M4h7TunVzDc5xkOFYw5BGZOmNkxUdO/KnmsvuySeJli1Lp/5evby/bcQy6QUalAOyWFiyhOiyy8xeVmECchSxLIilS72DAqRHUrEev7Vr/edlYchP4x5q1YrDNmaFvt977BGvHttcW37eUw89ZL+tWbP8B2vY0q4d9ze33OKdrotlu+5KdPjh/N0UttDmutHX22cf/txrL6umGlH/zxs0cN8hXnvNvl35vh9KVSxrQURfKL9Xrp+mc6AQ4j0hxP1CCBlN03ZdEkKMFUIsFkIsXrVqlbEhCMMIAAAAAAAA2JB4/HFO0p5v74E0+PBDzvVQzCR9SS/F8xJEnNCAxUbWhhd5zvMR/o6IvYfkiPsswzA+8ghRnz7R26duNy5J1m/WjPuadu34t18usPHj2TtJhoiUVK/OOX+yum7UMIwmESItAXLAAKKNN462znPPEb3zjt2yo0ezOH/ssdHbZuKEE4haGKyD993H4Uo32yxafbbH8ZFHvHmhbM77TTcRff558eTpDbrPt9jCG8ZNZdQo/pQ5xPzEsihtMNGihdfjeocdOOSjyXPIFpvrQfYB227Ln7Yh+vR8Uyp+xyRJfzFsmP2yDRrwp7r/zz7LeQSzRN2/pk29IRNtuPhivkai9kk6eq6uKPnZ4p6jgQPd3NwSKZZtthlfZxdcQDRzJk+zzeUm2zNiBFHfvrnzd9yRj5lfKOeXX+ZctDpnnOFeJ377LOfbtDXfnmVRwqemTewwjERkOhR6t/goEd3tOM5qIcR4IrqNiHazXJcnOs48IppHRNSzZ0/jMq1b88g903QAAAAAAAAAKDc6dCA6++xCtyIecUMEgcLx6KOFbkHxc/31PAJ8u+3yv+0wQ1WPHvwZJf+bNAraiA1RwjvGIQ1DnKxD9wQQwvVayjf5EMuefZZo6lSi88+3XydKGNaKCjbypsXmm3OOSv2cN2zoelhkQaNGXg/KIKFInpuaNYnatMmuTVGJa7hu08Z7vSXxLIty3VZURLsuTbzxRriwu/32RB98wIKhrYBBxIL7f/7jze+URl/kd4zCPHhV+vcnuv127tuffJKnDRiQvG1hXHUV0f77R1/v2WeJ2rfnEpVXXnE9oEyk0Vc6TrxzK/9PGjRg700ios8+48+o4bwPP5xo0KDobfAbzDJzJtG11wa3RbY/aRjGKPeVLXPm8HG96qr06w4jye6sJCJVy21JRF+pCziO84PjODLq7w1E1MN23SjMmpU7kqNOHf8YqwAAAAAAAIDkQPQA5cabb7JhGZQvWYUMrF8/XdEgCmGGrq5diaqqwvOnNGzIn5MmER1zjLtuOVDMYTj9RIijjuLP6dPTq39DI+6+m8IwbijHMapYJkTh7q8WLbyez4ccQjR8eO5yW24Zz6DfpYt5eqGvBSFYXMl3SO799iP64ovw5XQGDIgnlBGx1+8pp8RbN2tk7i81dKKNgKTeJ2nfOw8/TPTpp27OQXUbfu1Q57/8MovQOkEetFncD02aEF15Zfr12pDEs+xNIuokhGhHRF8S0SFEdKi6gBBiU8dxvl7/c18i+mj996eJ6HwhRKP1v/ckoilxGzJyJH8edxwnqmvdmkcnyOkAAAAAAACAdPnrLzffBADlQs+e/qFuQGlTzGJJPrAJaTR5MoceO/ZYNrQNHx4/rOTWW8dbLyuK4fyPHk10881uO0yGypYt+bNzZ6LVq3Png/xQisc8rWs7X55lWXD33fnZTpj4kBWjRxO991622wijFO8NFb9z1L490YEHcqhIWzp1Ipo3z+u1vemm/CnDMaqYjl3a944pJGUUsczPU+3II4mOPjp8/bi88grRggVEc+cmryspscUyx3HWCiGOIxa+KonoZsdxPhRCzCCixY7jLCSi44UQ+xLRWiL6kYhGrV/3RyHETGLBjYhohuM4iTOMFbpTBgAAAAAAYEOhWBOyAwCAiQ4d+HPy5MK2IwvSMl7WrMk5oyRxhbLFi9nwKAW6Aw9M3rakFIMx/6abOJzYR+uHkZtCYA0YQLRoEdEuuxDNmJE7H8Qj6nk3eZYVO1EN1/fcQ/T22+H1BBn49d8bil02yX4muaZkXrlCYtP+GTOi5xcsNJ98wp9RxDIiojFjvL9r1/a/PmQePHXwSj7unShimR9BAyT19ZctM3vWLVvmH/a4d28u48aZ+6V8ksSzjBzHeYKIntCmTVe+TyEfjzHHcW4mopuTbF8yfz7R2LFEf/zBv1es4N9E8C4DAAAAAAAAAAA2dBo0KH9DbpxcMlkgc6QREa1a5YZ3jEqa56tdO/5s0iS9Om0x5YNSv+uGxv79/ddPuv0NDWng/fvvaOsFCUXFjm2bDz6Yi04pe5ZlTSleD2njd2+0bet+nzYtb82JTCHP4U03Ed1wg9d7K8t7J0wMS+oZ5re+HJyk4zddZYstuBSSRGJZsTB1qiuUSf74g6dDLAMAAAAAAAAA4McttxAtXFjoVgCQjK+/JmrUKHy5fJNEnKpViz/TMG5Om0a03XZEgwYlrysNNsRcWIVA5u1ZuzbaeqXsWZYU6f0ycKC3Xr9j0bKlG3Z1u+3SaUOxE3asg66bUhcUTfv2/fdufw38adKEaIrmUpSPPiaOWDZ4MOfFC8ImP1spUhZi2YoV0aYDAAAAAAAAAABERKNGcQGglGne3P1+770cCipftG/PYZPSzmP58MMsZnfunLyu6tW9eWXywXXXEZ18MlGLFrnz1JxlYSQ1pg4aRHT++cnqKFWSepap52jzzTlH0Zw56bQtK5JeL40aEX32mfm6NW2jenUW1j7+mI9POZLFQIRSEmJVTO3eeOP8t6NcOOcczkO3887533aQ2PX44/7r6ctHuZYXLeL+pZgpC7GsdWui5cvN0wEAAAAAAAAAAAA2FIYPz+/2nnyS6JVXXI+UtGjXzs3bVYoMHOh650hUo2K+RuX37Uv0++/xc9DpfPVVOvXkA+lZloZYVrs2C0LFSpoeS2pIvZo1+V6cOTN3uX793O/lKpQ9/jjRVlvxd3mvFot3WLG0A8SnRw+zppEPTHkzbfjuO/6ME8axf//cUMPFRlmIZbNmEY0eTVRV5U6rUYOnAwAAAAAAAAAAWVJuIWgAiMImmxRPvrRSIq6hstBsummhW2BP3DCMG0oOLhsqKog+/TR3+kcfcQjGcmfwYPf7Sy8R3XUXUf36yest1LVVav0NyI4uXVg/iTooRfckLLdrqizEMqLcTgZ/aAAAAAAAAAAAsmbBAqJtty10KwAApYQahjEsn0waFMKYKQ2q1avnf9uSpDnLpKBZCsTx8kjC5pvnZzvFxDbbcCkW4pzrpP1KudjbS3E/Zs5M9/qrV49o9er46+ejz5k2jahPn+zqN1EWYtnUqURr1ninrVnD00eOLEybAAAAAAAAAACUP8OGFboFAGTPww8H5zACdpTbCPwg7rmH8+d17eqdvsUWbli7rJE5yzYEsUyyIV1jpYzpPJ18MtFOO5XGc0W5XmdLlxLVqlXoVpg566xCt8BLPkIJFyIUc1mIZStWRJsOAAAAAAAAAAAAAOwYOrTQLSg/NtmEP1u3Ns9P0xhdCMP2JpsQTZqUO33Jkvy1QYbL69w52nr5DMPYpk3hchaB/LPzzkR33skh8HQuvTT77ZeryJUWUfuKYuahh4jmzEknbGgQ5XZNlYVY1rq1+Y/F74EDAAAAAAAAAAAAAIBCsf/+RA8+SLTPPub5pRgmLC0mT3a9wpKw6aZETz1FtOOO0dbLl1i2ahVR7docDi0p+Q7DCOIxZgzRwIHBNutrr41+zdqyIfcrGxq77cYlK8q1zykLsWzWLKLRo4mqqtxpNWrwdAAAAAAAAAAAAAAACs0VVxCNH0/UoQMbGPffP3ydNAyRpWbMvPDC9Oraa6/o68iwYlkLC02apFdXuRquSwmb60WIcOeO8ePTaQ/wB/dJepTbsSwLsYwot0OCUg4AAAAAAAAAAACQyzvvEK1eXehWbHjsvjvRf/+b/+2WmzEza+TxKsWcZSpjxxL98UehWwGKCb0v+PbbDdOGviHuc9qUq0BfFmLZ1KlEa9Z4p61Zw9NHjixMmwAAAAAAAAAAAACKkW23LXQLAChe8uVZljXXX1/oFmxYlIJooF/TMndi3PXBhou8FmR/WS6Uxe6sWBFtOgAAAAAAAAAAAAAAxUqaRulSMOIXE6XoWVauXh6lRCkJSSefHG89mUswzRCioLQptz6nLMSyxo2jTQcAAAAAAAAAAAAAAACdfHuWNWhAdMIJyeqAWAZskNdHtZix5jbZhOi664ieeiq9NoHSpFz7nLIIwwgAAAAAAAAAAAAAAMil3IyZWXPCCURHHEHUvn1+tvfzz/nZDgBpMG5coVsAioly+38pC8+yH34wT//xx/y2AwAAAAAAAAAAAACAtEjDEFluxsysOfxw9poopYhVpRQCsNzB/Va8qOemQQOi3XYrXFtKnXL1LCt5sWz+fP95rVvnrx0AAAAAAAAAAAAAAKQJcpcBG/bdl2izzeLnogKlh7yfZR4xG6Q4NGhQ+u0pNX7+mej55wvditKlXMWykg/DGBTTd9as/LUDAAAAAAAAAAAAAAAA8k2zZkRfflnoVoB80qYN0emnE40ebb/O9tvDCxGkC8SyIsMvBCMR0ciR+WsHAAAAAAAAAAAAAABp0KkTf3bsmLyuigoOKTh7dvK6AADFgRBEF1xQ6FaUJhAMk1Oux7DkxTIAAAAAAAAAAAAAAMqJww8nat+eqE+f5HUJETzYHACQnFtvJZoxg6hXr0K3BID8Ac8yAAAAAAAAAAAAAABAZghB1LdvoVuxYbF4MdHy5YVuBShVOnUiuuOOQreifLnjDqIlS9Kpq9wEnkIAz7IiZP78QrcAAAAAAAAAAAAAAABQ6vTowQUAUHwcdlihWwBUpFhWbsJjRZKVhRADhRBLhRDLhBBnBCx3kBDCEUL0XP+7rRDiTyHEv9eX6+Jsf9y4uC0HAAAAAAAAAAAAAAAAAAAAcSg3sSy2Z5kQopKIriaiPYhoJRG9KYRY6DjOEm25+kR0PBH9S6viE8dxto27fSKi339PsjYAAAAAAAAAAAAAAAAAADYUyjWEYJbUrEm0erX7u1yPYRLPsl5EtMxxnE8dx6kionuIaKhhuZlEdBER/ZVgW5EpN1UTAAAAAAAAAAAAAAAAAAAgn3z1FdHKle7viRP5s2bNwrQnK5KIZS2I6Avl98r10/4fIUR3ImrlOM5jhvXbCSHeEUL8Uwixs99GhBBjhRCLhRCLV61aZd248eOtFwUAAAAAAAAAAAAAAAAAAAAajRsTtVCUn4suIlqzhqh69cK1KQuSiGUm363/d8ATQlQQ0WVEdIphua+JqLXjON2J6GQiuksIsZFpI47jzHMcp6fjOD2bNm1q3bhrrrFeFAAAAAAAAAAAAAAAAAAAAIQgBFG12Am+ipckYtlKImql/G5JRF8pv+sT0VZE9IIQ4nMi2pGIFgohejqOs9pxnB+IiBzHeYuIPiGizgnaAgAAAAAAAAAAAAAAAAAAkAkdOhS6BSBLkuh/bxJRJyFEOyL6kogOIaJD5UzHcX4hoibytxDiBSI61XGcxUKIpkT0o+M4fwsh2hNRJyL6NGoDatQgqqoyTwcAAAAAAAAAAAAAAAAAABCmOHkR+Pln6A7lTmzPMsdx1hLRcUT0NBF9REQLHMf5UAgxQwixb8jquxDRe0KId4nofiIa7zjOj1HbUL9+tOkAAAAAAAAAAAAAAAAAAABRaNCAqHbtQrcCZEmiyJKO4zxBRE9o06b7LLur8v0BInogybaJiH70kdf8pgMAAAAAAAAAAAAAAAAAAACgkiRnWcFp3TradAAAAAAAAAAAAAAAAAAAAABUSlosGzw42nQAAAAAAAAAAAAAAAAAAAAAVEpaLFuwwDz9iSfM0wEAAAAAAAAAAAAAAAAAsGHRoAF/1qxZ2HaA4iVRzrJCMn8+0Q8/mOetWJHftgAAAAAAAAAAAAAAUK688grRTz8VuhUAABCfuXOJttySaODAQrcEFCvCcZxCt8Ganj17OosXLyYiorZtiZYvN3ygdt0AACAASURBVC/Xpg3R55/nrVkAAAAAAAAAAAAAAAAAAAAgY4QQbzmO0zPteks2DGOQ99isWflrBwAAAAAAAAAAAAAAAAAAAChdSlYsa93aPH3jjYlGjsxvWwAAAAAAAAAAAAAAAAAAAEBpUrJi2eDB5unDh+e3HQAAAAAAAAAAAAAAAAAAAKB0KVmx7Iknok0HAAAAAAAAAAAAAAAAAAAAQKdkxbLly6NNBwAAAAAAAAAAAAAAAAAAAECnZMWyyspo0wEAAAAAAAAAAAAAAAAAAADQKVmx7O+/o00HAAAAAAAAAAAAAAAAAAAAQKdkxbI2baJNBwAAAAAAAAAAAAAAAAAAAECnZMWyWbOIatTwTqtRg6cDAAAAAAAAAAAAAAAAAAAAYEPJimVERI4T/BsAAAAAAAAAAAAAAAAAAACAIEpWLJs6lWjNGu+0NWt4OgAAAAAAAAAAAAAAAAAAAAA2lKxYtmJFtOkAAAAAAAAAAAAAAAAAAAAA6JSsWNa6dbTpAAAAAAAAAAAAAAAAAAAAAOiUrFg2eHC06QAAAAAAAAAAAAAAAAAAAADolKxY9sQT0aYDAAAAAAAAAAAAAAAAAAAAoFOyYhlylgEAAAAAAAAAAAAAAAAAAICklKxYhpxlAAAAAAAAAAAAAAAAAAAAICmJxDIhxEAhxFIhxDIhxBkByx0khHCEED2VaVPWr7dUCLFX1G3PmkVUo4Z3Wo0aPB0AAAAAAAAAAAAAAAAAAAAAG6rFXVEIUUlEVxPRHkS0kojeFEIsdBxnibZcfSI6noj+pUzrSkSHENGWRLQZET0nhOjsOM7fUdrgOMG/AQAAAAAAAAAAAAAAAAAAAAgiiWdZLyJa5jjOp47jVBHRPUQ01LDcTCK6iIj+UqYNJaJ7HMdZ7TjOZ0S0bH191kydSrRmjXfamjU8HQAAAAAAAAAAAAAAAAAAAAAbYnuWEVELIvpC+b2SiHZQFxBCdCeiVo7jPCaEOFVb93Vt3RamjQghxhLR2PU/VwshPuCvPXqYll++nEiIt96y3w0AAKAmRPR9oRsBACg70LcAALIAfQsAIAvQtwAAsgB9CwAgC7pkUWkSsUwYpv1/IEQhRAURXUZEo6Ku65noOPOIaN76Ohc7jtPTtBwAAMQFfQsAIAvQtwAAsgB9CwAgC9C3AACyAH0LACALhBCLs6g3iVi2kohaKb9bEtFXyu/6RLQVEb0ghCAiak5EC4UQ+1qsCwAAAAAAAAAAAAAAAAAAAEDmJMlZ9iYRdRJCtBNC1CCiQ4hooZzpOM4vjuM0cRynreM4bYnDLu7rOM7i9csdIoSoKYRoR0SdiOiNBG0BAAAAAAAAAAAAAAAAAAAAIDKxPcscx1krhDiOiJ4mokoiutlxnA+FEDOIaLHjOAsD1v1QCLGAiJYQ0VoiOtZxnL8tNjsvbnsBACAA9C0AgCxA3wIAyAL0LQCALEDfAgDIAvQtAIAsyKRv+T/27jtciiJ9G/DzCoKIgWgCMWFCURFM62IO6LpiFkVFPvOac8AsqKuYdw38VldQVnRRMKBizopEQVAkKUlyRjL1/VHTOz1zuns6VIeZee7rOtfMdKiq7unu01NvV5Uo5ThUGBEREREREREREREREVHFi9INIxEREREREREREREREVFZY7CMiIiIiIiIiIiIiIiIqlZZBMtEpIOIjBeRiSJyS9rlIaJsE5FtReRTEflJRMaKyNW56Y1E5EMRmZB7bZibLiLyZO4aM1pE9rWl1SW3/AQR6ZLWNhFRdohILREZKSLv5D7vICJDcteJV0WkTm563dznibn529vSuDU3fbyIHJvOlhBRVohIAxHpLyI/5+5fDuJ9CxFFJSLX5n4P/Sgir4jIRrxvIaKgROQFEZkjIj/aphm7TxGRtiIyJrfOkyIiyW4hEaXB5drycO430WgRGSAiDWzzHO9H3GJHbvc8XjIfLBORWgD+CeA4AK0AnCUirdItFRFl3FoA1yuldgdwIIDLc9eNWwB8rJTaGcDHuc+Avr7snPu7GMAzgL75A3AXgAMA7A/gLusGkIiq2tUAfrJ9/juAx3LXloUALshNvwDAQqVUSwCP5ZZD7nrUCcAeADoAeDp3v0NE1esJAO8rpXYDsDf0NYb3LUQUmog0A3AVgHZKqT0B1IK+/+B9CxEF9SL0+W9n8j7lmdyy1nrFeRFRZXoRNc/3DwHsqZTaC8AvAG4F3O9HSsSO3O55XGU+WAZ9AZ2olJqslFoNoB+AjimXiYgyTCn1u1JqRO79UugKp2bQ147eucV6Azgp974jgD5K+w5AAxHZGsCxAD5USi1QSi2EvmDzpo2oiolIcwB/AfCv3GcBcASA/rlFiq8t1jWnP4Ajc8t3BNBPKbVKKTUFwETo+x0iqkIishmAQwA8DwBKqdVKqUXgfQsRRVcbQD0RqQ1gYwC/g/ctRBSQUuoLAAuKJhu5T8nN20wp9a1SSgHoY0uLiCqY07VFKfWBUmpt7uN3AJrn3rvdjzjGjkrU1bgqh2BZMwDTbJ+n56YREZWU6z6kDYAhALZUSv0O6IAagC1yi7ldZ3j9IaJijwO4CcD63OfGABbZbubs14n/XUNy8xfnlue1hYjsdgQwF8C/RXfx+i8RqQ/etxBRBEqpGQB6ApgKHSRbDGA4eN9CRGaYuk9plntfPJ2I6P8BeC/3Pui1xauuxlU5BMuc+qlViZeCiMqOiGwC4HUA1yillngt6jBNeUwnoiokIicAmKOUGm6f7LCoKjGP1xYisqsNYF8Azyil2gBYjnxXRk54bSGiknLdm3UEsAOAbQDUh+6iqBjvW4jIpKDXEl5jiKgGEekGPcxOX2uSw2LGry3lECybDmBb2+fmAGamVBYiKhMisiF0oKyvUuqN3OTZuSb+yL3OyU13u87w+kNEdgcDOFFEfoVu2n8EdEuzBrnujYDC68T/riG5+ZtDdzHAawsR2U0HMF0pNST3uT908Iz3LUQUxVEApiil5iql1gB4A8CfwPsWIjLD1H3KdOS7WbNPJ6IqJSJdAJwAoHOue1Yg+LVlHtzveVyVQ7BsKICdRWQHEakDPZDbWymXiYgyLNcv7fMAflJKPWqb9RaALrn3XQC8aZt+nmgHAlic60ZgMIBjRKRh7snMY3LTiKgKKaVuVUo1V0ptD30/8olSqjOATwGcllus+NpiXXNOyy2vctM7iUhdEdkBehDr7xPaDCLKGKXULADTRGTX3KQjAYwD71uIKJqpAA4UkY1zv4+sawvvW4jIBCP3Kbl5S0XkwNy16jxbWkRUZUSkA4CbAZyolPrDNsvtfsQxdpS7h3G753FVu9QCaVNKrRWRK6AvqrUAvKCUGptysYgo2w4GcC6AMSIyKjftNgAPAnhNRC6A/vF4em7euwCOhx4c8g8AXQFAKbVARO6DvvACwL1KqeJBbYmIbgbQT0S6AxgJHaxH7vUlEZkI/WR2JwBQSo0VkdegK6zWArhcKbUu+WITUYZcCaBv7gfeZOh7kQ3A+xYiCkkpNURE+gMYAX2/MRJALwCDwPsWIgpARF4BcBiAJiIyHcBdMFu/chmAFwHUgx6fyBqjiIgqmMu15VYAdQF8qOPn+E4pdanX/YhH7Mitrsa9TPmWbERERERERERERERERETVpRy6YSQiIiIiIiIiIiIiIiKKBYNlREREREREREREREREVLUYLCMiIiIiIiIiIiIiIqKqxWAZERERERERERERERERVS0Gy4iIiIiIiIiIiIiIiKhqMVhGREREREREREREREREVYvBMiIiIiIiIiIiIiIiIqpaDJYRERERERERERERERFR1WKwjIiIiIiIiIiIiIiIiKoWg2VERERERERERERERERUtRgsIyIiIiIiIiIiIiIioqrFYBkRERERERERERERERFVLQbLiIiIiIiIiIiIiIiIqGoxWEZERERERERERERERERVi8EyIiIiIiIiIiIiIiIiqloMlhEREREREREREREREVHVYrCMiIiIiIiIiIiIiIiIqhaDZURERERERERERERERFS1GCwjIiIiIqKyISK1RGSZiLQwuWyaRKSliKgY0j1KRH61fR4vIu39LBsir3+JyG1h1/dIt7uIvGg6XSIiIiIiIrvaaReAiIiIiIgql4gss33cGMAqAOtyny9RSvUNkp5Sah2ATUwvWw2UUruaSEdELgRwjlLqMFvaF5pIm4iIiIiIKA0MlhERERERUWyUUv8LVuVaLl2olPrIbXkRqa2UWptE2YiIiIiIiIgAdsNIREREREQpynWz96qIvCIiSwGcIyIHich3IrJIRH4XkSdFZMPc8rVFRInI9rnPL+fmvyciS0XkWxHZIeiyufnHicgvIrJYRJ4Ska9F5HyXcvsp4yUiMlFEForIk7Z1a4nIYyIyX0QmAejgsX9uF5F+RdP+KSKP5t5fKCI/5bZnUq7Vl1ta00XksNz7jUXkpVzZxgJo65Dv5Fy6Y0XkxNz01gD+AaB9rovLebZ9e7dt/Utz2z5fRAaKyNZ+9k0pInJSrjyLROQTEdnVNu82EZkpIktE5Gfbth4oIiNy02eLyMN+8yMiIiIiourAYBkREREREaXtZAD/AbA5gFcBrAVwNYAmAA6GDiZd4rH+2QDuANAIwFQA9wVdVkS2APAagBtz+U4BsL9HOn7KeDx0EKoNdBDwqNz0ywAcA2DvXB5neOTzHwAniEj9XDlrAzg9Nx0AZgP4C4DNAFwE4CkR2csjPcu9ALYFsGOunF2K5v+S267NAfQA8B8R2VIpNQbAFQC+VEptopRqUpywiByTS/80AM0AzARQ3N2m275xJSK7A3gZwJUAmgL4CMDbIrKhiOwBvf/3VUptBuA46O8XAJ4C8HBueksA/UvlRURERERE1YXBMiIiIiIiSttXSqm3lVLrlVIrlFJDlVJDlFJrlVKTAfQCcKjH+v2VUsOUUmuggzL7hFj2BACjlFJv5uY9BmCeWyI+y/iAUmqxUupXAJ/Z8joDwGNKqelKqfkAHvTIZzKAHwF0zE06GsAipdSw3Py3lVKTlfYJgI8BtPfYfssZALorpRYqpX6Dbi1mz/c1pdTvue/kPwB+BdDOR7oA0BnAv5RSo5RSKwHcAuBQEWluW8Zt33jpBOAtpdQnue/oQegg4QHQwcuNAOyR68pzSm7fAcAaADuLSGOl1FKl1BCf20FERERERFWCwTIiIiIiIkrbNPsHEdlNRAaJyCwRWQLdSqlGCyabWbb3fwDYxG1Bj2W3sZdDKaUATHdLxGcZfeUF4DeP8gK6FdlZufdnw9ZKS0ROEJEhIrJARBZBt1jz2leWrb3KICLni8gPue4OFwHYzWe6gN6+/6WnlFoCYCF0KzNLkO/MLd310N9RM6XUeADXQ38Pc0R367lVbtGuAFoBGC8i34vI8T63g4iIiIiIqgSDZURERERElDZV9Pk56NZULXNd590JQGIuw+8A/tfySUQEhcGdYlHK+Dt0F4iWFiWWfxXAUbmWWR2R64JRROpBdyn4AIAtlVINAHzgsxyz3MogIjsCeAa6u8jGuXR/tqVb/H0VmwlgO1t6mwJoCGCGj3IFSXcD6O9sBgAopV5WSh0MYAcAtaD3C5RS45VSnQBsAeARAK+LyEYRy0JERERERBWEwTIiIiIiIsqaTQEsBrA8N06V13hlprwDYF8R+WtuXLCrocfFiqOMrwG4RkSaiUhjADd7LayUmg3gKwD/BjBeKTUhN6sugDoA5gJYJyInADgyQBluE5EGItICehwyyybQAbG50HHDC6FblllmA2guIhu6pP0KgAtEZC8RqQsdtPpSKeXaUi9AmU8UkcNyed8IYCmAISKyu4gcnstvRe5vHfQGnCsiTXIt0Rbntm19xLIQEREREVEFYbCMiIiIiIiy5noAXaADIc9Bt6yKVS4gdSaARwHMB7ATgJEAVsVQxmegxxYbA2AodOuwUv4D4Kjcq1XmRQCuBTAAwAIAp0EH/fy4C7qF268A3gPQx5buaABPAvg+t8xuAOzjfH0IYAKA2SJi707RWv996O4QB+TWbwE9jlkkSqmx0Pv8GehAXgcAJ+bGL6sL4CHoceZmQbdkuz236vEAfhKRpQB6AjhTKbU6anmIiIiIiKhyiO6Kn4iIiIiIiCwiUgu627/TlFJfpl0eIiIiIiIiig9blhEREREREQEQkQ4isnmuK787AKyFbl1FREREREREFcxXsExEXhCROSLyo8t8EZEnRWSiiIwWkX1t87qIyITcXxfb9LYiMia3zpO5AbSJiIiIiIjS8mcAk6G78usA4CSllFs3jERERERERFQhfHXDKCKHAFgGoI9Sak+H+ccDuBK6L/gDADyhlDpARBoBGAagHfQgysMBtFVKLRSR76EHzf4OwLsAnlRKvWdms4iIiIiIiIiIiIiIiIhK89WyTCn1BfSA0W46QgfSlFLqOwANRGRrAMcC+FAptUAptRB6IOgOuXmbKaW+VTpa1wfASZG2hIiIiIiIiIiIiIiIiCig2obSaQZgmu3z9Nw0r+nTHabXICIXA7gYAOrXr992t912cyzA8OHuhWvbtkTpiYiIiIgoEOv+m/fa1WnlSmDsWKBuXWDPGn2PmJXksRYmryjlGzUKWLcO2HtvoLapX+eUebNnA9OnA1tsAWy7bbg01qwB1q4F6tXTn53qRLyOyaDHrdfypo/jP/4AfvpJb1urVuHSKN7HkyYBixYBO+4INGwYvYx+jBkDrF4NtG4N1KlT+B21agWsWAFMmaLLs+OOerq1TOPGwPz5hem1bq3TBICNNtLX4T320O8tY8cWTvd7XFj7Z4cddJks9vTtaTmlsXAhMHky0KABsNNO+bK0agWMG5dfr7hMe+4J/Jgb9KVpU2Du3Jr5WPtyzz31/x17eYrLsnQp8MsvwCabAFtvDUyYAGy6KbDLLjXLbCkuU+3a+vyy2313fVxa6tTRZdpnH6BWLffy2KcX78Og562XRYv097jZZsCSJTXn77gjMG+e/j633Taf9zbbADNn1ly+Vi29bda5BAB77QVsuGFhuffcE5gzR/81bw5suWV+nlLAiBH57ZoyBViwANh+e/09jh8P1K8POFX1WnlY37n1eZ999DXHrk0bYNky/V2X0rIlsHhx4XEWlLUfnMoL6GNt001rzrPvA0vbtsDUqc7lsR8jTsdLvXr6OuJlo430eVxcRrc07edg8bH4ww81zwv7+V2sfn1g+XLv8jmxzr8GDfRxHdYGGwDr14dfv5if/U1JGj5PKdXUeLJKKV9/ALYH8KPLvEEA/mz7/DGAtgBuBHC7bfodAK4HsB+Aj2zT2wN4u1QZ2rZtq9w0bqyUvgwX/jVu7LoKERERERGFZN1vU3UaP15//zvvHH9eSR5rVl7r1/tbft26aOVr0ECvu2BBuPWpPD36qP7er7kmfBp16xYed071IV6CHrdeyzdsqOfNnes/PS/Dh+v02rQJn8Zjj+k0rr5afz7lFP35v/81U0Y/WrTQef76q/5s/25+/FGpV17R7884I7+ONb9r15rf59Sp+fe77aZfx40rzLN4ut/j4tRT9TyrTNbf+PE1y+aWxn//q+edcor+vOee+vPo0YXrFZfHug4CSl16qXM+22+vP0+eXLM8xT77TE9v316pDz7Q7486yrnMTtsGKLXFFjWnDRvmXG7r+u1WHrdtd8o3yv+6gQP1+scc45xu//7OeXfv7rx8o0Y1yzh7ds1pEycqddVV+v3jjxeWadWqwjw7d9bv+/RR6ssv9fuDD3beHms96zu3Pi9eXLOsS5bkv+tSf+++q9QVV/hb1u1vxgz38gJKffKJ8zyllDrnnMJlf/vNPZ+LL86/nzSp5vzWrUuXdY898uWoXbv0MWjfN8WczosxY9zzPuCAaPvZum6H/dtss2jrF//ttZfZ9PgX9Q/DlPIX1wry56sbRh+mA7A/D9UcwMwS05s7TCciIiIiIiIiIg+rVqVdAn9+/DFbT+KLpF2CPKssSgVfN8w6cacXdt9GaTkCAG+/rVs/WTbI1XSabFFSToJ+l27fm1M6paaVyjvMMVKcplsZsnRuB3Hqqe7zevXKv99pp+h5mb5ulEozan5xlJeoFFPBsrcAnCfagQAWK6V+BzAYwDEi0lBEGgI4BsDg3LylInKgiAiA8wC8GaUAC1xGVHObTkREREREROTEbwUNK3Ko3A0cGF/aixfrrgO7dAm3/ooVwNChZsuUVWvX6q41KbgTTwSOOir/2R4sC3uN9rNe1q7/UYKvcXErSxaDvWnll6WHCUxLO1iWpXOByoev3qRF5BUAhwFoIiLTAdwFYEMAUEo9C+BdAMcDmAjgDwBdc/MWiMh9AKzbm3uVUlb46jIALwKoB+C93F9ojRrV7M/Zmk5ERERERERERIVOPtlchWJxOn/8oV+//DJcej//DOy/PzBjhh5XyUSZsmrXXfV4X36ZbkWTxUBLEPaxqky0LEtiPzz1lNn00vru7Mdi8XFZXCb7/JEj9Wu5tJKtFosXm0uLwS4qR76CZUqps0rMVwAud5n3AoAXHKYPAxDzUNBERERERERERFSuli6NnkYWK13tAariQFmpYFiWW+aE6QbQZP72YFmWu+a76ir/y65dC7z4ItC1K1CrltlyJNUN4/DhwEsv5T9b2z9qVOkylpJGN4wtW+ptCPI9Aulei4rzPv30msvYv6NS6wPAL78EWz6Iau1KldJlqhvG1LEbRiIiIiIiIkpSFivgqfpU+nEYZfuyHCzJYtmilCkr22MFk5JqWZbEdj/xBHDRRcD//V9y5TBxXbGn0a6d8/Sg5fYbxHNjaj9NmgRcfbXzvKSuyVHz6d/fe/6wYaXTOO0093lsWUblqGKCZW7dLbIbRiIiIiIiIgqCFTRElGVxBWhMBUiWLImeTlhJjVmWpHnz9KufBgFhWvb5VSrtMMeliWM5yDabDgIGlWZQOWi5778/2fyytn6x0aPNpkfZ5KsbRiIiIiIiIqIpU4DXXtPjHBER+ZGlwENWWj/Zhdk/WdqnxQYOBDbfHKhXL538TYxZljUmAlpjxgRbPsyyxfPjCEy5pWky6BfEf/8LrFkTvixxs7ZVqeDbnXawKsvXOapcFdOyjN0wEhERERERxatDB+CWW4CZM9MuSTawIoeyICvHYVbKYWevKM4a+5hlQZb3o1Say5cDl12mW4DdeSfwxhv+0/ZrxQp/y5kOLJgYsyyO48VrbCe/opTrnnui5x/EgAFA/frO86J0w1gqvVJM5Hfttfn3Z5wBdO4cPc0wgmzLwIHB00874MxgG6WhYoJl7IaRiIiIiIgoXkuX6tdKr4Co9O2jbMjycTZjhm5FakKWWlkkyXSXdSaPl3/8A3j2WeDBB4H77guf5/r1wMsvA+vWmStbmHLYWcGylSvNdsMYdf8feGDwdVau1P93gxwrps63MPvAnveLL/rLJ+kxy5SKvo9KjfUVRFL/B8J0jZp2sOrzz6OtTxRGxQTLiIiIiIiIKBmVVPl9221A06Zpl4IoW444AjjzTF1ZX86yfK0yUUnutn2ltttqMRK15ci//gWce64OvmVlX1vBsgkT8gGCNAOTlsWLg6/Tti2w2Wb5z37KFWdXe6WWve02f8va5wUNaroFy7Jy/JVi8tiKO9AWtVvNqOX7449o6xOFUTHBMrfuFufPT7YcREREREREVD4eeACYNy/tUlDcli3Tlehvvpl2SfLibAES1fTp+nXtWvNplxJnpXeSFepR8nJa12la2O/eb9lKLTdnTuFrXMK2rDJZJ5hGMGbcuOB5p9Fi1Spf2ODGP/7hPs/0OGgiyQeZylXUYHra3TgShVExwbIWLZyniwB9+yZbFiIiIiIiokpUKRVApnB/lI8JE/T3dffdaZekPNSurV+DdK/ndj4k3Roha9xaFGWhtVOpQES5fRcTJxZ2Nxd0XLggym3fBOXWgstvN4hB9s+gQfr1uOOA887zv549L7/n0/DhwEcfBc/DlLRawKVxvKZ9jqSdP5WnigmW9ejh/pRNt27Jl4eIiIiIiKhSlUt3R2GxgqXyZPE7zWKZLLVq6dc0WpYVi7Kf0tzHq1bp17/+Nb48wl6L4wgiRS2LCTvvDLRvHz2drJ6bfrs2NJGm3wBY//7Ak09Gy9M6Bt5/H3jppWDrAsAjj/hvIX777cD48f6WTUJSx9qnnwZfJ+0xy4jSUDHBss6d3U/CqVOTLQsRERERERERZU+lB3pNsYJlxS3L3ngjeAVoFvZ5GpW21r4zVSdlshvGKHlmkX0/rFlTc7qJVnxpVvyn0Q2jW57F6d96a3x5OZkypea0hx4CunaNXg5TRHTXv0OHpl0S3ZWnCNCnT/B1y70bRQbrKIyKCZYBQOPGztMbNUq2HERERERERFT5WBFDUdgriN99V38OE1gxeRxaXQZa3TAWtyw79VTgww+90xg0KD/mWZjymQzQFKcVJO2779bLh21dVy6BJkqGicCDn3PJ1PUgyYBh8bny5z+7L3vAAc7Tly0zVx4TOnUC9t/fvRvWcrBqFdCyJfDee+HW5zWQylFFBcuIiIiIiIgoPtUSHEp6O6tlv6Ypi/vYXqYXXtCv33+fTlkA4J13gAYNgK++cg+WAcD8+d7pnHCCriQOKyvf1cMP61erO8W4RNle010fRqnczkI3jKZk5Ri0uO2j9evj6yovarAsSJeRxdv39df+88mqIUP0a/H1I2vHlpdffwUmTQKuukp/LqeyE4VVUcGyBQuCTSciIiIiIiL/wnZpRZQVWTh2ncqwQa52prjbQxPWrQPuuQdYssR7OWtMm/btgRUr9PsgrarsFam//55/n4V97tf77wNNmgDLl1fHeD3FZYyjzGl+/2HzdtoPfrsljFNxXrVqARdemFz+TmUwwet7KofzqJhS+XJvUMY17+XeDSNRGGV8ytbk1t0iu2EkIiIiWCkWlwAAIABJREFUIiIi0+IeG4bMyVKFq1NZrArVMJWTpbbt9dd1l4I33ug/TavrsKefLhwDKow0u2G08vZbhptv1i3nfvklHzCMm9P2Rt0HpbbXSt9UQDBKsMN+zGflWpil6wXgvV+sVqlBj/Uw4uriMSvfu0lWC1z7tt1+O7B6deFyWTvWnIQtY9rfa1LXcKostdMuABERERERERFREtKuvLOzl8UKlnlVSi5fDtx3n24lFoTVDdjy5cHL9sgjQNOmwfJL0urVwBdfAEcdZTbdRx+NnobfYy1MRfT48cHXsTNxHnToAIwaFT0du3IIHKQpzVZs1jS/ZQhS1ixdl02ztyzr0SO9coTB85GqUUW1LGM3jERERERERPGplm4YOWYZJcH+vVvnlFPLsmHDgNGjgQceAP7+d+CZZ4Ll4/d8tS9nL1vSdSpBzoebbwaOPhoYOtR5fthrlT0IZLIrP7s4r6Om0u7Wzf37HzwYmD3bfJ5OSu3LIONuFbv9dn/rBcnj//4PmD69dN5+pblvk1DJ3f2V8/1SFo4NoqRVVLCM3TASERERERFRUliRVD6y/l15tSzbbz9g773zLcSKu0XMyrbF1bWa1/b99JN+nTfPX1phypSV/RuEqTL37w9ce220NErtc6egcZKcWvv42X9uy8yZA1x8MXDccdHKFSTPoMtEyd9v+p9/7p2O3c8/+1+2HJRzgMxJuXbDSBRGRQXLiIiIiIiIiIjcZKnyzqkbxnXr4suvXFpMhvmOggRk7EaMADbeGPj99+B5Ju2ll8yn6ec7WrnSfL5uZXArT6nvN83zurjM1jnsN4Drh9P2vfqqv/KE5da6rn9/f+sH6fa1HANiWRD3fitOP2h+/F6pHFVUsIzdMBIREREREcUvTMXk6tX5Ae+zrlyCCnEYPx745z/TLkX1sYJlcXRHVsmtqcJ2z2d54glgxQrggw/MlckSJYDjtO5tt9WcNniwc1DGb3ApamW4n/xMHEu//uo9P2yQLWh6abOXq1Mn93mm87I7+2zzaWd1f4flJwBcDiq5e0wiNxUVLGM3jERERERERNnUqRPQpIm/ZdetA84/HxgzJr7yLFwI9OoVX/rlarfdgCuuKF05XW6yWGFpL5NXN4xB0omyXBZa3T32mHf3bW6ilj2O8RijfC9+173mGufu/kqdv1n4rpMQ9rwPsl4S15asjFkW17Zm8fpsStSAvpe4z+NK/l6I3NROuwBERERERGTGqlVA3bppl4IqWXGFcpCKlAED/C/7yy9A797AkCH+1wnq/POBt96KlkYlVyQ9/rj+qxRxBENMsspVDk/yx7kPr7vObHrFZY2ji8e0OY33dPzx4ca3ctvWX34pnVZc+ykr50QWrvdplyGN/NPe5iyL+9o0Z45+nTy5Mq+dRE4qqmWZW5ce5dLVBxERERFRWOPGARttBPTrl3ZJiMqDVQlEzuIcO4s0pzHL0qwY9lux6VZGv4EXu1mzoo2JZarVRteuQLdu4cthWlrdB7qtv2xZ6XXdyhxkW5yWPeec/PvbbtPLHHmk/zTDyEJrK7sg+zDOMctMqfRuGO3KeduiBqrj7B2AKC6+gmUi0kFExovIRBG5xWH+diLysYiMFpHPRKR5bvrhIjLK9rdSRE7KzXtRRKbY5u0TdWNq1Qo2nYiIiIioUowcqV/ffjvdclBlC1MZnlVeFVjVPGaZJSutOSqZUzeMcY5ZlsXjeuutgb/8JXw6JlsM3n9/9DSCiOP6GfX4MT32l4n8X3kl/956IOiTT6LnNWoUsP/+/ssRVBznW/fuwEcfmc3Xa/nie8o0umHM4v/HIMq9/ETVpmSwTERqAfgngOMAtAJwloi0KlqsJ4A+Sqm9ANwL4AEAUEp9qpTaRym1D4AjAPwBwD5s6o3WfKXUqKgb4/bkG5+IIyIiIiIiItMquRKs0oJlcXfDOHEicN55wJo1pZd1KkOQYFnQVhlhtjnOY/uyy4DGjfOfTQQ+Sm2jyQBCkmnExS2AGsf5keZ+8Drvr78eGDo02fKEZS//E084LxPH+GwnnmgmjyhlKEfl/CARUdJOPjntEhTy07JsfwATlVKTlVKrAfQD0LFomVYAPs69/9RhPgCcBuA9pdQfYQtbiv1my890IiIiIiIiIqqpUh86HTkS+Oor8+l27Qq89BLw3Xell3WqGI6zZZlXvnb2Cl4TldduFcbPPgssWBA9fSB4OUtVYjvNjyMIERe/eQatzE+q8j/JIINXXia6YTS5LVG7sgwj7PHrZyzQIAH/cg+kmeoqlqhSTZuWdgkK+QmWNQNgL/b03DS7HwCcmnt/MoBNRaQ4RNUJwCtF03rkum58TEQchyIXkYtFZJiIDJs7d66P4hIREREREVEc4m6dE4RSwAknAIMHx5N2ktzy69tX7+tZs5ItD1B5Lcssa9YA7dvHl36QY8d+Hlnvy2G/28s9bBiwcKF+n+Y4RCbGyzLhueeALbeMnk7YMarsx8/q1cHW9SqLn/KY+A6SarkkAnz8sfOybuUoh/EEAfMB5KBpd3RqPlFl7Ochg2FE3oYNS7sEhfwEy5wum8Wn+g0ADhWRkQAOBTADwNr/JSCyNYDWAOw/Y24FsBuA/QA0AnCzU+ZKqV5KqXZKqXZNmzb1LKjbk0nz53uuRkRERERUMfijnJKQheNs9Wpg0KCa3UQlKe790KuXfh0/Pt58nNhblq1cCSxalGz+69ebrUCJ+7uK2tVhlJZlaQZ3n3uudFnWrwcmTIi/LGHmm8jD7tJLgTlzoqdvotx1HR9J19yO17CtpNJ+gML0OWCiZVlcTB/zaWxrpbcsS6rMY8Ykkw9RNfETLJsOYFvb5+YAZtoXUErNVEqdopRqA6Bbbtpi2yJnABiglFpjW+d3pa0C8G/o7h4jadHCebqIfiKPiIiIiIiIykc5VpKZlOb224M2++8PNGyYbP49ewL77Qd8+WWy+Ublt6WO27Q4vvM40/ZK08p37lxgl13SCfpastwlYjnkWe7dMJpIN0wQ6uijo+cLxNuyzG35JI/fSvtfb9+eSts2okrnJ1g2FMDOIrKDiNSB7k6xoAdaEWkiIlZatwJ4oSiNs1DUBWOutRlERACcBODH4MUv1KOHe//S3bpFTZ2IiIiIKPvSfrqbKhsrfUpTCnj5Zd3dnylpnNf2lmVpPL0+apR+nTo1+bzDMFWZHcd37TdN08sVmzEj3Hp+xHmOLF0aX9qAd/A0qKAtE526J3QSZf9muZVWEGGCSh99FE9ZgpbDS5Dv1s+YjGF4lX3FCrP/T5NwzDFpl4CIwioZLFNKrQVwBXQXij8BeE0pNVZE7hURq8OLwwCMF5FfAGwJoIe1vohsD90y7fOipPuKyBgAYwA0AdA90pYA6NzZ/QL7229RUyciIiIiyr4sVzRROn74ATjrLGDt2tLL+pXUcRZnBbiJbp+clnv1VeDcc4EHHzRTlrRkZewsU8dAFvexkzDlTLrFWBzrhRU1Pz/dEZ59dvB00woQ+U3LdDeMpgwaZDY9k8dxnGOBmUwraEArSBDwgguCpe1m3jx/ZQCAdu2AOnXM5JuGJLqKJSJz/LQsg1LqXaXULkqpnZRSPXLT7lRKvZV7318ptXNumQtzXSta6/6qlGqmlFpflOYRSqnWSqk9lVLnKKWWmdigWrWCTSciIiIiIqpknToB/frFN2YQFbLGzJ41K91yRGVvWZaGSq5ALK74XrECGDs2nbKYFFelcNiuLZ2mhwlg/PCD8zSRaN2EZqEleNTgWtBlSpk2LXoacQkyzlbSopQlje24887Cz27D6lSCLB0nRFl0zTVpl6CQr2BZOXG7oU/7Rp+IiIiIKAlZqHyjbGKFDQFAnz7AV1+VXq7SWpYlJcx51qVLsO7awu6TJK4BSY/V4zdAZ6oso0bphw+s72vgQOfldt8dWLjQTJ6l2I8Hk8EvO5Mtk9MW9kGGNMf2GjDAe36WWpeGccopyeVFRNnSs2faJShUccEytiwjIiIiomrGgAgVMxlsKLcu1sKmnZXtjKMcXboA7duXXi7tB05Nb3vc32mUMcs+Lx60IqBS22aVze9ycYmzQj+poGqbNrpb21LGj4+WT1pjlrnxs81pCnJsffhhuDzi2rd+fP+9d7rlfu9Xbg9FBFHu3w1RnHbd1X/M5vLL4y2LpeKCZWxZRkRERFS97rgD+OCDtEtBaVuwAFi0KO1SZE8a4+JUuqiVln4rCNOoSKy0lmVJHbNh8km7onjp0mTyifod9O4N3H6787y092FQEyYAH3/sPj/O43XECN31p18iwLhxpZcJOg6aaXHn07lzOvkWe/dd4IsvapZh1Srn5SldvF8icrdBgMhUUveltZPJJjmNG+f7iC+eTkRERESVrXt3/VqpP0xvugk46STgT39KuyTZZt37V+pxUE3KrQI8qCwfo2k/cJrlfeMkyLEa9bg2vW822wzo3z9YuRYuBFaurFkur24Yo475dP75+tX6Xx9GqW302wovqpNPzr+PmlfQri/bto2WXxYlEajL0nhqHTsWflbKPZhXSprdSxJRdasdIDKVVLCs4lqWERERERFVqocfBg4+2HlepQcVTDjoIL0PKbysdE8I5Cvqw/54LodzJsz+fuwxoEWLdPI2Kenu9ZJUvG/jDp75CQAFGTMNALbaCthmm2DrRA2W+UmzWLkeP2l1w5j2eR+FU9mT+P7d9tns2cnlmZWWwFST33EVqXJMn552CbLnnnucpwcZNuuyy3Rw7YEHzJTJTcUFy5xalXlNJyIiIiJzpk/XT7suW5Z2SaoPf2yX9t13unVeVr3yCjBkiPl0/VSUf/ttsMq2KMebqWPVal2ydq35cvgto6ltMVnhf9112WoBEVW5dcOYRXEEDFavdp4epJWTyfPMb8uib7/1l2exN96Ir7vKrAf0/H5PWd8OSyVcCyopyFnpfv457RIQpaNnz/x7+/8H+4OLQVqW7b03sGYNcMst+jUuFRcsc4tIBolUEhEREVE43boBb70FvP562iWpbj/+CEyalHYpKKizzwYOPNB8uqUqMD/+WHft+cgj5vN2cvnlwKmnRk9nwYLoaZC7tCtf084/rCiBnXIU5HtKo2VZ8XI9egTPY+FCfc264IL8tGefDZ6OmzSP9eK8y7X1dXEXoPbpceaZliSCZUlu3003AWeemVx+SXrjDe/5EycmUw5KTiX9j4/CLRZzww3590GCZXZh1/Oj4oJlbv2qp93fOhEREVE1KddKznJm/2HWujXQsmV6ZaHy8ttv+nXcuNLLmji3n3mmdOURKxoKjRgBTJ6cbJ68jgcT5ZjNyvGelXKEkUTZrWslkN0K7qDnbfHyY8bUXCZrY+xlLe80WnmZzDMrXca99lraJYjHM8+kXQJKWjn/LzWpTZv8e7d94hX06tULOOQQs2Xyo+KCZWxZRkRERJQe/jhIDyu2yW7WLODaa8N3UVhK0ONt8WLz6Uc95uPqhjHMdbBUfldfDey0U83pkyYBY8cGz89EmcpNHNszdiyw7bbAnDne+Sxfnh9jL46yDBrkb7m4v9Pi1j2lKvSTbFnml59ua7MsaLlNtpBL07p1wIsv+ls26/eqSult8erSvPh/e5Qxy9z2W7meA0SUjgMOKPxsv4a4XXd33bXw8yuvAL17A599Blx0EVCvntEi+hJjo7V0sGUZERERUfqi/MB+7z3g8MOBjTYyVx7KHqV05Q4faovH3/4GDBgAHHlkflqaFV8zZ5pJ5+uvgRYtdIAiqe2ZMgWYPdt/F5lBylWq0rZUWlYL0qx0wTV9uv5utttOn9smuoPNcsV2z556mwcN8i7nJpvo/TJ1qvP8qNvYqZP3/KwGgEwGy9z2YZaPnzik9R2vXJn+vr7++prTyq2VFwB88QXQtSvw1Vfuy9iD7ybyJCJz0r4WpkUpve3W9cg+tukGLs21nnqq8HPx/UyUBwHCqpqWZdV6oBIRERElKeo91/DhwPHH6xYxFEy53e8+/7zueiMr3f9UGusHqvXD1XrvpFRls9OyQflJu1cvvZzX0/R//jOwyy7hyhDWjjsCBx0UT9pZruBUSrdQDHJtGT5cv/72W/RuI03vm7T39bRp+ffWPp09G/jmm8Ll/vOf+MowenR8aVuCtNhMMpARNK9y+59qSes4f+ihdPK18xqzLMnvM+p3sGSJfp09O7k8icgck9cbp14Fwrj5ZjPpeOndW1+/Dj1Uf169Ov+bvk4d53WslmO77+48n8EyA9xakCkF9O2bbFmIiIiIqlXYH+0LFujXrI4FQuZY9+YTJqRbjmoQRyVhHBVzDz+sX3//3Xs564n6LFQOZqEMcVEKGDIk2DpxHGvlELTw6nrQS79+wMEHF27jsGE1A2gWt+l+lWrpd//9/tLx+52U2hdJnj+jRgVbPu1zO+xxn0bFYin77JNMPlG6zzWZb9S6R+s7DHIMpH28FrvjjrRLQJQek/ctptLq2NFMOl522023pL/oovxnv0aOdH5YrmdPYOONdc8zSam4YNl227nP69YtuXIQERERVaOsdvVUCSp1n/7wA7BoUdqloLD8HpdBf+ynHSAJc75FOUezeH6nXaa08w/KZMX20qXO08MGy5I6n4IGx6I+GDN1KvD99/q91zauW6dbSVL1CduyMIpbbom2/ty5+rWcg2Xdu6ddAqLK8Nxz0dO4917dlbjfB2Ki6twZWLVKdxVurxto0wa47z7nderWBerXrzl9n330uK8dOsRX3mIVFyzr0cN93m+/JVcOIiIiIgovzh/9n3wCjB0bX/ppyVpFiV/XXls4rhalJ+1uGE3kU2nKbT9kuWVZnPvSXkavfIYOLb1+qTSiuuACYL/94ks/SNnbtImW5nbbAWvWOM/z+52kHZgHzH7fWb9mPPtsfGl7dcMYh+XL40l33Dj96jbGj5MstigkqjReDXTsTP5fOeIIfR07//zwadxxhy7TTTcVTrdagMXB6nbRvi9GjABuvz2+PE2puGBZ587u/1A4eDgRERFRcCtWAC++mEwFTBKVVkceCey5Z/z5kH8jRqRdgmT84x/AG2+YSWvaNOCJJ4KtE8c5bPKcDVq+qNtTjmNirV0LfPxx/PkA4bYn6vEwdy7w7bfh8w+iWTNzadnHBvQyeLB+DbKfevYsnXcp9vxeeEF39RhF2O7uij+vXRutHHZe+zTrAaSoli/X29+rV7pBEz/H9WWXxZe/1/c8b158D9DH9b8kSLCsf/9gebBFP1Fwfv93Z/nBoWKbbRZs+aOPDpdP8XVy2LDgv2OSUnHBMsD95sBtPDMiIiIicnfzzUDXrvlKPjcrVujKCIpHqcqYLDwdX6l+/DFfgR/FlVcCp54aPR0AOOEE4JprdNCslDi6R427lY6f4znOYz7psW/8pnPvvcBRRwGffWYmXy+mg2V//AE89ZR3Zf5BBwF/+pP/NKOYObPw88KF7q2UTPHTCspu4ULgxhvjK4+fMgTlddwk1brPhJ9/NpteEqxxH00rl/sLr5ZlI0YA22+v32d9ex5/XL8GKecllwTLo9IDyERxiBIsO/zwaHmfdlr+/ZZbhkujOACvFLDLLqXXe/TR/Pu2bfVrw4b5aUcfrccqc+K2z9q2Ba66qnTeaajIYJlbCzK2LCMiIiIK7vff9euSJd7LHXEE8Pbb+j1/hMfr4YeBCRMKp3Gfx6d165oV+Gmzngo30YqgXMbaWrkyvbwB3TJw5Ej3+cXliSPgN368fp0923n+6tXB0vOilNl9fOutumJk4ED3ZSZNKszfpFLpNWoEnH222TyL+Q3GWWX1c3772U9RgyjFx6nfLg6DCNLqZ/hw5+lTpwIPPlh47I4ZYy6Al/UgC1Dd9wJOLRWT6Joxrn0epGVZUKtWxZc2UaWK8j8g6vl8/PH5902bhkvDqfznnuu+/JVXAtddB/ztb/lp1n2JvUvHDz5wH2v18st1QO6cc4KXNy0VGSxza0HGlmVEREREwfltlfLdd/GXpZrZ9/9NN0V/QpEojKTGLHNSr56ZsoR15ZXAvvuaTbPUNgTdRpPBHtMtyxYs0K/LlgXLP8kAhdWV2ZgxwE8/lV7eqWxe+81vMLPUvn/9dX/pADrIHLVlrKluF73SsVr9+NGunfP0k07SQVl70PXTT5NvAZqWiRNLP9hkilPgN+1gotP5lfXvzEucwbKtt44vbaJKFaVlmdf53L07ULu2/3KceKL/Zb0ope9tX37Zef5mmwGPPALUrZufdtxx+vXww3W3um7rWrbfXj/oVU7XnIoMlrkdvGn/4yYiIiIqR2G6cCvnyolyUTywPO91ycnq1cDo0fp9HN0wlvNxZ2J/ZO1aFySIUorpYFnYY8VrvdGj9fwffwyXtpu99gJatSq9nH0f+dm+oN0wuvn+e+cyOEn6GI2jG8bOnf0tZwVi160L3/otjWuaU/myfm3t1y/tEmTHqlXAV1+ZTzfOYBkRBRclWObV290uuwCbbuq/HMVdun/6qfNyAwfme31xIwLUqaPft28P/Pe/3ssfdphuXXbAAcDTT/v//1xOKvLS63YjlLUfMkRERETlIEyFDe+7zAvTxRuRNfaJFz+BL6WAxYvDlyOO4zXO60yYtMulO0u/4gqWmRwPzqrUGTAgWnpJjefn1E1c0DSiLJu2k04Kt56fYKh9rMNy2iflyqkV14oVyZcjC264QVcym8b7PKJsiatlmVLAdtv5z6NFi8LPe+yhXxs3rjn9hBPc07HKZL02bVo4Nlq1NkaqyGAZEREREZnHyqfy065dzXGeKB5PPAFMmRJP2n376oG0nVqllDov3cYQCOqBB4AGDfItGoNeD/z8sE76GmPix/6ZZ6ZfhjiZLF+QQIb9KWkRYNQo/Wq1kgzDK1/72GBBurGz758o+yrrx0EQ9v2c5DltD5YV8ypHFva9UxmyUK6gzjsv3HpbbWW2HHZODxo98ojZPKJcl7yU4zFAVMmCnJNWt86WUsGyJ5/U79u0cV/uo4+ARx8FmjQp/E1g3cN4tV4rLsdpp+kxPu3reY2TeuONwD33lE6/EvgKlolIBxEZLyITReQWh/nbicjHIjJaRD4Tkea2eetEZFTu7y3b9B1EZIiITBCRV0WkjplNcj8A2YSZiIiIKLisdElU7cLsk+HDgZ9/Nl8WKrRwIXDNNcARR0RLw81VVwGLFoUbi+aHH8KXya5bt8LPWThHo5bBxDZ8/HG09LLWhV7UvE0FRY84onA5q3vJQw4JXiY/7BVEp58efH23bZo9u/BzHE9pf/CB+7yxY/1/jyNGhC+DJQvXBUCXwyto969/me2y1I9p09znOe23rNdfOZU5bOvjtm3d502cGC5Ni1NrTtPBrbiO+6wfA0TVJkjLsi23LJxWKli2ySb6fbNm7ssdeSRw7bX6vX2Ms3Xr8nmUaondpIl+feopoFGjfHmB/L2QU9eKDz0E3Hmnd9qVouSlV0RqAfgngOMAtAJwlogU997dE0AfpdReAO4F8IBt3gql1D65P/sQdH8H8JhSamcACwFcEGE7CrhFQr0ipERERETkLSuVYBQfpYAJE9IuRfmxfmdE6aYwTAV9UKXO4TgD4+X2hHyWxnlKS6kyLVoUrNs1E2OWRTnHvNjrCsaMMZPmkCG6xcxLL+Wn+d0HQY6Hv/zFfd7AgfpJdD+GDPGfp19xtEC1FP+v8uqGsfjzRRcVdjWVhOJus0rJeqDkoovMpeV1nBx/fLS077sv2vp+eAVCo8j6MUCUNYMHh1+3XTv9+uijejwuJ0GCZa1bF07zavW11VbAPvsA//wn0Lt3fvpOO/nLb6utdIDrzTd114vWen7Hw7TGS7MCaVa3slts4S//SuPn0rs/gIlKqclKqdUA+gHoWLRMKwDWM3WfOswvICIC4AgAVqPE3gBC9l7tlL6plIiIiIiIY5ZlUxyVrv/+tx5kuk8fYPr0cOWqRkHHyVm2rOa0qE/P+1Eu52Ucx3aSrK50/Aj729XPtsfR8s4+rWHDmi1CTP4WN92dn99uGDfeOHja9u228rFar3z+efD0LHvvHX5dALj9dqCjZ+2MeUmdl7vsUvhZJB9cUKrwOw3SHXFW6pOyFCgp7k7MNK9jxmlstCCsroPLUVaORSI3prs0jeKOO4Bjjgm3bp06wOab6/etW7uPLxrknLTSszi1ymrbVnc7fdhhOu2//U3fW1lK/TaYPh2YPFn/v3j5ZWD//f2X037dPfxw4Nln8+McX3SR7gL+b38rnU4l8vPvtxkA+3MS03PT7H4AcGru/ckANhURa1i5jURkmIh8JyJWQKwxgEVKKevwc0oTACAiF+fWHzZ37lwfxfX+R9u3r68kiIiIiKhIViumq0US+3/oUP3apQuw7bbx51cpglZoPf10POUwaf164OCDgXfecZ7vdjwqpcc1cGr14WbsWD1/8uRwZQ3L9DllpRekdWaWr6tOZSvureWnnwo/xzE2XRIVxtZ2iQD16gVfX6maQXOnILqIbsE1dWrN9Z3MmBG8LNXM3pWU1S0VAFx8sdn0k5ClYJnTeJkmZfk6mKYNN0y7BETevMbXSlqUh0vWry/8/+EWLPPbFbSVltVVYr16uuXYr78WLrfhhjpQFlazZsAOOwRbx2o9Zv8fIwJcckm+hdkGGwBnn+1vDLRK5Offr9PtQPG/shsAHCoiIwEcCmAGAOvQaqGUagfgbACPi8hOPtPUE5XqpZRqp5Rq17RpUx/F9Vbc1z4REREReQvaaibosuVi4EDg3XfTLkVeube+qUR+97XTd5fmE+RO5V6+HPjmG+Css/yvA+hAUc+ewVqzvPGG/2Wrjdt+Lj5errqqZguMqOf+N9/4L49bufzOC8vU9c0KlhW3SAqiePusz8WBsQMPBB57LFwe5SbN/z/2YNnXX5tJM8ntyVKwLG68T3HGh5Yo6+I4d62xu0zaaCPv+evXF7ZMfvBB5+WeeAIYN65XVwZYAAAgAElEQVR0ftb/f6uXDms/bbdd4T2vfdyxpLz/vn5or3hMNcrz8+93OgD7Jbo5gJn2BZRSM5VSpyil2gDolpu22JqXe50M4DMAbQDMA9BARGq7pRlF48bu8377zVQuRERERNUhyW4Ys9zlzMkne48NY9Ls2TXH5jH9g7RtW+Dmm82mWa2yfNwGYWI7rOPUXlEdJW2v4z7OCtYwaUcpT9Rteeop4JVXoqXhR9zdIcbJbzeMfirCgpg1q/QyxfUU5RQ8KO4uM82y2x/uGTUqP90tAHrqqXrsvSxisIyqtVUHZV/LlsCtt8bT+nHp0nDreY2v1aiR97r21uHr1wMdOuj/D8Xq1AF23x345BN/ZapfP5+m5eST8++Lu2o0zena2rw5cNll8eZb7vz8+x0KYGcR2UFE6gDoBOAt+wIi0kRErLRuBfBCbnpDEalrLQPgYADjlFIKemwza0jVLgDejLoxlieecJ9XKT9kiYiIiJLGyozkbLUVsP324dYt/p7cvrcRI4CHHgqXBznL+jmSVvleftm7O/ys77c4xTXGl9NnN6tW+e9mLUzLMhHgmmtqzrviCu8WVsXdF5aaHoWJ1mRuLct+/NF9GTJHpDBY9uqr+Xlu3+8bb+hW40HycPPRRzW7JY2imo4Vp1aslmraD0Tl4vffgfvvN5+u1Q1gGO3b61enByCsFlxuLcaUKmxZBgA9egAtWhSOzWpdjw4/vGYa8+fn31vdOBanmZQwvcJQXslgWW5csSsADAbwE4DXlFJjReReETkxt9hhAMaLyC8AtgTQIzd9dwDDROQH6ODYg0op6zmtmwFcJyIToccwe97QNqFzZ6/tMZULERERUXVI44ab92w1f+wV7xNWIKVj3bp4vgs/x3zU88JrnDFTaTk591zg9tuD5wGU13GeZGs0p/Wc9tWMGXrcCa/WUhttpAe0D5tvqTIAhQ+0Wmn885/AddeVzkukMN+ePWsuu3Qp8OWX3mXzEjZY5rQ/qv3/V3FLsyTzdbtfCfv9OuXh5uijgVatzOQDVFfLsmXL3OeV0/8A06p52ynbli/Xr3Xrmk13yZLoaTi11rJaaZ52Ws15FnvLMgDYdVfd6nvrrf3l26gRcOml+r21X6zruNv/IFP/m8gsX/9+lVLvKqV2UUrtpJTqkZt2p1Lqrdz7/kqpnXPLXKiUWpWb/o1SqrVSau/c6/O2NCcrpfZXSrVUSp1urUNERERE2cKn08pLceUKvzdzVq7UT6e6BX7i2tdZG+MMSO64SqsbxjDuuiv8uiYCmU7nfvPmunvGDh30tL33dl53/Hh/eZSq2DE5ZpmVV/F6H31Uc9mHHwYOOQSYO9c9Pb/dMJoS5bzN2rFdXG6/LRGT5rZ/s7Y/izmVr5qCZURUnvbbL5l8jj3WfV7jxt5dMAL5YFlxF+GWu+8O3grM6cGdp54C5s0D6tXTn93StMbAdrv3OOggf2WgePDfLxERERF5SnLMMnLntzUT9318rCdpn3km3XJQ/MKcR2G6NY0z6Om0DaNHR0sjyTHL3n/febrXPlu5Mnh5Ro4Exo4Nvp5bWewt4op5DRmRZcXf2bnn+lsuSW4ty1q3TqZlmWkcr4qIsi6pB7cGDHCfN2eO7hbSycKF+QfdgHz3iHZK6YediluWWazpbdoUTr/gAuCoowqn1a6tg3cWt2CZNZaZfVm7zz7zbnFbypFH6tcGDcKnUc0YLCMiIiIiXxiEKXTooe6tNLKkkr+3iROBKVOSy6/SA5Ru40I5ycI228vw66/A8OHh13f6XG5MtuqyBN1HcZTBbSwwJ88/DzRsGCw4su++zuOPBJV2a8+sKNUN46hR8eXtVNnZpEmw48Hrexw6NFy5wvi//0suryzjeUVU2bbcsvQyVkstJxts4N4St0ED3SWiFSyztyxr2RKYNaswHcD94cTi3gMaNAA+/BAYMgTo3t29bE5ptm+vu6J++mnn9erUyQfUwnjySWDCBH/7lmqqymCZ1+DSRERERFTI+pHQtSswYoS/dZKqdH70UeCmm5LJq9gXXwRvpUFm7bwzsOOOaZciz+9xf9NNwHPPxVsWJybPyzjPcXvl6C+/+Ftnhx2Adu3iKU+cwu5HpwrkZ591TzupYFmYNIPyCurec48e7/H229PvkjZKJX+5B269FD+db5JTy7LiMe9MW78eWL3afLpuLSWIiCqJ1U203Zln1pz217+Gz6NfP+Ccc4Ddd89P++abwmDS9dfr1+IuEEsNR7D//kC3bs7zrHWLx4UVAf72N+fx1UzYcEMdDKRwqjJYdvXVaZeAiIiIqDy99FLaJSh0/fV6rJpqELayr1wqXUWAH39MuxT+mAggXHONmbJ07w4sXepvWRPjYmVJnOU2Mb5VkGBJcX6vvqrXd2vJ4lS+b74p/PzZZ/7z91uurLcsszzwQLi8omALGC2t64m9G0aneXF5/HHdcoGIKl/79mmXoPI4XbdfeaXmNK/WZU7s46ntsYf+DWu1MGvVCmjatHD59u31/wq31lhh/o+IAJ9+CnzySfB1KT0VGyxz6/cTAObPT64cRERE5WrdOuDLL9MuRTKuvRa47LK0S5FdrADMpji+l7S/62+/NZtenz56mxYtMpNeqadLg/6Qbts2erD3+eeBW26JloYl7e8/aWGDnn67YvOTnts+79TJXx5ejj22dD6lFAcGowTL/KZRStBtscYaTCqI4zVmWbky1TIxKcX5mhqzjJJXSecRlb+XX067BJXnsMNqTvMaD/Tyy4GttvJO848/gK+/dp43ezbw/ff+y3fGGfq1uHWYX4cdprsDpvJRscGych04l4iIKCvuvx845BDg88/TLkn8Hn+8ZvdVFI3JrsVIS6JlWVZaGL39NvDVV9HTeewx/WpqXDPr+Fy8WJfRYu235cudBw93M2KEmW5ErWBAkrJwrGShDFEltQ1hu6JzCjr07w9Mnuyej1cZwojyf+Gnn4BNNgF69w6fRliV1A2j3/KkXW63bhizHiz76KO0S5Bd1Xxf+P77aZeAitWqlXYJkmOqBwQvM2YAXboAV12lx//yYl3HDzusdDe19erprgidbLFFsPHAzj4bWLOG3RpWk4oNlnXu7D0/7Zs4IiKirBs3Tr/OnJluOSh91VxRUU4q4XuytuHEE7Pf1c2JJzpPf+stYPBg/VRrUtL47ivh91TY/bZmDfDaa+UzBhxgtmXZ6acDe+1VOH3NGv8tOINu6wZFtRaDBvkPSltdu77zTrA8g7JvUxbGdUuSVwvNJLfD3g1jHGPtxWnVqrRLQFn0xRdpl4CKVVOwbJNN/C330EP59+3aAX371lzGap1VbJtt9OsTTwBHHeWdzz336HuPo4/Wn7t1A4YM8VfGqKzuG6k6VGywrJQPPki7BERERNmW9YoFSoffCteox0+5Hn8TJ8Y37lapfeK3a8C5c4GOHc2UycuyZcAjj0R7ov/NN+M9FvbaC9huu+jp2Ms4bpwerPzSS6On61fU8zLssRUXkWQCgGEr+e+/Xw8+//rrpfNYtky3RHQTdDt/+SXcekDp77F379JBBnsrSruzzgIaNvTXsizo8eR3PJNS4jiO7WULM7ZaufC7LUG6toqD2zGW9ZZl5G769LRLQJRXCcEyv72p+P2feeON+ffbbqtbYvXqVbhM167+0rKbMaPw8x57AD/8AGy+uf7cvTuw//7B0yUqpWqDZZdcEqyLFCIiIqIkXHABcMopaZeiUPFT/VTovffy73feOXyf9kGFrYh96CHd+ilum24K3HCDe17LltWcVrxNJ52kW/DEZcwYYOpUPeaXqYp0q3XNzz+bSc8uK+P/uE1LOv209odVgeNnLOxttgEaNPCftlLe22XNCxNwKrXO+efXDEL5baFjBQ6TCpZZLXH8Xgf799djsSapkrph9Ktz53SvU27dMAYpUyUFOSvBypVpl4AorxyCZVbLK8vxxxd+/tOfaq5zwQX59/Pn624OrTrzHj30Pb2XF17Qr9b186KLCq+7HTrobpEnTwb++1/dKqxUt4vbbKP39113eS9HZFrVVn389htw5ZVpl4KIiCi7WFmQjhdeAAYMSLsUhezHQpzjlhx+OHDkkcHXS1vxj9C4lNqnbudslIrLWbOAgw7Sr2GtWOE8fcIE/2Uw7csvgc8+y3/++9+BpUtLr+enZVbxMo8+Gv94ynFcr9Mco2jmTGD33c2nm4ZSx1Xx/jv//HgeUPB7jCxcWPi5uEXOm28Gy6c4aBGGU7DjoouASZOCHX8DB4bL36+wwcBKNm9ecnlNmpTvkosty4goDm7jYGXFl18WPsQHAFttVfi5WbOa6x14YP59o0Z6nR131J8POqh0vk2b6levh4N22w3YYQfgtNN0q7BS3S4COmB3992llyMyqaKDZaV+ZDz7bPYqo4iIiLKClT3hTJsGLFmSdimiGTcO+OqrePNYt67mMWYPXlQzv70fhK14DnJuP/MM8N13wHPPhcsrbW7besghOjhrKj27NWsKP19/ffyDpJvqhtEpMO7WKiPO/xGDBvlbznQZ7APGm0g7yDlq5denT/R83coSprVe8Wf70+d+mDh2HnnE+X/SvfcGSyfpcaEq6aGjsOfDnDlmy+HlX//Kv7cHxyrpeyCi9NSu7X8crzS0agX8+c81W79tv33h50aN9DX9iisKp0+bVtiV/IUXAmPH6vtl68EfKyhW7PjjgYcfBh57LNImEGVCRQfLLrmk9DKnnAIMGxZ/WYiIiMoVKxmCadEC2HfftEsRzR57AO3b5z97jckSVu3a+kdYNRgzBli92v/yt9ziPD1sZWXa3U85pfn6687jOKV5vYkSHLGv+9RT0csSVNz7zSvgUSrvjz4yXx4/1q0DFizwXqZ4u954I77yuLH233/+E38+YY7xqC1yTLQse+894Isvak73k94ZZziXxbTvvquZTzV2wwhko7tYtiQjItNGjSrP38V77QWMH19z+l/+kn+vFNC8uf4NaNlgAx2As3NrlLLBBrrr9c02i15eorRVdLDs6ae95197rX7dbz/g/ffjLw8RERFVh0mTvOcvXVqzi4xy9MgjwF//6jzPT2WZ1b99JfvtN/0j9brr/K/z8cdmy1D8XST9Q9/pWDjzzGTyDtOyJ8wySbW8iqsSesyY+PLq29dMOkFdcw3QuDGwfLn5tOP4Hu64w3yaYXh1o+iHn650Te2/oNeyOI/F55+vWZ4o11qnMR3T5LUtTg8+WJIMnDFYRkQWt98nUdgDSUnr1q30Mk7dKwK6pdkuu+gxSb//Pj/9mGOCl8Nq+V+3rr/lL7kEOOus4PkQpamig2Wl9OoFDB2q3x93XPBuHIiIiKpBOT/dnFXnnae7q/j117RL4o9bJdkNNwDvvJNsWcqNNV7Lt9+aTzts13te53Ta53uQyuXisZWSYHL/+Ple1qzxN7Zb1G4Yn31Wvzq1xFLK+YnkUmkGLVsYXnn366df//gj2XzjZnLcLz8eeijY8itXFn625+n2MOucOcAWW+in9rNm6lT9sEPSDxmcf36y+ZXy97+7zyseCy4LLcuilKEcW44QUaGddkq7BGZ17Og+r1kzoHdvHQxzUru2fu3USTcWsdivdXvv7Z3/CScAW26pe0+57bZ8XXopzz4bf8t5ItOqOli2fDnQrh3Qv7/+fNddevyCdevSLRcRERFVtnHj9Kvp8VMGDizsUiMOUSvlq02Y/eC0zrp1wL//Hb08aXA6ZkxURgZpreeH035fsaJm5b/fdU249lr9NPD8+d75xFG5a+W1bBmw557u80sJUzYT+zNqGl7rl2N3oSL+ugguTv+nn8Ll55ae07TBg4G5c3Vr5SCS+B62287/GCzF5fn5Z/PlKTdpnSsffphOvkSUDZUS9H7tNf0/c8cd3ZdZt04/iNm4cX6affs32sh5PRHgH//QY4Luv793Od5+G5g1S6/TowfQurX/bSAqNxUfLPMz+OKppwLTp+v3X36po+6XXcZKHiIiIqByfmxkydq1+rV4AOaoTj4ZePdd72XeegsYOTJYuvZjoBLvjz79NJ7WJ3ZRz6NevXS3cmEk1Q3jyy/rCu8ogpTNTzdlUY/XjTcG6tULl17QFldO2/7pp/7z86NUmYJ0XWYfl+mDD/Q4dED+YYAopk4NVoakpXkdjBIsGzvWbFnSltX7E6V0a+J77km7JNXrgQfSLgERhdG8uZl0TP1/iKM7xyBOPlm/em2PU4MP+/3joYe6r3v55cDBB4crG1GlqvhgmdWliJujjtKvzZrpH9wnnZRfb4MNKu8HBREREaXP+lHjFSwL2h3VsGH+luvYUbcuOOig8K3phw4tPS5blrv6s5syBTjiCODCC9MuiTerZZEJQVtv+DFtGnDuucApp/hbPkvHgMX0mGVhlinmd/woU5VCYbsxO/ZY4LTT9PviYyBM2Ux02eOU788/69Z6Ub5H+3JBtu2XX6LlaclqgMiNn5ZlUQKAWTRsGPCnP6VdivRkLYgd9DgZMiR6WYgoHKXMdMkb9f/Djjvq8bluvbX0slttpV9nzCi9bKtWNafVr+++vJ8HKx98sOa0bbbRry1bZvd/JVFWVXywrHNn7/n2AdTr1wcGDNBPRlr23FNfWKyuGomIiKpFFiuz09avn74vWLo0Wjp+gmVt2gDffOM/TXsf9H58952/ljlA4Y8sEd1VR8uWwfKzy9KxtWSJfk36Aak1a/RYQFG64pwzx99ypiqmvaxerV9nzqw5z9SP9JUrCysi7NsxaJAebLz43AySd1wBL4tXq61Fi2q2yluyxP9xmWawLM0uE4Ou17Ej8PjjwMSJzuv73X5rf/sJBFl23dV/OeOQVmWZdY21GzmycCy+Ll30a7lU6M2d6/2widN1kIiI3A0frl+VAjbbLNi6116bf3/mmfo1zP+TY4/Nv1dKjy/t1A31tGn5908/Ddx9t37fqJF3+rvu6nxf9/XX+ffW+GIWazuK7yE33FC/TpkC/L//550vEQVT8cEyoPRFsm/fws9HH60vjPZBbE8/XafDrhSIiIiqV48e+nXKlGjpWN0wlvLbb9HyyYofftD3Udb2xBWUyFIQrpSnnwZuvhl49FF/yzvdz7pV1kbZD1Erq4MED4Lmf+qphd3z2NO9804dsBs/PnzeUfZb1GO6SZOaXYE6tXb0SmPw4MLKlEGDgq0PhOuGMaucymc9oGAFd+Pw8MP+l501SwdKg7DOkVJd7rqtl7Tbb6857cUXgXnzoqedxjbNnw9ssYVzV2FulZrVJmwLVZP52pVLEJaomm25pX5VCli82N861oN7xQEmANh++9Lr33df/n2LFsD77wObb64/X365ft1005rr2a//l10GXHKJLnfx2GAff6wfbOvaVX8uvhbVr6/X23vv/LQNXGrprYfrmjTRgcXx44Hu3fW4ml6yfq9GlEVVESy79FLv+daTbMVuuklXZu2wQ37a3XfrC9xtt8X7I4uIiChtrFyoyfoBE/WHhxXkCFKhdv756X0nYfK176NevfTrO+/o16xWJC5bpn94+g1mRs3L/hqnJH4oe7W0MaU4OGDPy8q/U6fw6fspe/GxayoY5xT4tD+5XCqNV18FOnQo3QV9KUEquf12RZj2/xIRHbD/5BOgTh09ze13nInWdPaeS157zTudrbf2l5+Tl17S42L5ldb3sGJFOvnGxQryzZoVf172Vg5U+hjO6r0FEZVmv49s3brm/BYtak5r00a/Ov0vbdy49P/0jTfOvx88WL9usYV+PeEE73Xfece5RZf9/uKII4CmTYEbbtCfi69h9odGnn1W9zhhLbPzzoXLWq3WunfX3envsAPQrZv7dTHtey+iclYVwbKnn/ae79WFQq1awOTJ+gnyu+7KT3/gAd3VS/36uksYIiKiSsMn0Qp17w6MHq3fR62QCRMs6907Wp5RFHfDGFVWK7TuuEP/mRgvacUKva+eeir4uk7nXpD9nsYP5KB5mmgB4BQsKx5LzyngFLRMdm7BMj8t6oIe925PFztZuFC/RhlLEADefDNa16BO4jwe/f6f2mcf4MgjzQXL/PLbVWpYQcYydPoeTj01/mCW2z41MQ5j0te6fv0Ku/sCCusSTD80YB8eolyxwpaI/LBfP526qf/885rTXn1VB62uuio/Lcj1d6+99GufPsBuu+n3DRvqV6ubQzd/+Qvw/PM1pzutZ7V8a9BAv86Yoe9P7S3RLrkEuPFG4Kuv9PYMGVI4dlu9enrbLrmk9HbZ8fc8UXBVESwDSt+kNWvmPX/77XWrssWLgZ4989P/+ENftESAt9/WfbKvX+9vYEciIqJyYKKiY+ZMPS5oObvjjvx7Uz884voBE2SsMz/sx4CJlhdxBcui7M/Ro/OtvEwEC6yK4D59oqcFRDsPk+qK0I1V9rff1j/+g3Irk1OwrNiCBf7z8XNcFne95hUsKxZ07DinYNnq1Xq8u0WLnLuxM9Eq0upu1m/LslLSriz/9df8+7p19aufYFnYcyHu7TV5jr7xhnN3nSa5lfevf605Lei+M7Gv77zT/7JnnQW8917hNHtLQku1V06yG0ai6rHbbsArr/hfvm3bcPk0aVJzmogOWtmDa0cfrV9btSqdZsuW+t7/3HPz0wYMAJ54Athxx3DltMpw5ZX5zzvvDDz2GNC/v/68zTbOXfkC+P/s3Xd8FHX6B/DPN6EHsAQbKsHelZNYTk8scIdyKgo2DMgpCgZP0bMielZsZzksgFg5iKdYUBRsFDtdigIC0gOoJHBgEiAk+f7+ePL9zezszO7s7mxJ8nm/Xnnt7uzszGzJ7sw83+d5kJ8v699jj9DyjLFq2VIuTUCQiPzzFSxTSp2rlFqqlPpZKXWXy/15SqkpSqmFSqkvlFIH1E7voJSarpRaVHvf5bbHvK6UWqWUml/71yG4pxUuWinGDRvCe5e5ad0auPVW2RFzjty88EKpb5udLV98l1+e/NGEREREdUGnTkCPHpGzueuSRE/+BNnXZOHC8Nf19NNj245kiPQazZiRnHXaG2Qn4s035bWxn2SPlfP5O1/rhngy9cILgVNPlf3jID77Xq9hLAEyP8sL6jHO5xztNXALlh10kPzttRdQXh5+f7TvWD/b+9BDVgZWosvKBPZSp+aEmp+g4qxZ3vctWpTYNgHBvH5B9QNMpmR+ToJ4TvaeNfFwy17N1OzpVLFnK155Zfq2gyidXnst8v0DByZv3UcdFX0et6yoeBx6aGwlsKdNc59u9jtMIsOSJaH3+/2+79dP9jPtQaJDD5Vj0VNOAR58UErbA5IFlpMT+vi2bUMz1eLx2WfAs89at5UCbr5Zlp0q++4r2XhjxqRunUT1RdRgmVIqG8ALAM4DcDSAXkopZ4z+SQD/0VofD+BBAI/WTq8AcJXW+hgA5wL4t1Jqd9vjbtdad6j9m48kilaKEQB6945tmQcfLDv/WoeWaDTGjZMmlUrJ33vvyQjQH3+MbT1ERETpFMSJrlWrEl9GJklnsOyii6zrCxfKqMPCwsS2J5ogT7IWF0sN/6B98YUcCAdh6lS5/OEH/49xBikifUZWrbKal/t9baPNt3Gj90nJaJ/Xnj3l8UHw87/hzMywc3uefgKN9nniLSuXyAluP8/7119je4zXe75+fXiwx5T9iRYE8vvdtWtXcEGOdJdh9POZcpt+8cXxLduveD9vCxbE97h09TXJ9GBZMtSVQHKy2Hu+p7JlhSmV7bRpU+q2gcjo29f7vgsvjK3UcqyiZUUde2xw35+xDoRs1Sq8VOGee0qPsbFjrWxnUxbRcCvN6EYpGVBkfPGFDKb78ksZrHfvvcBLL8l52WgVxuzLmJ/UM9bJ0amTlWFGRP75+Xo+GcDPWuuVWutKAG8C6O6Y52gApgDBNHO/1nqZ1np57fUNAH4DsBfSpHPn6PP4/bJ0uv9+2SkuKfGO3PfsKV/axx0nX+CPPRb/yFciIqK6qL6cQEpVGUa3A9kPPrCum7LPkTIgghBUzzKtpWR1MsTSmyoZfv899Hak0ikHHxxa1tspntc4kc/Ae++5D/yKRSzbXFwc+f7PPw+97fw/2bYN+Mc/QoNi0davVHBlBf0+xnmf8+RVPGUYvZh+GEEFy4LgZ11B9AeMhbPnSaylMZ0S6S+Y6t/DZG+X1/Lry+++G68M4vr8nDOZV2Bu7tzUbgcREPk794MPkhssizYYIzs7uGBZPAM/TF8wY948uSwokIwoN/b+XgBwxhmht6dPB556KvxxZ54J7L136LRGjYBjjvG/vWeemVhJRCKqW/x8Pe8PwH76obh2mt0CAD1rr18MoJVSKtc+g1LqZABNANiLFw6tLc/4jFKqqdvKlVL9lVJzlFJzNiU4JGjy5OjzbNgAdOkS/zpycyVDTWvpZ7ZmjXcJn8GDZX6lpGzjmjXAbbdJDwIiIiLj3XdTOzLXyXkwtXZt/GX06ssJJOeB4ZYtsZVeDrIMYyKS/X5s3x4eRMrUTAA3X34p+2Z+OEt5+d2fc3sP7NM2bJBLP8GgWNYRz3KCcs89kdc/Z07kxz/wgPR+sAfVom13PD3F/IilZ1ms64vlvTAjroMqqwQkJ7joVFAAfPSR+wkuP/xsw/ff+39cKn+j3L7/I/1vuPnpJ//zJvt/O4jlx7qM5cutHnvpkAmfIyKqm2L5/gaAww93n3733eHTggiWaR0eoHKzzz7R53Fylk1v1859vkjf7199FXr71FNlIBURUaL8BMvcvkKdu3+3AThTKTUPwJkA1gP4/3GNSqn9AIwBcLXW2nxtDwZwJICTAOwJ4E63lWutR2mt87XW+XvtlXhSmp/ssilT/PUvi6Z5c/nSz8uTH5pduyTzbOrU0NIEgIwMb99eDhT32EN+uK66Su4zP3Tbtrkf7BERUf311VfAJZcAd9zhfr/WErxKpbw84I9/9L5v8GDvx9aXE0jO55GbG9vBYizBsiOOkPMp5eEAACAASURBVHIt6WQ/oK6s9PcYraWESuvWoctJVnZDMk4EP/WU/5P4Tz/trw+Sl19/BW64QfYX7fbfX/YBvZ7fokXyntjvjydbZtIk4M47438OJSXxPc4P53N3vkZu87iJ9jrEE7xO5DstyMyyeP+vysutsqNOzkB3tGV5bVO0bbvggtC+YrHwk9mXzJNniWbaOsUa+PHaN3Djd1vj7dUSRGbZu+/Gts4pU6LPk0zO8mOZMhCGiGLXtWt4/6pk+uyz2Obfbz/36QUF4dOifQe1auX9nf3NN8ALL8j1aJUAAOD556PPc+CBobcPPTT6Y4DwQKDfxxERJcLPIVgxAPtX2wEANthn0Fpv0Fr30Fr/AcCQ2mlbAUAp1RrARAD3aK1n2B6zUYudAF6DlHtMOj/ZZUDs/cv8aNRITqadfTawcqUcFG7cKL3N3IwZIz9gZtTHbrsBHTsCQ4ZYpR537AB27gx+W4mIKDNs2SKXa9a43//ssxKgireHSSTxnAReu1bKDAe5zEyUaOmuWEo1LVsGfPhhbMv3K57347nn/M/rFshNVnaD3yCe0/jxwW5HrJYvB95/Hxg0SHrs2stsGmvXer9uxx4rQbZEX9f164EnnpA+DrF6/XXgpJPkeiJl6bwk+v/mdxuCzixLNDPLb38OIHpgy2udV17pPZhw2DD/648kU7NJtQ7vJR3Eb5Tf51ufAir33+/dtyaW1zTeoGm6DBoUepvBMqK6a8iQ1K7P2ZMrmrffdp9uyjDbRfoOevBBKYHs9lt16KHA6acDAwfK7dxcOdZ8+GFrnuOPl8uXX5aAX6tWocuwVwf4wx/k8rzzgBNPDA2aTZ/uvY1eFi+O/TFERLHyEyybDeAwpdRBSqkmAK4AMME+g1KqjVLKLGswgFdrpzcBMB7Af7TWbzses1/tpQJwEQDHoUryFBb6m0+pYDLMvOTkSD3eSy+VgwitJR358suBK67wftwjj0jWmVKSvdasmVyfOFGCZ6tXy4jbeJubExFR5oh2ksn0X1mxIvJ8iUj0ROfatdZBW30NlsUqU06o+X0e8XwGvJad6Ofp99+BRx8NPzHbr1/o7Y0brWBzJA88kNj22MXzuXj7beDii60ynm7LiJYZ8803oa+rswRksv/vnD3GEhFvUMtPOaFU9yxLVDz/K9FGXdu398svgQkTvOeN9v1klrV8eeT5khUsu/deKeEYD62BsWOD3R77soOcLyjJDFpG+h6tL7/7bkaMcJ/+zjup3Q6ihi4/P/FlKBWa0W0CPUEwASa7Pfe0rt9wg1x6lVr8+mvAq9BWRUX4NOc+8llnWdfvvRdo2zb8Mb//Hj6ABABuvFECiW3bygB+81ofcwzw5z9b840dCxx3nAzwN95+G/jTnyRDbO7c0EF0p54qQbtPPnF/XkbXrrLfD7gHBomIghY1WKa1rgLwdwCfAlgCYJzWepFS6kGllCkKdBaApUqpZQD2AWAKSFwGoBOAvyml5tf+dai9r0gp9QOAHwC0AWAbq5Bcw4cDu+/ub97evaX8Taqcdhrw5pvAf/8rZXBqamSE3YAB0RtQnn++BM8OOgho0gRo0QK45Rb50T/tNCmzsnGjZNetX1+/D1yIiOobr5NcqWgmn+iyzzknuGUFbfVqYMmS2B9Xl4JllZXAP/8p+wFO5nmsXBm551pQwTKt/ZeW++or92XcfrscdEfLCGvbNvZ9OGf/g1hF+lxEew2nTfO+b+fO2HqWffpp5HmD5pX5GhTnc3d7nb/7LvIyKiuB0aMjz5NIGcZkfLfFUobRaNw48v327bQHObt1C5/Xb7As2rRkeTjK0WOk/5nly62S93bO7R89Wr4fY2EGsURTn4JlJDJtH4eovjntNPfpl1zir+VKJPZS4a++Gl6Vys+gm1i0b29dN7/dVVXugb8//cl7OYcfLoE9M3hk993Df7/d9jGbNg29nZMTPs1u3Tpg82apMPHmmxLssisoABYulOs//CAZZoccIoG+vDz3ZfbqJcGwSD75BLjrLrlu3p+rr478GCKiRPiKy2utJwGY5Jj2T9v1dwCEjZ/SWo8F4DpmT2t9jtv0VNmyRUqb+Dko3rBBvpTHjnWvB5wspvRKTg4wcqQ1ff58GTU6YYIcRI8a5X2C5d//lsvp04GWLUPvu/BC+TEcMEBOZO7c6a+BJxERZY5UBMsSZQ/CBLGdt90GdOkCnHtu4sty9hB96ing1lujPy6oIFdQ71uk5bz2GvDQQ/I7//jj7vMcckjk5QR5kjWWZa1aBRx8cOg0U25ux47oj481y37ZMn/zffNNaC82I9L7sHy5jNg99tjYtgmI/nmL1gsuGd8P9vXZG7UHFUi2C2L777svehDRrKemJrb+evbHBqWoKL4+cF6l8NzYtzmowFcyynDGK1JpVq/S/M7t/9vfvEfze/HzvTN+fPSMvKCl633I5P2ToMXac42IYuM1iEQpqTCQSB9D+3fkxRdHH2D/3nsyHyD9Y8vKpArUhAnAjBmh87qdZ3vxRdl/WrNGBrsDcn7Oz3dmkybWb1yLFsD334dWUzD7je3bW0G0CRNC93N79JDBZ927S9ZXtN8I89q3aCHVsCKJZ1/Xr+3brdeLiCgZ4hivWH/EcjAJSJZZJnwpd+ggga8rr5RyjVOnyg9qTY2M8mjWLPqoUkB+LN9+W044ZmVJVlp2tqRWT50qAbi775ZgHCClHc2P7v/+B2zdmrznSEREsUl3KTBnGchffrGu23vpBLGdTz0lte+T4bbb/M2XCZllK1f625cxvU3dTuCm6iTm/PlyqVRsPbHcPntBnvBt1y6+x51xBnDCCeHTI72f//uflKeJRin3Hl233+79GK2TfyLc72dl3brkbgcQ3+fW/p0UbbnZ2VZJpGRsix+9ewOzZsX+uGglb70CZG7zJ5pZls4gyUcf+e/jZrd5c/i0TZsS3x6nHj2AO+8MfrmRMFhGRHVdpIzraAEcP8s2y/fzvWUCZYBUgTrlFOk7q7Vct3PrN9aypQTMAOCyy6Tn80cf+Vv3hbU1vuwD/HbbTVq8TJgAHHWUTPvoI6tC1QUXhM7fqBEwdChw8sn+W9VkgmbN4su8JyLyq8F/xcS6875rlxxotGiRnO1JhFLA3/8uJ8MqK2Vbt2yRxsMHHigZatHU1ADbtkkK+znnSG3gAQNk2U2ayMmD1q2BPfaQkTaXXy6lHQHJHFi9OqlPkYiIHDIhs2zsWMl4to/U328/9144frbzySeBpUvjK4+YKq+/ntjj3YJl3bt7lylxKi6WbDBzstVvVtHw4d73ARJQKCsLvf/ZZ4FnnvG3XV7sJfK8stvcOHtvOUXKHPEj6MBOsv4P/Sw31ZllqeSnDGOsy3Bj/3/06kXkZLZlwwbv+1LJBNCDCJbFs/1uAbZ0BGkmTox8v9c2PfFEbOsZMCC2+QHJACAiosjc+jFHCpI473MbWGffH3X2rczK8ndctW5d5NLlbrwGZ3XtKuftOnaUfXpnNQWnI48MLSFsD8plZQHjxsmArmefleOyaK1ciIgoXIMPlgHxHQhu326VZ0llT7NYNGokAa1//1saaZaVWRlou3bJicjmzWXkqt+Tc0DoKM1x46QnSKdOwD77SDkr00NkyRIZoTJ+PDBzpvtoGiIiSkyiJyG1lrrzfkraeZk5Uy4XLw6dPn16+LzOsiRO27dLBs2RRwJHHy017zOBc1/htdeCX+6ECaGNryMxB7/mNff7OXBmyzif1377hZadmT3baqodKz/7V9FGhp54ovd9paWReyukg5/nHGtlg0hMKVI/7//EifGV9TMS+a6J5bF+yjAGVR4wnnm8HnP66bE/NhniDZa5BbmifVajZaOlK5MpyP+xZOjYMT3rTeR3PhF1PVhf3+25Z7q3gBoSe5+uaNwCR716uc9ryonbB2QdcED4fH/8o3W9efPQ+/LzrT5cplLT+PHAW28BX3wRutxYy/NG0sjRHMf+nTluHDB4sHV7yRLppWnKyOfmui+zWbPEe7gRETVUDJbVSmQn3vQ0y+TAmZ1S8oN8+OFARQUwZoxkhGktpUdGjgT++leZt1Urf8v8+mvreo8eso6jj5Zl9eghOx2XXSbBs+HDpcyjl5oa2S4iIor++5RoZtnUqXLgeccd8T3ebVsMt6ygP/858jKcz6O4OLFtCkrQJ/v8lmH0Otm8bVvs63Lj9rzsJ5pNCcdkSaSMislsT4Xx44H166PP5+dzssceke+Pt2dXpPd561bg/PPlL16J/A+k+mS5fdR1LNugdezbmmmBgLVrpY9KrCVe3eaPtgy3Uf+ZkFkW6Tgj3aJlvCXTwoXpWW+6y0RTZEH1YCXy480343/sBx8A110XPv3bb4GePcOn3323BJs6dAidbgJuJtDUpImUCzeZWbNnW+fBLrpIzmOdeWZ823zxxdZ6jj5aLr/5JvJjzHfmd99JWcVHHgmf5+GH5fU455z4touIiLwxWGajdeK1b+2BM6WkH1hdssceUk7E1Eretk0u16+XZqC//QbMmRM6uiUWI0fKqPbOna3X6OCD5WD7yiuBzz4DunWTkpFeJ+h+/dVf42wioqBt2iTfk3PmpHtLLIkGy0xAy08gwIvXukeODG5Z6eZ3u+691998QfQsi1WqT4i5vWYLFoTeTmS/K5UnSXv0kLI20axcGX2eePoo+ckSivT+mnKVy5fHvu4PP4z9MU5vvOE/m8ZPn7po/4/xBktqaoINli1YkJ7vtJ49vT8PXpllbsHnaNt+333RH9O2rf+SlkHJ5JP/qQzy+3XJJcldfjL/BzJ1n6Eu4WtIqdSyZfyPbdXKfR/htNOs6/b727SRYNNnn4XO/8orwLx5MngckICW6UPbsqVkmAXlvfesrP6ZM2UQYLRM9Jtvlssjj/Sep0kTq28ZEREFi8Eyh+rqYNOVp0wJDZ4NHBjcslOpbVvgsMMk3bxjRxndUlUlB6PTp0tGwr//LZljXvWYvaxaJb1u/vtfqdn86acyvVkzCZx17y6ZcG+/La/hvvtK/emqKplvwwagXz8pLfL995k9mpSI6rapUyW49K9/pW6d0QICmdCzzKw7iOBFppy0KSmxAohVVe6jOo3PP7euP/xw6H0jRgCLFnk/Nqjn67YcM5LWvC9upclSfRLzpZdCb9eVYBkg+yvRJJK5FYmfwMdtt3k/3sy3ebOUOY3FvHlymcjr/cEHifVpcn6WysvjX1a09QQdaIn0/59MXqUIzWv50kuh/bmcZXSB+F4L+2NqaiQ4ZPbZUyWTg2VBBJ/rmkz5XSd3mV62lFLrueeSu/xE9iViKeEIyABswCqZeOmlctm8uewj77efZG+98kr82xSLli39VaLq21e+N6NVIiAiouRoFH2WhmfyZLls0SL4DKYRI0JHV7Ztm9ho/nTKzpbLU0+1ajsbGzdKnec2bSQ7rbJS6iqXlcW2jo8/tq5fdpl1/csvrTrSxvjxwJYtcn3mTNm52HdfCbo553Wzc2fm9T4hotQbNkwGTRx7bPzLqK62viPjpbUE5XbbLfJ8yQyW+V1mpGBZrCdhnOtMV4klc2CttWTF/POf7vOtXAn85S/u92ktg2SaNrV6xZSVAbfcYpVRDOqkrp8sLrd1pfskZjzBMrPNiVYDSIYgykjHUobR/r/nNyjz5JPxbVeqPit+/uffeCP25frZ/poaYO7cYJc7aVJsywtKpO8lAOjfP/oyiopiX6/9eybVQTJD6+ifo3R9902YkJ71plO6f2coMgbLUu/66+OrvpAK8Zb1O/FEGRTTvLlkcr3/PvDUU+Hz7btv9GV16SLZXoD0BysuBtats3qQlZbKelq0CH/shRfKQO533w39Haiudv9dsPcwIyIiAhgsi6iiQg4Se/dO3jpM2UajcWOrVE5dtt9+1vXWreXSXnbIHMTu2iX9zpo3l0CX6ZUWDxMoA4BTTgm974Yb5AR4z55S7rGiAjjmGGDGDNlhU0pGGi1ZIun48+bJDp/9vdm6VVL/zcm5rVslEBctwLZ5MxsnE9UlN98s/+fxZuF8+y3wpz9JI2g/9e1vuAHYZ5/wYMy8ecCdd1q3y8vlZPhee0kpNVPCIxWZZZdfLt/TF1wQ2uDaMOt+993w+9x+0yKdyMyEjADnaxkpALJ1q/d9v/wil/aywsOHAy+/bN1OZrDMKdWZZX4kEgzNxF41yQoOxNKjzk063udYg06G27YqJWW4k01rqVYQ62MisX+Pp9K336ZnvfbXY/Pm9G9DIvNQMDLhd5288f1JvV270r0F3uLZtxoyRLLWH3hABmIceaRUJXILlkU7L3L44ZLpZaoVLVkiA9jNIDb7MmbNkhL5dkcc4f79nokDrIiIKDPxJyOKggKr2Xfz5slf365doWUblZIf9nhGdmYysxPWuLGMXvrjH6XkotaSlfbQQ1Lu6OOPgbfeklH4iXjhBSnl+MEHctL36quBk08GbrpJMtZMSn7fvsCBB0qd6qwsyWDbvBn44Qdg992BBx+0lrn77hIs+9vf3BucA9L7LTcX+OqryNu3caOcTOHIvnA33+yd0UEUi5oa+f+fMcPfvC+8EF+pL1MK1mQpRzN8uHvfF+dJ98mTJdvtpJMkGGekqgzjrbfK5dlnW9OOOCJ0nmnTwh/nFSzzksjz0Br45JPEX4v58/3PG+l7u21bubRnNzvnT2YZRsN8RuzlIjOF/eSF8/PkxTyf+hwsc76fS5dGns+thJ5dECdDY329X3wxvvW4BadNH91E+Nn+jz6K/XnWtaCL1pGD/Imy/54l+p7Fy8/nva69b3VZQyw9WZc01ONPPwPakiVZpYT9uPJK7/v+8hdroLOXAw8Mvb1+vZQg32034OmnrT5b++wT/lhT0txZsrprV+v60qWhbT1atgwNlNmddJKcQyIiIgoSg2UxqKiQA6vCwtSuV2vJbnMG0eprDeN99wXuuUdqUp97rgSznn7aClr+/DMwZ46MMLrzzmCDmLNmSbafcdZZEuw6/ni5/cADsm2NbDmZo0dLzzWl5ESx/USZycCYNSt0PV99JcsyrrtO+kacckrsTdBXrIh+UqCyMriTAlu3pvYEw7BhEjyl+Pz4o4ySr68HwlqHZq1GsnEjMG6cZJhGWp7x97+H9/ZJ5sl5rUN7+nita+3a5G0DIKVN7JlQhltZyWXL5DLSd4Lbsi69NDTgZ5dIGcb//Ed6WibaeyCW/xc/wRH7c3B+X6dyRLfbZyfVPcuc7MEy83lyWr48+mP9mjEjuf/HQQTLMjEICIS+n37e23ifR79+kXsExsvPNt9zj/SlDHq5mWT+fBnwlSzDhiVv2X4lo/ccUX1V177DgpLO5x1vyeann05svY8+GnkfOStLemq9+qrcdus1umqVdT8Q+bfe3p/r8suBwYPl+jvvyCBmQCppfPKJv+0nIiJKBQbL4jB8uBW4SXXgzO5//wsPoNXXTDS7Qw4BOnaUrK7HHrOCmFrLicCyMhk9X1wsNauDNnSo94nUc86RDIKxY4HHH7dKD9x+u2zPHXcAa9bISLb775eeGwMHWr3x5s6V2+ZEzXnnSeZacbG8t//9b+j6Fi2SQJ29QbvT1q1SKvLRRxN51uKXX+QEy2OPJb4sSo0ePeSA5uef070lyfHKKzIC0n6SvaQEmDgx8uPKykJLtxrOA+fS0sj3RxLrQfjIkfLd9umncttvv5WgMsvM49u0AS66KPz+SNsT6aSkW2bZe+95lwjzWtYPP8hgikil2EwwaPVq73n8iCUI4yewZl6D4mLvYNn48f7X6Sbe9z/Ik0XffBP7Y7KyZOBLpKbtM2fK5d/+JoNYjHiCMfZeqMmQ6oEJsfYVTOV6Eyl55Oxxe8stwGmnxb+8WBQXxzZ/Xes9/MMP6d6C5NM6+v9iQw0QEDk11MByOr8DystlkK29dYUfTZr4m++YY6zrRx0ll5deCtx1l5xDmTMHyMuzBgSbigonnyyXV18tr89xx4Uut0cPGTx31VXWNLcMMqO4GHj+ebluzwBr2lTO02gNdOgg015+uX6fwyIiorqDwbIE2QNnWlsll9LJKxNNKQnE1GcHHgjk5EhT2P33lxFL5r3Zvl0uN22SgNfy5ZKF4MwcCUKfPrIz6ty2f/0r9IRgQYFkkpmybcYeewDPPiujrEaPtjLUrrwyNAhgAiCDB0sj3epqCYzYR7b/9ptcmhFgv/4KzJ4tGXRDh7ofIO3YISUonQcR5oTQO+9EewUiu+oq4Oijw6dv2SIBA57ACI7JBqqvB8KmtM+SJda0v/5Vyns4M87sn6u8PPea+el8nRYulMtzz5X/wWiBgGHD5H89GWUY3UZ4RjrxHWndsfYZ8lrW00/Lsj76yPux48b5X09NjQxecGMveXfTTTKwwYvf4Mjs2fI7YO9XBljPt0cPf8vx4vXZjdQfzr5+L9ECz3ZnnBHbsgH5XD3xhPd7AVjbP3q0/DY5p8ci2VlbyepZlqggvtseeEBev+nTo7+3//pX8K91SUlij4/nO9LPY044IfblppNblnB94yezjPuaRCJT/hdeey3567AHdtKdWXbWWXIsbvz5z6HzmL63ds7vtTlzgJUr5Rh99mxrur3k/OzZ0iPe/vp27CgDy777Ts6JnHCCBMycrQ+clRHMOYDsbFlvRUX0gTGFhXJOpk+fyPP16xe5RCQREVGqMFgWsPXrMy94ZjdihHsQrSEE0po1k8s2bYC775aMrD595CSdeb8qKmRH0ATXXn9danevWiXNalNp0CDrun3n8vzzZXtGjw7N/ujaVXYy+/WTUWEmUGB2cktKpAfTvvvK/fvvL+WGTCDOrnlz2YF3niA2BxVeBxfmdXTz1VdWaZ4xYyS4oVRokKNfP9mhnj5dAtGZEuDZsSO+kdivvBJa1jMdzAFMppZh3LIltv5QTm7P76efwqfZKSW9CN0E+Zlznij+058kGOxn/nHjop9ovuUWCbwEFSyLtr5IJ1gjrTs/P7bt8FqWea8jvUc//iiXkV5n44knvLOZ7Afrzz0nJxnc/PKL//8t01PKWQoxqM+c1+vmp6RcpMzTxx+Pb3uA4Er1Ofv/mdI9mXKCL2ixBJn8vgZBfrd16RJ9vXfcASxYENw6g2C+H2JhLyFVX9hLiddXNTX+SzQTkTuTkZQqe+8d3+NMZhLg3dvKOOkk63o69yHatJHLv/3NmuYsT+6WseXc5o4dgYMOknNO+fmyT7pjh/T5MnJyZNk5OeHLy8mRcyKABMyc+/pmf+SQQ6xzRsZBB/lrh5GVJVlkmVpimoiIyInBsiRzBs/SWbYxGq9AWn0v62jXvLm1I9esGdC3r5REa99eGtXX1FjBtF27pEzQ118DDz4I3HqrjNy6/HLpc5ZMBx8cunNtjB4tl/PmSWm6228HnnxSpm3dKj2YnO6/X3qDbNsWPhJ3/nzrZNfbbwMTJsj1HTvkBOwpp0g2RGWl/GVlhTbktTvzTODmm8Onv/QS8O67ct2U0rv3XuCGG0KDddu2Rc48CEJ1tfuJ72uvlTIVfka1b9smgZhff5XHXXBB8NsZi0zNLNNaRi8ecADwhz+4zzNtmnzWvFRUuAfGnOUJndOjbZfz9u+/S9kTe0ZTPAd8334b+TfAuUw/69i6NdgyjPbXsVu30CxSr5Gj++6beI8w53bYmefnFiwzASgnZ/lMQL6vb73VKns7bVpi2wnId6rfYJnX+/n998H8f3q9/3vuGd43027yZOCww+JbdhD8fK++/nrobVOiz+92ffaZdT1TBw7YJaPca5C/ARUVsq8TTX0IZm7cmO4tCJ59kFJ9pbXst0abh4i8tWiR7i3wx1SZAKS8XyT27O/ddkvO9njJy7Oum/0a+76hCVoB7hVYAPktnzZNqtC4Bb+ysqzXYNGixMsEZ2UB77/vPWiMiIioPmKwLMWcZRu19jciJ50ilXVUSkaoNpRgmn1EVaNG1kite++VoFR+PvDmm3Lyz/4eL1smmVUVFcCoUZJh9cgjoaPbkuHJJyXIF8nXXwNDhsgBQ1ZW6IiyJ5+U0Xrvvw9cdhnw0EMyfckS2UmfNUv67DRtavUSKS6WUk07d7qvz37SEgCeeQa45BIpj7lokUwzZSfsPUt2202Cll995eup/7/SUjn48JMZdsQRsp4NG4ABA6w+Q2ad27bJ5cqV4f1UjL33lmCpCfJs2hQ+z/DhwLp1sT0PLwsXhpfxtPOTjZMqJSXAFVfI67hqlXyevBpcL1kiPQBvvNF7eb17W8Eyt+cXz4kwt+UsWybB8UGDpFQJALz1lgRCowXGN2+Ovyybn2CZvcRetOdbWWl9hr3YSyY6ezt5ZQDGWmYxGq/PqlsWob1nQjSPPy6lHPv08Zd55kdNTeJl94YMidxT0m9gNtL7/5//eN939dX+lp+JpkzxN1/XrtbJtLoQLHvggeCXGfTzfu+96PM0hAymusheqqu+8vP777Z/RkSWutKP0f7/7vZb9/vvciwLhO6zOQfiRHLwwXFtWshAs/x84MQT5bq9FPyIETIItlcvGVhXU2MdExt3320t46yz5PjC61jUOProYKocde8ee281IiKiuozBsgxQUVH3Amh21dWRg2lduqR7C9PvsMOkl0vz5sB110kPnMGDJdhk3nNz0rW0VAIpJSWSNfHGG1Iu7OKLpTyCabybShdfHH2euXOt6/ffDxx+uBxkTZwYehDzzTfujz/ySOu6OVnuFlCaOVMut2+X4Nlnn8lJ/K1b3Zfbpg2wYgXw8MNyUv/RR71PoqxYIQ2Xu3WToKYJFuzaJZcmM++QQ4DOneX5KRVaIswECc3BmPNk4W+/SdbceedZ0zZvjn+E8wknyLbY/ec/kl0IJL8M49SpkUtblZdb1x95RIJML70UPXhn3k/Tx8uNPXBqnt/kyVbpJec6/LzGbttlghUrV4bW8v/oI+9yjmabcnMlw9APk1npXG8ksQTLzjsvGv9c9AAAIABJREFU8ijaqVMzo+SY1/Mwz9MtizCa55+X7wBAMlmDyvJWKvHMMkCyy7z4yeABkpslkamlc7x+T9yYkrh1IVgWS/nCdGSW+bVlS+rXSQT4+7x/913yt4OoLkvlb789qyoRbpllLVtapRq7d7emO0s2RgqenXyydX7G7E8a5eUywG+ffaQKytNPW/f9/LNV5eX88+U41lk14/rrpZ+YUjL41P66X3ONXA4dKucInKUaiYiIKHgMlmUotwDa2LHp3qr4TJnCrDQ/lJKsrj33lNJ0ublSK75XLymn+N57EhSaOdP6TFRXyw761q1SFvGnn2TaTz8Bjz0mGQt7752eE+Br18rzOP/80FF1JjvNyR50MNlCjzzivfxly+SApEcPKeN33nmSjWRGCt99d+jBxo4dkoVy990SgHzmGQky7dolAS77CUf7icoJE6xMN3umzaxZVpDK2ZAZsA76nMEyc6K2pEQCd0rJez1ihEwvLo58AqekxMp489K3rzVy0WQKOk8QX3VVeJZfPDp3Bo47zv2+H36QA9T//ldu28sjupU7tPOTEWf/XJnnZ38vamrk9TTZa17LevFFCfi7zWMPRsXKbJPf7+7ffot9HfbXTWv5nD/xROjI2fffl96EJgNxwgQrAGznFXBONednoWtXOYHhFvj1GwCIlKGYiKCCZUGckEpmsMytybwfpk9lJli1Si4zIcs2SH6fTzqedzw9wuqq+t73t65hiUWixKWyTKFSMtDSbuJE2cfyU67Z8MqWz8uT6go33CDH0+PHy3R7uda+fYEvv3R/fIsW8rjXX5fja+Oii+S+KVNkX6ldO+kpPHiwbP9BB0kJ8LIyyR5r1Ch6qUi7UaOs4xh7NhoRERElD4NldUhBQXgArS5motlFy0pTiicgIsnKkh301q3lgOaII2TaEUcAd95pZVMVF1uflaoqOWn2228y0n7oUMnQefdd+RzZGwJnogcekOwhEzAymUvTp0u5iQMPlBPjzrJmO3dKQBGQz9w//iHBgyZNpD/dFVeEr+uii0JHIAISdDDs5Um+/9492OEMlpkTONu2WSU1AOCpp+TzfuCBwOmnhy9n5kwJPu21l3wX+GWCZfbgSU0NMGaMBCG++05eu6DMnWu9N6Zs36RJcmmeu/1527fJbburq4HnnpPG0E72kqH/+lf4/dXV8nqee27oOpyBieuvt4L2QY1sta/PL+fJPT+Pd2aWPf64/O+PGiWf36++kszQs8+2HtO9u/RZNDIta8jteT/3nBUsu+UWa3q0E6Jah/aycN6XqG+/tUb9JiLTg2XxcusdF69YyiW5efxxuWyowbK6kFFXl5kBL5QZ7FngRBTZgQe6Tzf7Js6BD5WVkXuhejHBt/x89/uc++CdO8u+3+67ey+zfXvpnXv88XK8Yd/fBWTwqNGqlTynE06QfWRAWgHYz6N06mRV57B76ikJ5vXta01r29YKujk98ohUKjHc+ov5kZ1dd8/zEBER1VUMltUTbploWkfeuawrRoyIHExjdlpssrPlddtrL6k/fvfdUiKyRw/5HP3+e+hnqKZGSkh88428F1OmyElHky3Uvr217FQ0gi4vl+whr3KUO3dKyTWnTz+NfGA3bpy/9dsPwuy14jt2tEp82C1ZYpUF1BoYPVqub98eOt/KlaG3nSc2Tz1VDgQB4J13JBgSqQ8RYL1HQGgmkb001umnW/3mqqq8e4g57dwZ/nr+9pscAPfrJ7ftmWT2285MPiD8hK89s+ymmyTgcf757vMA7j3pTN8f05Q62kllrePL7vKSSLDMnh0YyfDhwKuvWrdNdtjatcAHHwB/+Yv74+yfN7cgS6oCaKWloWVMvbYHCH2/jWgBgI8+cg+0BuWXX/wHhCK9pu+8E8z2pJOzv0bQguqtdsIJwSwnU2RyZhlRujjLGhNlEj89H5Np8ODQ2yZjydk6wQy0a9w4dHrjxqF9t3v1cq+icPXVMhjTWLlSSuybkvVvvSUtB55+2uopNmGCNb/JwLLv/23dKuUOjXbtZHsWLJAqI6a3VrNmcul2bOY0f35oVRH7Y8x15zmV4mLZdiIiIqp/GCyr57Zs8c5GC6Lhaybwk53GvmnxU0p6dJ1+umTgnHMOcMcdkomltZS2Mp+p8nIre+2NNySzraZGgjoPPADcfLOcvP/gAzm4GTrU/QR4XbVxo/v0vn2B1aulnKZbVpWbxYvloLJDB2DkyPD7BwwIHd3497/LQeXatda0K6+0erx9+aW8NyUloVlF9m3v1St85GNNDTB7dnhA4KGHgFNOCZ1mMsrGjpVRmV7BMsDK8jN27JDPx6+/SsajWZ89GDJxYuhj7JllzuUD4SP93QIrpuQnYB28O8USOPr3v61ee7H21oqnZJnpwwSEngw32+z1nKIFmZyvbbLccosEv02JPACYMSN8PvNd7hQtAGBKT7qZMsXfNtYVK1akd/3HHpve9fvRv791Ai3T+f0+yOSeZUREFC7WLKNog+NisXatZD2tWGFlcpn9qz59pCz+8cdLz2ev/svG3LlyfPfGG9I6wGnUKBmMuX69BJdMq4Hrr5f7u3aVx91yi9Uy4IILZP/dDC60b9/ee0s1lV9+scol2nteA/Kcfv5ZKnhMnSrriObww60BicaCBTLY7ttv3QfS7b9/astUEhERUep47PpQQ2AvIWdXVGT176kvTN80L0pJWbpYytuRt+xsCbwYffqEz2OyPZzBo+pqOYA78ECpCX/wwVLi8KCDgKVL62YW4fjx3mU6vNgP2goLo8//wgtyaUoOOt13nwTERo6UA1Une/B8zBgJhG3bZo0c/etfJUsHkGCQW01/cz8gWVE33STXTelPu19/Db394YfS3+iXX2SkqRHphLEzoGMvNenGrQyjvVync5sAyfjxk+EFSL88e4lAr95aw4ZJqVClvINZ8bA/r2gBvrfeAu6/X04y2DMkjUaN3F/PSy9NaBPDLFwol/bg6WWXhc83d678OUUKFGgtwUsvqQ4ebNuW2vVRuJdekgEf9YnfMrosw0hElBmi7a869ekj2VTPPCPHTZ06xb9uU3Lx4IOBTz6RCgVbt0p2VdOmwB57WFlWZt5GjSRgd9VVocs68URrH9lewaK8XMrcmyCbc4DuwIGR2yyYYJrd0qWh2V2dOknv5TPOCJ/3kEPk0lmSMRb247BUVE4hIiKizKF0Jja58JCfn6/nzJmT7s1o8AYObLi9GQoL5aCCMkNNjRycNW0qIyHff19OhO67r5wUrayUkZHFxcA994Q//vnnpZRgkCM265MnnwRuu826fcYZMir0gw/C5507V0pRetl3X+kLYEpkvveejDY1Xn9dGl9HozXwyity4G3vBQAAb77p3nvOPO7HH4HjjvNe9scfSwmXWJmf0U2bZNSrcdVV1mdr1qzw0qFdusgJE3sfvESdfTYwbRpw112hfRrcHH64nHzIhJ5lc+fKCZeKithGXB9xRGh2oP259OiR/lJHlHmKihrmwJg2bSSzmIiooZo9O7R8YLJ89ll4GeyHHgLuvVeuv/++1TPLD+fpmmj7bXvv7V1W3O3Uz//+J/v8998fmkW2775WxYf99nOvFGF8+SVw1lne9xMREREFTSk1V2vt0g01Mb4KoCmlzlVKLVVK/ayUusvl/jyl1BSl1EKl1BdKqQNs9/VVSi2v/etrm95RKfVD7TKfVSoTTteRH8OHe5d2HDs2M068Jgv7p2WWrCyrnv2eewLXXCM91Jo1k8ydW2+VUoVDhrh/Xm+4Qcp8bNtmlZDcsUP6iT3/vGQdrV4tB72XXCI19e2ZQ/Wd6R9gfP21e6AMiJ7d8MsvoQfPzmwmv1k+c+cC114bHigDvANlftdhHxUbi5oa6Y/iLOtnD8K69dibPDnYQBkggTKzTdHU1GTOCQ2T9fLnP8f2uJoa4PPP3ftlMVBGbhpqOUIGyoiS6/DD070F5OQcxJWf756JFDStQ8vMX3utDNp78EHgu++ssuV2CxcC9jHBLVtGXsett0r/aUCy6E84QfbF77tPqsfs3ClVGwAZLNGkifeydt9dSuc7yy2a3mDmWOu990L75Nrt2BF5e4mIiIjqiqiZZUqpbADLAPwZQDGA2QB6aa0X2+Z5G8BHWuvRSqlzAFytte6jlNoTwBwA+QA0gLkAOmqttyilZgEYBGAGgEkAntVafxxpW5hZVvc15Kw0O2ao1Q87d8oBZFWVjMpctEiCdZs3S039226T2998I6Ult2yRx3XsKEEfr1J3dVGHDlLCJZJzz5WSL4nwkzHlRmsJxEye7D1Pfco4ufVW4Kmnos9XXh5774xkmD4d+MMfYu8n1aKFZKMB8h7X58EaFIzRo0P7PRIRBYHZm6lz443Ac89Fn2/iRODiiyULvbJSMtFravz1ZT3pJMlEi9UNN1j9a6+7To73Dj44NBC1YIHsNxvvvw90727dnj5dejubsulep2smTZJstZkzvfuKlZXJ8y0pkf6wsZRwXL9e9pv9/GZOnAicf74MLnz7bf/rICIiIopXsjLL/ATL/gjgfq1119rbgwFAa/2obZ5FALpqrYtrM8S2aq1bK6V6AThLaz2gdr4XAXxR+zdNa31k7fSQ+bwwWFb/MZhmadRIStPVl5P35E1ryaz5/XcJvjVvLiNM77tPMrl69JD7DzoI+OGH8Awmiq6qyvtEQn10882R+3UZS5fKSaR081uGM5IdO2IPtlHD89prwNVXp3sriKi+yc7O3N6A110nWdirV6d7S/xp104qRrgNwqqpsSp6AJLRt2wZ8OmnQNeuofN6neaYMydyOcZNmyT449wvadVK9tUB2c864wygZ0+5/cILQOfO/vepbr9dSh9efLF3JvyPP8r6/vhHf8tMp6oqYPBg4M47JXBMRERElGzpLMO4P4B1ttvFtdPsFgCo3VXExQBaKaVyIzx2/9rrkZYJAFBK9VdKzVFKzdm0aZOPzaW6LFKJR/PXuXO6tzI1qqqA3r0jl31UCtjf9T+H6hJTwnOPPSRTRikpp/L++/KZf/dduf7MMzLC0/k/8dtvwNq18pmZO1cO8D/6SEbQVlVZJVN2202adXfoICcKDj9cStI0BG496+ozP4EyIDMCZUDigTKAgTLyp7Aw3VtARPVRJgbK8vOBGTOAUaMSz7zu2lUqBBhbt8a3HHvZ7iefdJ/n55+BefNkX/W996Q8+lFHAaecYj2Ppk1lX3n+fCk3+Je/SJlDQPanDz3Uexvy82X/2fQQGzRIylivWQMsXizBHrfXa9s2qR7xzDPA0KEymM08h549Y9uneuIJGbAUqWT0scfWjUAZIMcx//oXA2VERERU9/nJLLsUkjV2be3tPgBO1lrfaJunLYDnARwE4CtI4OwYAP0BNNVaP1w7370AKmrneVRr3aV2+hkA7tBaXxBpW5hZRn4dc4wc7FCoZs2Al19mthq501pGsLZuLbe3bZOTFa1aycmWH36Q8jL9+slJhBNPZCYoERER0amnyr5S0Jo0ce9x5aVdO+mL9cILwEMPWSUHDzkEWLnS+3G33y7BDqdJkyQActJJkpl7zTUyXWvgqquAMWOAc84Bpk6Nvm0zZkjAq2dPCRK9844Ewb7/XkpHm0yyqip/pRKdKiuBN98E+vRJPDi4c6f0Kb7mGtn3fewx4Oyzw+fTWkpaR+sxRkRERETByugyjI75WwL4SWt9AMswUqYqKpKsLXLXsiUwciSDahSfFSukD9buu0uA9tdf5UTIySfLiOKjjpKgXF6eXP/1V+uxffrIiRciIiJKXBD9Qhu6Sy+N3Idp0SJgn30kqJSTI8ETQAJUK1bEv94+fSRgc9ZZMoDJzVVXAf/5j3Xb69De9JQ68EAp8b3//nLZv7+Upn31VemttWpV6OPsy9u1S4J3LVta5QgB4JVXgGuvletu/XjffVfKLU+YILfXrwf++U+pKNK0qTVfTY2swz6NiIiIiMhNOoNljQAsA9AZwHoAswFcqbVeZJunDYDNWusapdRQANVa638qpfYEMBfAibWzfg+go9Z6s1JqNoAbAcwEMAnAc1rrSZG2hcEySpWiIinJUVqa7i2pGwoL5YCXKAhmlG5OjpwcatxY+rjNny8nZC66CJg1S0pSDhoE7L23BHe/+06avh92mJwAevHF8GUfc4yc1CIiooare3f5nWgILrzQClLUZUp5B4KS7YorJGPJi3273n9f+lCddZYEKU2J4EsukUwquzvukHJ80ZapNZBV2zxh4UIp+VhSIr1sDzlEAkxffilBKnupROfyBg+W/mWHHGJNnzhRSv3tuacs+4QTvLcDCA0M2ufZulUGSdl99pls42GHuW8TEREREVG80tazTGtdBeDvAD4FsATAOK31IqXUg0qpC2tnOwvAUqXUMgD7ABha+9jNAB6CBNhmA3iwdhoAFAJ4GcDPAFYA+DioJ0WUqIICOQiN1j+NvU/EiBHRe6uZv+bNJRhJ5EUpGbWslPRZM33c/vAH4PnngS5dgLvvlpI/3bvLSZ7Ro4Hly4GbbgLOO0+CZ5WV8n/644/W/6z9+sKF0vD+l1+A8eOByy6THhTPPScnsIqKgIcfDt++o47y3xPMr0zpHUZE1BA4AwL1WaNG/uZ7+un417HXXtb1nBy5DKIX5YMPyu+01sCnn8o0Uyo6KPbtNFUnLrwwdJ5YMp1MIKpHD3ncvfcCX30lmWmffx46b6tWobfPPBP4+GPpnWWnFLB6tfSjPe446T3bpYu1rsaN5bZXoMws47HHQgNlAPDXv0qgDACOP16Cd6efDqxbJ/tJTsccE96XSqnwQBkgfcQYKCMiIiKiuiRqZlkmYWYZ1SVFRcCQIeEHvBS7zp0li4gok61aJf/vrVoBublyYqtDB+mf+OGHcoLrl1+Ao48Gioulcf1++wEzZ0qwbvhw4K235PaJJ0pvkYEDJSOgsFAayv/8c7qfJRFRdHPmAPmBj/ELzpAhMjjCS9Om0rMoERMnSiDC6YIL5DchVdzWd+utwPbtoVUBnn4a+Mc/4lvHBx/I4JUJE4ABA4CNG+V37oADQuc74QRgwQLr9g03SG8tN5dc4l768N57ZSDLpElSznnTJqBvX8mqWr9esp5uvBG4557Qx91yi/yOAvJbevfdwLhxss133CE9fadOlfKAL7wg2/bII1KCcY89rADR9OkyqG7lSnmezZqFB4qKi6XMoVffrF27pEfXLbcAY8fK+zN+fOJ9toiIiIiIGoq0lWHMJAyWUX3WpQswZUq6t6LuY781aiiqquRE3Y4dMiq8rExGgf/6q5RrWrdOTvoNHgw8/riMFP/ySyA7W7LuamqAN94A+vWLvq7jj3cfYQ5I/5N160KnPfoocNttcsJwxw7JxqP6p107YO3a4JfbqZNkYiRb69befYBeftnqwROr9u0lWF5X7L038NtvwS7zhx9kgEC8Fi+WgQWJ+vRT4PrrrT5M/fvLd9LIkfL9eMMNUibOqaQkPHsmVlq7Bz+0lkDKhg2h06+/XrYrVm3bhi/LBKGaNQPOOCM8o8kc/tm37+mnJcv5r3+V7/Cbb5bXraJCAp/XXiv/F4BkcP/lL8A338i89uwhE8zavl2qCQCyfZWV8p1x0knA3LnWNqxbJ79Rt94qv2nPPCP/ly+/LL8vTrt2AV9/DZxzTvhzeuQRoFcv6b31009SjvnGG+U3sX17KV/4228yUKWsTAJVAwZYr0N1NTBtmuyTV1WFZuXZX7OSEvl969Ah4ltDRERERERJkqxgGbTWdeavY8eOmqihKyyMVhySf37/CgvT/W4Spd/OnVovWaL1rl1al5Za03/7TevKytB5d+3SuqxM67VrtV68WOuKCmve8nKtV6+W6U4lJVpv2CDzT5ok0958U+v//lfrpUvl/3HePK0/+0zrRx/V+pNPtL78cq07d9b6ppu0fuYZrdu0kfluu03rLl2s/+M//Unr887T+sUXtX7oIa2//db7f/6mm7SeMEHrK64Inf7OO7JNNTVaH320TOve3br/tNPCl3XEEfLaOae/+GL4fOb6jBlat2vn7/vpkku0HjbMuj1njry+F10kt3v21HrRIuv+nj3lcvhwrbt10/rTT637nM/X/phbbpHXG9D6gQe0vu46radN03rmzNB5//EPrfv103r2bK2bNpVpCxdqfddd4cvday+tDz3UfZ3vvht6+8YbtX7qKbn+yCPyWdJa6+efl2mvvOL9Gl16afi0uXP9vb6LFsnnedUqa9q0adZ14513oi/rrbe0/v5767Z9mRdfLPeb2x9+6G/7Bg0KvX3BBd7z3nefdT0nx9/yZ87U+uqrtV6xIvQ9PO88a30LFsh185kzf88+q/XLL1u3335ba6Xk+oMPyv+Y1lrvs4/12Z0xQ7YzJ0frPn3Ct2f6dNmOM86Q+bTWeu+9rfdixozQ+V99NXwZixdr3alT6PuptXw3Od9XO3NfcbF8Lj7/3PqO+sc/5P279lqtzzzTmnfHDq23bbNu33KLPKZHD7n9/fdyu2dPrV9/Pfy7dMcO+T6cN0/mf+01mf7111r/9JPWVVXWsu3fM7fdFrrNP/4otz//XOuRI+V76+uv5bts+3b5W7xY3teKCq3Hj5f3w/j2W/lOPuUUrTdtcn993F6rSGpqrOe7fbs8V7uqKvnfIyIiIiIiiheAOVoHH39iZhlRPTNwIDBqlIyOpeQ4+mhpcE5EqbNrl5ymbdJEbm/fLiP73fqhLFsGHHqoZBMAkkVn+iYa69ZJdoFbP5/KSukBM2eOrKdTJymPWVwM9OwZOu+CBZLN16ULsGWLlOAEJHthzz1l+StWSBaTva9PUZFsT00NcPbZcjlrlmS5lJXJOgHJyNi61crO+/13YOnS8BJ3O3dK2bfzz7deo5IS2bbDD5fM5WOPlUyPpk3lvrZtrXk3bZJMGvtrVFYGlJdL30Bnbx37+zJ1qjz/7dultNj118v8v/8uJdEAKUG6ebN8f1ZVSRbJtGlWxuLGjcC++4auf+tW6Vu4fbtsAyCP3bVL3r/27SVzsrBQ7l+3Djj5ZPn9Ky8Hbr8d+PZbee2OO06ySJYvlwyZl14Kfy41NVKGrlcv4JRTQu978UV5XsuXy2dr7lzguuuAefPkdcrJkfJsGzbIZ6R3b3mPzevXo4f0+nnoIXk+b74JXHmlvP4vvCCfxUsukXWddpps98KFUibu5putLCfz+rz3nnyejjpKPnNm+oYN8jpu3CifYfP5XbNGnp/Znixb1+KqKsnUOftsuV1cLOtr1kz+55SSy/Jy+fxkZ8t8y5fLe5SfLxlI69ZZn1vzem7b5t7LaNYs2U6TbWQ+h3ZLl8oyu3SR2/PnS5brhx/K57x1a3mPV60CunaV17OqCnjnHeDyy0M/S3PnSim9gw8OX09JiTzXli3D73N67jkpDW2y3tavl/fv4YflNa2uludkMqoSoZRs8+bN8lpOmybrBoDZs4HS0sg9qpLhp5/k89OuXWrXS0REREREZMcyjGCwjChoAwcCI0akeyvqP5aGJCJKzAsvAH/8o/Tzqwt27JBA0d57B7vcykoJXDVtGjq9qkqCV24lTzdvlqApy6HWLXPmSBlCE3AmIiIiIiIiwWAZGCwjSoeiImDIEBmVTqmTmwsMG8YAGxEREREREREREZGRrGBZVvRZiKghKygAVq/20wEl/M+t9BL5U1oqZbxM6bhof6ZMFRERERERERERERHFhsEyIkqaLVuiB9TGjrV6/FD8pkzxH1iz/7VvL9mDRERERERERERERA0Vg2VElFYFBUBJSWwZawywBWfNmugZbFlZ0t8OkMBa+/YyjYE2IiIiIiIiIiIiqg/Ys4yI6rWBA4FRo4Dq6nRvScPSrBmwcyfQrh0wdCh7rxEREREREREREVHi2LOMiCgOw4cDVVWxZa01aZLura77duyQ19NP5pr5a9YMaNOGWWtERERERERERESUWgyWERHZFBRIRlQsZSE7d073VtcPO3cCpaWxBdkaNfLuvcaSkUREREREREREROQHg2VERAmaPNk7Sy0vT4I5eXly2z6dEmfKa7oF13r3lunO4FujRlYPNiIiIiIiIiIiIiL2LCMiymBFRcCQIRLsodTJygIGDJAynkRERERERERERJQZ2LOMiKgBKigAVq/2328tJyfdW1w/1NQAI0b467Vm/tq0YalHIiIiIiIiIiKiuojBMiKieqKgACgri63fGvuuBae0NHKftexsln8kIiIiIiIiIiLKRAyWERGRZ981rx5sTZqke4vrnniy1bKz5bJ9e2atERERERERERERJQuDZURE5IspCVlTA+zcyZKQqVBTI5dr1oRnrTVvLgG0oiIJpiklvdZYFpKIiIiIiIiIiCg2Smud7m3wLT8/X8+ZMyfdm0FERAErKgIGDZJShpR8ubnAsGESACUiIiIiIiIiIqorlFJztdb5QS+XmWVERJR2BQVASYn/Hmtjx0rAh+ITrb+ayUzr0iU0W61VK2arERERERERERFR/cNgGRER1Tl+gmv2Hmt5eUDnzune6rqltBSYMkVeS6OszDvIxv5qRERERERERERUVzFYRkRE9ZK9x9rq1cDkyeyzlkyR+qvZ+6mZYJrptZaVJVlsbdrIdQbbiIiIiIiIiIgo1dizjIiIKAZFRcCQIRIUotRgjzUiIiIiIiIiIgLS3LNMKXWuUmqpUupnpdRdLve3U0pNU0rNU0otVEp1q51eoJSab/urUUp1qL3vi9plmvv2DvapERERBc9krLG3Wur46bGWlSU91tq0Ce275sxiY+YaERERERERERE5Rc0sU0plA1gG4M8AigHMBtBLa73YNs8oAPO01iOUUkcDmKS1bu9YznEAPtBaH1x7+wsAt2mtfaeKMbOMiIjqK2aspZ5SEtTMywOGDo2cuWben7VrgXbtos9PRERERERERETBS2dm2clxt053AAAgAElEQVQAftZar9RaVwJ4E0B3xzwaQOva67sB2OCynF4A/hvvhhIREdVn0TLWmKUWPDNeyKvPmlJAq1Zy2bu3zKe1Nf/AgfLXqJHM06iR3HZiZhsRERERERERUWbzk1l2CYBztdbX1t7uA+AUrfXfbfPsB+AzAHsAyAHQRWs917GcFQC6a61/rL39BYBcANUA3gXwsHbZGKVUfwD9AaBdu3Yd13DIPRERUQi3rKdvvwVGjEj3ljVc2dkSWKup8Z4nK0vuz8sDunUDJk1i5hoRERERERERUSTpzCxTLtOcQa1eAF7XWh8AoBuAMUqp/1+2UuoUABUmUFarQGt9HIAzav/6uK1caz1Ka52vtc7fa6+9fGwuERFRw2Ky0mpq5LKgABg+XLLR8vIk6ykvT26PHQvk5KR7i+u/6urIgTLAun/NGglsOjPXnNltJoON2WlERERERERERMHyEywrBnCg7fYBCC+z2A/AOADQWk8H0AxAG9v9V8BRglFrvb728ncAb0DKPRIREVFA3IJoBQVAWZl3uUevv8LCdD+bhqusTC6rq+UyUtlI+1+bNqFBtUTKQbKUJBERERERERHVZ37KMDYCsAxAZwDrAcwGcKXWepFtno8BvKW1fl0pdRSAKQD211rr2gyztQA6aa1X2pa5u9a6RCnVGBJIm6y1HhlpW/Lz8/WcOXPifa5EREQUsKIiYMAAoLw83VtC0Shl9WlLVIsWwKhRLBVJRERERERERKmVtjKMWusqAH8H8CmAJQDGaa0XKaUeVEpdWDvbrQCuU0otgAS+/mbrP9YJQLEJlNVqCuBTpdRCAPMhQbiXAnlGRERElDKRMtUKC6V3FyCXnTsDubnp3d6GLKhAGQBUVFjZbS1bShabvVQkS0YSERERERERUV3ipwwjtNaTtNaHa60P0VoPrZ32T631hNrri7XWp2utT9Bad9Baf2Z77Bda61MdyyvXWnfUWh+vtT5Gaz1Ia10d5BMjIiKi9Bo+HKiqkiBNVRUweTJQUhIeVDO91QAJsFDdUl4OlJbKdVMqMtGSkXZuJSD9loVk+UgiIiIiIiIi8iNqGcZMwjKMREREDVNRETBkiARfnLKzreAM1X+NG0uArbLSmuZWFrKoCOjfX7Lg7HJzgWHDWEKSiIiIiIiIqC5KWxlGIiIionQrKABWr3Yv91hVZWWnKSXBkJyc8GXk5kppSJaCrNt27QoNlAESEOvTxyoHqZRktDkDZYBkwfXvH55lZrLQIpWRZKYaERERERERUf3EzDIiIiJqsAYOBEaOtPp5NW0qgZLy8vRuF2WOxo2B1q0lyKZUaO83t4w2wMqEXLsWaNcOGDqUmWxEREREREREQWBmGREREVHAhg8HamqsLLUdO4CyMvcMNnt/NaXcs9cAyTqi+mPXLqsnm3OMWUWF1ZPNZKOZrLY1a2T+NWsk682eqZZIhhqz24iIiIiIiIiCx8wyIiIioiQYOFCyjqqrJVDSpAmwc2e6t4rSLStLAmv2UpIme23z5vBMNHu/PmdmW7THEhEREREREdU3ycosY7CMiIiIKI3sJfv23FOmbd4sJf62b5fMt+xsYJ99gA0b0rutlFpuwTG/8vIYOCMiIiIiIqL6h2UYiYiIiOqhggJg9WoJipWUyF9NjZSDrK6WYElVFbB+vZSBzM11X07jxnKfUhIo6dw5pU+DkiCRMW1r1lglIrOygC5dwss3mpKO9jKSLO1IREREREREDRGDZURERER1REGBBNOc/dPy8oDXXrMCbatXA5Mnh88zdqzVf62wMN3PhlJFa2DKlNA+ar17A1ddJdcBCcwCoUG2Nm3CA2d+eqaxrxoRERERERHVNSzDSERERNSAuZWBLC2V0o/V1ZKttmMHUF4eeTmJlAykzNe5MzB/vnw27JQCzjkH+Pln6zP0v/9ZwTcjNxcYNoxlIYmIiIiIiCgxLMNIRERERIFzKwNpSj9qLbfLyiJnqWktjzfX3cpF5ubKdJaHrJumTAkPlAHhWWulpeGBMkCm9+4t2WpdulhlHxs1AgYOjG1bmLlGREREREREQWOwjIiIiIiisgfVVq+OnCFkLxdp/kpKZLpbecjCQrkEZBrVX6WlElwzAbXqamDECHnf7X+tWnn3V+vTJ7SkZP/+/gJmQQfZGLQjIiIiIiKqPxgsIyIiIqKUcgbehg+XS5OhZg+m5ebKn/O6PbvNzE/1R1lZaH+13r2t/mrOcp8VFcCgQXJ94MDwrLWiIsloM8vwG2SLFAwrKpLHxxO0IyIiIiIioszDnmVEREREVG+49WDbvDm0Hxv7qzUskd5v531ZWcCAAcDpp0vwq6LCuq9FC2DUKLnet697ucm8PAn8EhERERERUXIkq2cZg2VERERERD4MHAiMHMlAW0OWmwts3x4aRLNTSrIjiYiIiIiIKDmSFSxjGUYiIiIiIh+GD5dAiL0Xm/lz9mHr3Jn91+qj0lLvQBkgmWkDB8bWy4y9z4iIiIiIiNKPwTIiIiIiogQ5+7BNngyMGRMaQCssDA+oUf1SXQ2MGBHay6xvX6BlS3nflQKys+WyTRuZ7uyl1qePBNz8YrCNiIiIiIgocSzDSERERESUwYqKgEGDJKvJyM0FLrsMGDcudDrVL3l5wNChEox1U1Tk3VvN6zFERERERER1GXuWgcEyIiIiIiIvRUXA1VcDu3ZZ0xo3Bjp1Ar74QrKeqO7KyQGaNQM2bwbatQO6dZOgmNv7mpsrWWtr18q8kQJuREREREREdQl7lhERERERkaeCAuC110JLPb72mpSErKqyeqvl5lqPyckBGjVK3zaTf+XlkkVoyjWOGOEdAC0tDS3t2Lu3lH10lmi0l3Bs00b+3Mo5mvmUks+LUiz5SERERERE9Qszy4iIiIiIGrCiImDIEO8sJPv9LVoA27dLbzYjNxfYsUOCOVR/mHKOQHipR7vcXGDYMGauERERERFRajCzjIiIiIiIAldQAKxeLQGw1avDgx72+8vKJJtJa+uvpESm26eZLLa8vDQ8IQpERYVkpPXu7R0oAySLrX//yFlrXllofuYhIiIiIiJKBWaWERERERFRUpnstDVrpISfOQQxWUkAcM01QGVl+raREhcty9C899nZwBFHAEuWWJ8F+zKYqUZERERERF7SmlmmlDpXKbVUKfWzUuoul/vbKaWmKaXmKaUWKqW61U5vr5TarpSaX/s30vaYjkqpH2qX+axSSgX3tIiIiIiIKFOY7DStJUPNnpVWUCB/r75q9VvLzbV6q2Vny2VenmSrObPXmjRJ29Mih9LSyOU4TWCsuhpYvDg8UGaW4ZapRkRERERElExRg2VKqWwALwA4D8DRAHoppY52zHYPgHFa6z8AuALAcNt9K7TWHWr/rrdNHwGgP4DDav/Ojf9pEBERERFRXWYv91hSIn9aA1VVculVInLnTgma5eREX0fLlkDnzsnYegqSKQGplPy1aeNdxrFNm+jzERERERERReMns+xkAD9rrVdqrSsBvAmgu2MeDaB17fXdAGyItECl1H4AWmutp2upA/kfABfFtOVERERERESQoJm9b5rpl6ZUaEba778DkyfL7RYt0r3V5FdpaWjwzPz17i33uc3HwBkREREREcXCT7BsfwDrbLeLa6fZ3Q+gt1KqGMAkADfa7juotjzjl0qpM2zLLI6yTACAUqq/UmqOUmrOpk2bfGwuERERERE1ZPYsNa+MtFGjQgNqhYXhJR2zs8Mz1nJyrBKRlLmcAbbsbLls3x4YONBfRlpRkcyflSWXDL4REREREdVffoJlbr3EnNXlewF4XWt9AIBuAMYopbIAbATQrrY84z8AvKGUau1zmTJR61Fa63ytdf5ee+3lY3OJiIiIiIgicwbUhg8P7ZuWlweMHh2asaa13DYlIu1ZbJTZamrkcs0aYMQI74w083fMMdI7bc0aeZ/XrJHbAwcygEZEREREVB/5CZYVAzjQdvsAhJdZ7AdgHABoracDaAagjdZ6p9a6tHb6XAArABxeu8wDoiyTiIiIiIgoZaJlpEV6jD2gFqkUpPOvsDDJT4risnix9E6zq6iQQJs9gHbNNQyYERERERHVB36CZbMBHKaUOkgp1QTAFQAmOOZZC6AzACiljoIEyzYppfZSSmXXTj8YwGEAVmqtNwL4XSl1qlJKAbgKwAeBPCMiIiIiIqI08xt4Gz48PLBWWMhSj3VFZaWVlWYv9WgCaKaUo1KSjRat9CMREREREaWH0tq1+mHoTEp1A/BvANkAXtVaD1VKPQhgjtZ6glLqaAAvAWgJKad4h9b6M6VUTwAPAqgCUA3gPq31h7XLzAfwOoDmAD4GcKOOsjH5+fl6zpw58T1TIiIiIiKiOqxLF2DKFH/z5uYCHToAU6dKFhSlllLAOecAX30F7NoVed68PKBbN2DSJGDtWqBdO2DoUH+ZjUREREREDY1Saq7WOj/w5foJlmUKBsuIiIiIiKghGzgQGDUKqK6WTKb+/SU7LZKiImDQIKtPV06OXJaXJ3dbKX5ZWcAeewCbN3sHz4qKgCFDGGAjIiIiooaFwTIwWEZERERERJRMJgCzZk26t4TcZGdLoDSS3FzgssuYqUZERERE9VOygmV+epYRERERERFRA2B6rWktf507p3uLyC5aoAyQDMIRIyTgqbVcXn219EnLygrtqUZERERERILBMiIiIiIiInI1eTIwdqz01VJKSjhm1R5FZmdLMC03N73bSNHt2iVBNBM8691bgmcMmhERERERCQbLiIiIiIiIyJPJNqupAcrKJLtJa6CqSoJpJSVWJprWVnANkIAaILcLC6MH1sz8lHylpRI0GzgwdHpRkWSfxZKFZh6jFNCokVwyg42IiIiI6hL2LCMiIiIiIqKMYe+b5qdHFwUjLw/o1g145RWgsjL0vpYtgfJy9/5nRUVA//5ARUX4Mlu0AEaNYr80IiIiIgoOe5YRERERERFRvWfvm1ZVFZq1Zs9ea9Ei3Vtav6xZI73OnIEyQDIK7SUclbLKOA4Z4h4oA2T6kCGxZavFk9lGRERERJQoZpYRERERERFRnWMCNWvXWhlPQHhWWk6OZEVR+jRuLH3T7Ldfey0848wtS43ZaURERERkl6zMMgbLiIiIiIiIqF4bOBAYOVKyo+wYSEufrCx5P9q1k/KPkyZJkNNNXp5kGxIRERERsQwjERERERERURyGDwfGjJGgi1JyOXaslBfMy0v31jVMNTVWaccRI7wDZYDcx5KMRERERJRMDJYRERERERFRvWd6odXUyKUp6zd0aHj/M6Xk0gTVtAYKC1O5teS0Zg1w9dUSMCsqkp5pSslfy5byZ26bfmrR+p+xPxoRERERGQyWERERERERUYNVUCA9sexZZ2PGSIDMHlQb/n/t3Xt01eWd7/H3l4BgkEobpnWECnbsUu4XM1SP1hs9jpdptVZXoQlScYqgrdbpmiMVpxdnWMvbadEZwaEdrQM55bjsOO2ytoylnGo7ow6XEC/owVZAxGMhrchFLoHn/PHbm+wkOyGBhCTk/Vprr9/+Pb/n98tv7ywenuzPfp5nfhacNQ7W+vSBsrKGI9ZmzaoP3NR+9u2DysrsUVtbX75zZ8PpNGtrYdo0mD49C9nyI9imTs2m5IT69dEKj8+Y0f6BmYGcJElS9+CaZZIkSZIktVJVFcyZAxs3ZuttzZ1bH6gVq7dhA5SUwP79WZg2d252/JZbGgY+OnrKyrJtsfe/pAQefbT477St8oHcrl31ZaWlWTjbHteXJEnqiTpqzTLDMkmSJEmSOkGxMEWdr6VAq7VhKWQjyYqtxTZ0aDZqUZIkSW3XUWGZ0zBKkiRJktQJik0BmV8jrfHDqR2Pnl274IYbmpa3derGjRvbVi5JkqTO48gySZIkSZK6gWKjmsApHTtS4dSZ06Zl02kWq1NspJgjyyRJktqfI8skSZIkSerBKiqykOXAgWxbUZE9tm6tH4G2eHHTkWqLF0Mv//o/LBs2QGVl9igWlOXr5EeXVVVlIVmvXrBjBxx3XMO6paX14ZskSZK6DkeWSZIkSZJ0jCu2PlpEFrCpffTtm72fe/c2LD/hhCw4KynJAreyMti+vb5er17ZtI/z57fu57Rl3TRJkqRjjSPLJEmSJEnSYSm2PtqiRdmos9LS1l+nrCxbP60t5/QUe/Y0DcogC8qgfmRabW3DegcOwIIFcOON9WX5EWoR0Lt3th02LKvTlnXTJEmS1DrdfmTZvn372LRpE7t37+6ku1Jb9OvXjyFDhtCnT5/OvhVJkiRJEk1HKp12Gvzylw1HnZWWZmFbfgRTVZVrpXWESZOgurr597W50YDF1kFzBJokSToWddTIsm4flr3xxhsMGDCAsrIyIqKT7kytkVKitraW7du3c+qpp3b27UiSJEmSmtHaoKWw3oc+BLt3w86dR/9+e7qIbIQaNB9k5oO2oUMNziRJUvdlWEbxsGzt2rWcccYZBmXdREqJV199leHDh3f2rUiSJEmSjoJ8oLZhQ2ffybHruOPgT/80e49bsxZdBMyc2fp10iRJkroK1yxrgUFZ9+HvSpIkSZJ6loqKbIrAlLLH4sVZuKP2s3dvfRjZmu9EpwQPPeRaZ5IkSXmtCssi4pKIeC0iXo+I2UWOnxIRyyNidUTURMRlufL/HhErI+LF3PaignP+T+6a1bnHh9vvZUmSJEmSpK6oogL27MlCs6FDs1FOQ4fCrFlN98vK6s/r3z/b9zuY7SMlmD4dhg3L3tPevbPtsGGGaJIkqec5ZFgWESXAg8ClwAhgSkSMaFTtDuCxlNJ4YDKQH8i/Ffh0Smk0MA1Y1Oi8ipTSuNzj90fwOlqtqirr+PXq1T4dwNraWsaNG8e4ceM46aSTGDx48MH9vXv3tuoa1113Ha+99lqLdR588EGq2qm3eu6551JdXd0u15IkSZIk6XDkR5wdOJBt589vur91a/2ItB07sv0DB7IgTUeucETa/v3ZdsMGmDoVbryx8+5LkiTpaGvNyLKJwOsppd+llPYCS4ArGtVJwAdyz08ENgOklFanlDbnyl8G+kVE3yO/7cNTVQUzZmQdv5Sy7YwZRxaYlZWVUV1dTXV1NTNnzuTWW289uH9cbl6JlBIH8ivtFvHII49w+umnt/hzbrrpJipcfVeSJEmSJObPzwKzkpJsv6QEJk3q3Hs6lqQECxZAnz5NPzM5ki8ht/cXmCVJktpLa8KywcCbBfubcmWFvgVURsQm4CngK0Wu8zlgdUppT0HZI7kpGP82mlnMKiJmRMSKiFixZcuWVtxu8+bMgV27Gpbt2pWVt7fXX3+dUaNGMXPmTCZMmMDbb7/NjBkzKC8vZ+TIkdx5550H6+ZHetXV1TFw4EBmz57N2LFjOfvss/n977MBd3fccQfz5s07WH/27NlMnDiR008/nf/4j/8AYOfOnXzuc59j7NixTJkyhfLy8kOOIFu8eDGjR49m1KhR3H777QDU1dUxderUg+UPPPAAAN/97ncZMWIEY8eOpbKyst3fM0mSJEmSWmv+fKiry4Kdujr4xS9arh/RcFpHHVpdHVRWwqBBWcB1wgnZfuGXkCsrs7DyUFM5dsQXmCVJktpLa8KyYiFW4+VipwA/SCkNAS4DFkXEwWtHxEjgbuCGgnMqctMzfjL3mFrsh6eUFqaUylNK5X/yJ3/Sittt3saNbSs/Uq+88grXX389q1evZvDgwdx1112sWLGCNWvW8PTTT/PKK680OWfbtm2cf/75rFmzhrPPPpuHH3646LVTSrzwwgvce++9B4O3f/iHf+Ckk05izZo1zJ49m9WrV7d4f5s2beKOO+5g+fLlrF69mt/85jc8+eSTrFy5kq1bt/Liiy/y0ksvce211wJwzz33UF1dzZo1a/jHf/zHI3x3JEmSJElqX0OHFi+PgEWL6qd1zK+Xptaprc3et507ix/PT6ZTOJVjPmSrqsoe06YdvS8wS5IktVVrwrJNwEcL9oeQm2axwPXAYwAppf8E+gGDACJiCPAEcG1K6bf5E1JKb+W224H/RTbdY4c65ZS2lR+pP/uzP+PP//zPD+7/8Ic/ZMKECUyYMIG1a9cWDcuOP/54Lr30UgDOPPNM1q9fX/TaV111VZM6v/71r5k8eTIAY8eOZeTIkS3e3/PPP89FF13EoEGD6NOnD1/4whd45plnOO2003jttde45ZZbWLp0KSeeeCIAI0eOpLKykqqqKvr06dOm90KSJEmSpI42dy6UljYsi4CZM7M10vLy66UVBmcR2XbWrPr9sjLIrbCgw1Bbm4VmU6fWB2mNtfQFZqdtlCRJR0trwrL/Aj4eEadGxHHAZOAnjepsBCYBRMRwsrBsS0QMBH4KfD2l9Jt85YjoHRH5MK0P8JfAS0f6Yg6lWKe5tDQr7wj9+/c/+HzdunXcf//9/PKXv6SmpoZLLrmE3bt3NznnuIJeeElJCXV1dUWv3bdv3yZ1Umo84K9lzdUvKyujpqaGc889lwceeIAbbsgGBC5dupSZM2fywgsvUF5ezv7merqSJEmSJHWCigpYuLBh+LVoUTZlY0vnrF+fjY5avz6rm9/fuhX27MkCtOKLR6g1DvVxRWEIlg/IIppO+Th1KnzqU9mItYjskZ8CctCg+ukimwvWDN8kSVJzDhmWpZTqgC8DS4G1wGMppZcj4s6I+Eyu2teAL0XEGuCHwBdTlsR8GTgN+Nvc2mTVEfFhoC+wNCJqgGrgLeB77f3iGivWaV64sOG3yzrKe++9x4ABA/jABz7A22+/zdKlS9v9Z5x77rk89thjALz44otFR64VOuuss1i+fDm1tbXU1dWxZMkSzj//fLZs2UJKiWuuuYZvf/vbrFq1iv3797Np0yYuuugi7r33XrZs2cKuxvMnSJIkSZLUyRqHX+3xN//8+Vnolp+6saQk2zry7MillIViN96YhVfXXZcFY83VXbYsG7GWl58Csra2frrIfLB244319VwzTZIktaR3ayqllJ4CnmpU9o2C568A5xQ57++Bv2/msme2/jbbT0XF0QnHGpswYQIjRoxg1KhRfOxjH+Occ5q8XUfsK1/5Ctdeey1jxoxhwoQJjBo16uAUisUMGTKEO++8kwsuuICUEp/+9Ke5/PLLWbVqFddffz0pJSKCu+++m7q6Or7whS+wfft2Dhw4wG233caAAQPa/TVIkiRJktQVtfR5Qj6IKfxOaWlp9gVdgFtuaRjwqKkFC7JHe0kJHnoIzjkn+73NmdP8mmmd8TmRJEnqWqKtU/d1pvLy8rRixYoGZWvXrmX48OGddEddS11dHXV1dfTr149169Zx8cUXs27dOnr3blUmetT4O5MkSZIkHWuqqrLgZePGbG30uXObhjD5Ohs2ZDPedKOPZLqtsrJsOs1evYq/3xH1o9MkSVLXFxErU0rl7X3drpWi6Ijs2LGDSZMmUVdXR0qJf/qnf+pyQZkkSZIkScei1sxkU1incbh22WXw1FNZkFZSAvv3Q//+sHNnx9/7say2NlvnrFev7D1t7JRTjv49SZKkrueQa5ap+xg4cCArV65kzZo11NTUcPHFF3f2LUmSJEmSpCIar602f362TQnq6rLtjh2weHH9Wmk6PMuWFQ/KIAsnBw3K1jcbNiwL1YYNa7iWWVVV88ckSdKxwbBMkiRJkiSpi8qHaik1fJSVdfadHTtqa7P10jZsyN7bDRugsjIbkXbCCdnzwmMzZtQHZm0J0gzdJEnqugzLJEmSJEmSupn774fS0s6+i2PbsmXFp8HctSsL0AYNgunTmw/SClVVZcdaU1eSJB19hmWSJEmSJEndTEUFLFxYP0VjSUm2LSvLHhHZscWL60ejzZrVefd7LKqthb17G5bt2gW33NK07pw52bHGdefM6bj7kyRJrWdYJkmSJEmS1A0VTtGYX+ds69bskV8LraKivv78+fWhWURn3fWxr7a26YixjRuL122uXJIkHV2GZUfoggsuYOnSpQ3K5s2bx4033tjieSeccAIAmzdv5uqrr2722itWrGjxOvPmzWNXwVeTLrvsMt59993W3HqLvvWtb3Hfffcd8XUkSZIkSVLXMn8+LFqUjTzLj0CbNct10NpT49Flp5xSvF5K2bpogwa5lpkkSZ3JsOwITZkyhSVLljQoW7JkCVOmTGnV+SeffDKPP/74Yf/8xmHZU089xcCBAw/7epIkSZIk6diXH5WWH4E2f342Ii0/ZePixa27jiPUiqutzabGjMhCsA0bmq+7c2dWP7+WWWVldl7+MWBAFqBVVWVhWltCtcM5R5KknuiYCsu++lW44IL2fXz1qy3/zKuvvponn3ySPXv2ALB+/Xo2b97Mueeey44dO5g0aRITJkxg9OjR/PjHP25y/vr16xk1ahQA77//PpMnT2bMmDF8/vOf5/333z9Yb9asWZSXlzNy5Ei++c1vAvDAAw+wefNmLrzwQi688EIAhg0bxtatWwH4zne+w6hRoxg1ahTz5s07+POGDx/Ol770JUaOHMnFF1/c4OcUU11dzVlnncWYMWP47Gc/yx//+MeDP3/EiBGMGTOGyZMnA/CrX/2KcePGMW7cOMaPH8/27dtbfgMlSZIkSVKXU1FRvx5aY0OH1odqixZBnz5H9966iwMHsm1KR3adHTtg6lSYPj0L0/Kh2tSpWZjWXAhWVQUzZjQ8Z8YMAzNJkoo5psKyzlBWVsbEiRP5+c9/DmSjyj7/+c8TEfTr148nnniCVatWsXz5cr72ta+RWughLViwgNLSUmpqapgzZw4rV648eGzu3LmsWLGCmpoafvWrX1FTU8PNN9/MySefzPLly1m+fHmDa61cuZJHHnmE559/nueee47vfe97rF69GoB169Zx00038fLLLzNw4EB+9KMftfgar732Wu6++25qamoYPXo03/72twG46667WL16NTU1NTz00EMA3DDmdWEAAA60SURBVHfffTz44INUV1fz7LPPcvzxx7f9TZUkSZIkSZ1u7lwoLW1YVlqaledVVMAjjzScwrF//2xUldpPSrB3b9MyaDoabdCgLBCbMwcKJiMCsv05c47OPUuS1J307uwbaE+5wVNHXX4qxiuuuIIlS5bw8MMPA5BS4vbbb+eZZ56hV69evPXWW7zzzjucdNJJRa/zzDPPcPPNNwMwZswYxowZc/DYY489xsKFC6mrq+Ptt9/mlVdeaXC8sV//+td89rOfpX///gBcddVVPPvss3zmM5/h1FNPZdy4cQCceeaZrF+/vtnrbNu2jXfffZfzzz8fgGnTpnHNNdccvMeKigquvPJKrrzySgDOOecc/vqv/5qKigquuuoqhgwZ0pq3UJIkSZIkdTEVFdl2zhzYuDFbd2vu3PrywnqNy/JhTeF5kIU66li1tS2/zxs3Hr17kSSpu3BkWTu48sorWbZsGatWreL9999nwoQJAFRVVbFlyxZWrlxJdXU1H/nIR9i9e3eL14oik32/8cYb3HfffSxbtoyamhouv/zyQ16npRFsffv2Pfi8pKSEurq6Fq/VnJ/+9KfcdNNNrFy5kjPPPJO6ujpmz57N97//fd5//33OOussXn311cO6tiRJkiRJ6nyN1zZrHIq15byKioYj0FqS++6vOsCHPuQ6ZpIkNWZY1g5OOOEELrjgAqZPn86UKVMOlm/bto0Pf/jD9OnTh+XLl7OhpdVcgfPOO4+qXA/lpZdeoqamBoD33nuP/v37c+KJJ/LOO+/ws5/97OA5AwYMKLou2Hnnnce//du/sWvXLnbu3MkTTzzBJz/5yTa/thNPPJEPfvCDPPvsswAsWrSI888/nwMHDvDmm29y4YUXcs899/Duu++yY8cOfvvb3zJ69Ghuu+02ysvLDcskSZIkSdJB99/fdGrHQmVlsHhxtk7XrFnZtIJqX9u2uY6ZJEmNGZa1kylTprBmzRomT558sKyiooIVK1ZQXl5OVVUVZ5xxRovXmDVrFjt27GDMmDHcc889TJw4EYCxY8cyfvx4Ro4cyfTp0znnnHMOnjNjxgwuvfRSLrzwwgbXmjBhAl/84heZOHEin/jEJ/irv/orxo8ff1iv7dFHH+Vv/uZvGDNmDNXV1XzjG99g//79VFZWMnr0aMaPH8+tt97KwIEDmTdvHqNGjWLs2LEcf/zxXHrppYf1MyVJkiRJ0rGnogIWLoShQ7MgbOjQLBxLKXts3Vo/em3+fFi0qL5uWRkcd1zz1x46NAvY1LLGEwzt2gXTptUHZlVVjjyTJPU80dJ0fV1NeXl5WrFiRYOytWvXMnz48E66Ix0Of2eSJEmSJOlwFVsPrXB6yKoquO462Lev8+6xO+rTJwsl9+5teqxXL7jhhizAzDvU70GSpI4QEStTSuXtfV1HlkmSJEmSJKnbONQ6ahUV8MgjLY9Ii4BJk1wbrdC+fcWDMsje6wULsvftU5+CQYOgsrLhdI7XXZeVOyJNktQdGZZJkiRJkiTpmFIYqG3dCg8/3HDqx0WL4Be/yNZGW7w4G1Wl1lm2DGprm5bv25eV58OzysosPDM0kyR1B8dEWNadppLs6fxdSZIkSZKko62l0WiFI9HUvmprs9CsXz9HnUmSurZuH5b169eP2tpaQ5huIKVEbW0t/fr16+xbkSRJkiRJOigfpqVU/1i8OJvCUUduz56Go85mzIAbb8wCtIj6hyPRJEmdJbpTyFReXp5WrFjRoGzfvn1s2rSJ3bt3d9JdqS369evHkCFD6OP8BpIkSZIkqRuIaP7Y4sXZds6cLATSkSspgYED4Q9/gFNOgblzm65LJ0nquSJiZUqpvN2v293DMkmSJEmSJKmjDBtWPAgbOjQbjdZYVRXcckvxdb3UdhEwcybMn5/tV1Vl4eTGjfVhGjQtM2CTpGNTR4VlrZqGMSIuiYjXIuL1iJhd5PgpEbE8IlZHRE1EXFZw7Ou5816LiL9o7TUlSZIkSZKkzjZ3LpSWNiwrLa0PaRqrqICtW7NRZ43PU9ulBAsWwIABWXBWWZmFl/kpHadNg+nTG5ZVVhaf0rGqKgs/XTtNktTYIcOyiCgBHgQuBUYAUyJiRKNqdwCPpZTGA5OB+blzR+T2RwKXAPMjoqSV15QkSZIkSZI6VUUFLFyYjSSLyLYLFx565FLheZBNL1i4Vdvs2FG8fP9+2Lu3aXltbbY2Wj4Qq6rK9gtDtcLjkqSerTUjyyYCr6eUfpdS2gssAa5oVCcBH8g9PxHYnHt+BbAkpbQnpfQG8Hrueq25piRJkiRJktTpKiqyKRcPHMi2rZ3iL39eSlBX13C7eHF9kNbSumg6fLt2ZdMzQrbdtavp8WnTDMwkSdC7FXUGA28W7G8CPtGozreAf4+IrwD9gU8VnPtco3MH554f6poARMQMYEZud09EvNSKe5akthgEbO3sm5B0zLFtkdQRbFskdQTblk6W0qAPwcmDoc9xDY/seA+OL4WS1nyGpyI2bGg5jNy/P5u2sbKydgus39jy1Qp/T/v2wua3YOsf2veOjym2LZI6wukdcdHW/Edb7L+T1Gh/CvCDlNL/jIizgUURMaqFc4uNaGt8zawwpYXAQoCIWNERC7dJ6tlsWyR1BNsWSR3BtkVSR7BtkdQRbFskdYSIWNER121NWLYJ+GjB/hDqp1nMu55sTTJSSv8ZEf3IvjnQ0rmHuqYkSZIkSZIkSZLUoVqzZtl/AR+PiFMj4jhgMvCTRnU2ApMAImI40A/Ykqs3OSL6RsSpwMeBF1p5TUmSJEmSJEmSJKlDHXJkWUqpLiK+DCwFSoCHU0ovR8SdwIqU0k+ArwHfi4hbyaZT/GJKKQEvR8RjwCtAHXBTSmk/QLFrtuJ+F7b9JUrSIdm2SOoIti2SOoJti6SOYNsiqSPYtkjqCB3StkSWaUmSJEmSJEmSJEk9T2umYZQkSZIkSZIkSZKOSYZlkiRJkiRJkiRJ6rG6RVgWEZdExGsR8XpEzO7s+5HUtUXERyNieUSsjYiXI+KWXPmHIuLpiFiX234wVx4R8UCujamJiAkF15qWq78uIqZ11muS1HVERElErI6IJ3P7p0bE87l24n9HxHG58r65/ddzx4cVXOPrufLXIuIvOueVSOoqImJgRDweEa/m+i9n22+RdKQi4tbc30MvRcQPI6Kf/RZJbRURD0fE7yPipYKyduunRMSZEfFi7pwHIiKO7iuU1BmaaVvuzf1NVBMRT0TEwIJjRfsjzWVHzfV5WtLlw7KIKAEeBC4FRgBTImJE596VpC6uDvhaSmk4cBZwU67dmA0sSyl9HFiW24esffl47jEDWABZ5w/4JvAJYCLwzXwHUFKPdguwtmD/buC7ubblj8D1ufLrgT+mlE4DvpurR649mgyMBC4B5uf6O5J6rvuBn6eUzgDGkrUx9lskHbaIGAzcDJSnlEYBJWT9D/stktrqB2T//gu1Zz9lQa5u/rzGP0vSsekHNP33/jQwKqU0Bvi/wNeh+f7IIbKj5vo8zeryYRlZA/p6Sul3KaW9wBLgik6+J0ldWErp7ZTSqtzz7WQfOA0mazsezVV7FLgy9/wK4F9S5jlgYET8KfAXwNMppT+klP5I1mDbaZN6sIgYAlwOfD+3H8BFwOO5Ko3blnyb8zgwKVf/CmBJSmlPSukN4HWy/o6kHigiPgCcB/wzQEppb0rpXey3SDpyvYHjI6I3UAq8jf0WSW2UUnoG+EOj4nbpp+SOfSCl9J8ppQT8S8G1JB3DirUtKaV/TynV5XafA4bknjfXHymaHR3is5pmdYewbDDwZsH+plyZJB1SbvqQ8cDzwEdSSm9DFqgBH85Va66dsf2R1Ng84H8AB3L7ZcC7BZ25wnbiYBuSO74tV9+2RVKhjwFbgEcim+L1+xHRH/stko5ASukt4D5gI1lItg1Yif0WSe2jvfopg3PPG5dL0nTgZ7nnbW1bWvqsplndISwrNk9tOup3IanbiYgTgB8BX00pvddS1SJlqYVyST1QRPwl8PuU0srC4iJV0yGO2bZIKtQbmAAsSCmNB3ZSP5VRMbYtkg4pN73ZFcCpwMlAf7Ipihqz3yKpPbW1LbGNkdRERMwhW2anKl9UpFq7ty3dISzbBHy0YH8IsLmT7kVSNxERfciCsqqU0r/mit/JDfEnt/19rry5dsb2R1Khc4DPRMR6sqH9F5GNNBuYm94IGrYTB9uQ3PETyaYYsG2RVGgTsCml9Hxu/3Gy8Mx+i6Qj8SngjZTSlpTSPuBfgf+G/RZJ7aO9+imbqJ9mrbBcUg8VEdOAvwQqctOzQtvblq003+dpVncIy/4L+HhEnBoRx5Et5PaTTr4nSV1Ybl7afwbWppS+U3DoJ8C03PNpwI8Lyq+NzFnAttw0AkuBiyPig7lvZl6cK5PUA6WUvp5SGpJSGkbWH/llSqkCWA5cnavWuG3JtzlX5+qnXPnkiOgbEaeSLWL9wlF6GZK6mJTS/wPejIjTc0WTgFew3yLpyGwEzoqI0tzfR/m2xX6LpPbQLv2U3LHtEXFWrq26tuBaknqYiLgEuA34TEppV8Gh5vojRbOjXB+muT5Ps3ofqkJnSynVRcSXyRrVEuDhlNLLnXxbkrq2c4CpwIsRUZ0rux24C3gsIq4n++Pxmtyxp4DLyBaH3AVcB5BS+kNE/B1ZwwtwZ0qp8aK2knQbsCQi/h5YTRbWk9suiojXyb6ZPRkgpfRyRDxG9oFVHXBTSmn/0b9tSV3IV4Cq3B94vyPri/TCfoukw5RSej4iHgdWkfU3VgMLgZ9iv0VSG0TED4ELgEERsQn4Ju37+cos4AfA8WTrE+XXKJJ0DGumbfk60Bd4OsvPeS6lNLOl/kgL2VFzn9U0f0/1I9kkSZIkSZIkSZKknqU7TMMoSZIkSZIkSZIkdQjDMkmSJEmSJEmSJPVYhmWSJEmSJEmSJEnqsQzLJEmSJEmSJEmS1GMZlkmSJEmSJEmSJKnHMiyTJEmSJEmSJElSj2VYJkmSJEmSJEmSpB7r/wM203FUbOyE7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2160x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results(analysis,\"FastText_MLP_12000_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 64\n",
    "epochs      = 10\n",
    "learning_rate = 0.0003\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(8, kernel_size=(3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling1D((4),padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(4, kernel_size=(3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling1D((2 ),padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=learning_rate)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 200)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 200, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 200)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.expand_dims(X_valid, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 200, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 3000 samples\n",
      "Epoch 1/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 1.0310 - accuracy: 0.4532 - val_loss: 0.9841 - val_accuracy: 0.4997\n",
      "Epoch 2/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9753 - accuracy: 0.4981 - val_loss: 0.9645 - val_accuracy: 0.5103\n",
      "Epoch 3/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9635 - accuracy: 0.5093 - val_loss: 0.9561 - val_accuracy: 0.5147\n",
      "Epoch 4/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9547 - accuracy: 0.5177 - val_loss: 0.9501 - val_accuracy: 0.5230\n",
      "Epoch 5/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9504 - accuracy: 0.5218 - val_loss: 0.9434 - val_accuracy: 0.5297\n",
      "Epoch 6/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9480 - accuracy: 0.5254 - val_loss: 0.9414 - val_accuracy: 0.5330\n",
      "Epoch 7/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9431 - accuracy: 0.5268 - val_loss: 0.9418 - val_accuracy: 0.5300\n",
      "Epoch 8/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9408 - accuracy: 0.5286 - val_loss: 0.9419 - val_accuracy: 0.5273\n",
      "Epoch 9/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9417 - accuracy: 0.5261 - val_loss: 0.9444 - val_accuracy: 0.5260\n",
      "Epoch 10/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9392 - accuracy: 0.5312 - val_loss: 0.9428 - val_accuracy: 0.5310\n",
      "Epoch 11/1800\n",
      "14000/14000 [==============================] - 1s 106us/step - loss: 0.9400 - accuracy: 0.5315 - val_loss: 0.9417 - val_accuracy: 0.5280\n",
      "Epoch 12/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9375 - accuracy: 0.5304 - val_loss: 0.9361 - val_accuracy: 0.5277\n",
      "Epoch 13/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9362 - accuracy: 0.5301 - val_loss: 0.9367 - val_accuracy: 0.5307\n",
      "Epoch 14/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9367 - accuracy: 0.5344 - val_loss: 0.9362 - val_accuracy: 0.5287\n",
      "Epoch 15/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9337 - accuracy: 0.5313 - val_loss: 0.9330 - val_accuracy: 0.5307\n",
      "Epoch 16/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9331 - accuracy: 0.5344 - val_loss: 0.9304 - val_accuracy: 0.5360\n",
      "Epoch 17/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9321 - accuracy: 0.5354 - val_loss: 0.9327 - val_accuracy: 0.5320\n",
      "Epoch 18/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9327 - accuracy: 0.5327 - val_loss: 0.9299 - val_accuracy: 0.5317\n",
      "Epoch 19/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9328 - accuracy: 0.5330 - val_loss: 0.9287 - val_accuracy: 0.5317\n",
      "Epoch 20/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9320 - accuracy: 0.5299 - val_loss: 0.9328 - val_accuracy: 0.5280\n",
      "Epoch 21/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9289 - accuracy: 0.5380 - val_loss: 0.9320 - val_accuracy: 0.5273\n",
      "Epoch 22/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9315 - accuracy: 0.5331 - val_loss: 0.9280 - val_accuracy: 0.5290\n",
      "Epoch 23/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9280 - accuracy: 0.5379 - val_loss: 0.9280 - val_accuracy: 0.5290\n",
      "Epoch 24/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9286 - accuracy: 0.5341 - val_loss: 0.9305 - val_accuracy: 0.5320\n",
      "Epoch 25/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9294 - accuracy: 0.5314 - val_loss: 0.9314 - val_accuracy: 0.5277\n",
      "Epoch 26/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9291 - accuracy: 0.5378 - val_loss: 0.9258 - val_accuracy: 0.5307\n",
      "Epoch 27/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9280 - accuracy: 0.5370 - val_loss: 0.9259 - val_accuracy: 0.5307\n",
      "Epoch 28/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9258 - accuracy: 0.5376 - val_loss: 0.9285 - val_accuracy: 0.5297\n",
      "Epoch 29/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9299 - accuracy: 0.5339 - val_loss: 0.9253 - val_accuracy: 0.5303\n",
      "Epoch 30/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9236 - accuracy: 0.5388 - val_loss: 0.9299 - val_accuracy: 0.5313\n",
      "Epoch 31/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9250 - accuracy: 0.5369 - val_loss: 0.9256 - val_accuracy: 0.5293\n",
      "Epoch 32/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9254 - accuracy: 0.5359 - val_loss: 0.9262 - val_accuracy: 0.5323\n",
      "Epoch 33/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9239 - accuracy: 0.5400 - val_loss: 0.9264 - val_accuracy: 0.5313\n",
      "Epoch 34/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9243 - accuracy: 0.5371 - val_loss: 0.9234 - val_accuracy: 0.5303\n",
      "Epoch 35/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9250 - accuracy: 0.5359 - val_loss: 0.9309 - val_accuracy: 0.5300\n",
      "Epoch 36/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9238 - accuracy: 0.5385 - val_loss: 0.9232 - val_accuracy: 0.5317\n",
      "Epoch 37/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9230 - accuracy: 0.5393 - val_loss: 0.9240 - val_accuracy: 0.5310\n",
      "Epoch 38/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9249 - accuracy: 0.5382 - val_loss: 0.9245 - val_accuracy: 0.5333\n",
      "Epoch 39/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9229 - accuracy: 0.5372 - val_loss: 0.9273 - val_accuracy: 0.5280\n",
      "Epoch 40/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9227 - accuracy: 0.5351 - val_loss: 0.9270 - val_accuracy: 0.5307\n",
      "Epoch 41/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9223 - accuracy: 0.5382 - val_loss: 0.9277 - val_accuracy: 0.5323\n",
      "Epoch 42/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9220 - accuracy: 0.5369 - val_loss: 0.9259 - val_accuracy: 0.5307\n",
      "Epoch 43/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9219 - accuracy: 0.5376 - val_loss: 0.9265 - val_accuracy: 0.5330\n",
      "Epoch 44/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9224 - accuracy: 0.5381 - val_loss: 0.9280 - val_accuracy: 0.5293\n",
      "Epoch 45/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9215 - accuracy: 0.5384 - val_loss: 0.9240 - val_accuracy: 0.5323\n",
      "Epoch 46/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9203 - accuracy: 0.5391 - val_loss: 0.9231 - val_accuracy: 0.5317\n",
      "Epoch 47/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9198 - accuracy: 0.5412 - val_loss: 0.9242 - val_accuracy: 0.5313\n",
      "Epoch 48/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9213 - accuracy: 0.5377 - val_loss: 0.9257 - val_accuracy: 0.5297\n",
      "Epoch 49/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9216 - accuracy: 0.5400 - val_loss: 0.9240 - val_accuracy: 0.5317\n",
      "Epoch 50/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9183 - accuracy: 0.5420 - val_loss: 0.9275 - val_accuracy: 0.5287\n",
      "Epoch 51/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9223 - accuracy: 0.5410 - val_loss: 0.9261 - val_accuracy: 0.5327\n",
      "Epoch 52/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9211 - accuracy: 0.5384 - val_loss: 0.9242 - val_accuracy: 0.5327\n",
      "Epoch 53/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9203 - accuracy: 0.5375 - val_loss: 0.9239 - val_accuracy: 0.5357\n",
      "Epoch 54/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9190 - accuracy: 0.5394 - val_loss: 0.9268 - val_accuracy: 0.5327\n",
      "Epoch 55/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9219 - accuracy: 0.5385 - val_loss: 0.9256 - val_accuracy: 0.5320\n",
      "Epoch 56/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9212 - accuracy: 0.5410 - val_loss: 0.9247 - val_accuracy: 0.5323\n",
      "Epoch 57/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9210 - accuracy: 0.5382 - val_loss: 0.9252 - val_accuracy: 0.5340\n",
      "Epoch 58/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9190 - accuracy: 0.5351 - val_loss: 0.9268 - val_accuracy: 0.5323\n",
      "Epoch 59/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9179 - accuracy: 0.5389 - val_loss: 0.9269 - val_accuracy: 0.5307\n",
      "Epoch 60/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9197 - accuracy: 0.5376 - val_loss: 0.9291 - val_accuracy: 0.5317\n",
      "Epoch 61/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9180 - accuracy: 0.5392 - val_loss: 0.9213 - val_accuracy: 0.5333\n",
      "Epoch 62/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9177 - accuracy: 0.5382 - val_loss: 0.9236 - val_accuracy: 0.5307\n",
      "Epoch 63/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9201 - accuracy: 0.5419 - val_loss: 0.9235 - val_accuracy: 0.5327\n",
      "Epoch 64/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9170 - accuracy: 0.5369 - val_loss: 0.9222 - val_accuracy: 0.5327\n",
      "Epoch 65/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9189 - accuracy: 0.5424 - val_loss: 0.9257 - val_accuracy: 0.5277\n",
      "Epoch 66/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9169 - accuracy: 0.5416 - val_loss: 0.9221 - val_accuracy: 0.5320\n",
      "Epoch 67/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9167 - accuracy: 0.5402 - val_loss: 0.9250 - val_accuracy: 0.5313\n",
      "Epoch 68/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9188 - accuracy: 0.5445 - val_loss: 0.9220 - val_accuracy: 0.5337\n",
      "Epoch 69/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9191 - accuracy: 0.5424 - val_loss: 0.9204 - val_accuracy: 0.5287\n",
      "Epoch 70/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9204 - accuracy: 0.5401 - val_loss: 0.9204 - val_accuracy: 0.5350\n",
      "Epoch 71/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9168 - accuracy: 0.5410 - val_loss: 0.9229 - val_accuracy: 0.5340\n",
      "Epoch 72/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9187 - accuracy: 0.5422 - val_loss: 0.9220 - val_accuracy: 0.5327\n",
      "Epoch 73/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9182 - accuracy: 0.5420 - val_loss: 0.9243 - val_accuracy: 0.5340\n",
      "Epoch 74/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9172 - accuracy: 0.5436 - val_loss: 0.9199 - val_accuracy: 0.5333\n",
      "Epoch 75/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9164 - accuracy: 0.5418 - val_loss: 0.9257 - val_accuracy: 0.5303\n",
      "Epoch 76/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9160 - accuracy: 0.5409 - val_loss: 0.9233 - val_accuracy: 0.5327\n",
      "Epoch 77/1800\n",
      "14000/14000 [==============================] - 2s 131us/step - loss: 0.9190 - accuracy: 0.5354 - val_loss: 0.9204 - val_accuracy: 0.5347\n",
      "Epoch 78/1800\n",
      "14000/14000 [==============================] - 2s 133us/step - loss: 0.9171 - accuracy: 0.5400 - val_loss: 0.9259 - val_accuracy: 0.5323\n",
      "Epoch 79/1800\n",
      "14000/14000 [==============================] - 2s 127us/step - loss: 0.9182 - accuracy: 0.5438 - val_loss: 0.9205 - val_accuracy: 0.5320\n",
      "Epoch 80/1800\n",
      "14000/14000 [==============================] - 2s 113us/step - loss: 0.9182 - accuracy: 0.5396 - val_loss: 0.9258 - val_accuracy: 0.5287\n",
      "Epoch 81/1800\n",
      "14000/14000 [==============================] - 1s 107us/step - loss: 0.9165 - accuracy: 0.5418 - val_loss: 0.9200 - val_accuracy: 0.5333\n",
      "Epoch 82/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9163 - accuracy: 0.5429 - val_loss: 0.9214 - val_accuracy: 0.5300\n",
      "Epoch 83/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9155 - accuracy: 0.5395 - val_loss: 0.9213 - val_accuracy: 0.5327\n",
      "Epoch 84/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9172 - accuracy: 0.5424 - val_loss: 0.9234 - val_accuracy: 0.5280\n",
      "Epoch 85/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9174 - accuracy: 0.5409 - val_loss: 0.9198 - val_accuracy: 0.5363\n",
      "Epoch 86/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9155 - accuracy: 0.5384 - val_loss: 0.9200 - val_accuracy: 0.5323\n",
      "Epoch 87/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9173 - accuracy: 0.5389 - val_loss: 0.9178 - val_accuracy: 0.5340\n",
      "Epoch 88/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9163 - accuracy: 0.5426 - val_loss: 0.9198 - val_accuracy: 0.5293\n",
      "Epoch 89/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9162 - accuracy: 0.5374 - val_loss: 0.9200 - val_accuracy: 0.5323\n",
      "Epoch 90/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9170 - accuracy: 0.5411 - val_loss: 0.9193 - val_accuracy: 0.5337\n",
      "Epoch 91/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9177 - accuracy: 0.5390 - val_loss: 0.9194 - val_accuracy: 0.5333\n",
      "Epoch 92/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9177 - accuracy: 0.5401 - val_loss: 0.9196 - val_accuracy: 0.5327\n",
      "Epoch 93/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9165 - accuracy: 0.5437 - val_loss: 0.9209 - val_accuracy: 0.5310\n",
      "Epoch 94/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9162 - accuracy: 0.5437 - val_loss: 0.9205 - val_accuracy: 0.5367\n",
      "Epoch 95/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9173 - accuracy: 0.5388 - val_loss: 0.9216 - val_accuracy: 0.5277\n",
      "Epoch 96/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9150 - accuracy: 0.5446 - val_loss: 0.9198 - val_accuracy: 0.5320\n",
      "Epoch 97/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9161 - accuracy: 0.5396 - val_loss: 0.9208 - val_accuracy: 0.5343\n",
      "Epoch 98/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9170 - accuracy: 0.5426 - val_loss: 0.9179 - val_accuracy: 0.5333\n",
      "Epoch 99/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9159 - accuracy: 0.5406 - val_loss: 0.9198 - val_accuracy: 0.5337\n",
      "Epoch 100/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9153 - accuracy: 0.5429 - val_loss: 0.9175 - val_accuracy: 0.5337\n",
      "Epoch 101/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9154 - accuracy: 0.5447 - val_loss: 0.9182 - val_accuracy: 0.5347\n",
      "Epoch 102/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9149 - accuracy: 0.5402 - val_loss: 0.9195 - val_accuracy: 0.5363\n",
      "Epoch 103/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9150 - accuracy: 0.5398 - val_loss: 0.9189 - val_accuracy: 0.5310\n",
      "Epoch 104/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9154 - accuracy: 0.5424 - val_loss: 0.9190 - val_accuracy: 0.5330\n",
      "Epoch 105/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9171 - accuracy: 0.5391 - val_loss: 0.9234 - val_accuracy: 0.5280\n",
      "Epoch 106/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9149 - accuracy: 0.5419 - val_loss: 0.9182 - val_accuracy: 0.5333\n",
      "Epoch 107/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9160 - accuracy: 0.5408 - val_loss: 0.9219 - val_accuracy: 0.5333\n",
      "Epoch 108/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9157 - accuracy: 0.5364 - val_loss: 0.9177 - val_accuracy: 0.5353\n",
      "Epoch 109/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9148 - accuracy: 0.5427 - val_loss: 0.9173 - val_accuracy: 0.5363\n",
      "Epoch 110/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9177 - accuracy: 0.5380 - val_loss: 0.9201 - val_accuracy: 0.5347\n",
      "Epoch 111/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9131 - accuracy: 0.5409 - val_loss: 0.9179 - val_accuracy: 0.5317\n",
      "Epoch 112/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9141 - accuracy: 0.5456 - val_loss: 0.9172 - val_accuracy: 0.5330\n",
      "Epoch 113/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9145 - accuracy: 0.5452 - val_loss: 0.9183 - val_accuracy: 0.5310\n",
      "Epoch 114/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9145 - accuracy: 0.5421 - val_loss: 0.9219 - val_accuracy: 0.5320\n",
      "Epoch 115/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9131 - accuracy: 0.5459 - val_loss: 0.9182 - val_accuracy: 0.5333\n",
      "Epoch 116/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9123 - accuracy: 0.5496 - val_loss: 0.9194 - val_accuracy: 0.5320\n",
      "Epoch 117/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9136 - accuracy: 0.5436 - val_loss: 0.9165 - val_accuracy: 0.5350\n",
      "Epoch 118/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9149 - accuracy: 0.5417 - val_loss: 0.9206 - val_accuracy: 0.5323\n",
      "Epoch 119/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9147 - accuracy: 0.5444 - val_loss: 0.9182 - val_accuracy: 0.5337\n",
      "Epoch 120/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9143 - accuracy: 0.5426 - val_loss: 0.9172 - val_accuracy: 0.5330\n",
      "Epoch 121/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9159 - accuracy: 0.5446 - val_loss: 0.9205 - val_accuracy: 0.5347\n",
      "Epoch 122/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9160 - accuracy: 0.5411 - val_loss: 0.9189 - val_accuracy: 0.5353\n",
      "Epoch 123/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9129 - accuracy: 0.5432 - val_loss: 0.9168 - val_accuracy: 0.5360\n",
      "Epoch 124/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9134 - accuracy: 0.5415 - val_loss: 0.9186 - val_accuracy: 0.5353\n",
      "Epoch 125/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9133 - accuracy: 0.5419 - val_loss: 0.9169 - val_accuracy: 0.5387\n",
      "Epoch 126/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9131 - accuracy: 0.5441 - val_loss: 0.9163 - val_accuracy: 0.5377\n",
      "Epoch 127/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9136 - accuracy: 0.5432 - val_loss: 0.9185 - val_accuracy: 0.5343\n",
      "Epoch 128/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9137 - accuracy: 0.5424 - val_loss: 0.9159 - val_accuracy: 0.5350\n",
      "Epoch 129/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9127 - accuracy: 0.5399 - val_loss: 0.9180 - val_accuracy: 0.5383\n",
      "Epoch 130/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9151 - accuracy: 0.5436 - val_loss: 0.9162 - val_accuracy: 0.5357\n",
      "Epoch 131/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9140 - accuracy: 0.5451 - val_loss: 0.9166 - val_accuracy: 0.5330\n",
      "Epoch 132/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9130 - accuracy: 0.5463 - val_loss: 0.9183 - val_accuracy: 0.5380\n",
      "Epoch 133/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9133 - accuracy: 0.5384 - val_loss: 0.9167 - val_accuracy: 0.5333\n",
      "Epoch 134/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9144 - accuracy: 0.5441 - val_loss: 0.9172 - val_accuracy: 0.5360\n",
      "Epoch 135/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9126 - accuracy: 0.5444 - val_loss: 0.9199 - val_accuracy: 0.5350\n",
      "Epoch 136/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9144 - accuracy: 0.5411 - val_loss: 0.9162 - val_accuracy: 0.5367\n",
      "Epoch 137/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9134 - accuracy: 0.5443 - val_loss: 0.9170 - val_accuracy: 0.5290\n",
      "Epoch 138/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9152 - accuracy: 0.5422 - val_loss: 0.9200 - val_accuracy: 0.5317\n",
      "Epoch 139/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9154 - accuracy: 0.5397 - val_loss: 0.9172 - val_accuracy: 0.5307\n",
      "Epoch 140/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9129 - accuracy: 0.5422 - val_loss: 0.9170 - val_accuracy: 0.5323\n",
      "Epoch 141/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9128 - accuracy: 0.5417 - val_loss: 0.9182 - val_accuracy: 0.5340\n",
      "Epoch 142/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9117 - accuracy: 0.5396 - val_loss: 0.9171 - val_accuracy: 0.5333\n",
      "Epoch 143/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9156 - accuracy: 0.5440 - val_loss: 0.9176 - val_accuracy: 0.5340\n",
      "Epoch 144/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9130 - accuracy: 0.5435 - val_loss: 0.9197 - val_accuracy: 0.5313\n",
      "Epoch 145/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9146 - accuracy: 0.5429 - val_loss: 0.9173 - val_accuracy: 0.5327\n",
      "Epoch 146/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9138 - accuracy: 0.5413 - val_loss: 0.9176 - val_accuracy: 0.5357\n",
      "Epoch 147/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9124 - accuracy: 0.5461 - val_loss: 0.9166 - val_accuracy: 0.5303\n",
      "Epoch 148/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9128 - accuracy: 0.5441 - val_loss: 0.9156 - val_accuracy: 0.5363\n",
      "Epoch 149/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9147 - accuracy: 0.5437 - val_loss: 0.9183 - val_accuracy: 0.5310\n",
      "Epoch 150/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9131 - accuracy: 0.5429 - val_loss: 0.9165 - val_accuracy: 0.5350\n",
      "Epoch 151/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9133 - accuracy: 0.5416 - val_loss: 0.9149 - val_accuracy: 0.5360\n",
      "Epoch 152/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9120 - accuracy: 0.5409 - val_loss: 0.9171 - val_accuracy: 0.5343\n",
      "Epoch 153/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9131 - accuracy: 0.5431 - val_loss: 0.9198 - val_accuracy: 0.5303\n",
      "Epoch 154/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9114 - accuracy: 0.5491 - val_loss: 0.9166 - val_accuracy: 0.5343\n",
      "Epoch 155/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9125 - accuracy: 0.5444 - val_loss: 0.9165 - val_accuracy: 0.5303\n",
      "Epoch 156/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9140 - accuracy: 0.5416 - val_loss: 0.9165 - val_accuracy: 0.5333\n",
      "Epoch 157/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9114 - accuracy: 0.5444 - val_loss: 0.9149 - val_accuracy: 0.5347\n",
      "Epoch 158/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9134 - accuracy: 0.5396 - val_loss: 0.9162 - val_accuracy: 0.5370\n",
      "Epoch 159/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9131 - accuracy: 0.5434 - val_loss: 0.9174 - val_accuracy: 0.5367\n",
      "Epoch 160/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9131 - accuracy: 0.5454 - val_loss: 0.9190 - val_accuracy: 0.5340\n",
      "Epoch 161/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9120 - accuracy: 0.5386 - val_loss: 0.9158 - val_accuracy: 0.5353\n",
      "Epoch 162/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9127 - accuracy: 0.5414 - val_loss: 0.9162 - val_accuracy: 0.5317\n",
      "Epoch 163/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9135 - accuracy: 0.5432 - val_loss: 0.9177 - val_accuracy: 0.5357\n",
      "Epoch 164/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9137 - accuracy: 0.5421 - val_loss: 0.9154 - val_accuracy: 0.5373\n",
      "Epoch 165/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9108 - accuracy: 0.5431 - val_loss: 0.9173 - val_accuracy: 0.5333\n",
      "Epoch 166/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9138 - accuracy: 0.5410 - val_loss: 0.9185 - val_accuracy: 0.5367\n",
      "Epoch 167/1800\n",
      "14000/14000 [==============================] - 2s 157us/step - loss: 0.9129 - accuracy: 0.5446 - val_loss: 0.9177 - val_accuracy: 0.5353\n",
      "Epoch 168/1800\n",
      "14000/14000 [==============================] - 2s 109us/step - loss: 0.9123 - accuracy: 0.5428 - val_loss: 0.9191 - val_accuracy: 0.5300\n",
      "Epoch 169/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9133 - accuracy: 0.5380 - val_loss: 0.9164 - val_accuracy: 0.5313\n",
      "Epoch 170/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9121 - accuracy: 0.5459 - val_loss: 0.9187 - val_accuracy: 0.5340\n",
      "Epoch 171/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9132 - accuracy: 0.5431 - val_loss: 0.9188 - val_accuracy: 0.5340\n",
      "Epoch 172/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9122 - accuracy: 0.5446 - val_loss: 0.9171 - val_accuracy: 0.5373\n",
      "Epoch 173/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9117 - accuracy: 0.5449 - val_loss: 0.9165 - val_accuracy: 0.5340\n",
      "Epoch 174/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9119 - accuracy: 0.5451 - val_loss: 0.9168 - val_accuracy: 0.5337\n",
      "Epoch 175/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9111 - accuracy: 0.5454 - val_loss: 0.9158 - val_accuracy: 0.5307\n",
      "Epoch 176/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9112 - accuracy: 0.5453 - val_loss: 0.9172 - val_accuracy: 0.5307\n",
      "Epoch 177/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9144 - accuracy: 0.5398 - val_loss: 0.9162 - val_accuracy: 0.5303\n",
      "Epoch 178/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9104 - accuracy: 0.5431 - val_loss: 0.9188 - val_accuracy: 0.5343\n",
      "Epoch 179/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9125 - accuracy: 0.5438 - val_loss: 0.9152 - val_accuracy: 0.5380\n",
      "Epoch 180/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9120 - accuracy: 0.5416 - val_loss: 0.9177 - val_accuracy: 0.5300\n",
      "Epoch 181/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9133 - accuracy: 0.5406 - val_loss: 0.9160 - val_accuracy: 0.5350\n",
      "Epoch 182/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9135 - accuracy: 0.5406 - val_loss: 0.9159 - val_accuracy: 0.5327\n",
      "Epoch 183/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9114 - accuracy: 0.5473 - val_loss: 0.9175 - val_accuracy: 0.5283\n",
      "Epoch 184/1800\n",
      "14000/14000 [==============================] - 1s 102us/step - loss: 0.9106 - accuracy: 0.5431 - val_loss: 0.9153 - val_accuracy: 0.5323\n",
      "Epoch 185/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9146 - accuracy: 0.5443 - val_loss: 0.9168 - val_accuracy: 0.5310\n",
      "Epoch 186/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9106 - accuracy: 0.5420 - val_loss: 0.9176 - val_accuracy: 0.5340\n",
      "Epoch 187/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9130 - accuracy: 0.5451 - val_loss: 0.9152 - val_accuracy: 0.5377\n",
      "Epoch 188/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9114 - accuracy: 0.5446 - val_loss: 0.9153 - val_accuracy: 0.5367\n",
      "Epoch 189/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9106 - accuracy: 0.5408 - val_loss: 0.9152 - val_accuracy: 0.5340\n",
      "Epoch 190/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9115 - accuracy: 0.5442 - val_loss: 0.9160 - val_accuracy: 0.5333\n",
      "Epoch 191/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9108 - accuracy: 0.5465 - val_loss: 0.9149 - val_accuracy: 0.5293\n",
      "Epoch 192/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9140 - accuracy: 0.5406 - val_loss: 0.9178 - val_accuracy: 0.5297\n",
      "Epoch 193/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9121 - accuracy: 0.5426 - val_loss: 0.9166 - val_accuracy: 0.5383\n",
      "Epoch 194/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9120 - accuracy: 0.5414 - val_loss: 0.9142 - val_accuracy: 0.5363\n",
      "Epoch 195/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9109 - accuracy: 0.5459 - val_loss: 0.9175 - val_accuracy: 0.5363\n",
      "Epoch 196/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9109 - accuracy: 0.5445 - val_loss: 0.9193 - val_accuracy: 0.5333\n",
      "Epoch 197/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9117 - accuracy: 0.5450 - val_loss: 0.9181 - val_accuracy: 0.5337\n",
      "Epoch 198/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9119 - accuracy: 0.5455 - val_loss: 0.9161 - val_accuracy: 0.5333\n",
      "Epoch 199/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9123 - accuracy: 0.5445 - val_loss: 0.9162 - val_accuracy: 0.5353\n",
      "Epoch 200/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9127 - accuracy: 0.5386 - val_loss: 0.9140 - val_accuracy: 0.5360\n",
      "Epoch 201/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9113 - accuracy: 0.5461 - val_loss: 0.9164 - val_accuracy: 0.5347\n",
      "Epoch 202/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9116 - accuracy: 0.5448 - val_loss: 0.9198 - val_accuracy: 0.5320\n",
      "Epoch 203/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9108 - accuracy: 0.5431 - val_loss: 0.9185 - val_accuracy: 0.5337\n",
      "Epoch 204/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9099 - accuracy: 0.5469 - val_loss: 0.9169 - val_accuracy: 0.5413\n",
      "Epoch 205/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9113 - accuracy: 0.5465 - val_loss: 0.9148 - val_accuracy: 0.5377\n",
      "Epoch 206/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9103 - accuracy: 0.5441 - val_loss: 0.9162 - val_accuracy: 0.5320\n",
      "Epoch 207/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9118 - accuracy: 0.5446 - val_loss: 0.9161 - val_accuracy: 0.5363\n",
      "Epoch 208/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9104 - accuracy: 0.5415 - val_loss: 0.9162 - val_accuracy: 0.5273\n",
      "Epoch 209/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9124 - accuracy: 0.5418 - val_loss: 0.9151 - val_accuracy: 0.5380\n",
      "Epoch 210/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9118 - accuracy: 0.5413 - val_loss: 0.9158 - val_accuracy: 0.5350\n",
      "Epoch 211/1800\n",
      "14000/14000 [==============================] - 2s 110us/step - loss: 0.9090 - accuracy: 0.5411 - val_loss: 0.9153 - val_accuracy: 0.5337\n",
      "Epoch 212/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9104 - accuracy: 0.5489 - val_loss: 0.9155 - val_accuracy: 0.5373\n",
      "Epoch 213/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9114 - accuracy: 0.5450 - val_loss: 0.9176 - val_accuracy: 0.5307\n",
      "Epoch 214/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9127 - accuracy: 0.5456 - val_loss: 0.9166 - val_accuracy: 0.5363\n",
      "Epoch 215/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9095 - accuracy: 0.5455 - val_loss: 0.9167 - val_accuracy: 0.5363\n",
      "Epoch 216/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9111 - accuracy: 0.5474 - val_loss: 0.9178 - val_accuracy: 0.5313\n",
      "Epoch 217/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9087 - accuracy: 0.5433 - val_loss: 0.9173 - val_accuracy: 0.5373\n",
      "Epoch 218/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9099 - accuracy: 0.5428 - val_loss: 0.9148 - val_accuracy: 0.5333\n",
      "Epoch 219/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9109 - accuracy: 0.5447 - val_loss: 0.9164 - val_accuracy: 0.5327\n",
      "Epoch 220/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9087 - accuracy: 0.5466 - val_loss: 0.9161 - val_accuracy: 0.5390\n",
      "Epoch 221/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9107 - accuracy: 0.5424 - val_loss: 0.9152 - val_accuracy: 0.5357\n",
      "Epoch 222/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9100 - accuracy: 0.5467 - val_loss: 0.9151 - val_accuracy: 0.5327\n",
      "Epoch 223/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9112 - accuracy: 0.5414 - val_loss: 0.9174 - val_accuracy: 0.5353\n",
      "Epoch 224/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9097 - accuracy: 0.5467 - val_loss: 0.9157 - val_accuracy: 0.5343\n",
      "Epoch 225/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9105 - accuracy: 0.5446 - val_loss: 0.9158 - val_accuracy: 0.5313\n",
      "Epoch 226/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9125 - accuracy: 0.5413 - val_loss: 0.9144 - val_accuracy: 0.5387\n",
      "Epoch 227/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9091 - accuracy: 0.5449 - val_loss: 0.9175 - val_accuracy: 0.5393\n",
      "Epoch 228/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9098 - accuracy: 0.5486 - val_loss: 0.9138 - val_accuracy: 0.5367\n",
      "Epoch 229/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9123 - accuracy: 0.5475 - val_loss: 0.9141 - val_accuracy: 0.5337\n",
      "Epoch 230/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9095 - accuracy: 0.5418 - val_loss: 0.9157 - val_accuracy: 0.5377\n",
      "Epoch 231/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9127 - accuracy: 0.5474 - val_loss: 0.9158 - val_accuracy: 0.5333\n",
      "Epoch 232/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9102 - accuracy: 0.5444 - val_loss: 0.9152 - val_accuracy: 0.5317\n",
      "Epoch 233/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9090 - accuracy: 0.5486 - val_loss: 0.9182 - val_accuracy: 0.5307\n",
      "Epoch 234/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9101 - accuracy: 0.5456 - val_loss: 0.9155 - val_accuracy: 0.5317\n",
      "Epoch 235/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9107 - accuracy: 0.5483 - val_loss: 0.9154 - val_accuracy: 0.5387\n",
      "Epoch 236/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9112 - accuracy: 0.5458 - val_loss: 0.9150 - val_accuracy: 0.5347\n",
      "Epoch 237/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9104 - accuracy: 0.5476 - val_loss: 0.9158 - val_accuracy: 0.5343\n",
      "Epoch 238/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9107 - accuracy: 0.5415 - val_loss: 0.9134 - val_accuracy: 0.5350\n",
      "Epoch 239/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9123 - accuracy: 0.5442 - val_loss: 0.9166 - val_accuracy: 0.5373\n",
      "Epoch 240/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9106 - accuracy: 0.5428 - val_loss: 0.9145 - val_accuracy: 0.5343\n",
      "Epoch 241/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9095 - accuracy: 0.5420 - val_loss: 0.9151 - val_accuracy: 0.5357\n",
      "Epoch 242/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9111 - accuracy: 0.5422 - val_loss: 0.9159 - val_accuracy: 0.5383\n",
      "Epoch 243/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9123 - accuracy: 0.5481 - val_loss: 0.9144 - val_accuracy: 0.5377\n",
      "Epoch 244/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9104 - accuracy: 0.5463 - val_loss: 0.9160 - val_accuracy: 0.5363\n",
      "Epoch 245/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9094 - accuracy: 0.5446 - val_loss: 0.9154 - val_accuracy: 0.5317\n",
      "Epoch 246/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9086 - accuracy: 0.5425 - val_loss: 0.9154 - val_accuracy: 0.5323\n",
      "Epoch 247/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9112 - accuracy: 0.5419 - val_loss: 0.9164 - val_accuracy: 0.5387\n",
      "Epoch 248/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9092 - accuracy: 0.5436 - val_loss: 0.9152 - val_accuracy: 0.5340\n",
      "Epoch 249/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9104 - accuracy: 0.5419 - val_loss: 0.9147 - val_accuracy: 0.5323\n",
      "Epoch 250/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9093 - accuracy: 0.5414 - val_loss: 0.9162 - val_accuracy: 0.5323\n",
      "Epoch 251/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9102 - accuracy: 0.5438 - val_loss: 0.9138 - val_accuracy: 0.5330\n",
      "Epoch 252/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9078 - accuracy: 0.5481 - val_loss: 0.9162 - val_accuracy: 0.5367\n",
      "Epoch 253/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9112 - accuracy: 0.5452 - val_loss: 0.9128 - val_accuracy: 0.5307\n",
      "Epoch 254/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9097 - accuracy: 0.5468 - val_loss: 0.9146 - val_accuracy: 0.5353\n",
      "Epoch 255/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9096 - accuracy: 0.5444 - val_loss: 0.9138 - val_accuracy: 0.5333\n",
      "Epoch 256/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9101 - accuracy: 0.5426 - val_loss: 0.9138 - val_accuracy: 0.5323\n",
      "Epoch 257/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9088 - accuracy: 0.5444 - val_loss: 0.9141 - val_accuracy: 0.5353\n",
      "Epoch 258/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9104 - accuracy: 0.5423 - val_loss: 0.9166 - val_accuracy: 0.5363\n",
      "Epoch 259/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9106 - accuracy: 0.5446 - val_loss: 0.9142 - val_accuracy: 0.5357\n",
      "Epoch 260/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9080 - accuracy: 0.5470 - val_loss: 0.9136 - val_accuracy: 0.5323\n",
      "Epoch 261/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9104 - accuracy: 0.5414 - val_loss: 0.9155 - val_accuracy: 0.5383\n",
      "Epoch 262/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9104 - accuracy: 0.5428 - val_loss: 0.9154 - val_accuracy: 0.5397\n",
      "Epoch 263/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9080 - accuracy: 0.5460 - val_loss: 0.9137 - val_accuracy: 0.5333\n",
      "Epoch 264/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9116 - accuracy: 0.5448 - val_loss: 0.9140 - val_accuracy: 0.5320\n",
      "Epoch 265/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9096 - accuracy: 0.5501 - val_loss: 0.9158 - val_accuracy: 0.5310\n",
      "Epoch 266/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9090 - accuracy: 0.5486 - val_loss: 0.9146 - val_accuracy: 0.5360\n",
      "Epoch 267/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9096 - accuracy: 0.5464 - val_loss: 0.9154 - val_accuracy: 0.5297\n",
      "Epoch 268/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9094 - accuracy: 0.5449 - val_loss: 0.9152 - val_accuracy: 0.5410\n",
      "Epoch 269/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9119 - accuracy: 0.5441 - val_loss: 0.9138 - val_accuracy: 0.5383\n",
      "Epoch 270/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9092 - accuracy: 0.5475 - val_loss: 0.9181 - val_accuracy: 0.5340\n",
      "Epoch 271/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9093 - accuracy: 0.5469 - val_loss: 0.9138 - val_accuracy: 0.5297\n",
      "Epoch 272/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9070 - accuracy: 0.5481 - val_loss: 0.9168 - val_accuracy: 0.5377\n",
      "Epoch 273/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9118 - accuracy: 0.5428 - val_loss: 0.9150 - val_accuracy: 0.5367\n",
      "Epoch 274/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9109 - accuracy: 0.5477 - val_loss: 0.9140 - val_accuracy: 0.5350\n",
      "Epoch 275/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9098 - accuracy: 0.5452 - val_loss: 0.9177 - val_accuracy: 0.5340\n",
      "Epoch 276/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9082 - accuracy: 0.5481 - val_loss: 0.9131 - val_accuracy: 0.5377\n",
      "Epoch 277/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9092 - accuracy: 0.5436 - val_loss: 0.9162 - val_accuracy: 0.5350\n",
      "Epoch 278/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9095 - accuracy: 0.5475 - val_loss: 0.9151 - val_accuracy: 0.5373\n",
      "Epoch 279/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9112 - accuracy: 0.5446 - val_loss: 0.9143 - val_accuracy: 0.5337\n",
      "Epoch 280/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9102 - accuracy: 0.5435 - val_loss: 0.9138 - val_accuracy: 0.5357\n",
      "Epoch 281/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9115 - accuracy: 0.5471 - val_loss: 0.9133 - val_accuracy: 0.5340\n",
      "Epoch 282/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9102 - accuracy: 0.5436 - val_loss: 0.9136 - val_accuracy: 0.5357\n",
      "Epoch 283/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9094 - accuracy: 0.5463 - val_loss: 0.9142 - val_accuracy: 0.5377\n",
      "Epoch 284/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9109 - accuracy: 0.5440 - val_loss: 0.9154 - val_accuracy: 0.5357\n",
      "Epoch 285/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9099 - accuracy: 0.5398 - val_loss: 0.9165 - val_accuracy: 0.5363\n",
      "Epoch 286/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9100 - accuracy: 0.5451 - val_loss: 0.9156 - val_accuracy: 0.5343\n",
      "Epoch 287/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9094 - accuracy: 0.5452 - val_loss: 0.9139 - val_accuracy: 0.5310\n",
      "Epoch 288/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9082 - accuracy: 0.5501 - val_loss: 0.9137 - val_accuracy: 0.5333\n",
      "Epoch 289/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9098 - accuracy: 0.5427 - val_loss: 0.9125 - val_accuracy: 0.5360\n",
      "Epoch 290/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9096 - accuracy: 0.5448 - val_loss: 0.9146 - val_accuracy: 0.5390\n",
      "Epoch 291/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9101 - accuracy: 0.5461 - val_loss: 0.9138 - val_accuracy: 0.5393\n",
      "Epoch 292/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9071 - accuracy: 0.5459 - val_loss: 0.9148 - val_accuracy: 0.5360\n",
      "Epoch 293/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9084 - accuracy: 0.5430 - val_loss: 0.9139 - val_accuracy: 0.5370\n",
      "Epoch 294/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9117 - accuracy: 0.5461 - val_loss: 0.9142 - val_accuracy: 0.5337\n",
      "Epoch 295/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9101 - accuracy: 0.5444 - val_loss: 0.9152 - val_accuracy: 0.5393\n",
      "Epoch 296/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9103 - accuracy: 0.5444 - val_loss: 0.9153 - val_accuracy: 0.5393\n",
      "Epoch 297/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9112 - accuracy: 0.5413 - val_loss: 0.9146 - val_accuracy: 0.5393\n",
      "Epoch 298/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9090 - accuracy: 0.5421 - val_loss: 0.9154 - val_accuracy: 0.5363\n",
      "Epoch 299/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9090 - accuracy: 0.5427 - val_loss: 0.9150 - val_accuracy: 0.5367\n",
      "Epoch 300/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9082 - accuracy: 0.5435 - val_loss: 0.9155 - val_accuracy: 0.5357\n",
      "Epoch 301/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9103 - accuracy: 0.5444 - val_loss: 0.9172 - val_accuracy: 0.5363\n",
      "Epoch 302/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9103 - accuracy: 0.5429 - val_loss: 0.9157 - val_accuracy: 0.5347\n",
      "Epoch 303/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9103 - accuracy: 0.5446 - val_loss: 0.9158 - val_accuracy: 0.5373\n",
      "Epoch 304/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9095 - accuracy: 0.5434 - val_loss: 0.9156 - val_accuracy: 0.5353\n",
      "Epoch 305/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9087 - accuracy: 0.5449 - val_loss: 0.9163 - val_accuracy: 0.5380\n",
      "Epoch 306/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9087 - accuracy: 0.5445 - val_loss: 0.9132 - val_accuracy: 0.5360\n",
      "Epoch 307/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9098 - accuracy: 0.5434 - val_loss: 0.9143 - val_accuracy: 0.5370\n",
      "Epoch 308/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9089 - accuracy: 0.5430 - val_loss: 0.9145 - val_accuracy: 0.5387\n",
      "Epoch 309/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9089 - accuracy: 0.5464 - val_loss: 0.9139 - val_accuracy: 0.5360\n",
      "Epoch 310/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9094 - accuracy: 0.5468 - val_loss: 0.9156 - val_accuracy: 0.5390\n",
      "Epoch 311/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9081 - accuracy: 0.5472 - val_loss: 0.9155 - val_accuracy: 0.5367\n",
      "Epoch 312/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9099 - accuracy: 0.5445 - val_loss: 0.9173 - val_accuracy: 0.5347\n",
      "Epoch 313/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9087 - accuracy: 0.5454 - val_loss: 0.9175 - val_accuracy: 0.5337\n",
      "Epoch 314/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9108 - accuracy: 0.5424 - val_loss: 0.9155 - val_accuracy: 0.5350\n",
      "Epoch 315/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9075 - accuracy: 0.5442 - val_loss: 0.9149 - val_accuracy: 0.5360\n",
      "Epoch 316/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9087 - accuracy: 0.5504 - val_loss: 0.9152 - val_accuracy: 0.5407\n",
      "Epoch 317/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9084 - accuracy: 0.5444 - val_loss: 0.9142 - val_accuracy: 0.5370\n",
      "Epoch 318/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9086 - accuracy: 0.5446 - val_loss: 0.9128 - val_accuracy: 0.5380\n",
      "Epoch 319/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9094 - accuracy: 0.5461 - val_loss: 0.9158 - val_accuracy: 0.5403\n",
      "Epoch 320/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9096 - accuracy: 0.5429 - val_loss: 0.9151 - val_accuracy: 0.5347\n",
      "Epoch 321/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9090 - accuracy: 0.5458 - val_loss: 0.9160 - val_accuracy: 0.5373\n",
      "Epoch 322/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9091 - accuracy: 0.5436 - val_loss: 0.9131 - val_accuracy: 0.5360\n",
      "Epoch 323/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9106 - accuracy: 0.5421 - val_loss: 0.9141 - val_accuracy: 0.5347\n",
      "Epoch 324/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9082 - accuracy: 0.5459 - val_loss: 0.9182 - val_accuracy: 0.5390\n",
      "Epoch 325/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9082 - accuracy: 0.5469 - val_loss: 0.9139 - val_accuracy: 0.5350\n",
      "Epoch 326/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9096 - accuracy: 0.5479 - val_loss: 0.9143 - val_accuracy: 0.5333\n",
      "Epoch 327/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9086 - accuracy: 0.5496 - val_loss: 0.9154 - val_accuracy: 0.5383\n",
      "Epoch 328/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9070 - accuracy: 0.5482 - val_loss: 0.9140 - val_accuracy: 0.5363\n",
      "Epoch 329/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9072 - accuracy: 0.5490 - val_loss: 0.9149 - val_accuracy: 0.5357\n",
      "Epoch 330/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9083 - accuracy: 0.5464 - val_loss: 0.9145 - val_accuracy: 0.5397\n",
      "Epoch 331/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9089 - accuracy: 0.5449 - val_loss: 0.9171 - val_accuracy: 0.5387\n",
      "Epoch 332/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9078 - accuracy: 0.5474 - val_loss: 0.9152 - val_accuracy: 0.5370\n",
      "Epoch 333/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9074 - accuracy: 0.5459 - val_loss: 0.9148 - val_accuracy: 0.5350\n",
      "Epoch 334/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9079 - accuracy: 0.5481 - val_loss: 0.9152 - val_accuracy: 0.5340\n",
      "Epoch 335/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9101 - accuracy: 0.5464 - val_loss: 0.9144 - val_accuracy: 0.5387\n",
      "Epoch 336/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9108 - accuracy: 0.5469 - val_loss: 0.9156 - val_accuracy: 0.5370\n",
      "Epoch 337/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9089 - accuracy: 0.5472 - val_loss: 0.9177 - val_accuracy: 0.5373\n",
      "Epoch 338/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9081 - accuracy: 0.5479 - val_loss: 0.9161 - val_accuracy: 0.5393\n",
      "Epoch 339/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9096 - accuracy: 0.5441 - val_loss: 0.9158 - val_accuracy: 0.5397\n",
      "Epoch 340/1800\n",
      "14000/14000 [==============================] - 2s 107us/step - loss: 0.9104 - accuracy: 0.5454 - val_loss: 0.9156 - val_accuracy: 0.5343\n",
      "Epoch 341/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9069 - accuracy: 0.5448 - val_loss: 0.9153 - val_accuracy: 0.5377\n",
      "Epoch 342/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9080 - accuracy: 0.5443 - val_loss: 0.9142 - val_accuracy: 0.5393\n",
      "Epoch 343/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9086 - accuracy: 0.5447 - val_loss: 0.9137 - val_accuracy: 0.5373\n",
      "Epoch 344/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9065 - accuracy: 0.5479 - val_loss: 0.9138 - val_accuracy: 0.5380\n",
      "Epoch 345/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9072 - accuracy: 0.5441 - val_loss: 0.9139 - val_accuracy: 0.5417\n",
      "Epoch 346/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9080 - accuracy: 0.5459 - val_loss: 0.9129 - val_accuracy: 0.5360\n",
      "Epoch 347/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9085 - accuracy: 0.5433 - val_loss: 0.9159 - val_accuracy: 0.5403\n",
      "Epoch 348/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9087 - accuracy: 0.5462 - val_loss: 0.9132 - val_accuracy: 0.5383\n",
      "Epoch 349/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9077 - accuracy: 0.5469 - val_loss: 0.9145 - val_accuracy: 0.5367\n",
      "Epoch 350/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9074 - accuracy: 0.5479 - val_loss: 0.9133 - val_accuracy: 0.5343\n",
      "Epoch 351/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9079 - accuracy: 0.5473 - val_loss: 0.9125 - val_accuracy: 0.5370\n",
      "Epoch 352/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9079 - accuracy: 0.5435 - val_loss: 0.9126 - val_accuracy: 0.5410\n",
      "Epoch 353/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9080 - accuracy: 0.5478 - val_loss: 0.9133 - val_accuracy: 0.5417\n",
      "Epoch 354/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9059 - accuracy: 0.5479 - val_loss: 0.9149 - val_accuracy: 0.5400\n",
      "Epoch 355/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9083 - accuracy: 0.5461 - val_loss: 0.9133 - val_accuracy: 0.5387\n",
      "Epoch 356/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9073 - accuracy: 0.5468 - val_loss: 0.9131 - val_accuracy: 0.5437\n",
      "Epoch 357/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9092 - accuracy: 0.5441 - val_loss: 0.9135 - val_accuracy: 0.5383\n",
      "Epoch 358/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9076 - accuracy: 0.5461 - val_loss: 0.9145 - val_accuracy: 0.5410\n",
      "Epoch 359/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9082 - accuracy: 0.5519 - val_loss: 0.9136 - val_accuracy: 0.5323\n",
      "Epoch 360/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9097 - accuracy: 0.5459 - val_loss: 0.9148 - val_accuracy: 0.5420\n",
      "Epoch 361/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9095 - accuracy: 0.5437 - val_loss: 0.9178 - val_accuracy: 0.5350\n",
      "Epoch 362/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9075 - accuracy: 0.5456 - val_loss: 0.9133 - val_accuracy: 0.5380\n",
      "Epoch 363/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9085 - accuracy: 0.5468 - val_loss: 0.9144 - val_accuracy: 0.5377\n",
      "Epoch 364/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9102 - accuracy: 0.5437 - val_loss: 0.9155 - val_accuracy: 0.5417\n",
      "Epoch 365/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9075 - accuracy: 0.5423 - val_loss: 0.9124 - val_accuracy: 0.5400\n",
      "Epoch 366/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9072 - accuracy: 0.5486 - val_loss: 0.9145 - val_accuracy: 0.5437\n",
      "Epoch 367/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9077 - accuracy: 0.5461 - val_loss: 0.9190 - val_accuracy: 0.5403\n",
      "Epoch 368/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9121 - accuracy: 0.5435 - val_loss: 0.9177 - val_accuracy: 0.5407\n",
      "Epoch 369/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9087 - accuracy: 0.5468 - val_loss: 0.9150 - val_accuracy: 0.5400\n",
      "Epoch 370/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9093 - accuracy: 0.5484 - val_loss: 0.9131 - val_accuracy: 0.5390\n",
      "Epoch 371/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9094 - accuracy: 0.5431 - val_loss: 0.9139 - val_accuracy: 0.5357\n",
      "Epoch 372/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9069 - accuracy: 0.5449 - val_loss: 0.9152 - val_accuracy: 0.5390\n",
      "Epoch 373/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9076 - accuracy: 0.5482 - val_loss: 0.9152 - val_accuracy: 0.5417\n",
      "Epoch 374/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9078 - accuracy: 0.5488 - val_loss: 0.9137 - val_accuracy: 0.5377\n",
      "Epoch 375/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9068 - accuracy: 0.5446 - val_loss: 0.9122 - val_accuracy: 0.5400\n",
      "Epoch 376/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9075 - accuracy: 0.5459 - val_loss: 0.9139 - val_accuracy: 0.5370\n",
      "Epoch 377/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9077 - accuracy: 0.5498 - val_loss: 0.9134 - val_accuracy: 0.5400\n",
      "Epoch 378/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9056 - accuracy: 0.5485 - val_loss: 0.9150 - val_accuracy: 0.5380\n",
      "Epoch 379/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9080 - accuracy: 0.5446 - val_loss: 0.9132 - val_accuracy: 0.5377\n",
      "Epoch 380/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9084 - accuracy: 0.5491 - val_loss: 0.9140 - val_accuracy: 0.5337\n",
      "Epoch 381/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9086 - accuracy: 0.5476 - val_loss: 0.9143 - val_accuracy: 0.5387\n",
      "Epoch 382/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9069 - accuracy: 0.5466 - val_loss: 0.9150 - val_accuracy: 0.5323\n",
      "Epoch 383/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9081 - accuracy: 0.5483 - val_loss: 0.9152 - val_accuracy: 0.5413\n",
      "Epoch 384/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9071 - accuracy: 0.5474 - val_loss: 0.9122 - val_accuracy: 0.5353\n",
      "Epoch 385/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9082 - accuracy: 0.5471 - val_loss: 0.9151 - val_accuracy: 0.5370\n",
      "Epoch 386/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9078 - accuracy: 0.5466 - val_loss: 0.9130 - val_accuracy: 0.5360\n",
      "Epoch 387/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9071 - accuracy: 0.5424 - val_loss: 0.9145 - val_accuracy: 0.5377\n",
      "Epoch 388/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9071 - accuracy: 0.5468 - val_loss: 0.9175 - val_accuracy: 0.5400\n",
      "Epoch 389/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9097 - accuracy: 0.5446 - val_loss: 0.9145 - val_accuracy: 0.5403\n",
      "Epoch 390/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9083 - accuracy: 0.5456 - val_loss: 0.9152 - val_accuracy: 0.5427\n",
      "Epoch 391/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9083 - accuracy: 0.5459 - val_loss: 0.9128 - val_accuracy: 0.5403\n",
      "Epoch 392/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9061 - accuracy: 0.5453 - val_loss: 0.9130 - val_accuracy: 0.5397\n",
      "Epoch 393/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9069 - accuracy: 0.5470 - val_loss: 0.9143 - val_accuracy: 0.5423\n",
      "Epoch 394/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9066 - accuracy: 0.5477 - val_loss: 0.9138 - val_accuracy: 0.5367\n",
      "Epoch 395/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9083 - accuracy: 0.5484 - val_loss: 0.9138 - val_accuracy: 0.5377\n",
      "Epoch 396/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9073 - accuracy: 0.5499 - val_loss: 0.9140 - val_accuracy: 0.5407\n",
      "Epoch 397/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9071 - accuracy: 0.5481 - val_loss: 0.9126 - val_accuracy: 0.5360\n",
      "Epoch 398/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9088 - accuracy: 0.5451 - val_loss: 0.9156 - val_accuracy: 0.5377\n",
      "Epoch 399/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9072 - accuracy: 0.5431 - val_loss: 0.9153 - val_accuracy: 0.5427\n",
      "Epoch 400/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9075 - accuracy: 0.5446 - val_loss: 0.9179 - val_accuracy: 0.5443\n",
      "Epoch 401/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9082 - accuracy: 0.5469 - val_loss: 0.9153 - val_accuracy: 0.5397\n",
      "Epoch 402/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9084 - accuracy: 0.5454 - val_loss: 0.9125 - val_accuracy: 0.5413\n",
      "Epoch 403/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9086 - accuracy: 0.5444 - val_loss: 0.9137 - val_accuracy: 0.5403\n",
      "Epoch 404/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9069 - accuracy: 0.5436 - val_loss: 0.9133 - val_accuracy: 0.5360\n",
      "Epoch 405/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9087 - accuracy: 0.5451 - val_loss: 0.9144 - val_accuracy: 0.5433\n",
      "Epoch 406/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9094 - accuracy: 0.5464 - val_loss: 0.9126 - val_accuracy: 0.5387\n",
      "Epoch 407/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9059 - accuracy: 0.5464 - val_loss: 0.9129 - val_accuracy: 0.5383\n",
      "Epoch 408/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9074 - accuracy: 0.5506 - val_loss: 0.9129 - val_accuracy: 0.5420\n",
      "Epoch 409/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9055 - accuracy: 0.5463 - val_loss: 0.9126 - val_accuracy: 0.5390\n",
      "Epoch 410/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9062 - accuracy: 0.5444 - val_loss: 0.9144 - val_accuracy: 0.5410\n",
      "Epoch 411/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9083 - accuracy: 0.5461 - val_loss: 0.9129 - val_accuracy: 0.5400\n",
      "Epoch 412/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9072 - accuracy: 0.5469 - val_loss: 0.9134 - val_accuracy: 0.5400\n",
      "Epoch 413/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9071 - accuracy: 0.5462 - val_loss: 0.9131 - val_accuracy: 0.5407\n",
      "Epoch 414/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9081 - accuracy: 0.5449 - val_loss: 0.9146 - val_accuracy: 0.5397\n",
      "Epoch 415/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9068 - accuracy: 0.5441 - val_loss: 0.9130 - val_accuracy: 0.5383\n",
      "Epoch 416/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9074 - accuracy: 0.5488 - val_loss: 0.9124 - val_accuracy: 0.5377\n",
      "Epoch 417/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9059 - accuracy: 0.5466 - val_loss: 0.9158 - val_accuracy: 0.5420\n",
      "Epoch 418/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9076 - accuracy: 0.5450 - val_loss: 0.9153 - val_accuracy: 0.5407\n",
      "Epoch 419/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9071 - accuracy: 0.5479 - val_loss: 0.9141 - val_accuracy: 0.5437\n",
      "Epoch 420/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9065 - accuracy: 0.5463 - val_loss: 0.9139 - val_accuracy: 0.5440\n",
      "Epoch 421/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9065 - accuracy: 0.5436 - val_loss: 0.9136 - val_accuracy: 0.5457\n",
      "Epoch 422/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9090 - accuracy: 0.5437 - val_loss: 0.9153 - val_accuracy: 0.5433\n",
      "Epoch 423/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9094 - accuracy: 0.5434 - val_loss: 0.9138 - val_accuracy: 0.5390\n",
      "Epoch 424/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9070 - accuracy: 0.5449 - val_loss: 0.9113 - val_accuracy: 0.5400\n",
      "Epoch 425/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9072 - accuracy: 0.5438 - val_loss: 0.9119 - val_accuracy: 0.5420\n",
      "Epoch 426/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9086 - accuracy: 0.5455 - val_loss: 0.9123 - val_accuracy: 0.5387\n",
      "Epoch 427/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9074 - accuracy: 0.5496 - val_loss: 0.9144 - val_accuracy: 0.5450\n",
      "Epoch 428/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9086 - accuracy: 0.5425 - val_loss: 0.9121 - val_accuracy: 0.5383\n",
      "Epoch 429/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9064 - accuracy: 0.5484 - val_loss: 0.9123 - val_accuracy: 0.5363\n",
      "Epoch 430/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9066 - accuracy: 0.5460 - val_loss: 0.9134 - val_accuracy: 0.5360\n",
      "Epoch 431/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9083 - accuracy: 0.5457 - val_loss: 0.9139 - val_accuracy: 0.5417\n",
      "Epoch 432/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9095 - accuracy: 0.5453 - val_loss: 0.9126 - val_accuracy: 0.5407\n",
      "Epoch 433/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9080 - accuracy: 0.5460 - val_loss: 0.9143 - val_accuracy: 0.5420\n",
      "Epoch 434/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9085 - accuracy: 0.5421 - val_loss: 0.9130 - val_accuracy: 0.5407\n",
      "Epoch 435/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9069 - accuracy: 0.5466 - val_loss: 0.9138 - val_accuracy: 0.5383\n",
      "Epoch 436/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9082 - accuracy: 0.5484 - val_loss: 0.9152 - val_accuracy: 0.5400\n",
      "Epoch 437/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9045 - accuracy: 0.5503 - val_loss: 0.9122 - val_accuracy: 0.5407\n",
      "Epoch 438/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9058 - accuracy: 0.5492 - val_loss: 0.9140 - val_accuracy: 0.5363\n",
      "Epoch 439/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9077 - accuracy: 0.5482 - val_loss: 0.9116 - val_accuracy: 0.5403\n",
      "Epoch 440/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9055 - accuracy: 0.5453 - val_loss: 0.9120 - val_accuracy: 0.5433\n",
      "Epoch 441/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9089 - accuracy: 0.5464 - val_loss: 0.9164 - val_accuracy: 0.5433\n",
      "Epoch 442/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9076 - accuracy: 0.5464 - val_loss: 0.9146 - val_accuracy: 0.5347\n",
      "Epoch 443/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9067 - accuracy: 0.5479 - val_loss: 0.9152 - val_accuracy: 0.5443\n",
      "Epoch 444/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9071 - accuracy: 0.5469 - val_loss: 0.9143 - val_accuracy: 0.5433\n",
      "Epoch 445/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9062 - accuracy: 0.5461 - val_loss: 0.9146 - val_accuracy: 0.5390\n",
      "Epoch 446/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9083 - accuracy: 0.5436 - val_loss: 0.9138 - val_accuracy: 0.5393\n",
      "Epoch 447/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9103 - accuracy: 0.5449 - val_loss: 0.9132 - val_accuracy: 0.5353\n",
      "Epoch 448/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9077 - accuracy: 0.5482 - val_loss: 0.9145 - val_accuracy: 0.5383\n",
      "Epoch 449/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9059 - accuracy: 0.5509 - val_loss: 0.9156 - val_accuracy: 0.5420\n",
      "Epoch 450/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9080 - accuracy: 0.5415 - val_loss: 0.9147 - val_accuracy: 0.5373\n",
      "Epoch 451/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9061 - accuracy: 0.5486 - val_loss: 0.9159 - val_accuracy: 0.5377\n",
      "Epoch 452/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9080 - accuracy: 0.5456 - val_loss: 0.9119 - val_accuracy: 0.5413\n",
      "Epoch 453/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9074 - accuracy: 0.5477 - val_loss: 0.9145 - val_accuracy: 0.5390\n",
      "Epoch 454/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9072 - accuracy: 0.5473 - val_loss: 0.9128 - val_accuracy: 0.5430\n",
      "Epoch 455/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9071 - accuracy: 0.5495 - val_loss: 0.9142 - val_accuracy: 0.5450\n",
      "Epoch 456/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9047 - accuracy: 0.5471 - val_loss: 0.9137 - val_accuracy: 0.5373\n",
      "Epoch 457/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9067 - accuracy: 0.5442 - val_loss: 0.9145 - val_accuracy: 0.5423\n",
      "Epoch 458/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9054 - accuracy: 0.5493 - val_loss: 0.9148 - val_accuracy: 0.5400\n",
      "Epoch 459/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9062 - accuracy: 0.5471 - val_loss: 0.9115 - val_accuracy: 0.5427\n",
      "Epoch 460/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9049 - accuracy: 0.5477 - val_loss: 0.9132 - val_accuracy: 0.5403\n",
      "Epoch 461/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9065 - accuracy: 0.5476 - val_loss: 0.9139 - val_accuracy: 0.5427\n",
      "Epoch 462/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9092 - accuracy: 0.5450 - val_loss: 0.9120 - val_accuracy: 0.5390\n",
      "Epoch 463/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9064 - accuracy: 0.5468 - val_loss: 0.9131 - val_accuracy: 0.5410\n",
      "Epoch 464/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9083 - accuracy: 0.5430 - val_loss: 0.9131 - val_accuracy: 0.5397\n",
      "Epoch 465/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9073 - accuracy: 0.5461 - val_loss: 0.9129 - val_accuracy: 0.5420\n",
      "Epoch 466/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9065 - accuracy: 0.5445 - val_loss: 0.9149 - val_accuracy: 0.5447\n",
      "Epoch 467/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9091 - accuracy: 0.5466 - val_loss: 0.9163 - val_accuracy: 0.5303\n",
      "Epoch 468/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9066 - accuracy: 0.5473 - val_loss: 0.9137 - val_accuracy: 0.5370\n",
      "Epoch 469/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9069 - accuracy: 0.5456 - val_loss: 0.9149 - val_accuracy: 0.5410\n",
      "Epoch 470/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9075 - accuracy: 0.5438 - val_loss: 0.9121 - val_accuracy: 0.5357\n",
      "Epoch 471/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9062 - accuracy: 0.5454 - val_loss: 0.9150 - val_accuracy: 0.5420\n",
      "Epoch 472/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9067 - accuracy: 0.5474 - val_loss: 0.9148 - val_accuracy: 0.5403\n",
      "Epoch 473/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9057 - accuracy: 0.5490 - val_loss: 0.9134 - val_accuracy: 0.5370\n",
      "Epoch 474/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9063 - accuracy: 0.5511 - val_loss: 0.9133 - val_accuracy: 0.5410\n",
      "Epoch 475/1800\n",
      "14000/14000 [==============================] - 2s 128us/step - loss: 0.9087 - accuracy: 0.5446 - val_loss: 0.9162 - val_accuracy: 0.5407\n",
      "Epoch 476/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9067 - accuracy: 0.5469 - val_loss: 0.9154 - val_accuracy: 0.5347\n",
      "Epoch 477/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9057 - accuracy: 0.5461 - val_loss: 0.9130 - val_accuracy: 0.5417\n",
      "Epoch 478/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9066 - accuracy: 0.5462 - val_loss: 0.9139 - val_accuracy: 0.5433\n",
      "Epoch 479/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9077 - accuracy: 0.5467 - val_loss: 0.9148 - val_accuracy: 0.5387\n",
      "Epoch 480/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9068 - accuracy: 0.5469 - val_loss: 0.9156 - val_accuracy: 0.5433\n",
      "Epoch 481/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9077 - accuracy: 0.5501 - val_loss: 0.9152 - val_accuracy: 0.5393\n",
      "Epoch 482/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9070 - accuracy: 0.5486 - val_loss: 0.9119 - val_accuracy: 0.5393\n",
      "Epoch 483/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9070 - accuracy: 0.5446 - val_loss: 0.9135 - val_accuracy: 0.5423\n",
      "Epoch 484/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9066 - accuracy: 0.5468 - val_loss: 0.9123 - val_accuracy: 0.5413\n",
      "Epoch 485/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9087 - accuracy: 0.5480 - val_loss: 0.9174 - val_accuracy: 0.5370\n",
      "Epoch 486/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9054 - accuracy: 0.5455 - val_loss: 0.9128 - val_accuracy: 0.5393\n",
      "Epoch 487/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9076 - accuracy: 0.5456 - val_loss: 0.9159 - val_accuracy: 0.5383\n",
      "Epoch 488/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9094 - accuracy: 0.5476 - val_loss: 0.9135 - val_accuracy: 0.5393\n",
      "Epoch 489/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9074 - accuracy: 0.5499 - val_loss: 0.9137 - val_accuracy: 0.5377\n",
      "Epoch 490/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9062 - accuracy: 0.5475 - val_loss: 0.9132 - val_accuracy: 0.5393\n",
      "Epoch 491/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9055 - accuracy: 0.5469 - val_loss: 0.9130 - val_accuracy: 0.5407\n",
      "Epoch 492/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9038 - accuracy: 0.5494 - val_loss: 0.9131 - val_accuracy: 0.5397\n",
      "Epoch 493/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9068 - accuracy: 0.5459 - val_loss: 0.9155 - val_accuracy: 0.5427\n",
      "Epoch 494/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9058 - accuracy: 0.5461 - val_loss: 0.9129 - val_accuracy: 0.5383\n",
      "Epoch 495/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9048 - accuracy: 0.5491 - val_loss: 0.9125 - val_accuracy: 0.5387\n",
      "Epoch 496/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9084 - accuracy: 0.5432 - val_loss: 0.9124 - val_accuracy: 0.5417\n",
      "Epoch 497/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9070 - accuracy: 0.5457 - val_loss: 0.9130 - val_accuracy: 0.5387\n",
      "Epoch 498/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9076 - accuracy: 0.5469 - val_loss: 0.9135 - val_accuracy: 0.5363\n",
      "Epoch 499/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9066 - accuracy: 0.5484 - val_loss: 0.9143 - val_accuracy: 0.5353\n",
      "Epoch 500/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9051 - accuracy: 0.5452 - val_loss: 0.9135 - val_accuracy: 0.5370\n",
      "Epoch 501/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9043 - accuracy: 0.5488 - val_loss: 0.9119 - val_accuracy: 0.5413\n",
      "Epoch 502/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9059 - accuracy: 0.5479 - val_loss: 0.9132 - val_accuracy: 0.5410\n",
      "Epoch 503/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9069 - accuracy: 0.5439 - val_loss: 0.9159 - val_accuracy: 0.5417\n",
      "Epoch 504/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9050 - accuracy: 0.5488 - val_loss: 0.9118 - val_accuracy: 0.5387\n",
      "Epoch 505/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9059 - accuracy: 0.5484 - val_loss: 0.9138 - val_accuracy: 0.5397\n",
      "Epoch 506/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9059 - accuracy: 0.5506 - val_loss: 0.9167 - val_accuracy: 0.5423\n",
      "Epoch 507/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9059 - accuracy: 0.5467 - val_loss: 0.9174 - val_accuracy: 0.5323\n",
      "Epoch 508/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9095 - accuracy: 0.5463 - val_loss: 0.9140 - val_accuracy: 0.5417\n",
      "Epoch 509/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9078 - accuracy: 0.5449 - val_loss: 0.9175 - val_accuracy: 0.5430\n",
      "Epoch 510/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9052 - accuracy: 0.5459 - val_loss: 0.9154 - val_accuracy: 0.5410\n",
      "Epoch 511/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9084 - accuracy: 0.5495 - val_loss: 0.9145 - val_accuracy: 0.5383\n",
      "Epoch 512/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9057 - accuracy: 0.5488 - val_loss: 0.9143 - val_accuracy: 0.5367\n",
      "Epoch 513/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9072 - accuracy: 0.5509 - val_loss: 0.9133 - val_accuracy: 0.5390\n",
      "Epoch 514/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9050 - accuracy: 0.5517 - val_loss: 0.9143 - val_accuracy: 0.5410\n",
      "Epoch 515/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9060 - accuracy: 0.5448 - val_loss: 0.9158 - val_accuracy: 0.5440\n",
      "Epoch 516/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9057 - accuracy: 0.5486 - val_loss: 0.9141 - val_accuracy: 0.5357\n",
      "Epoch 517/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9043 - accuracy: 0.5464 - val_loss: 0.9110 - val_accuracy: 0.5427\n",
      "Epoch 518/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9080 - accuracy: 0.5433 - val_loss: 0.9163 - val_accuracy: 0.5353\n",
      "Epoch 519/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9065 - accuracy: 0.5529 - val_loss: 0.9148 - val_accuracy: 0.5373\n",
      "Epoch 520/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9057 - accuracy: 0.5473 - val_loss: 0.9130 - val_accuracy: 0.5403\n",
      "Epoch 521/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9067 - accuracy: 0.5435 - val_loss: 0.9129 - val_accuracy: 0.5417\n",
      "Epoch 522/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9074 - accuracy: 0.5421 - val_loss: 0.9136 - val_accuracy: 0.5437\n",
      "Epoch 523/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9093 - accuracy: 0.5446 - val_loss: 0.9143 - val_accuracy: 0.5447\n",
      "Epoch 524/1800\n",
      "14000/14000 [==============================] - 1s 105us/step - loss: 0.9077 - accuracy: 0.5439 - val_loss: 0.9146 - val_accuracy: 0.5397\n",
      "Epoch 525/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9079 - accuracy: 0.5486 - val_loss: 0.9139 - val_accuracy: 0.5433\n",
      "Epoch 526/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9049 - accuracy: 0.5494 - val_loss: 0.9130 - val_accuracy: 0.5383\n",
      "Epoch 527/1800\n",
      "14000/14000 [==============================] - 2s 135us/step - loss: 0.9069 - accuracy: 0.5453 - val_loss: 0.9142 - val_accuracy: 0.5453\n",
      "Epoch 528/1800\n",
      "14000/14000 [==============================] - 2s 146us/step - loss: 0.9053 - accuracy: 0.5451 - val_loss: 0.9124 - val_accuracy: 0.5480\n",
      "Epoch 529/1800\n",
      "14000/14000 [==============================] - 2s 136us/step - loss: 0.9065 - accuracy: 0.5461 - val_loss: 0.9128 - val_accuracy: 0.5407\n",
      "Epoch 530/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9065 - accuracy: 0.5502 - val_loss: 0.9124 - val_accuracy: 0.5387\n",
      "Epoch 531/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9082 - accuracy: 0.5442 - val_loss: 0.9128 - val_accuracy: 0.5400\n",
      "Epoch 532/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9061 - accuracy: 0.5453 - val_loss: 0.9142 - val_accuracy: 0.5413\n",
      "Epoch 533/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9059 - accuracy: 0.5476 - val_loss: 0.9133 - val_accuracy: 0.5410\n",
      "Epoch 534/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9075 - accuracy: 0.5465 - val_loss: 0.9119 - val_accuracy: 0.5450\n",
      "Epoch 535/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9078 - accuracy: 0.5464 - val_loss: 0.9127 - val_accuracy: 0.5437\n",
      "Epoch 536/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9052 - accuracy: 0.5496 - val_loss: 0.9204 - val_accuracy: 0.5353\n",
      "Epoch 537/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9048 - accuracy: 0.5456 - val_loss: 0.9126 - val_accuracy: 0.5403\n",
      "Epoch 538/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9050 - accuracy: 0.5486 - val_loss: 0.9127 - val_accuracy: 0.5397\n",
      "Epoch 539/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9056 - accuracy: 0.5499 - val_loss: 0.9140 - val_accuracy: 0.5340\n",
      "Epoch 540/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9051 - accuracy: 0.5469 - val_loss: 0.9129 - val_accuracy: 0.5423\n",
      "Epoch 541/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9045 - accuracy: 0.5479 - val_loss: 0.9118 - val_accuracy: 0.5457\n",
      "Epoch 542/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9056 - accuracy: 0.5466 - val_loss: 0.9127 - val_accuracy: 0.5443\n",
      "Epoch 543/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9045 - accuracy: 0.5493 - val_loss: 0.9127 - val_accuracy: 0.5457\n",
      "Epoch 544/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9060 - accuracy: 0.5499 - val_loss: 0.9110 - val_accuracy: 0.5467\n",
      "Epoch 545/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9047 - accuracy: 0.5496 - val_loss: 0.9145 - val_accuracy: 0.5433\n",
      "Epoch 546/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9065 - accuracy: 0.5479 - val_loss: 0.9120 - val_accuracy: 0.5400\n",
      "Epoch 547/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9062 - accuracy: 0.5452 - val_loss: 0.9121 - val_accuracy: 0.5400\n",
      "Epoch 548/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9036 - accuracy: 0.5511 - val_loss: 0.9135 - val_accuracy: 0.5430\n",
      "Epoch 549/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9052 - accuracy: 0.5479 - val_loss: 0.9130 - val_accuracy: 0.5463\n",
      "Epoch 550/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9056 - accuracy: 0.5429 - val_loss: 0.9123 - val_accuracy: 0.5433\n",
      "Epoch 551/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9088 - accuracy: 0.5458 - val_loss: 0.9135 - val_accuracy: 0.5370\n",
      "Epoch 552/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9067 - accuracy: 0.5473 - val_loss: 0.9135 - val_accuracy: 0.5420\n",
      "Epoch 553/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9072 - accuracy: 0.5485 - val_loss: 0.9131 - val_accuracy: 0.5403\n",
      "Epoch 554/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9076 - accuracy: 0.5445 - val_loss: 0.9121 - val_accuracy: 0.5390\n",
      "Epoch 555/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9077 - accuracy: 0.5479 - val_loss: 0.9104 - val_accuracy: 0.5447\n",
      "Epoch 556/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9071 - accuracy: 0.5466 - val_loss: 0.9115 - val_accuracy: 0.5377\n",
      "Epoch 557/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9064 - accuracy: 0.5451 - val_loss: 0.9141 - val_accuracy: 0.5387\n",
      "Epoch 558/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9074 - accuracy: 0.5445 - val_loss: 0.9121 - val_accuracy: 0.5400\n",
      "Epoch 559/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9066 - accuracy: 0.5464 - val_loss: 0.9124 - val_accuracy: 0.5340\n",
      "Epoch 560/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9063 - accuracy: 0.5457 - val_loss: 0.9132 - val_accuracy: 0.5377\n",
      "Epoch 561/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9055 - accuracy: 0.5467 - val_loss: 0.9139 - val_accuracy: 0.5390\n",
      "Epoch 562/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9055 - accuracy: 0.5492 - val_loss: 0.9142 - val_accuracy: 0.5340\n",
      "Epoch 563/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9068 - accuracy: 0.5457 - val_loss: 0.9139 - val_accuracy: 0.5407\n",
      "Epoch 564/1800\n",
      "14000/14000 [==============================] - 3s 186us/step - loss: 0.9059 - accuracy: 0.5479 - val_loss: 0.9137 - val_accuracy: 0.5400\n",
      "Epoch 565/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9068 - accuracy: 0.5448 - val_loss: 0.9126 - val_accuracy: 0.5413\n",
      "Epoch 566/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9069 - accuracy: 0.5491 - val_loss: 0.9144 - val_accuracy: 0.5373\n",
      "Epoch 567/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9062 - accuracy: 0.5479 - val_loss: 0.9150 - val_accuracy: 0.5400\n",
      "Epoch 568/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9075 - accuracy: 0.5426 - val_loss: 0.9120 - val_accuracy: 0.5480\n",
      "Epoch 569/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9057 - accuracy: 0.5483 - val_loss: 0.9145 - val_accuracy: 0.5460\n",
      "Epoch 570/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9066 - accuracy: 0.5505 - val_loss: 0.9140 - val_accuracy: 0.5440\n",
      "Epoch 571/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9051 - accuracy: 0.5481 - val_loss: 0.9155 - val_accuracy: 0.5417\n",
      "Epoch 572/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9037 - accuracy: 0.5518 - val_loss: 0.9127 - val_accuracy: 0.5353\n",
      "Epoch 573/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9040 - accuracy: 0.5474 - val_loss: 0.9138 - val_accuracy: 0.5417\n",
      "Epoch 574/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9061 - accuracy: 0.5429 - val_loss: 0.9123 - val_accuracy: 0.5407\n",
      "Epoch 575/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9058 - accuracy: 0.5471 - val_loss: 0.9142 - val_accuracy: 0.5453\n",
      "Epoch 576/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9061 - accuracy: 0.5494 - val_loss: 0.9155 - val_accuracy: 0.5387\n",
      "Epoch 577/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9063 - accuracy: 0.5472 - val_loss: 0.9134 - val_accuracy: 0.5360\n",
      "Epoch 578/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9044 - accuracy: 0.5496 - val_loss: 0.9135 - val_accuracy: 0.5387\n",
      "Epoch 579/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9059 - accuracy: 0.5488 - val_loss: 0.9160 - val_accuracy: 0.5410\n",
      "Epoch 580/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9060 - accuracy: 0.5484 - val_loss: 0.9147 - val_accuracy: 0.5380\n",
      "Epoch 581/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9076 - accuracy: 0.5420 - val_loss: 0.9134 - val_accuracy: 0.5430\n",
      "Epoch 582/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9050 - accuracy: 0.5504 - val_loss: 0.9108 - val_accuracy: 0.5463\n",
      "Epoch 583/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9078 - accuracy: 0.5463 - val_loss: 0.9148 - val_accuracy: 0.5447\n",
      "Epoch 584/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9060 - accuracy: 0.5494 - val_loss: 0.9121 - val_accuracy: 0.5440\n",
      "Epoch 585/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9053 - accuracy: 0.5501 - val_loss: 0.9152 - val_accuracy: 0.5373\n",
      "Epoch 586/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9083 - accuracy: 0.5463 - val_loss: 0.9165 - val_accuracy: 0.5423\n",
      "Epoch 587/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9069 - accuracy: 0.5442 - val_loss: 0.9121 - val_accuracy: 0.5447\n",
      "Epoch 588/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9057 - accuracy: 0.5507 - val_loss: 0.9133 - val_accuracy: 0.5383\n",
      "Epoch 589/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9053 - accuracy: 0.5474 - val_loss: 0.9124 - val_accuracy: 0.5447\n",
      "Epoch 590/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9056 - accuracy: 0.5430 - val_loss: 0.9173 - val_accuracy: 0.5323\n",
      "Epoch 591/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9073 - accuracy: 0.5461 - val_loss: 0.9145 - val_accuracy: 0.5440\n",
      "Epoch 592/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9050 - accuracy: 0.5503 - val_loss: 0.9182 - val_accuracy: 0.5453\n",
      "Epoch 593/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9054 - accuracy: 0.5456 - val_loss: 0.9131 - val_accuracy: 0.5447\n",
      "Epoch 594/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9053 - accuracy: 0.5465 - val_loss: 0.9137 - val_accuracy: 0.5403\n",
      "Epoch 595/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9036 - accuracy: 0.5466 - val_loss: 0.9148 - val_accuracy: 0.5347\n",
      "Epoch 596/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9067 - accuracy: 0.5455 - val_loss: 0.9167 - val_accuracy: 0.5397\n",
      "Epoch 597/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9075 - accuracy: 0.5481 - val_loss: 0.9178 - val_accuracy: 0.5420\n",
      "Epoch 598/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9045 - accuracy: 0.5501 - val_loss: 0.9139 - val_accuracy: 0.5443\n",
      "Epoch 599/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9041 - accuracy: 0.5473 - val_loss: 0.9148 - val_accuracy: 0.5457\n",
      "Epoch 600/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9039 - accuracy: 0.5501 - val_loss: 0.9136 - val_accuracy: 0.5390\n",
      "Epoch 601/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9068 - accuracy: 0.5467 - val_loss: 0.9133 - val_accuracy: 0.5467\n",
      "Epoch 602/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9083 - accuracy: 0.5453 - val_loss: 0.9109 - val_accuracy: 0.5453\n",
      "Epoch 603/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9060 - accuracy: 0.5492 - val_loss: 0.9133 - val_accuracy: 0.5457\n",
      "Epoch 604/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9044 - accuracy: 0.5491 - val_loss: 0.9135 - val_accuracy: 0.5353\n",
      "Epoch 605/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9051 - accuracy: 0.5528 - val_loss: 0.9147 - val_accuracy: 0.5447\n",
      "Epoch 606/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9053 - accuracy: 0.5458 - val_loss: 0.9144 - val_accuracy: 0.5417\n",
      "Epoch 607/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9081 - accuracy: 0.5427 - val_loss: 0.9161 - val_accuracy: 0.5373\n",
      "Epoch 608/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9037 - accuracy: 0.5484 - val_loss: 0.9116 - val_accuracy: 0.5410\n",
      "Epoch 609/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9052 - accuracy: 0.5496 - val_loss: 0.9123 - val_accuracy: 0.5453\n",
      "Epoch 610/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9055 - accuracy: 0.5482 - val_loss: 0.9151 - val_accuracy: 0.5457\n",
      "Epoch 611/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9060 - accuracy: 0.5456 - val_loss: 0.9156 - val_accuracy: 0.5440\n",
      "Epoch 612/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9035 - accuracy: 0.5482 - val_loss: 0.9153 - val_accuracy: 0.5430\n",
      "Epoch 613/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9052 - accuracy: 0.5494 - val_loss: 0.9114 - val_accuracy: 0.5393\n",
      "Epoch 614/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9064 - accuracy: 0.5458 - val_loss: 0.9149 - val_accuracy: 0.5417\n",
      "Epoch 615/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9038 - accuracy: 0.5487 - val_loss: 0.9127 - val_accuracy: 0.5453\n",
      "Epoch 616/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9068 - accuracy: 0.5500 - val_loss: 0.9109 - val_accuracy: 0.5453\n",
      "Epoch 617/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9040 - accuracy: 0.5497 - val_loss: 0.9120 - val_accuracy: 0.5457\n",
      "Epoch 618/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9049 - accuracy: 0.5479 - val_loss: 0.9150 - val_accuracy: 0.5410\n",
      "Epoch 619/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9039 - accuracy: 0.5509 - val_loss: 0.9145 - val_accuracy: 0.5357\n",
      "Epoch 620/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9063 - accuracy: 0.5498 - val_loss: 0.9127 - val_accuracy: 0.5407\n",
      "Epoch 621/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9056 - accuracy: 0.5476 - val_loss: 0.9166 - val_accuracy: 0.5380\n",
      "Epoch 622/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9041 - accuracy: 0.5502 - val_loss: 0.9144 - val_accuracy: 0.5367\n",
      "Epoch 623/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9032 - accuracy: 0.5516 - val_loss: 0.9132 - val_accuracy: 0.5417\n",
      "Epoch 624/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9065 - accuracy: 0.5472 - val_loss: 0.9132 - val_accuracy: 0.5410\n",
      "Epoch 625/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9070 - accuracy: 0.5469 - val_loss: 0.9140 - val_accuracy: 0.5417\n",
      "Epoch 626/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9079 - accuracy: 0.5491 - val_loss: 0.9138 - val_accuracy: 0.5400\n",
      "Epoch 627/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9047 - accuracy: 0.5492 - val_loss: 0.9132 - val_accuracy: 0.5433\n",
      "Epoch 628/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9052 - accuracy: 0.5456 - val_loss: 0.9122 - val_accuracy: 0.5437\n",
      "Epoch 629/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9066 - accuracy: 0.5491 - val_loss: 0.9184 - val_accuracy: 0.5437\n",
      "Epoch 630/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9058 - accuracy: 0.5477 - val_loss: 0.9146 - val_accuracy: 0.5413\n",
      "Epoch 631/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9061 - accuracy: 0.5470 - val_loss: 0.9113 - val_accuracy: 0.5460\n",
      "Epoch 632/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9048 - accuracy: 0.5471 - val_loss: 0.9120 - val_accuracy: 0.5470\n",
      "Epoch 633/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9054 - accuracy: 0.5494 - val_loss: 0.9159 - val_accuracy: 0.5383\n",
      "Epoch 634/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9058 - accuracy: 0.5470 - val_loss: 0.9120 - val_accuracy: 0.5460\n",
      "Epoch 635/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9054 - accuracy: 0.5459 - val_loss: 0.9118 - val_accuracy: 0.5437\n",
      "Epoch 636/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9051 - accuracy: 0.5481 - val_loss: 0.9111 - val_accuracy: 0.5447\n",
      "Epoch 637/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9068 - accuracy: 0.5497 - val_loss: 0.9126 - val_accuracy: 0.5443\n",
      "Epoch 638/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9041 - accuracy: 0.5526 - val_loss: 0.9137 - val_accuracy: 0.5463\n",
      "Epoch 639/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9043 - accuracy: 0.5508 - val_loss: 0.9120 - val_accuracy: 0.5357\n",
      "Epoch 640/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9067 - accuracy: 0.5464 - val_loss: 0.9137 - val_accuracy: 0.5323\n",
      "Epoch 641/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9045 - accuracy: 0.5486 - val_loss: 0.9133 - val_accuracy: 0.5457\n",
      "Epoch 642/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9060 - accuracy: 0.5444 - val_loss: 0.9127 - val_accuracy: 0.5437\n",
      "Epoch 643/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9062 - accuracy: 0.5499 - val_loss: 0.9103 - val_accuracy: 0.5497\n",
      "Epoch 644/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9078 - accuracy: 0.5476 - val_loss: 0.9183 - val_accuracy: 0.5410\n",
      "Epoch 645/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9034 - accuracy: 0.5466 - val_loss: 0.9122 - val_accuracy: 0.5480\n",
      "Epoch 646/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9049 - accuracy: 0.5492 - val_loss: 0.9117 - val_accuracy: 0.5417\n",
      "Epoch 647/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9050 - accuracy: 0.5503 - val_loss: 0.9158 - val_accuracy: 0.5367\n",
      "Epoch 648/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9061 - accuracy: 0.5481 - val_loss: 0.9121 - val_accuracy: 0.5430\n",
      "Epoch 649/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9043 - accuracy: 0.5479 - val_loss: 0.9153 - val_accuracy: 0.5450\n",
      "Epoch 650/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9064 - accuracy: 0.5453 - val_loss: 0.9144 - val_accuracy: 0.5410\n",
      "Epoch 651/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9073 - accuracy: 0.5459 - val_loss: 0.9115 - val_accuracy: 0.5457\n",
      "Epoch 652/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9043 - accuracy: 0.5493 - val_loss: 0.9161 - val_accuracy: 0.5400\n",
      "Epoch 653/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9056 - accuracy: 0.5485 - val_loss: 0.9119 - val_accuracy: 0.5463\n",
      "Epoch 654/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9055 - accuracy: 0.5440 - val_loss: 0.9143 - val_accuracy: 0.5457\n",
      "Epoch 655/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9058 - accuracy: 0.5499 - val_loss: 0.9111 - val_accuracy: 0.5513\n",
      "Epoch 656/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9042 - accuracy: 0.5456 - val_loss: 0.9127 - val_accuracy: 0.5497\n",
      "Epoch 657/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9044 - accuracy: 0.5473 - val_loss: 0.9147 - val_accuracy: 0.5460\n",
      "Epoch 658/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9045 - accuracy: 0.5491 - val_loss: 0.9121 - val_accuracy: 0.5490\n",
      "Epoch 659/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9052 - accuracy: 0.5433 - val_loss: 0.9151 - val_accuracy: 0.5360\n",
      "Epoch 660/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9063 - accuracy: 0.5486 - val_loss: 0.9126 - val_accuracy: 0.5430\n",
      "Epoch 661/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9047 - accuracy: 0.5484 - val_loss: 0.9164 - val_accuracy: 0.5413\n",
      "Epoch 662/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9035 - accuracy: 0.5521 - val_loss: 0.9137 - val_accuracy: 0.5443\n",
      "Epoch 663/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9072 - accuracy: 0.5429 - val_loss: 0.9138 - val_accuracy: 0.5447\n",
      "Epoch 664/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9045 - accuracy: 0.5450 - val_loss: 0.9175 - val_accuracy: 0.5427\n",
      "Epoch 665/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9053 - accuracy: 0.5503 - val_loss: 0.9131 - val_accuracy: 0.5373\n",
      "Epoch 666/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9057 - accuracy: 0.5433 - val_loss: 0.9130 - val_accuracy: 0.5447\n",
      "Epoch 667/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9049 - accuracy: 0.5458 - val_loss: 0.9117 - val_accuracy: 0.5417\n",
      "Epoch 668/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9053 - accuracy: 0.5504 - val_loss: 0.9129 - val_accuracy: 0.5447\n",
      "Epoch 669/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9045 - accuracy: 0.5486 - val_loss: 0.9127 - val_accuracy: 0.5443\n",
      "Epoch 670/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9052 - accuracy: 0.5511 - val_loss: 0.9145 - val_accuracy: 0.5480\n",
      "Epoch 671/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9065 - accuracy: 0.5468 - val_loss: 0.9135 - val_accuracy: 0.5343\n",
      "Epoch 672/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9067 - accuracy: 0.5494 - val_loss: 0.9115 - val_accuracy: 0.5437\n",
      "Epoch 673/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9050 - accuracy: 0.5447 - val_loss: 0.9130 - val_accuracy: 0.5370\n",
      "Epoch 674/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9047 - accuracy: 0.5456 - val_loss: 0.9121 - val_accuracy: 0.5470\n",
      "Epoch 675/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9064 - accuracy: 0.5461 - val_loss: 0.9123 - val_accuracy: 0.5393\n",
      "Epoch 676/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9055 - accuracy: 0.5501 - val_loss: 0.9121 - val_accuracy: 0.5437\n",
      "Epoch 677/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9040 - accuracy: 0.5499 - val_loss: 0.9127 - val_accuracy: 0.5457\n",
      "Epoch 678/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9042 - accuracy: 0.5475 - val_loss: 0.9157 - val_accuracy: 0.5457\n",
      "Epoch 679/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9056 - accuracy: 0.5461 - val_loss: 0.9120 - val_accuracy: 0.5460\n",
      "Epoch 680/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9068 - accuracy: 0.5469 - val_loss: 0.9108 - val_accuracy: 0.5527\n",
      "Epoch 681/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9054 - accuracy: 0.5474 - val_loss: 0.9142 - val_accuracy: 0.5487\n",
      "Epoch 682/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9038 - accuracy: 0.5432 - val_loss: 0.9112 - val_accuracy: 0.5453\n",
      "Epoch 683/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9075 - accuracy: 0.5469 - val_loss: 0.9126 - val_accuracy: 0.5487\n",
      "Epoch 684/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9052 - accuracy: 0.5508 - val_loss: 0.9139 - val_accuracy: 0.5417\n",
      "Epoch 685/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9069 - accuracy: 0.5414 - val_loss: 0.9149 - val_accuracy: 0.5410\n",
      "Epoch 686/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9024 - accuracy: 0.5533 - val_loss: 0.9121 - val_accuracy: 0.5493\n",
      "Epoch 687/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9065 - accuracy: 0.5466 - val_loss: 0.9111 - val_accuracy: 0.5503\n",
      "Epoch 688/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9034 - accuracy: 0.5501 - val_loss: 0.9110 - val_accuracy: 0.5447\n",
      "Epoch 689/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9070 - accuracy: 0.5452 - val_loss: 0.9122 - val_accuracy: 0.5460\n",
      "Epoch 690/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9056 - accuracy: 0.5483 - val_loss: 0.9122 - val_accuracy: 0.5467\n",
      "Epoch 691/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9053 - accuracy: 0.5430 - val_loss: 0.9145 - val_accuracy: 0.5460\n",
      "Epoch 692/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9060 - accuracy: 0.5462 - val_loss: 0.9126 - val_accuracy: 0.5457\n",
      "Epoch 693/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9057 - accuracy: 0.5524 - val_loss: 0.9131 - val_accuracy: 0.5397\n",
      "Epoch 694/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9061 - accuracy: 0.5511 - val_loss: 0.9146 - val_accuracy: 0.5500\n",
      "Epoch 695/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9048 - accuracy: 0.5482 - val_loss: 0.9129 - val_accuracy: 0.5377\n",
      "Epoch 696/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9027 - accuracy: 0.5484 - val_loss: 0.9120 - val_accuracy: 0.5450\n",
      "Epoch 697/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9056 - accuracy: 0.5479 - val_loss: 0.9140 - val_accuracy: 0.5373\n",
      "Epoch 698/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9059 - accuracy: 0.5449 - val_loss: 0.9115 - val_accuracy: 0.5397\n",
      "Epoch 699/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9047 - accuracy: 0.5464 - val_loss: 0.9153 - val_accuracy: 0.5397\n",
      "Epoch 700/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9070 - accuracy: 0.5443 - val_loss: 0.9112 - val_accuracy: 0.5410\n",
      "Epoch 701/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9043 - accuracy: 0.5496 - val_loss: 0.9129 - val_accuracy: 0.5400\n",
      "Epoch 702/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9049 - accuracy: 0.5501 - val_loss: 0.9151 - val_accuracy: 0.5293\n",
      "Epoch 703/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9058 - accuracy: 0.5508 - val_loss: 0.9128 - val_accuracy: 0.5460\n",
      "Epoch 704/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9057 - accuracy: 0.5481 - val_loss: 0.9113 - val_accuracy: 0.5393\n",
      "Epoch 705/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9068 - accuracy: 0.5469 - val_loss: 0.9155 - val_accuracy: 0.5433\n",
      "Epoch 706/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9049 - accuracy: 0.5514 - val_loss: 0.9107 - val_accuracy: 0.5423\n",
      "Epoch 707/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9058 - accuracy: 0.5490 - val_loss: 0.9122 - val_accuracy: 0.5477\n",
      "Epoch 708/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9046 - accuracy: 0.5491 - val_loss: 0.9119 - val_accuracy: 0.5477\n",
      "Epoch 709/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9057 - accuracy: 0.5494 - val_loss: 0.9121 - val_accuracy: 0.5397\n",
      "Epoch 710/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9031 - accuracy: 0.5511 - val_loss: 0.9110 - val_accuracy: 0.5407\n",
      "Epoch 711/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9073 - accuracy: 0.5479 - val_loss: 0.9144 - val_accuracy: 0.5373\n",
      "Epoch 712/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9036 - accuracy: 0.5501 - val_loss: 0.9139 - val_accuracy: 0.5350\n",
      "Epoch 713/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9055 - accuracy: 0.5517 - val_loss: 0.9108 - val_accuracy: 0.5457\n",
      "Epoch 714/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9037 - accuracy: 0.5484 - val_loss: 0.9154 - val_accuracy: 0.5303\n",
      "Epoch 715/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9072 - accuracy: 0.5514 - val_loss: 0.9140 - val_accuracy: 0.5377\n",
      "Epoch 716/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9054 - accuracy: 0.5491 - val_loss: 0.9139 - val_accuracy: 0.5407\n",
      "Epoch 717/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9053 - accuracy: 0.5434 - val_loss: 0.9147 - val_accuracy: 0.5413\n",
      "Epoch 718/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9034 - accuracy: 0.5466 - val_loss: 0.9142 - val_accuracy: 0.5377\n",
      "Epoch 719/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9019 - accuracy: 0.5441 - val_loss: 0.9127 - val_accuracy: 0.5460\n",
      "Epoch 720/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9057 - accuracy: 0.5452 - val_loss: 0.9127 - val_accuracy: 0.5330\n",
      "Epoch 721/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9053 - accuracy: 0.5475 - val_loss: 0.9141 - val_accuracy: 0.5407\n",
      "Epoch 722/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9055 - accuracy: 0.5491 - val_loss: 0.9141 - val_accuracy: 0.5377\n",
      "Epoch 723/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9048 - accuracy: 0.5490 - val_loss: 0.9130 - val_accuracy: 0.5413\n",
      "Epoch 724/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9022 - accuracy: 0.5468 - val_loss: 0.9124 - val_accuracy: 0.5437\n",
      "Epoch 725/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9038 - accuracy: 0.5523 - val_loss: 0.9118 - val_accuracy: 0.5457\n",
      "Epoch 726/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9075 - accuracy: 0.5494 - val_loss: 0.9128 - val_accuracy: 0.5367\n",
      "Epoch 727/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9062 - accuracy: 0.5520 - val_loss: 0.9126 - val_accuracy: 0.5453\n",
      "Epoch 728/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9040 - accuracy: 0.5482 - val_loss: 0.9117 - val_accuracy: 0.5503\n",
      "Epoch 729/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9064 - accuracy: 0.5468 - val_loss: 0.9145 - val_accuracy: 0.5450\n",
      "Epoch 730/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9055 - accuracy: 0.5480 - val_loss: 0.9103 - val_accuracy: 0.5490\n",
      "Epoch 731/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9041 - accuracy: 0.5496 - val_loss: 0.9116 - val_accuracy: 0.5477\n",
      "Epoch 732/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9035 - accuracy: 0.5514 - val_loss: 0.9124 - val_accuracy: 0.5410\n",
      "Epoch 733/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9064 - accuracy: 0.5519 - val_loss: 0.9118 - val_accuracy: 0.5473\n",
      "Epoch 734/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9052 - accuracy: 0.5504 - val_loss: 0.9108 - val_accuracy: 0.5420\n",
      "Epoch 735/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9045 - accuracy: 0.5504 - val_loss: 0.9127 - val_accuracy: 0.5447\n",
      "Epoch 736/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9045 - accuracy: 0.5511 - val_loss: 0.9121 - val_accuracy: 0.5410\n",
      "Epoch 737/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9061 - accuracy: 0.5493 - val_loss: 0.9120 - val_accuracy: 0.5447\n",
      "Epoch 738/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9041 - accuracy: 0.5480 - val_loss: 0.9121 - val_accuracy: 0.5447\n",
      "Epoch 739/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9035 - accuracy: 0.5494 - val_loss: 0.9123 - val_accuracy: 0.5467\n",
      "Epoch 740/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9061 - accuracy: 0.5477 - val_loss: 0.9142 - val_accuracy: 0.5403\n",
      "Epoch 741/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9045 - accuracy: 0.5521 - val_loss: 0.9134 - val_accuracy: 0.5460\n",
      "Epoch 742/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9041 - accuracy: 0.5491 - val_loss: 0.9123 - val_accuracy: 0.5423\n",
      "Epoch 743/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9063 - accuracy: 0.5468 - val_loss: 0.9103 - val_accuracy: 0.5460\n",
      "Epoch 744/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9049 - accuracy: 0.5504 - val_loss: 0.9091 - val_accuracy: 0.5460\n",
      "Epoch 745/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9039 - accuracy: 0.5462 - val_loss: 0.9122 - val_accuracy: 0.5427\n",
      "Epoch 746/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9034 - accuracy: 0.5474 - val_loss: 0.9112 - val_accuracy: 0.5410\n",
      "Epoch 747/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9067 - accuracy: 0.5447 - val_loss: 0.9116 - val_accuracy: 0.5450\n",
      "Epoch 748/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9061 - accuracy: 0.5465 - val_loss: 0.9111 - val_accuracy: 0.5433\n",
      "Epoch 749/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9027 - accuracy: 0.5456 - val_loss: 0.9105 - val_accuracy: 0.5437\n",
      "Epoch 750/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9056 - accuracy: 0.5483 - val_loss: 0.9101 - val_accuracy: 0.5517\n",
      "Epoch 751/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9024 - accuracy: 0.5519 - val_loss: 0.9129 - val_accuracy: 0.5450\n",
      "Epoch 752/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9052 - accuracy: 0.5491 - val_loss: 0.9146 - val_accuracy: 0.5413\n",
      "Epoch 753/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9035 - accuracy: 0.5510 - val_loss: 0.9128 - val_accuracy: 0.5447\n",
      "Epoch 754/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9048 - accuracy: 0.5491 - val_loss: 0.9135 - val_accuracy: 0.5450\n",
      "Epoch 755/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9045 - accuracy: 0.5496 - val_loss: 0.9125 - val_accuracy: 0.5397\n",
      "Epoch 756/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9075 - accuracy: 0.5466 - val_loss: 0.9138 - val_accuracy: 0.5450\n",
      "Epoch 757/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9055 - accuracy: 0.5486 - val_loss: 0.9116 - val_accuracy: 0.5443\n",
      "Epoch 758/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9053 - accuracy: 0.5446 - val_loss: 0.9136 - val_accuracy: 0.5477\n",
      "Epoch 759/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9043 - accuracy: 0.5451 - val_loss: 0.9146 - val_accuracy: 0.5417\n",
      "Epoch 760/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9041 - accuracy: 0.5543 - val_loss: 0.9141 - val_accuracy: 0.5453\n",
      "Epoch 761/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9057 - accuracy: 0.5519 - val_loss: 0.9131 - val_accuracy: 0.5387\n",
      "Epoch 762/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9042 - accuracy: 0.5528 - val_loss: 0.9130 - val_accuracy: 0.5433\n",
      "Epoch 763/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9062 - accuracy: 0.5488 - val_loss: 0.9126 - val_accuracy: 0.5417\n",
      "Epoch 764/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9041 - accuracy: 0.5502 - val_loss: 0.9121 - val_accuracy: 0.5413\n",
      "Epoch 765/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9045 - accuracy: 0.5501 - val_loss: 0.9167 - val_accuracy: 0.5393\n",
      "Epoch 766/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9046 - accuracy: 0.5461 - val_loss: 0.9125 - val_accuracy: 0.5480\n",
      "Epoch 767/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9051 - accuracy: 0.5448 - val_loss: 0.9108 - val_accuracy: 0.5453\n",
      "Epoch 768/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9067 - accuracy: 0.5492 - val_loss: 0.9106 - val_accuracy: 0.5437\n",
      "Epoch 769/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9037 - accuracy: 0.5529 - val_loss: 0.9131 - val_accuracy: 0.5410\n",
      "Epoch 770/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9047 - accuracy: 0.5484 - val_loss: 0.9124 - val_accuracy: 0.5447\n",
      "Epoch 771/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9032 - accuracy: 0.5464 - val_loss: 0.9140 - val_accuracy: 0.5350\n",
      "Epoch 772/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9047 - accuracy: 0.5483 - val_loss: 0.9114 - val_accuracy: 0.5423\n",
      "Epoch 773/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9031 - accuracy: 0.5524 - val_loss: 0.9132 - val_accuracy: 0.5407\n",
      "Epoch 774/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9059 - accuracy: 0.5456 - val_loss: 0.9133 - val_accuracy: 0.5440\n",
      "Epoch 775/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9063 - accuracy: 0.5496 - val_loss: 0.9134 - val_accuracy: 0.5383\n",
      "Epoch 776/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9043 - accuracy: 0.5450 - val_loss: 0.9142 - val_accuracy: 0.5433\n",
      "Epoch 777/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9041 - accuracy: 0.5467 - val_loss: 0.9133 - val_accuracy: 0.5403\n",
      "Epoch 778/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9051 - accuracy: 0.5489 - val_loss: 0.9106 - val_accuracy: 0.5443\n",
      "Epoch 779/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9061 - accuracy: 0.5492 - val_loss: 0.9146 - val_accuracy: 0.5417\n",
      "Epoch 780/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9043 - accuracy: 0.5470 - val_loss: 0.9139 - val_accuracy: 0.5437\n",
      "Epoch 781/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9051 - accuracy: 0.5491 - val_loss: 0.9127 - val_accuracy: 0.5380\n",
      "Epoch 782/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9053 - accuracy: 0.5457 - val_loss: 0.9112 - val_accuracy: 0.5427\n",
      "Epoch 783/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9067 - accuracy: 0.5465 - val_loss: 0.9138 - val_accuracy: 0.5423\n",
      "Epoch 784/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9049 - accuracy: 0.5471 - val_loss: 0.9128 - val_accuracy: 0.5457\n",
      "Epoch 785/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9042 - accuracy: 0.5454 - val_loss: 0.9121 - val_accuracy: 0.5387\n",
      "Epoch 786/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9055 - accuracy: 0.5437 - val_loss: 0.9129 - val_accuracy: 0.5413\n",
      "Epoch 787/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9040 - accuracy: 0.5469 - val_loss: 0.9131 - val_accuracy: 0.5443\n",
      "Epoch 788/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9043 - accuracy: 0.5529 - val_loss: 0.9128 - val_accuracy: 0.5447\n",
      "Epoch 789/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9043 - accuracy: 0.5497 - val_loss: 0.9146 - val_accuracy: 0.5467\n",
      "Epoch 790/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9051 - accuracy: 0.5439 - val_loss: 0.9125 - val_accuracy: 0.5430\n",
      "Epoch 791/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9035 - accuracy: 0.5481 - val_loss: 0.9120 - val_accuracy: 0.5397\n",
      "Epoch 792/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9041 - accuracy: 0.5498 - val_loss: 0.9124 - val_accuracy: 0.5420\n",
      "Epoch 793/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9044 - accuracy: 0.5469 - val_loss: 0.9146 - val_accuracy: 0.5330\n",
      "Epoch 794/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9058 - accuracy: 0.5507 - val_loss: 0.9103 - val_accuracy: 0.5453\n",
      "Epoch 795/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9052 - accuracy: 0.5479 - val_loss: 0.9118 - val_accuracy: 0.5447\n",
      "Epoch 796/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9038 - accuracy: 0.5463 - val_loss: 0.9137 - val_accuracy: 0.5380\n",
      "Epoch 797/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9037 - accuracy: 0.5496 - val_loss: 0.9126 - val_accuracy: 0.5490\n",
      "Epoch 798/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9030 - accuracy: 0.5474 - val_loss: 0.9138 - val_accuracy: 0.5383\n",
      "Epoch 799/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9027 - accuracy: 0.5487 - val_loss: 0.9118 - val_accuracy: 0.5463\n",
      "Epoch 800/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9026 - accuracy: 0.5490 - val_loss: 0.9144 - val_accuracy: 0.5407\n",
      "Epoch 801/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9019 - accuracy: 0.5525 - val_loss: 0.9104 - val_accuracy: 0.5440\n",
      "Epoch 802/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9075 - accuracy: 0.5441 - val_loss: 0.9123 - val_accuracy: 0.5427\n",
      "Epoch 803/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9048 - accuracy: 0.5511 - val_loss: 0.9112 - val_accuracy: 0.5427\n",
      "Epoch 804/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9029 - accuracy: 0.5516 - val_loss: 0.9141 - val_accuracy: 0.5413\n",
      "Epoch 805/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9038 - accuracy: 0.5522 - val_loss: 0.9137 - val_accuracy: 0.5343\n",
      "Epoch 806/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9033 - accuracy: 0.5500 - val_loss: 0.9127 - val_accuracy: 0.5393\n",
      "Epoch 807/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9050 - accuracy: 0.5486 - val_loss: 0.9130 - val_accuracy: 0.5423\n",
      "Epoch 808/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9054 - accuracy: 0.5452 - val_loss: 0.9126 - val_accuracy: 0.5403\n",
      "Epoch 809/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9051 - accuracy: 0.5488 - val_loss: 0.9119 - val_accuracy: 0.5437\n",
      "Epoch 810/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9052 - accuracy: 0.5466 - val_loss: 0.9136 - val_accuracy: 0.5433\n",
      "Epoch 811/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9057 - accuracy: 0.5481 - val_loss: 0.9118 - val_accuracy: 0.5403\n",
      "Epoch 812/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9042 - accuracy: 0.5520 - val_loss: 0.9120 - val_accuracy: 0.5383\n",
      "Epoch 813/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9041 - accuracy: 0.5495 - val_loss: 0.9136 - val_accuracy: 0.5377\n",
      "Epoch 814/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9050 - accuracy: 0.5470 - val_loss: 0.9146 - val_accuracy: 0.5360\n",
      "Epoch 815/1800\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.9055 - accuracy: 0.5457 - val_loss: 0.9129 - val_accuracy: 0.5370\n",
      "Epoch 816/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9032 - accuracy: 0.5500 - val_loss: 0.9114 - val_accuracy: 0.5463\n",
      "Epoch 817/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9054 - accuracy: 0.5475 - val_loss: 0.9161 - val_accuracy: 0.5283\n",
      "Epoch 818/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9053 - accuracy: 0.5489 - val_loss: 0.9130 - val_accuracy: 0.5350\n",
      "Epoch 819/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9066 - accuracy: 0.5444 - val_loss: 0.9118 - val_accuracy: 0.5400\n",
      "Epoch 820/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9056 - accuracy: 0.5485 - val_loss: 0.9121 - val_accuracy: 0.5453\n",
      "Epoch 821/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9057 - accuracy: 0.5519 - val_loss: 0.9135 - val_accuracy: 0.5457\n",
      "Epoch 822/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9007 - accuracy: 0.5539 - val_loss: 0.9134 - val_accuracy: 0.5470\n",
      "Epoch 823/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9041 - accuracy: 0.5485 - val_loss: 0.9131 - val_accuracy: 0.5443\n",
      "Epoch 824/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9033 - accuracy: 0.5506 - val_loss: 0.9117 - val_accuracy: 0.5497\n",
      "Epoch 825/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9066 - accuracy: 0.5475 - val_loss: 0.9118 - val_accuracy: 0.5430\n",
      "Epoch 826/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9063 - accuracy: 0.5460 - val_loss: 0.9139 - val_accuracy: 0.5463\n",
      "Epoch 827/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9029 - accuracy: 0.5534 - val_loss: 0.9133 - val_accuracy: 0.5373\n",
      "Epoch 828/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9063 - accuracy: 0.5489 - val_loss: 0.9141 - val_accuracy: 0.5363\n",
      "Epoch 829/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9051 - accuracy: 0.5486 - val_loss: 0.9132 - val_accuracy: 0.5457\n",
      "Epoch 830/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9037 - accuracy: 0.5483 - val_loss: 0.9147 - val_accuracy: 0.5360\n",
      "Epoch 831/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9020 - accuracy: 0.5483 - val_loss: 0.9139 - val_accuracy: 0.5393\n",
      "Epoch 832/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9056 - accuracy: 0.5429 - val_loss: 0.9126 - val_accuracy: 0.5453\n",
      "Epoch 833/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9038 - accuracy: 0.5504 - val_loss: 0.9120 - val_accuracy: 0.5477\n",
      "Epoch 834/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9043 - accuracy: 0.5503 - val_loss: 0.9127 - val_accuracy: 0.5477\n",
      "Epoch 835/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9038 - accuracy: 0.5476 - val_loss: 0.9143 - val_accuracy: 0.5370\n",
      "Epoch 836/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9026 - accuracy: 0.5479 - val_loss: 0.9113 - val_accuracy: 0.5423\n",
      "Epoch 837/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9024 - accuracy: 0.5450 - val_loss: 0.9138 - val_accuracy: 0.5430\n",
      "Epoch 838/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9044 - accuracy: 0.5510 - val_loss: 0.9103 - val_accuracy: 0.5390\n",
      "Epoch 839/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9052 - accuracy: 0.5515 - val_loss: 0.9127 - val_accuracy: 0.5383\n",
      "Epoch 840/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9060 - accuracy: 0.5459 - val_loss: 0.9112 - val_accuracy: 0.5400\n",
      "Epoch 841/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9034 - accuracy: 0.5476 - val_loss: 0.9104 - val_accuracy: 0.5453\n",
      "Epoch 842/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9065 - accuracy: 0.5461 - val_loss: 0.9136 - val_accuracy: 0.5380\n",
      "Epoch 843/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9057 - accuracy: 0.5466 - val_loss: 0.9168 - val_accuracy: 0.5360\n",
      "Epoch 844/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9028 - accuracy: 0.5533 - val_loss: 0.9105 - val_accuracy: 0.5443\n",
      "Epoch 845/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9029 - accuracy: 0.5514 - val_loss: 0.9156 - val_accuracy: 0.5350\n",
      "Epoch 846/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9049 - accuracy: 0.5494 - val_loss: 0.9110 - val_accuracy: 0.5413\n",
      "Epoch 847/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9031 - accuracy: 0.5459 - val_loss: 0.9116 - val_accuracy: 0.5423\n",
      "Epoch 848/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9033 - accuracy: 0.5496 - val_loss: 0.9106 - val_accuracy: 0.5470\n",
      "Epoch 849/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9067 - accuracy: 0.5436 - val_loss: 0.9137 - val_accuracy: 0.5417\n",
      "Epoch 850/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9059 - accuracy: 0.5496 - val_loss: 0.9116 - val_accuracy: 0.5433\n",
      "Epoch 851/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9079 - accuracy: 0.5471 - val_loss: 0.9138 - val_accuracy: 0.5440\n",
      "Epoch 852/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9044 - accuracy: 0.5502 - val_loss: 0.9122 - val_accuracy: 0.5417\n",
      "Epoch 853/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9042 - accuracy: 0.5477 - val_loss: 0.9133 - val_accuracy: 0.5423\n",
      "Epoch 854/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9024 - accuracy: 0.5476 - val_loss: 0.9107 - val_accuracy: 0.5440\n",
      "Epoch 855/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9036 - accuracy: 0.5507 - val_loss: 0.9155 - val_accuracy: 0.5380\n",
      "Epoch 856/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9044 - accuracy: 0.5459 - val_loss: 0.9136 - val_accuracy: 0.5280\n",
      "Epoch 857/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9064 - accuracy: 0.5484 - val_loss: 0.9139 - val_accuracy: 0.5347\n",
      "Epoch 858/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9044 - accuracy: 0.5481 - val_loss: 0.9100 - val_accuracy: 0.5390\n",
      "Epoch 859/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9044 - accuracy: 0.5497 - val_loss: 0.9118 - val_accuracy: 0.5387\n",
      "Epoch 860/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9035 - accuracy: 0.5464 - val_loss: 0.9127 - val_accuracy: 0.5437\n",
      "Epoch 861/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9042 - accuracy: 0.5492 - val_loss: 0.9127 - val_accuracy: 0.5463\n",
      "Epoch 862/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9038 - accuracy: 0.5504 - val_loss: 0.9129 - val_accuracy: 0.5427\n",
      "Epoch 863/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9038 - accuracy: 0.5499 - val_loss: 0.9126 - val_accuracy: 0.5400\n",
      "Epoch 864/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9027 - accuracy: 0.5506 - val_loss: 0.9131 - val_accuracy: 0.5420\n",
      "Epoch 865/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9043 - accuracy: 0.5476 - val_loss: 0.9184 - val_accuracy: 0.5440\n",
      "Epoch 866/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9045 - accuracy: 0.5499 - val_loss: 0.9120 - val_accuracy: 0.5520\n",
      "Epoch 867/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9055 - accuracy: 0.5515 - val_loss: 0.9125 - val_accuracy: 0.5437\n",
      "Epoch 868/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9067 - accuracy: 0.5439 - val_loss: 0.9142 - val_accuracy: 0.5383\n",
      "Epoch 869/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9035 - accuracy: 0.5493 - val_loss: 0.9140 - val_accuracy: 0.5477\n",
      "Epoch 870/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9035 - accuracy: 0.5471 - val_loss: 0.9122 - val_accuracy: 0.5480\n",
      "Epoch 871/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9064 - accuracy: 0.5467 - val_loss: 0.9139 - val_accuracy: 0.5373\n",
      "Epoch 872/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9041 - accuracy: 0.5502 - val_loss: 0.9165 - val_accuracy: 0.5387\n",
      "Epoch 873/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9027 - accuracy: 0.5503 - val_loss: 0.9120 - val_accuracy: 0.5400\n",
      "Epoch 874/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9051 - accuracy: 0.5504 - val_loss: 0.9120 - val_accuracy: 0.5447\n",
      "Epoch 875/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9057 - accuracy: 0.5461 - val_loss: 0.9132 - val_accuracy: 0.5477\n",
      "Epoch 876/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9052 - accuracy: 0.5489 - val_loss: 0.9119 - val_accuracy: 0.5487\n",
      "Epoch 877/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9056 - accuracy: 0.5464 - val_loss: 0.9097 - val_accuracy: 0.5493\n",
      "Epoch 878/1800\n",
      "14000/14000 [==============================] - 2s 133us/step - loss: 0.9057 - accuracy: 0.5491 - val_loss: 0.9140 - val_accuracy: 0.5387\n",
      "Epoch 879/1800\n",
      "14000/14000 [==============================] - 2s 136us/step - loss: 0.9064 - accuracy: 0.5501 - val_loss: 0.9116 - val_accuracy: 0.5423\n",
      "Epoch 880/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9050 - accuracy: 0.5485 - val_loss: 0.9119 - val_accuracy: 0.5447\n",
      "Epoch 881/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9040 - accuracy: 0.5492 - val_loss: 0.9114 - val_accuracy: 0.5440\n",
      "Epoch 882/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9048 - accuracy: 0.5451 - val_loss: 0.9118 - val_accuracy: 0.5400\n",
      "Epoch 883/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9035 - accuracy: 0.5481 - val_loss: 0.9100 - val_accuracy: 0.5423\n",
      "Epoch 884/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9045 - accuracy: 0.5481 - val_loss: 0.9120 - val_accuracy: 0.5463\n",
      "Epoch 885/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9056 - accuracy: 0.5477 - val_loss: 0.9089 - val_accuracy: 0.5480\n",
      "Epoch 886/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9069 - accuracy: 0.5479 - val_loss: 0.9079 - val_accuracy: 0.5410\n",
      "Epoch 887/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9056 - accuracy: 0.5506 - val_loss: 0.9162 - val_accuracy: 0.5450\n",
      "Epoch 888/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9040 - accuracy: 0.5506 - val_loss: 0.9129 - val_accuracy: 0.5433\n",
      "Epoch 889/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9021 - accuracy: 0.5514 - val_loss: 0.9093 - val_accuracy: 0.5433\n",
      "Epoch 890/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9044 - accuracy: 0.5476 - val_loss: 0.9150 - val_accuracy: 0.5420\n",
      "Epoch 891/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9047 - accuracy: 0.5488 - val_loss: 0.9126 - val_accuracy: 0.5407\n",
      "Epoch 892/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9041 - accuracy: 0.5496 - val_loss: 0.9111 - val_accuracy: 0.5443\n",
      "Epoch 893/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9040 - accuracy: 0.5486 - val_loss: 0.9113 - val_accuracy: 0.5407\n",
      "Epoch 894/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9048 - accuracy: 0.5487 - val_loss: 0.9127 - val_accuracy: 0.5430\n",
      "Epoch 895/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9050 - accuracy: 0.5524 - val_loss: 0.9118 - val_accuracy: 0.5370\n",
      "Epoch 896/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9045 - accuracy: 0.5479 - val_loss: 0.9136 - val_accuracy: 0.5357\n",
      "Epoch 897/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9027 - accuracy: 0.5487 - val_loss: 0.9092 - val_accuracy: 0.5487\n",
      "Epoch 898/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9047 - accuracy: 0.5448 - val_loss: 0.9145 - val_accuracy: 0.5303\n",
      "Epoch 899/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9054 - accuracy: 0.5491 - val_loss: 0.9125 - val_accuracy: 0.5377\n",
      "Epoch 900/1800\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.9058 - accuracy: 0.54 - 1s 81us/step - loss: 0.9056 - accuracy: 0.5479 - val_loss: 0.9103 - val_accuracy: 0.5377\n",
      "Epoch 901/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9071 - accuracy: 0.5456 - val_loss: 0.9145 - val_accuracy: 0.5487\n",
      "Epoch 902/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9053 - accuracy: 0.5512 - val_loss: 0.9127 - val_accuracy: 0.5413\n",
      "Epoch 903/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9044 - accuracy: 0.5510 - val_loss: 0.9098 - val_accuracy: 0.5473\n",
      "Epoch 904/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9045 - accuracy: 0.5497 - val_loss: 0.9137 - val_accuracy: 0.5367\n",
      "Epoch 905/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9036 - accuracy: 0.5499 - val_loss: 0.9125 - val_accuracy: 0.5400\n",
      "Epoch 906/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9028 - accuracy: 0.5521 - val_loss: 0.9140 - val_accuracy: 0.5423\n",
      "Epoch 907/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9034 - accuracy: 0.5490 - val_loss: 0.9106 - val_accuracy: 0.5433\n",
      "Epoch 908/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9043 - accuracy: 0.5496 - val_loss: 0.9122 - val_accuracy: 0.5403\n",
      "Epoch 909/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9049 - accuracy: 0.5459 - val_loss: 0.9125 - val_accuracy: 0.5383\n",
      "Epoch 910/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9038 - accuracy: 0.5509 - val_loss: 0.9098 - val_accuracy: 0.5440\n",
      "Epoch 911/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9043 - accuracy: 0.5515 - val_loss: 0.9106 - val_accuracy: 0.5457\n",
      "Epoch 912/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9032 - accuracy: 0.5499 - val_loss: 0.9117 - val_accuracy: 0.5477\n",
      "Epoch 913/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9034 - accuracy: 0.5518 - val_loss: 0.9117 - val_accuracy: 0.5373\n",
      "Epoch 914/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9063 - accuracy: 0.5458 - val_loss: 0.9148 - val_accuracy: 0.5403\n",
      "Epoch 915/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9053 - accuracy: 0.5474 - val_loss: 0.9103 - val_accuracy: 0.5470\n",
      "Epoch 916/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9043 - accuracy: 0.5499 - val_loss: 0.9127 - val_accuracy: 0.5427\n",
      "Epoch 917/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9046 - accuracy: 0.5479 - val_loss: 0.9104 - val_accuracy: 0.5410\n",
      "Epoch 918/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9051 - accuracy: 0.5451 - val_loss: 0.9116 - val_accuracy: 0.5487\n",
      "Epoch 919/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9039 - accuracy: 0.5457 - val_loss: 0.9115 - val_accuracy: 0.5410\n",
      "Epoch 920/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9041 - accuracy: 0.5501 - val_loss: 0.9154 - val_accuracy: 0.5427\n",
      "Epoch 921/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9031 - accuracy: 0.5533 - val_loss: 0.9121 - val_accuracy: 0.5410\n",
      "Epoch 922/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9058 - accuracy: 0.5505 - val_loss: 0.9157 - val_accuracy: 0.5393\n",
      "Epoch 923/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9025 - accuracy: 0.5491 - val_loss: 0.9111 - val_accuracy: 0.5430\n",
      "Epoch 924/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9054 - accuracy: 0.5481 - val_loss: 0.9158 - val_accuracy: 0.5357\n",
      "Epoch 925/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9036 - accuracy: 0.5458 - val_loss: 0.9146 - val_accuracy: 0.5407\n",
      "Epoch 926/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9033 - accuracy: 0.5493 - val_loss: 0.9118 - val_accuracy: 0.5443\n",
      "Epoch 927/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9058 - accuracy: 0.5488 - val_loss: 0.9110 - val_accuracy: 0.5440\n",
      "Epoch 928/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9036 - accuracy: 0.5509 - val_loss: 0.9139 - val_accuracy: 0.5427\n",
      "Epoch 929/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9036 - accuracy: 0.5467 - val_loss: 0.9110 - val_accuracy: 0.5413\n",
      "Epoch 930/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9030 - accuracy: 0.5494 - val_loss: 0.9120 - val_accuracy: 0.5387\n",
      "Epoch 931/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9042 - accuracy: 0.5510 - val_loss: 0.9125 - val_accuracy: 0.5437\n",
      "Epoch 932/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9059 - accuracy: 0.5469 - val_loss: 0.9134 - val_accuracy: 0.5477\n",
      "Epoch 933/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9029 - accuracy: 0.5524 - val_loss: 0.9131 - val_accuracy: 0.5337\n",
      "Epoch 934/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9070 - accuracy: 0.5444 - val_loss: 0.9118 - val_accuracy: 0.5400\n",
      "Epoch 935/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9045 - accuracy: 0.5491 - val_loss: 0.9104 - val_accuracy: 0.5433\n",
      "Epoch 936/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9032 - accuracy: 0.5524 - val_loss: 0.9098 - val_accuracy: 0.5430\n",
      "Epoch 937/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9049 - accuracy: 0.5500 - val_loss: 0.9128 - val_accuracy: 0.5383\n",
      "Epoch 938/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9042 - accuracy: 0.5525 - val_loss: 0.9146 - val_accuracy: 0.5320\n",
      "Epoch 939/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9033 - accuracy: 0.5514 - val_loss: 0.9121 - val_accuracy: 0.5430\n",
      "Epoch 940/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9049 - accuracy: 0.5464 - val_loss: 0.9151 - val_accuracy: 0.5410\n",
      "Epoch 941/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9045 - accuracy: 0.5508 - val_loss: 0.9103 - val_accuracy: 0.5417\n",
      "Epoch 942/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9066 - accuracy: 0.5466 - val_loss: 0.9142 - val_accuracy: 0.5363\n",
      "Epoch 943/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9066 - accuracy: 0.5471 - val_loss: 0.9112 - val_accuracy: 0.5487\n",
      "Epoch 944/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9031 - accuracy: 0.5475 - val_loss: 0.9087 - val_accuracy: 0.5487\n",
      "Epoch 945/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9033 - accuracy: 0.5489 - val_loss: 0.9124 - val_accuracy: 0.5457\n",
      "Epoch 946/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9045 - accuracy: 0.5506 - val_loss: 0.9123 - val_accuracy: 0.5367\n",
      "Epoch 947/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9052 - accuracy: 0.5466 - val_loss: 0.9103 - val_accuracy: 0.5493\n",
      "Epoch 948/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9039 - accuracy: 0.5496 - val_loss: 0.9117 - val_accuracy: 0.5423\n",
      "Epoch 949/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9046 - accuracy: 0.5506 - val_loss: 0.9137 - val_accuracy: 0.5463\n",
      "Epoch 950/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9052 - accuracy: 0.5509 - val_loss: 0.9111 - val_accuracy: 0.5473\n",
      "Epoch 951/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9029 - accuracy: 0.5481 - val_loss: 0.9089 - val_accuracy: 0.5467\n",
      "Epoch 952/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9030 - accuracy: 0.5493 - val_loss: 0.9088 - val_accuracy: 0.5450\n",
      "Epoch 953/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9040 - accuracy: 0.5516 - val_loss: 0.9117 - val_accuracy: 0.5490\n",
      "Epoch 954/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9051 - accuracy: 0.5466 - val_loss: 0.9112 - val_accuracy: 0.5480\n",
      "Epoch 955/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9073 - accuracy: 0.5484 - val_loss: 0.9129 - val_accuracy: 0.5413\n",
      "Epoch 956/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9048 - accuracy: 0.5469 - val_loss: 0.9093 - val_accuracy: 0.5503\n",
      "Epoch 957/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9038 - accuracy: 0.5525 - val_loss: 0.9129 - val_accuracy: 0.5417\n",
      "Epoch 958/1800\n",
      "14000/14000 [==============================] - 2s 137us/step - loss: 0.9056 - accuracy: 0.5479 - val_loss: 0.9131 - val_accuracy: 0.5393\n",
      "Epoch 959/1800\n",
      "14000/14000 [==============================] - 2s 128us/step - loss: 0.9013 - accuracy: 0.5556 - val_loss: 0.9099 - val_accuracy: 0.5450\n",
      "Epoch 960/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9063 - accuracy: 0.5460 - val_loss: 0.9139 - val_accuracy: 0.5333\n",
      "Epoch 961/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9018 - accuracy: 0.5533 - val_loss: 0.9120 - val_accuracy: 0.5447\n",
      "Epoch 962/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9048 - accuracy: 0.5496 - val_loss: 0.9124 - val_accuracy: 0.5403\n",
      "Epoch 963/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9063 - accuracy: 0.5485 - val_loss: 0.9102 - val_accuracy: 0.5430\n",
      "Epoch 964/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9040 - accuracy: 0.5494 - val_loss: 0.9138 - val_accuracy: 0.5440\n",
      "Epoch 965/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9052 - accuracy: 0.5467 - val_loss: 0.9144 - val_accuracy: 0.5423\n",
      "Epoch 966/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9037 - accuracy: 0.5499 - val_loss: 0.9141 - val_accuracy: 0.5420\n",
      "Epoch 967/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9038 - accuracy: 0.5502 - val_loss: 0.9106 - val_accuracy: 0.5407\n",
      "Epoch 968/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9034 - accuracy: 0.5480 - val_loss: 0.9096 - val_accuracy: 0.5517\n",
      "Epoch 969/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9041 - accuracy: 0.5506 - val_loss: 0.9144 - val_accuracy: 0.5410\n",
      "Epoch 970/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9049 - accuracy: 0.5496 - val_loss: 0.9103 - val_accuracy: 0.5480\n",
      "Epoch 971/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9037 - accuracy: 0.5500 - val_loss: 0.9139 - val_accuracy: 0.5417\n",
      "Epoch 972/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9047 - accuracy: 0.5481 - val_loss: 0.9130 - val_accuracy: 0.5393\n",
      "Epoch 973/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9055 - accuracy: 0.5433 - val_loss: 0.9105 - val_accuracy: 0.5437\n",
      "Epoch 974/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9052 - accuracy: 0.5490 - val_loss: 0.9111 - val_accuracy: 0.5440\n",
      "Epoch 975/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9047 - accuracy: 0.5475 - val_loss: 0.9104 - val_accuracy: 0.5427\n",
      "Epoch 976/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9046 - accuracy: 0.5507 - val_loss: 0.9106 - val_accuracy: 0.5427\n",
      "Epoch 977/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9057 - accuracy: 0.5499 - val_loss: 0.9138 - val_accuracy: 0.5367\n",
      "Epoch 978/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9048 - accuracy: 0.5514 - val_loss: 0.9119 - val_accuracy: 0.5427\n",
      "Epoch 979/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9061 - accuracy: 0.5494 - val_loss: 0.9116 - val_accuracy: 0.5427\n",
      "Epoch 980/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9050 - accuracy: 0.5539 - val_loss: 0.9155 - val_accuracy: 0.5450\n",
      "Epoch 981/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9034 - accuracy: 0.5496 - val_loss: 0.9109 - val_accuracy: 0.5450\n",
      "Epoch 982/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9036 - accuracy: 0.5501 - val_loss: 0.9113 - val_accuracy: 0.5437\n",
      "Epoch 983/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9055 - accuracy: 0.5498 - val_loss: 0.9109 - val_accuracy: 0.5390\n",
      "Epoch 984/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9050 - accuracy: 0.5472 - val_loss: 0.9092 - val_accuracy: 0.5413\n",
      "Epoch 985/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9052 - accuracy: 0.5474 - val_loss: 0.9144 - val_accuracy: 0.5333\n",
      "Epoch 986/1800\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.54 - 1s 85us/step - loss: 0.9043 - accuracy: 0.5491 - val_loss: 0.9144 - val_accuracy: 0.5437\n",
      "Epoch 987/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9033 - accuracy: 0.5459 - val_loss: 0.9141 - val_accuracy: 0.5373\n",
      "Epoch 988/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9040 - accuracy: 0.5469 - val_loss: 0.9131 - val_accuracy: 0.5440\n",
      "Epoch 989/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9067 - accuracy: 0.5492 - val_loss: 0.9141 - val_accuracy: 0.5410\n",
      "Epoch 990/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9060 - accuracy: 0.5460 - val_loss: 0.9130 - val_accuracy: 0.5440\n",
      "Epoch 991/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9053 - accuracy: 0.5511 - val_loss: 0.9123 - val_accuracy: 0.5393\n",
      "Epoch 992/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9074 - accuracy: 0.5468 - val_loss: 0.9110 - val_accuracy: 0.5477\n",
      "Epoch 993/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9028 - accuracy: 0.5483 - val_loss: 0.9128 - val_accuracy: 0.5343\n",
      "Epoch 994/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9047 - accuracy: 0.5489 - val_loss: 0.9146 - val_accuracy: 0.5410\n",
      "Epoch 995/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9043 - accuracy: 0.5497 - val_loss: 0.9125 - val_accuracy: 0.5430\n",
      "Epoch 996/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9048 - accuracy: 0.5444 - val_loss: 0.9144 - val_accuracy: 0.5393\n",
      "Epoch 997/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9045 - accuracy: 0.5466 - val_loss: 0.9123 - val_accuracy: 0.5477\n",
      "Epoch 998/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9050 - accuracy: 0.5503 - val_loss: 0.9158 - val_accuracy: 0.5423\n",
      "Epoch 999/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9035 - accuracy: 0.5517 - val_loss: 0.9147 - val_accuracy: 0.5370\n",
      "Epoch 1000/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9044 - accuracy: 0.5509 - val_loss: 0.9097 - val_accuracy: 0.5497\n",
      "Epoch 1001/1800\n",
      "14000/14000 [==============================] - 1s 106us/step - loss: 0.9035 - accuracy: 0.5501 - val_loss: 0.9109 - val_accuracy: 0.5450\n",
      "Epoch 1002/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9051 - accuracy: 0.5497 - val_loss: 0.9109 - val_accuracy: 0.5413\n",
      "Epoch 1003/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9044 - accuracy: 0.5450 - val_loss: 0.9100 - val_accuracy: 0.5413\n",
      "Epoch 1004/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9033 - accuracy: 0.5510 - val_loss: 0.9114 - val_accuracy: 0.5437\n",
      "Epoch 1005/1800\n",
      "14000/14000 [==============================] - 1s 107us/step - loss: 0.9052 - accuracy: 0.5517 - val_loss: 0.9129 - val_accuracy: 0.5363\n",
      "Epoch 1006/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9058 - accuracy: 0.5524 - val_loss: 0.9111 - val_accuracy: 0.5440\n",
      "Epoch 1007/1800\n",
      "14000/14000 [==============================] - 1s 105us/step - loss: 0.9061 - accuracy: 0.5487 - val_loss: 0.9171 - val_accuracy: 0.5480\n",
      "Epoch 1008/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9066 - accuracy: 0.5499 - val_loss: 0.9144 - val_accuracy: 0.5400\n",
      "Epoch 1009/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9024 - accuracy: 0.5467 - val_loss: 0.9118 - val_accuracy: 0.5517\n",
      "Epoch 1010/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9034 - accuracy: 0.5479 - val_loss: 0.9109 - val_accuracy: 0.5417\n",
      "Epoch 1011/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9065 - accuracy: 0.5446 - val_loss: 0.9115 - val_accuracy: 0.5420\n",
      "Epoch 1012/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9038 - accuracy: 0.5539 - val_loss: 0.9102 - val_accuracy: 0.5500\n",
      "Epoch 1013/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9048 - accuracy: 0.5494 - val_loss: 0.9101 - val_accuracy: 0.5487\n",
      "Epoch 1014/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9040 - accuracy: 0.5518 - val_loss: 0.9136 - val_accuracy: 0.5460\n",
      "Epoch 1015/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9058 - accuracy: 0.5447 - val_loss: 0.9126 - val_accuracy: 0.5467\n",
      "Epoch 1016/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9051 - accuracy: 0.5502 - val_loss: 0.9118 - val_accuracy: 0.5420\n",
      "Epoch 1017/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9044 - accuracy: 0.5481 - val_loss: 0.9142 - val_accuracy: 0.5373\n",
      "Epoch 1018/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9028 - accuracy: 0.5483 - val_loss: 0.9125 - val_accuracy: 0.5373\n",
      "Epoch 1019/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9053 - accuracy: 0.5504 - val_loss: 0.9112 - val_accuracy: 0.5427\n",
      "Epoch 1020/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9049 - accuracy: 0.5482 - val_loss: 0.9154 - val_accuracy: 0.5413\n",
      "Epoch 1021/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9054 - accuracy: 0.5489 - val_loss: 0.9129 - val_accuracy: 0.5480\n",
      "Epoch 1022/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9053 - accuracy: 0.5491 - val_loss: 0.9145 - val_accuracy: 0.5437\n",
      "Epoch 1023/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9042 - accuracy: 0.5479 - val_loss: 0.9121 - val_accuracy: 0.5373\n",
      "Epoch 1024/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9012 - accuracy: 0.5509 - val_loss: 0.9100 - val_accuracy: 0.5500\n",
      "Epoch 1025/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9067 - accuracy: 0.5473 - val_loss: 0.9122 - val_accuracy: 0.5437\n",
      "Epoch 1026/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9044 - accuracy: 0.5463 - val_loss: 0.9173 - val_accuracy: 0.5437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9050 - accuracy: 0.5474 - val_loss: 0.9113 - val_accuracy: 0.5467\n",
      "Epoch 1028/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9048 - accuracy: 0.5499 - val_loss: 0.9128 - val_accuracy: 0.5433\n",
      "Epoch 1029/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9056 - accuracy: 0.5495 - val_loss: 0.9108 - val_accuracy: 0.5453\n",
      "Epoch 1030/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9038 - accuracy: 0.5499 - val_loss: 0.9113 - val_accuracy: 0.5483\n",
      "Epoch 1031/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9043 - accuracy: 0.5509 - val_loss: 0.9121 - val_accuracy: 0.5490\n",
      "Epoch 1032/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9023 - accuracy: 0.5510 - val_loss: 0.9114 - val_accuracy: 0.5473\n",
      "Epoch 1033/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9026 - accuracy: 0.5488 - val_loss: 0.9112 - val_accuracy: 0.5517\n",
      "Epoch 1034/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9052 - accuracy: 0.5454 - val_loss: 0.9134 - val_accuracy: 0.5463\n",
      "Epoch 1035/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9059 - accuracy: 0.5455 - val_loss: 0.9121 - val_accuracy: 0.5403\n",
      "Epoch 1036/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9031 - accuracy: 0.5470 - val_loss: 0.9127 - val_accuracy: 0.5440\n",
      "Epoch 1037/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9056 - accuracy: 0.5451 - val_loss: 0.9120 - val_accuracy: 0.5430\n",
      "Epoch 1038/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9057 - accuracy: 0.5471 - val_loss: 0.9123 - val_accuracy: 0.5403\n",
      "Epoch 1039/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9059 - accuracy: 0.5514 - val_loss: 0.9108 - val_accuracy: 0.5477\n",
      "Epoch 1040/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9040 - accuracy: 0.5476 - val_loss: 0.9171 - val_accuracy: 0.5387\n",
      "Epoch 1041/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9054 - accuracy: 0.5462 - val_loss: 0.9104 - val_accuracy: 0.5483\n",
      "Epoch 1042/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9053 - accuracy: 0.5489 - val_loss: 0.9113 - val_accuracy: 0.5423\n",
      "Epoch 1043/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9048 - accuracy: 0.5511 - val_loss: 0.9127 - val_accuracy: 0.5433\n",
      "Epoch 1044/1800\n",
      "14000/14000 [==============================] - 1s 103us/step - loss: 0.9055 - accuracy: 0.5481 - val_loss: 0.9116 - val_accuracy: 0.5407\n",
      "Epoch 1045/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9048 - accuracy: 0.5524 - val_loss: 0.9124 - val_accuracy: 0.5477\n",
      "Epoch 1046/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9050 - accuracy: 0.5455 - val_loss: 0.9111 - val_accuracy: 0.5410\n",
      "Epoch 1047/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9052 - accuracy: 0.5494 - val_loss: 0.9122 - val_accuracy: 0.5420\n",
      "Epoch 1048/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9050 - accuracy: 0.5471 - val_loss: 0.9112 - val_accuracy: 0.5430\n",
      "Epoch 1049/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9080 - accuracy: 0.5458 - val_loss: 0.9112 - val_accuracy: 0.5440\n",
      "Epoch 1050/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9037 - accuracy: 0.5520 - val_loss: 0.9101 - val_accuracy: 0.5467\n",
      "Epoch 1051/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9048 - accuracy: 0.5479 - val_loss: 0.9120 - val_accuracy: 0.5430\n",
      "Epoch 1052/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9027 - accuracy: 0.5531 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 1053/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9046 - accuracy: 0.5488 - val_loss: 0.9135 - val_accuracy: 0.5433\n",
      "Epoch 1054/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9039 - accuracy: 0.5501 - val_loss: 0.9144 - val_accuracy: 0.5343\n",
      "Epoch 1055/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9048 - accuracy: 0.5485 - val_loss: 0.9152 - val_accuracy: 0.5447\n",
      "Epoch 1056/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9061 - accuracy: 0.5468 - val_loss: 0.9129 - val_accuracy: 0.5430\n",
      "Epoch 1057/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9041 - accuracy: 0.5501 - val_loss: 0.9114 - val_accuracy: 0.5413\n",
      "Epoch 1058/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9046 - accuracy: 0.5494 - val_loss: 0.9093 - val_accuracy: 0.5457\n",
      "Epoch 1059/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9036 - accuracy: 0.5498 - val_loss: 0.9151 - val_accuracy: 0.5387\n",
      "Epoch 1060/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9048 - accuracy: 0.5495 - val_loss: 0.9090 - val_accuracy: 0.5457\n",
      "Epoch 1061/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9047 - accuracy: 0.5503 - val_loss: 0.9150 - val_accuracy: 0.5457\n",
      "Epoch 1062/1800\n",
      "14000/14000 [==============================] - 2s 176us/step - loss: 0.9069 - accuracy: 0.5507 - val_loss: 0.9132 - val_accuracy: 0.5397\n",
      "Epoch 1063/1800\n",
      "14000/14000 [==============================] - 2s 110us/step - loss: 0.9027 - accuracy: 0.5470 - val_loss: 0.9102 - val_accuracy: 0.5437\n",
      "Epoch 1064/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9039 - accuracy: 0.5499 - val_loss: 0.9093 - val_accuracy: 0.5470\n",
      "Epoch 1065/1800\n",
      "14000/14000 [==============================] - 2s 139us/step - loss: 0.9035 - accuracy: 0.5509 - val_loss: 0.9126 - val_accuracy: 0.5437\n",
      "Epoch 1066/1800\n",
      "14000/14000 [==============================] - 1s 107us/step - loss: 0.9017 - accuracy: 0.5490 - val_loss: 0.9100 - val_accuracy: 0.5433\n",
      "Epoch 1067/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9035 - accuracy: 0.5530 - val_loss: 0.9149 - val_accuracy: 0.5440\n",
      "Epoch 1068/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9038 - accuracy: 0.5514 - val_loss: 0.9143 - val_accuracy: 0.5357\n",
      "Epoch 1069/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9034 - accuracy: 0.5454 - val_loss: 0.9135 - val_accuracy: 0.5387\n",
      "Epoch 1070/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9059 - accuracy: 0.5464 - val_loss: 0.9136 - val_accuracy: 0.5453\n",
      "Epoch 1071/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9052 - accuracy: 0.5497 - val_loss: 0.9101 - val_accuracy: 0.5423\n",
      "Epoch 1072/1800\n",
      "14000/14000 [==============================] - 2s 112us/step - loss: 0.9047 - accuracy: 0.5492 - val_loss: 0.9184 - val_accuracy: 0.5407\n",
      "Epoch 1073/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9056 - accuracy: 0.5496 - val_loss: 0.9143 - val_accuracy: 0.5353\n",
      "Epoch 1074/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9044 - accuracy: 0.5474 - val_loss: 0.9166 - val_accuracy: 0.5423\n",
      "Epoch 1075/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9052 - accuracy: 0.5461 - val_loss: 0.9095 - val_accuracy: 0.5480\n",
      "Epoch 1076/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9036 - accuracy: 0.5494 - val_loss: 0.9098 - val_accuracy: 0.5477\n",
      "Epoch 1077/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9067 - accuracy: 0.5458 - val_loss: 0.9140 - val_accuracy: 0.5407\n",
      "Epoch 1078/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9048 - accuracy: 0.5452 - val_loss: 0.9121 - val_accuracy: 0.5433\n",
      "Epoch 1079/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9049 - accuracy: 0.5467 - val_loss: 0.9111 - val_accuracy: 0.5383\n",
      "Epoch 1080/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9044 - accuracy: 0.5463 - val_loss: 0.9115 - val_accuracy: 0.5433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1081/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9051 - accuracy: 0.5517 - val_loss: 0.9137 - val_accuracy: 0.5370\n",
      "Epoch 1082/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9036 - accuracy: 0.5449 - val_loss: 0.9116 - val_accuracy: 0.5423\n",
      "Epoch 1083/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9047 - accuracy: 0.5500 - val_loss: 0.9153 - val_accuracy: 0.5450\n",
      "Epoch 1084/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9049 - accuracy: 0.5474 - val_loss: 0.9170 - val_accuracy: 0.5403\n",
      "Epoch 1085/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9057 - accuracy: 0.5496 - val_loss: 0.9147 - val_accuracy: 0.5410\n",
      "Epoch 1086/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9066 - accuracy: 0.5478 - val_loss: 0.9132 - val_accuracy: 0.5467\n",
      "Epoch 1087/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9028 - accuracy: 0.5518 - val_loss: 0.9125 - val_accuracy: 0.5430\n",
      "Epoch 1088/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9035 - accuracy: 0.5499 - val_loss: 0.9119 - val_accuracy: 0.5427\n",
      "Epoch 1089/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9052 - accuracy: 0.5474 - val_loss: 0.9133 - val_accuracy: 0.5403\n",
      "Epoch 1090/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9041 - accuracy: 0.5483 - val_loss: 0.9127 - val_accuracy: 0.5430\n",
      "Epoch 1091/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9053 - accuracy: 0.5499 - val_loss: 0.9120 - val_accuracy: 0.5373\n",
      "Epoch 1092/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9057 - accuracy: 0.5496 - val_loss: 0.9149 - val_accuracy: 0.5393\n",
      "Epoch 1093/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9057 - accuracy: 0.5481 - val_loss: 0.9116 - val_accuracy: 0.5363\n",
      "Epoch 1094/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9045 - accuracy: 0.5514 - val_loss: 0.9128 - val_accuracy: 0.5407\n",
      "Epoch 1095/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9040 - accuracy: 0.5515 - val_loss: 0.9105 - val_accuracy: 0.5437\n",
      "Epoch 1096/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9061 - accuracy: 0.5484 - val_loss: 0.9109 - val_accuracy: 0.5393\n",
      "Epoch 1097/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9058 - accuracy: 0.5469 - val_loss: 0.9116 - val_accuracy: 0.5400\n",
      "Epoch 1098/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9036 - accuracy: 0.5495 - val_loss: 0.9105 - val_accuracy: 0.5400\n",
      "Epoch 1099/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9053 - accuracy: 0.5475 - val_loss: 0.9135 - val_accuracy: 0.5417\n",
      "Epoch 1100/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9053 - accuracy: 0.5461 - val_loss: 0.9131 - val_accuracy: 0.5443\n",
      "Epoch 1101/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9042 - accuracy: 0.5514 - val_loss: 0.9111 - val_accuracy: 0.5393\n",
      "Epoch 1102/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9056 - accuracy: 0.5453 - val_loss: 0.9155 - val_accuracy: 0.5413\n",
      "Epoch 1103/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9050 - accuracy: 0.5455 - val_loss: 0.9116 - val_accuracy: 0.5460\n",
      "Epoch 1104/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9055 - accuracy: 0.5451 - val_loss: 0.9108 - val_accuracy: 0.5503\n",
      "Epoch 1105/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9049 - accuracy: 0.5464 - val_loss: 0.9112 - val_accuracy: 0.5480\n",
      "Epoch 1106/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9051 - accuracy: 0.5479 - val_loss: 0.9161 - val_accuracy: 0.5430\n",
      "Epoch 1107/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9044 - accuracy: 0.5496 - val_loss: 0.9142 - val_accuracy: 0.5380\n",
      "Epoch 1108/1800\n",
      "14000/14000 [==============================] - 2s 114us/step - loss: 0.9066 - accuracy: 0.5447 - val_loss: 0.9119 - val_accuracy: 0.5377\n",
      "Epoch 1109/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9046 - accuracy: 0.5519 - val_loss: 0.9162 - val_accuracy: 0.5417\n",
      "Epoch 1110/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9054 - accuracy: 0.5436 - val_loss: 0.9121 - val_accuracy: 0.5410\n",
      "Epoch 1111/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9027 - accuracy: 0.5521 - val_loss: 0.9122 - val_accuracy: 0.5367\n",
      "Epoch 1112/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9035 - accuracy: 0.5509 - val_loss: 0.9118 - val_accuracy: 0.5420\n",
      "Epoch 1113/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9044 - accuracy: 0.5511 - val_loss: 0.9099 - val_accuracy: 0.5440\n",
      "Epoch 1114/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9048 - accuracy: 0.5466 - val_loss: 0.9126 - val_accuracy: 0.5413\n",
      "Epoch 1115/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9037 - accuracy: 0.5494 - val_loss: 0.9156 - val_accuracy: 0.5463\n",
      "Epoch 1116/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9042 - accuracy: 0.5498 - val_loss: 0.9132 - val_accuracy: 0.5407\n",
      "Epoch 1117/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9062 - accuracy: 0.5464 - val_loss: 0.9133 - val_accuracy: 0.5427\n",
      "Epoch 1118/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9048 - accuracy: 0.5484 - val_loss: 0.9115 - val_accuracy: 0.5447\n",
      "Epoch 1119/1800\n",
      "14000/14000 [==============================] - 1s 103us/step - loss: 0.9052 - accuracy: 0.5485 - val_loss: 0.9112 - val_accuracy: 0.5427\n",
      "Epoch 1120/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9038 - accuracy: 0.5492 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 1121/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9053 - accuracy: 0.5469 - val_loss: 0.9110 - val_accuracy: 0.5417\n",
      "Epoch 1122/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9059 - accuracy: 0.5493 - val_loss: 0.9123 - val_accuracy: 0.5407\n",
      "Epoch 1123/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9055 - accuracy: 0.5475 - val_loss: 0.9127 - val_accuracy: 0.5467\n",
      "Epoch 1124/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9041 - accuracy: 0.5499 - val_loss: 0.9108 - val_accuracy: 0.5457\n",
      "Epoch 1125/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9050 - accuracy: 0.5481 - val_loss: 0.9131 - val_accuracy: 0.5467\n",
      "Epoch 1126/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9050 - accuracy: 0.5489 - val_loss: 0.9116 - val_accuracy: 0.5473\n",
      "Epoch 1127/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9028 - accuracy: 0.5515 - val_loss: 0.9110 - val_accuracy: 0.5457\n",
      "Epoch 1128/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9038 - accuracy: 0.5479 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 1129/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9051 - accuracy: 0.5501 - val_loss: 0.9110 - val_accuracy: 0.5470\n",
      "Epoch 1130/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9057 - accuracy: 0.5472 - val_loss: 0.9126 - val_accuracy: 0.5420\n",
      "Epoch 1131/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9055 - accuracy: 0.5448 - val_loss: 0.9111 - val_accuracy: 0.5413\n",
      "Epoch 1132/1800\n",
      "14000/14000 [==============================] - 1s 102us/step - loss: 0.9037 - accuracy: 0.5459 - val_loss: 0.9156 - val_accuracy: 0.5413\n",
      "Epoch 1133/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9056 - accuracy: 0.5491 - val_loss: 0.9140 - val_accuracy: 0.5380\n",
      "Epoch 1134/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9046 - accuracy: 0.5491 - val_loss: 0.9127 - val_accuracy: 0.5460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1135/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9046 - accuracy: 0.5481 - val_loss: 0.9105 - val_accuracy: 0.5463\n",
      "Epoch 1136/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9050 - accuracy: 0.5480 - val_loss: 0.9112 - val_accuracy: 0.5413\n",
      "Epoch 1137/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9048 - accuracy: 0.5487 - val_loss: 0.9104 - val_accuracy: 0.5453\n",
      "Epoch 1138/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9039 - accuracy: 0.5536 - val_loss: 0.9101 - val_accuracy: 0.5493\n",
      "Epoch 1139/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9061 - accuracy: 0.5491 - val_loss: 0.9123 - val_accuracy: 0.5457\n",
      "Epoch 1140/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9037 - accuracy: 0.5491 - val_loss: 0.9098 - val_accuracy: 0.5407\n",
      "Epoch 1141/1800\n",
      "14000/14000 [==============================] - 1s 102us/step - loss: 0.9034 - accuracy: 0.5499 - val_loss: 0.9116 - val_accuracy: 0.5457\n",
      "Epoch 1142/1800\n",
      "14000/14000 [==============================] - 1s 105us/step - loss: 0.9031 - accuracy: 0.5476 - val_loss: 0.9106 - val_accuracy: 0.5427\n",
      "Epoch 1143/1800\n",
      "14000/14000 [==============================] - 1s 105us/step - loss: 0.9042 - accuracy: 0.5477 - val_loss: 0.9121 - val_accuracy: 0.5483\n",
      "Epoch 1144/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9039 - accuracy: 0.5483 - val_loss: 0.9139 - val_accuracy: 0.5450\n",
      "Epoch 1145/1800\n",
      "14000/14000 [==============================] - 1s 107us/step - loss: 0.9062 - accuracy: 0.5465 - val_loss: 0.9129 - val_accuracy: 0.5347\n",
      "Epoch 1146/1800\n",
      "14000/14000 [==============================] - 2s 109us/step - loss: 0.9038 - accuracy: 0.5473 - val_loss: 0.9112 - val_accuracy: 0.5400\n",
      "Epoch 1147/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9045 - accuracy: 0.5516 - val_loss: 0.9122 - val_accuracy: 0.5483\n",
      "Epoch 1148/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9060 - accuracy: 0.5491 - val_loss: 0.9141 - val_accuracy: 0.5450\n",
      "Epoch 1149/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9033 - accuracy: 0.5477 - val_loss: 0.9140 - val_accuracy: 0.5400\n",
      "Epoch 1150/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9036 - accuracy: 0.5500 - val_loss: 0.9136 - val_accuracy: 0.5450\n",
      "Epoch 1151/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9064 - accuracy: 0.5493 - val_loss: 0.9154 - val_accuracy: 0.5467\n",
      "Epoch 1152/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9057 - accuracy: 0.5514 - val_loss: 0.9132 - val_accuracy: 0.5417\n",
      "Epoch 1153/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9060 - accuracy: 0.5482 - val_loss: 0.9120 - val_accuracy: 0.5450\n",
      "Epoch 1154/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9056 - accuracy: 0.5505 - val_loss: 0.9125 - val_accuracy: 0.5357\n",
      "Epoch 1155/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9035 - accuracy: 0.5467 - val_loss: 0.9113 - val_accuracy: 0.5460\n",
      "Epoch 1156/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9050 - accuracy: 0.5509 - val_loss: 0.9129 - val_accuracy: 0.5347\n",
      "Epoch 1157/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9057 - accuracy: 0.5455 - val_loss: 0.9143 - val_accuracy: 0.5460\n",
      "Epoch 1158/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9068 - accuracy: 0.5493 - val_loss: 0.9128 - val_accuracy: 0.5403\n",
      "Epoch 1159/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9051 - accuracy: 0.5491 - val_loss: 0.9110 - val_accuracy: 0.5430\n",
      "Epoch 1160/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9047 - accuracy: 0.5471 - val_loss: 0.9144 - val_accuracy: 0.5453\n",
      "Epoch 1161/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9036 - accuracy: 0.5502 - val_loss: 0.9124 - val_accuracy: 0.5467\n",
      "Epoch 1162/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9049 - accuracy: 0.5480 - val_loss: 0.9156 - val_accuracy: 0.5457\n",
      "Epoch 1163/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9048 - accuracy: 0.5495 - val_loss: 0.9125 - val_accuracy: 0.5433\n",
      "Epoch 1164/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9050 - accuracy: 0.5508 - val_loss: 0.9129 - val_accuracy: 0.5407\n",
      "Epoch 1165/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9051 - accuracy: 0.5428 - val_loss: 0.9166 - val_accuracy: 0.5423\n",
      "Epoch 1166/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9040 - accuracy: 0.5494 - val_loss: 0.9102 - val_accuracy: 0.5487\n",
      "Epoch 1167/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9022 - accuracy: 0.5504 - val_loss: 0.9128 - val_accuracy: 0.5423\n",
      "Epoch 1168/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9071 - accuracy: 0.5472 - val_loss: 0.9114 - val_accuracy: 0.5457\n",
      "Epoch 1169/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9043 - accuracy: 0.5468 - val_loss: 0.9149 - val_accuracy: 0.5427\n",
      "Epoch 1170/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9039 - accuracy: 0.5492 - val_loss: 0.9170 - val_accuracy: 0.5393\n",
      "Epoch 1171/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9067 - accuracy: 0.5496 - val_loss: 0.9139 - val_accuracy: 0.5430\n",
      "Epoch 1172/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9040 - accuracy: 0.5538 - val_loss: 0.9158 - val_accuracy: 0.5387\n",
      "Epoch 1173/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9046 - accuracy: 0.5474 - val_loss: 0.9114 - val_accuracy: 0.5430\n",
      "Epoch 1174/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9042 - accuracy: 0.5500 - val_loss: 0.9125 - val_accuracy: 0.5443\n",
      "Epoch 1175/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9037 - accuracy: 0.5478 - val_loss: 0.9106 - val_accuracy: 0.5507\n",
      "Epoch 1176/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9052 - accuracy: 0.5461 - val_loss: 0.9149 - val_accuracy: 0.5387\n",
      "Epoch 1177/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9049 - accuracy: 0.5519 - val_loss: 0.9119 - val_accuracy: 0.5407\n",
      "Epoch 1178/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9062 - accuracy: 0.5529 - val_loss: 0.9093 - val_accuracy: 0.5463\n",
      "Epoch 1179/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9044 - accuracy: 0.5476 - val_loss: 0.9159 - val_accuracy: 0.5407\n",
      "Epoch 1180/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9056 - accuracy: 0.5476 - val_loss: 0.9099 - val_accuracy: 0.5397\n",
      "Epoch 1181/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9037 - accuracy: 0.5516 - val_loss: 0.9125 - val_accuracy: 0.5443\n",
      "Epoch 1182/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9069 - accuracy: 0.5463 - val_loss: 0.9088 - val_accuracy: 0.5463\n",
      "Epoch 1183/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9026 - accuracy: 0.5498 - val_loss: 0.9147 - val_accuracy: 0.5403\n",
      "Epoch 1184/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9028 - accuracy: 0.5485 - val_loss: 0.9137 - val_accuracy: 0.5450\n",
      "Epoch 1185/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9056 - accuracy: 0.5491 - val_loss: 0.9110 - val_accuracy: 0.5410\n",
      "Epoch 1186/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9034 - accuracy: 0.5502 - val_loss: 0.9162 - val_accuracy: 0.5407\n",
      "Epoch 1187/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9056 - accuracy: 0.5481 - val_loss: 0.9150 - val_accuracy: 0.5387\n",
      "Epoch 1188/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9060 - accuracy: 0.5440 - val_loss: 0.9127 - val_accuracy: 0.5483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1189/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9033 - accuracy: 0.5514 - val_loss: 0.9138 - val_accuracy: 0.5433\n",
      "Epoch 1190/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9050 - accuracy: 0.5466 - val_loss: 0.9102 - val_accuracy: 0.5443\n",
      "Epoch 1191/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9066 - accuracy: 0.5502 - val_loss: 0.9141 - val_accuracy: 0.5437\n",
      "Epoch 1192/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9054 - accuracy: 0.5519 - val_loss: 0.9135 - val_accuracy: 0.5397\n",
      "Epoch 1193/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9052 - accuracy: 0.5491 - val_loss: 0.9101 - val_accuracy: 0.5483\n",
      "Epoch 1194/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9030 - accuracy: 0.5516 - val_loss: 0.9145 - val_accuracy: 0.5420\n",
      "Epoch 1195/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9046 - accuracy: 0.5486 - val_loss: 0.9115 - val_accuracy: 0.5407\n",
      "Epoch 1196/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9048 - accuracy: 0.5491 - val_loss: 0.9163 - val_accuracy: 0.5360\n",
      "Epoch 1197/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9038 - accuracy: 0.5534 - val_loss: 0.9114 - val_accuracy: 0.5443\n",
      "Epoch 1198/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9035 - accuracy: 0.5485 - val_loss: 0.9133 - val_accuracy: 0.5453\n",
      "Epoch 1199/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9047 - accuracy: 0.5534 - val_loss: 0.9105 - val_accuracy: 0.5467\n",
      "Epoch 1200/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9060 - accuracy: 0.5496 - val_loss: 0.9115 - val_accuracy: 0.5493\n",
      "Epoch 1201/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9062 - accuracy: 0.5451 - val_loss: 0.9147 - val_accuracy: 0.5357\n",
      "Epoch 1202/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9050 - accuracy: 0.5471 - val_loss: 0.9117 - val_accuracy: 0.5413\n",
      "Epoch 1203/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9050 - accuracy: 0.5521 - val_loss: 0.9133 - val_accuracy: 0.5397\n",
      "Epoch 1204/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9070 - accuracy: 0.5450 - val_loss: 0.9132 - val_accuracy: 0.5440\n",
      "Epoch 1205/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9056 - accuracy: 0.5484 - val_loss: 0.9151 - val_accuracy: 0.5430\n",
      "Epoch 1206/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9046 - accuracy: 0.5528 - val_loss: 0.9145 - val_accuracy: 0.5437\n",
      "Epoch 1207/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9040 - accuracy: 0.5467 - val_loss: 0.9120 - val_accuracy: 0.5433\n",
      "Epoch 1208/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9044 - accuracy: 0.5449 - val_loss: 0.9118 - val_accuracy: 0.5463\n",
      "Epoch 1209/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9036 - accuracy: 0.5487 - val_loss: 0.9147 - val_accuracy: 0.5443\n",
      "Epoch 1210/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9042 - accuracy: 0.5507 - val_loss: 0.9108 - val_accuracy: 0.5433\n",
      "Epoch 1211/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9050 - accuracy: 0.5479 - val_loss: 0.9129 - val_accuracy: 0.5457\n",
      "Epoch 1212/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9065 - accuracy: 0.5509 - val_loss: 0.9119 - val_accuracy: 0.5410\n",
      "Epoch 1213/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9063 - accuracy: 0.5514 - val_loss: 0.9140 - val_accuracy: 0.5393\n",
      "Epoch 1214/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9050 - accuracy: 0.5475 - val_loss: 0.9109 - val_accuracy: 0.5430\n",
      "Epoch 1215/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9056 - accuracy: 0.5488 - val_loss: 0.9124 - val_accuracy: 0.5417\n",
      "Epoch 1216/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9056 - accuracy: 0.5485 - val_loss: 0.9121 - val_accuracy: 0.5387\n",
      "Epoch 1217/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9060 - accuracy: 0.5461 - val_loss: 0.9117 - val_accuracy: 0.5437\n",
      "Epoch 1218/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9053 - accuracy: 0.5474 - val_loss: 0.9121 - val_accuracy: 0.5433\n",
      "Epoch 1219/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9045 - accuracy: 0.5503 - val_loss: 0.9109 - val_accuracy: 0.5393\n",
      "Epoch 1220/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9046 - accuracy: 0.5444 - val_loss: 0.9126 - val_accuracy: 0.5400\n",
      "Epoch 1221/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9038 - accuracy: 0.5485 - val_loss: 0.9148 - val_accuracy: 0.5410\n",
      "Epoch 1222/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9040 - accuracy: 0.5482 - val_loss: 0.9123 - val_accuracy: 0.5463\n",
      "Epoch 1223/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9034 - accuracy: 0.5560 - val_loss: 0.9130 - val_accuracy: 0.5390\n",
      "Epoch 1224/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9037 - accuracy: 0.5519 - val_loss: 0.9119 - val_accuracy: 0.5410\n",
      "Epoch 1225/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9058 - accuracy: 0.5493 - val_loss: 0.9149 - val_accuracy: 0.5390\n",
      "Epoch 1226/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9045 - accuracy: 0.5492 - val_loss: 0.9109 - val_accuracy: 0.5423\n",
      "Epoch 1227/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9057 - accuracy: 0.5460 - val_loss: 0.9162 - val_accuracy: 0.5407\n",
      "Epoch 1228/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9032 - accuracy: 0.5519 - val_loss: 0.9112 - val_accuracy: 0.5397\n",
      "Epoch 1229/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9061 - accuracy: 0.5501 - val_loss: 0.9140 - val_accuracy: 0.5390\n",
      "Epoch 1230/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9040 - accuracy: 0.5492 - val_loss: 0.9132 - val_accuracy: 0.5380\n",
      "Epoch 1231/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9060 - accuracy: 0.5458 - val_loss: 0.9135 - val_accuracy: 0.5360\n",
      "Epoch 1232/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9062 - accuracy: 0.5421 - val_loss: 0.9158 - val_accuracy: 0.5403\n",
      "Epoch 1233/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9050 - accuracy: 0.5489 - val_loss: 0.9144 - val_accuracy: 0.5383\n",
      "Epoch 1234/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9047 - accuracy: 0.5498 - val_loss: 0.9105 - val_accuracy: 0.5447\n",
      "Epoch 1235/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9061 - accuracy: 0.5500 - val_loss: 0.9119 - val_accuracy: 0.5400\n",
      "Epoch 1236/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9033 - accuracy: 0.5519 - val_loss: 0.9097 - val_accuracy: 0.5450\n",
      "Epoch 1237/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9054 - accuracy: 0.5518 - val_loss: 0.9184 - val_accuracy: 0.5323\n",
      "Epoch 1238/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9046 - accuracy: 0.5483 - val_loss: 0.9144 - val_accuracy: 0.5410\n",
      "Epoch 1239/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9055 - accuracy: 0.5494 - val_loss: 0.9147 - val_accuracy: 0.5447\n",
      "Epoch 1240/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9042 - accuracy: 0.5508 - val_loss: 0.9139 - val_accuracy: 0.5467\n",
      "Epoch 1241/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9054 - accuracy: 0.5491 - val_loss: 0.9138 - val_accuracy: 0.5403\n",
      "Epoch 1242/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9050 - accuracy: 0.5495 - val_loss: 0.9124 - val_accuracy: 0.5437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1243/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9046 - accuracy: 0.5493 - val_loss: 0.9129 - val_accuracy: 0.5467\n",
      "Epoch 1244/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9039 - accuracy: 0.5459 - val_loss: 0.9146 - val_accuracy: 0.5383\n",
      "Epoch 1245/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9051 - accuracy: 0.5501 - val_loss: 0.9158 - val_accuracy: 0.5420\n",
      "Epoch 1246/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9066 - accuracy: 0.5476 - val_loss: 0.9110 - val_accuracy: 0.5393\n",
      "Epoch 1247/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9026 - accuracy: 0.5519 - val_loss: 0.9095 - val_accuracy: 0.5460\n",
      "Epoch 1248/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9070 - accuracy: 0.5442 - val_loss: 0.9112 - val_accuracy: 0.5473\n",
      "Epoch 1249/1800\n",
      "14000/14000 [==============================] - 1s 106us/step - loss: 0.9058 - accuracy: 0.5496 - val_loss: 0.9131 - val_accuracy: 0.5393\n",
      "Epoch 1250/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9063 - accuracy: 0.5464 - val_loss: 0.9165 - val_accuracy: 0.5430\n",
      "Epoch 1251/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9052 - accuracy: 0.5461 - val_loss: 0.9143 - val_accuracy: 0.5380\n",
      "Epoch 1252/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9050 - accuracy: 0.5437 - val_loss: 0.9099 - val_accuracy: 0.5383\n",
      "Epoch 1253/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9052 - accuracy: 0.5516 - val_loss: 0.9124 - val_accuracy: 0.5443\n",
      "Epoch 1254/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9061 - accuracy: 0.5484 - val_loss: 0.9104 - val_accuracy: 0.5470\n",
      "Epoch 1255/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9040 - accuracy: 0.5509 - val_loss: 0.9149 - val_accuracy: 0.5393\n",
      "Epoch 1256/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9032 - accuracy: 0.5484 - val_loss: 0.9123 - val_accuracy: 0.5367\n",
      "Epoch 1257/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9046 - accuracy: 0.5448 - val_loss: 0.9138 - val_accuracy: 0.5387\n",
      "Epoch 1258/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9053 - accuracy: 0.5489 - val_loss: 0.9108 - val_accuracy: 0.5437\n",
      "Epoch 1259/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9067 - accuracy: 0.5482 - val_loss: 0.9167 - val_accuracy: 0.5363\n",
      "Epoch 1260/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9046 - accuracy: 0.5469 - val_loss: 0.9135 - val_accuracy: 0.5387\n",
      "Epoch 1261/1800\n",
      "14000/14000 [==============================] - 2s 110us/step - loss: 0.9057 - accuracy: 0.5470 - val_loss: 0.9130 - val_accuracy: 0.5380\n",
      "Epoch 1262/1800\n",
      "14000/14000 [==============================] - 2s 134us/step - loss: 0.9061 - accuracy: 0.5477 - val_loss: 0.9137 - val_accuracy: 0.5307\n",
      "Epoch 1263/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9062 - accuracy: 0.5500 - val_loss: 0.9140 - val_accuracy: 0.5450\n",
      "Epoch 1264/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9058 - accuracy: 0.5476 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 1265/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9046 - accuracy: 0.5508 - val_loss: 0.9147 - val_accuracy: 0.5423\n",
      "Epoch 1266/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9037 - accuracy: 0.5454 - val_loss: 0.9090 - val_accuracy: 0.5447\n",
      "Epoch 1267/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9052 - accuracy: 0.5452 - val_loss: 0.9108 - val_accuracy: 0.5430\n",
      "Epoch 1268/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9047 - accuracy: 0.5484 - val_loss: 0.9167 - val_accuracy: 0.5420\n",
      "Epoch 1269/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9039 - accuracy: 0.5494 - val_loss: 0.9139 - val_accuracy: 0.5420\n",
      "Epoch 1270/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9060 - accuracy: 0.5511 - val_loss: 0.9126 - val_accuracy: 0.5407\n",
      "Epoch 1271/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9051 - accuracy: 0.5523 - val_loss: 0.9118 - val_accuracy: 0.5430\n",
      "Epoch 1272/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9046 - accuracy: 0.5506 - val_loss: 0.9151 - val_accuracy: 0.5420\n",
      "Epoch 1273/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9043 - accuracy: 0.5496 - val_loss: 0.9124 - val_accuracy: 0.5407\n",
      "Epoch 1274/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9060 - accuracy: 0.5471 - val_loss: 0.9117 - val_accuracy: 0.5390\n",
      "Epoch 1275/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9025 - accuracy: 0.5509 - val_loss: 0.9112 - val_accuracy: 0.5467\n",
      "Epoch 1276/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9043 - accuracy: 0.5464 - val_loss: 0.9117 - val_accuracy: 0.5430\n",
      "Epoch 1277/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9039 - accuracy: 0.5511 - val_loss: 0.9114 - val_accuracy: 0.5393\n",
      "Epoch 1278/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9042 - accuracy: 0.5479 - val_loss: 0.9150 - val_accuracy: 0.5430\n",
      "Epoch 1279/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9044 - accuracy: 0.5512 - val_loss: 0.9132 - val_accuracy: 0.5410\n",
      "Epoch 1280/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9047 - accuracy: 0.5466 - val_loss: 0.9151 - val_accuracy: 0.5413\n",
      "Epoch 1281/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9064 - accuracy: 0.5476 - val_loss: 0.9134 - val_accuracy: 0.5417\n",
      "Epoch 1282/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9047 - accuracy: 0.5496 - val_loss: 0.9106 - val_accuracy: 0.5440\n",
      "Epoch 1283/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9057 - accuracy: 0.5487 - val_loss: 0.9105 - val_accuracy: 0.5423\n",
      "Epoch 1284/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9036 - accuracy: 0.5512 - val_loss: 0.9109 - val_accuracy: 0.5407\n",
      "Epoch 1285/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9057 - accuracy: 0.5524 - val_loss: 0.9133 - val_accuracy: 0.5430\n",
      "Epoch 1286/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9073 - accuracy: 0.5463 - val_loss: 0.9106 - val_accuracy: 0.5403\n",
      "Epoch 1287/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9058 - accuracy: 0.5469 - val_loss: 0.9119 - val_accuracy: 0.5440\n",
      "Epoch 1288/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9028 - accuracy: 0.5527 - val_loss: 0.9147 - val_accuracy: 0.5427\n",
      "Epoch 1289/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9051 - accuracy: 0.5494 - val_loss: 0.9143 - val_accuracy: 0.5430\n",
      "Epoch 1290/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9051 - accuracy: 0.5451 - val_loss: 0.9140 - val_accuracy: 0.5463\n",
      "Epoch 1291/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9039 - accuracy: 0.5481 - val_loss: 0.9116 - val_accuracy: 0.5443\n",
      "Epoch 1292/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9070 - accuracy: 0.5496 - val_loss: 0.9134 - val_accuracy: 0.5413\n",
      "Epoch 1293/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9059 - accuracy: 0.5525 - val_loss: 0.9165 - val_accuracy: 0.5380\n",
      "Epoch 1294/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9020 - accuracy: 0.5504 - val_loss: 0.9115 - val_accuracy: 0.5457\n",
      "Epoch 1295/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9055 - accuracy: 0.5489 - val_loss: 0.9111 - val_accuracy: 0.5433\n",
      "Epoch 1296/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9058 - accuracy: 0.5503 - val_loss: 0.9149 - val_accuracy: 0.5340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1297/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9021 - accuracy: 0.5506 - val_loss: 0.9111 - val_accuracy: 0.5407\n",
      "Epoch 1298/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9058 - accuracy: 0.5510 - val_loss: 0.9123 - val_accuracy: 0.5417\n",
      "Epoch 1299/1800\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.9058 - accuracy: 0.5463 - val_loss: 0.9112 - val_accuracy: 0.5423\n",
      "Epoch 1300/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9069 - accuracy: 0.5491 - val_loss: 0.9140 - val_accuracy: 0.5433\n",
      "Epoch 1301/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9051 - accuracy: 0.5484 - val_loss: 0.9165 - val_accuracy: 0.5437\n",
      "Epoch 1302/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9055 - accuracy: 0.5503 - val_loss: 0.9155 - val_accuracy: 0.5413\n",
      "Epoch 1303/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9048 - accuracy: 0.5498 - val_loss: 0.9133 - val_accuracy: 0.5383\n",
      "Epoch 1304/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9061 - accuracy: 0.5459 - val_loss: 0.9104 - val_accuracy: 0.5443\n",
      "Epoch 1305/1800\n",
      "14000/14000 [==============================] - 1s 80us/step - loss: 0.9059 - accuracy: 0.5508 - val_loss: 0.9152 - val_accuracy: 0.5330\n",
      "Epoch 1306/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9054 - accuracy: 0.5496 - val_loss: 0.9155 - val_accuracy: 0.5360\n",
      "Epoch 1307/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9042 - accuracy: 0.5495 - val_loss: 0.9119 - val_accuracy: 0.5417\n",
      "Epoch 1308/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9046 - accuracy: 0.5501 - val_loss: 0.9113 - val_accuracy: 0.5430\n",
      "Epoch 1309/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9067 - accuracy: 0.5472 - val_loss: 0.9109 - val_accuracy: 0.5450\n",
      "Epoch 1310/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9049 - accuracy: 0.5517 - val_loss: 0.9170 - val_accuracy: 0.5437\n",
      "Epoch 1311/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9059 - accuracy: 0.5458 - val_loss: 0.9108 - val_accuracy: 0.5520\n",
      "Epoch 1312/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9058 - accuracy: 0.5495 - val_loss: 0.9137 - val_accuracy: 0.5433\n",
      "Epoch 1313/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9053 - accuracy: 0.5481 - val_loss: 0.9112 - val_accuracy: 0.5403\n",
      "Epoch 1314/1800\n",
      "14000/14000 [==============================] - 1s 103us/step - loss: 0.9050 - accuracy: 0.5460 - val_loss: 0.9148 - val_accuracy: 0.5427\n",
      "Epoch 1315/1800\n",
      "14000/14000 [==============================] - 2s 124us/step - loss: 0.9064 - accuracy: 0.5454 - val_loss: 0.9204 - val_accuracy: 0.5363\n",
      "Epoch 1316/1800\n",
      "14000/14000 [==============================] - 2s 118us/step - loss: 0.9049 - accuracy: 0.5501 - val_loss: 0.9108 - val_accuracy: 0.5423\n",
      "Epoch 1317/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9037 - accuracy: 0.5501 - val_loss: 0.9152 - val_accuracy: 0.5377\n",
      "Epoch 1318/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9061 - accuracy: 0.5484 - val_loss: 0.9126 - val_accuracy: 0.5423\n",
      "Epoch 1319/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9072 - accuracy: 0.5436 - val_loss: 0.9095 - val_accuracy: 0.5423\n",
      "Epoch 1320/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9041 - accuracy: 0.5485 - val_loss: 0.9142 - val_accuracy: 0.5443\n",
      "Epoch 1321/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9067 - accuracy: 0.5487 - val_loss: 0.9167 - val_accuracy: 0.5420\n",
      "Epoch 1322/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9059 - accuracy: 0.5472 - val_loss: 0.9178 - val_accuracy: 0.5343\n",
      "Epoch 1323/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9068 - accuracy: 0.5447 - val_loss: 0.9124 - val_accuracy: 0.5390\n",
      "Epoch 1324/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9088 - accuracy: 0.5480 - val_loss: 0.9143 - val_accuracy: 0.5357\n",
      "Epoch 1325/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9054 - accuracy: 0.5509 - val_loss: 0.9164 - val_accuracy: 0.5360\n",
      "Epoch 1326/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9059 - accuracy: 0.5478 - val_loss: 0.9181 - val_accuracy: 0.5393\n",
      "Epoch 1327/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9056 - accuracy: 0.5496 - val_loss: 0.9109 - val_accuracy: 0.5463\n",
      "Epoch 1328/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9062 - accuracy: 0.5482 - val_loss: 0.9162 - val_accuracy: 0.5430\n",
      "Epoch 1329/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9041 - accuracy: 0.5522 - val_loss: 0.9136 - val_accuracy: 0.5407\n",
      "Epoch 1330/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9063 - accuracy: 0.5474 - val_loss: 0.9129 - val_accuracy: 0.5440\n",
      "Epoch 1331/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9039 - accuracy: 0.5477 - val_loss: 0.9115 - val_accuracy: 0.5390\n",
      "Epoch 1332/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9082 - accuracy: 0.5437 - val_loss: 0.9170 - val_accuracy: 0.5393\n",
      "Epoch 1333/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9032 - accuracy: 0.5456 - val_loss: 0.9125 - val_accuracy: 0.5430\n",
      "Epoch 1334/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9047 - accuracy: 0.5524 - val_loss: 0.9164 - val_accuracy: 0.5437\n",
      "Epoch 1335/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9062 - accuracy: 0.5509 - val_loss: 0.9111 - val_accuracy: 0.5433\n",
      "Epoch 1336/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9054 - accuracy: 0.5483 - val_loss: 0.9146 - val_accuracy: 0.5427\n",
      "Epoch 1337/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9056 - accuracy: 0.5475 - val_loss: 0.9175 - val_accuracy: 0.5373\n",
      "Epoch 1338/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9063 - accuracy: 0.5493 - val_loss: 0.9152 - val_accuracy: 0.5390\n",
      "Epoch 1339/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9055 - accuracy: 0.5506 - val_loss: 0.9124 - val_accuracy: 0.5427\n",
      "Epoch 1340/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9071 - accuracy: 0.5482 - val_loss: 0.9124 - val_accuracy: 0.5417\n",
      "Epoch 1341/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9053 - accuracy: 0.5489 - val_loss: 0.9121 - val_accuracy: 0.5450\n",
      "Epoch 1342/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9039 - accuracy: 0.5494 - val_loss: 0.9130 - val_accuracy: 0.5407\n",
      "Epoch 1343/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9048 - accuracy: 0.5469 - val_loss: 0.9123 - val_accuracy: 0.5447\n",
      "Epoch 1344/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9064 - accuracy: 0.5481 - val_loss: 0.9167 - val_accuracy: 0.5370\n",
      "Epoch 1345/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9060 - accuracy: 0.5492 - val_loss: 0.9129 - val_accuracy: 0.5460\n",
      "Epoch 1346/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9047 - accuracy: 0.5474 - val_loss: 0.9150 - val_accuracy: 0.5440\n",
      "Epoch 1347/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9059 - accuracy: 0.5471 - val_loss: 0.9128 - val_accuracy: 0.5430\n",
      "Epoch 1348/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9057 - accuracy: 0.5504 - val_loss: 0.9141 - val_accuracy: 0.5393\n",
      "Epoch 1349/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9060 - accuracy: 0.5434 - val_loss: 0.9119 - val_accuracy: 0.5467\n",
      "Epoch 1350/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9047 - accuracy: 0.5471 - val_loss: 0.9144 - val_accuracy: 0.5443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1351/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9055 - accuracy: 0.5466 - val_loss: 0.9140 - val_accuracy: 0.5397\n",
      "Epoch 1352/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9072 - accuracy: 0.5489 - val_loss: 0.9155 - val_accuracy: 0.5347\n",
      "Epoch 1353/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9070 - accuracy: 0.5471 - val_loss: 0.9124 - val_accuracy: 0.5470\n",
      "Epoch 1354/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9037 - accuracy: 0.5528 - val_loss: 0.9130 - val_accuracy: 0.5410\n",
      "Epoch 1355/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9040 - accuracy: 0.5539 - val_loss: 0.9143 - val_accuracy: 0.5397\n",
      "Epoch 1356/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9056 - accuracy: 0.5459 - val_loss: 0.9131 - val_accuracy: 0.5420\n",
      "Epoch 1357/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9045 - accuracy: 0.5524 - val_loss: 0.9136 - val_accuracy: 0.5467\n",
      "Epoch 1358/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9051 - accuracy: 0.5504 - val_loss: 0.9135 - val_accuracy: 0.5393\n",
      "Epoch 1359/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9052 - accuracy: 0.5476 - val_loss: 0.9136 - val_accuracy: 0.5353\n",
      "Epoch 1360/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9045 - accuracy: 0.5503 - val_loss: 0.9172 - val_accuracy: 0.5430\n",
      "Epoch 1361/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9059 - accuracy: 0.5489 - val_loss: 0.9142 - val_accuracy: 0.5407\n",
      "Epoch 1362/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9033 - accuracy: 0.5528 - val_loss: 0.9145 - val_accuracy: 0.5433\n",
      "Epoch 1363/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9043 - accuracy: 0.5464 - val_loss: 0.9102 - val_accuracy: 0.5410\n",
      "Epoch 1364/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9029 - accuracy: 0.5525 - val_loss: 0.9150 - val_accuracy: 0.5347\n",
      "Epoch 1365/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9049 - accuracy: 0.5463 - val_loss: 0.9138 - val_accuracy: 0.5440\n",
      "Epoch 1366/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9054 - accuracy: 0.5519 - val_loss: 0.9102 - val_accuracy: 0.5440\n",
      "Epoch 1367/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9049 - accuracy: 0.5497 - val_loss: 0.9109 - val_accuracy: 0.5410\n",
      "Epoch 1368/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9074 - accuracy: 0.5488 - val_loss: 0.9153 - val_accuracy: 0.5377\n",
      "Epoch 1369/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9049 - accuracy: 0.5454 - val_loss: 0.9117 - val_accuracy: 0.5493\n",
      "Epoch 1370/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9064 - accuracy: 0.5463 - val_loss: 0.9137 - val_accuracy: 0.5393\n",
      "Epoch 1371/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9042 - accuracy: 0.5555 - val_loss: 0.9167 - val_accuracy: 0.5390\n",
      "Epoch 1372/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9043 - accuracy: 0.5478 - val_loss: 0.9142 - val_accuracy: 0.5360\n",
      "Epoch 1373/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9050 - accuracy: 0.5506 - val_loss: 0.9097 - val_accuracy: 0.5467\n",
      "Epoch 1374/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9040 - accuracy: 0.5509 - val_loss: 0.9172 - val_accuracy: 0.5403\n",
      "Epoch 1375/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9055 - accuracy: 0.5479 - val_loss: 0.9133 - val_accuracy: 0.5417\n",
      "Epoch 1376/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9045 - accuracy: 0.5486 - val_loss: 0.9167 - val_accuracy: 0.5380\n",
      "Epoch 1377/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9058 - accuracy: 0.5521 - val_loss: 0.9119 - val_accuracy: 0.5427\n",
      "Epoch 1378/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9065 - accuracy: 0.5513 - val_loss: 0.9173 - val_accuracy: 0.5367\n",
      "Epoch 1379/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9053 - accuracy: 0.5486 - val_loss: 0.9126 - val_accuracy: 0.5400\n",
      "Epoch 1380/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9048 - accuracy: 0.5499 - val_loss: 0.9207 - val_accuracy: 0.5353\n",
      "Epoch 1381/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9044 - accuracy: 0.5479 - val_loss: 0.9130 - val_accuracy: 0.5473\n",
      "Epoch 1382/1800\n",
      "14000/14000 [==============================] - ETA: 0s - loss: 0.9089 - accuracy: 0.54 - 1s 81us/step - loss: 0.9079 - accuracy: 0.5481 - val_loss: 0.9160 - val_accuracy: 0.5457\n",
      "Epoch 1383/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9059 - accuracy: 0.5464 - val_loss: 0.9127 - val_accuracy: 0.5433\n",
      "Epoch 1384/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9059 - accuracy: 0.5461 - val_loss: 0.9142 - val_accuracy: 0.5377\n",
      "Epoch 1385/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9035 - accuracy: 0.5490 - val_loss: 0.9116 - val_accuracy: 0.5450\n",
      "Epoch 1386/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9053 - accuracy: 0.5496 - val_loss: 0.9164 - val_accuracy: 0.5420\n",
      "Epoch 1387/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9046 - accuracy: 0.5484 - val_loss: 0.9120 - val_accuracy: 0.5370\n",
      "Epoch 1388/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9050 - accuracy: 0.5511 - val_loss: 0.9128 - val_accuracy: 0.5480\n",
      "Epoch 1389/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9064 - accuracy: 0.5459 - val_loss: 0.9097 - val_accuracy: 0.5460\n",
      "Epoch 1390/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9059 - accuracy: 0.5479 - val_loss: 0.9122 - val_accuracy: 0.5427\n",
      "Epoch 1391/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9055 - accuracy: 0.5447 - val_loss: 0.9154 - val_accuracy: 0.5407\n",
      "Epoch 1392/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9063 - accuracy: 0.5460 - val_loss: 0.9133 - val_accuracy: 0.5413\n",
      "Epoch 1393/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9065 - accuracy: 0.5455 - val_loss: 0.9151 - val_accuracy: 0.5337\n",
      "Epoch 1394/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9049 - accuracy: 0.5461 - val_loss: 0.9177 - val_accuracy: 0.5317\n",
      "Epoch 1395/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9074 - accuracy: 0.5467 - val_loss: 0.9178 - val_accuracy: 0.5397\n",
      "Epoch 1396/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9051 - accuracy: 0.5485 - val_loss: 0.9158 - val_accuracy: 0.5393\n",
      "Epoch 1397/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9050 - accuracy: 0.5456 - val_loss: 0.9123 - val_accuracy: 0.5413\n",
      "Epoch 1398/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9035 - accuracy: 0.5481 - val_loss: 0.9114 - val_accuracy: 0.5413\n",
      "Epoch 1399/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9036 - accuracy: 0.5496 - val_loss: 0.9156 - val_accuracy: 0.5407\n",
      "Epoch 1400/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9072 - accuracy: 0.5484 - val_loss: 0.9151 - val_accuracy: 0.5440\n",
      "Epoch 1401/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9046 - accuracy: 0.5471 - val_loss: 0.9134 - val_accuracy: 0.5383\n",
      "Epoch 1402/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9047 - accuracy: 0.5484 - val_loss: 0.9138 - val_accuracy: 0.5400\n",
      "Epoch 1403/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9067 - accuracy: 0.5480 - val_loss: 0.9129 - val_accuracy: 0.5400\n",
      "Epoch 1404/1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9039 - accuracy: 0.5511 - val_loss: 0.9117 - val_accuracy: 0.5373\n",
      "Epoch 1405/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9032 - accuracy: 0.5483 - val_loss: 0.9181 - val_accuracy: 0.5363\n",
      "Epoch 1406/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9068 - accuracy: 0.5482 - val_loss: 0.9118 - val_accuracy: 0.5397\n",
      "Epoch 1407/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9054 - accuracy: 0.5471 - val_loss: 0.9123 - val_accuracy: 0.5430\n",
      "Epoch 1408/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9041 - accuracy: 0.5479 - val_loss: 0.9185 - val_accuracy: 0.5350\n",
      "Epoch 1409/1800\n",
      "14000/14000 [==============================] - 2s 114us/step - loss: 0.9057 - accuracy: 0.5494 - val_loss: 0.9129 - val_accuracy: 0.5417\n",
      "Epoch 1410/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9065 - accuracy: 0.5454 - val_loss: 0.9144 - val_accuracy: 0.5430\n",
      "Epoch 1411/1800\n",
      "14000/14000 [==============================] - 1s 102us/step - loss: 0.9057 - accuracy: 0.5502 - val_loss: 0.9108 - val_accuracy: 0.5393\n",
      "Epoch 1412/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9052 - accuracy: 0.5490 - val_loss: 0.9147 - val_accuracy: 0.5330\n",
      "Epoch 1413/1800\n",
      "14000/14000 [==============================] - 1s 102us/step - loss: 0.9067 - accuracy: 0.5463 - val_loss: 0.9141 - val_accuracy: 0.5450\n",
      "Epoch 1414/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9076 - accuracy: 0.5469 - val_loss: 0.9130 - val_accuracy: 0.5430\n",
      "Epoch 1415/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9066 - accuracy: 0.5476 - val_loss: 0.9192 - val_accuracy: 0.5403\n",
      "Epoch 1416/1800\n",
      "14000/14000 [==============================] - 1s 105us/step - loss: 0.9056 - accuracy: 0.5467 - val_loss: 0.9182 - val_accuracy: 0.5417\n",
      "Epoch 1417/1800\n",
      "14000/14000 [==============================] - 2s 116us/step - loss: 0.9030 - accuracy: 0.5522 - val_loss: 0.9114 - val_accuracy: 0.5397\n",
      "Epoch 1418/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9049 - accuracy: 0.5524 - val_loss: 0.9106 - val_accuracy: 0.5420\n",
      "Epoch 1419/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9076 - accuracy: 0.5441 - val_loss: 0.9178 - val_accuracy: 0.5477\n",
      "Epoch 1420/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9048 - accuracy: 0.5456 - val_loss: 0.9126 - val_accuracy: 0.5413\n",
      "Epoch 1421/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9042 - accuracy: 0.5527 - val_loss: 0.9135 - val_accuracy: 0.5383\n",
      "Epoch 1422/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9063 - accuracy: 0.5449 - val_loss: 0.9139 - val_accuracy: 0.5403\n",
      "Epoch 1423/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9077 - accuracy: 0.5461 - val_loss: 0.9118 - val_accuracy: 0.5433\n",
      "Epoch 1424/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9058 - accuracy: 0.5507 - val_loss: 0.9125 - val_accuracy: 0.5470\n",
      "Epoch 1425/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9042 - accuracy: 0.5482 - val_loss: 0.9164 - val_accuracy: 0.5380\n",
      "Epoch 1426/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9043 - accuracy: 0.5458 - val_loss: 0.9118 - val_accuracy: 0.5380\n",
      "Epoch 1427/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9044 - accuracy: 0.5511 - val_loss: 0.9117 - val_accuracy: 0.5447\n",
      "Epoch 1428/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9051 - accuracy: 0.5472 - val_loss: 0.9129 - val_accuracy: 0.5440\n",
      "Epoch 1429/1800\n",
      "14000/14000 [==============================] - 2s 128us/step - loss: 0.9060 - accuracy: 0.5495 - val_loss: 0.9139 - val_accuracy: 0.5363\n",
      "Epoch 1430/1800\n",
      "14000/14000 [==============================] - 2s 111us/step - loss: 0.9048 - accuracy: 0.5499 - val_loss: 0.9137 - val_accuracy: 0.5400\n",
      "Epoch 1431/1800\n",
      "14000/14000 [==============================] - 3s 206us/step - loss: 0.9056 - accuracy: 0.5454 - val_loss: 0.9135 - val_accuracy: 0.5437\n",
      "Epoch 1432/1800\n",
      "14000/14000 [==============================] - 2s 155us/step - loss: 0.9056 - accuracy: 0.5507 - val_loss: 0.9146 - val_accuracy: 0.5470\n",
      "Epoch 1433/1800\n",
      "14000/14000 [==============================] - 2s 113us/step - loss: 0.9056 - accuracy: 0.5489 - val_loss: 0.9209 - val_accuracy: 0.5343\n",
      "Epoch 1434/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9055 - accuracy: 0.5497 - val_loss: 0.9149 - val_accuracy: 0.5397\n",
      "Epoch 1435/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9074 - accuracy: 0.5444 - val_loss: 0.9175 - val_accuracy: 0.5393\n",
      "Epoch 1436/1800\n",
      "14000/14000 [==============================] - 2s 107us/step - loss: 0.9053 - accuracy: 0.5484 - val_loss: 0.9166 - val_accuracy: 0.5390\n",
      "Epoch 1437/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9047 - accuracy: 0.5509 - val_loss: 0.9168 - val_accuracy: 0.5423\n",
      "Epoch 1438/1800\n",
      "14000/14000 [==============================] - 2s 111us/step - loss: 0.9044 - accuracy: 0.5527 - val_loss: 0.9180 - val_accuracy: 0.5407\n",
      "Epoch 1439/1800\n",
      "14000/14000 [==============================] - 1s 106us/step - loss: 0.9069 - accuracy: 0.5461 - val_loss: 0.9145 - val_accuracy: 0.5407\n",
      "Epoch 1440/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9061 - accuracy: 0.5506 - val_loss: 0.9171 - val_accuracy: 0.5437\n",
      "Epoch 1441/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9050 - accuracy: 0.5493 - val_loss: 0.9118 - val_accuracy: 0.5420\n",
      "Epoch 1442/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9053 - accuracy: 0.5498 - val_loss: 0.9137 - val_accuracy: 0.5410\n",
      "Epoch 1443/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9044 - accuracy: 0.5461 - val_loss: 0.9131 - val_accuracy: 0.5460\n",
      "Epoch 1444/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9051 - accuracy: 0.5461 - val_loss: 0.9144 - val_accuracy: 0.5403\n",
      "Epoch 1445/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9069 - accuracy: 0.5444 - val_loss: 0.9159 - val_accuracy: 0.5417\n",
      "Epoch 1446/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9066 - accuracy: 0.5502 - val_loss: 0.9163 - val_accuracy: 0.5297\n",
      "Epoch 1447/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9050 - accuracy: 0.5484 - val_loss: 0.9127 - val_accuracy: 0.5420\n",
      "Epoch 1448/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9069 - accuracy: 0.5461 - val_loss: 0.9122 - val_accuracy: 0.5430\n",
      "Epoch 1449/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9051 - accuracy: 0.5507 - val_loss: 0.9142 - val_accuracy: 0.5383\n",
      "Epoch 1450/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9053 - accuracy: 0.5503 - val_loss: 0.9163 - val_accuracy: 0.5343\n",
      "Epoch 1451/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9044 - accuracy: 0.5495 - val_loss: 0.9194 - val_accuracy: 0.5373\n",
      "Epoch 1452/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9057 - accuracy: 0.5471 - val_loss: 0.9129 - val_accuracy: 0.5463\n",
      "Epoch 1453/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9043 - accuracy: 0.5503 - val_loss: 0.9149 - val_accuracy: 0.5377\n",
      "Epoch 1454/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9033 - accuracy: 0.5478 - val_loss: 0.9137 - val_accuracy: 0.5447\n",
      "Epoch 1455/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9036 - accuracy: 0.5504 - val_loss: 0.9150 - val_accuracy: 0.5447\n",
      "Epoch 1456/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9059 - accuracy: 0.5461 - val_loss: 0.9185 - val_accuracy: 0.5373\n",
      "Epoch 1457/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9031 - accuracy: 0.5527 - val_loss: 0.9147 - val_accuracy: 0.5423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1458/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9062 - accuracy: 0.5437 - val_loss: 0.9117 - val_accuracy: 0.5400\n",
      "Epoch 1459/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9052 - accuracy: 0.5440 - val_loss: 0.9159 - val_accuracy: 0.5400\n",
      "Epoch 1460/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9051 - accuracy: 0.5479 - val_loss: 0.9125 - val_accuracy: 0.5447\n",
      "Epoch 1461/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9087 - accuracy: 0.5491 - val_loss: 0.9154 - val_accuracy: 0.5457\n",
      "Epoch 1462/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9048 - accuracy: 0.5516 - val_loss: 0.9151 - val_accuracy: 0.5390\n",
      "Epoch 1463/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9052 - accuracy: 0.5469 - val_loss: 0.9171 - val_accuracy: 0.5400\n",
      "Epoch 1464/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9063 - accuracy: 0.5501 - val_loss: 0.9124 - val_accuracy: 0.5407\n",
      "Epoch 1465/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9075 - accuracy: 0.5466 - val_loss: 0.9180 - val_accuracy: 0.5430\n",
      "Epoch 1466/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9060 - accuracy: 0.5464 - val_loss: 0.9127 - val_accuracy: 0.5423\n",
      "Epoch 1467/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9061 - accuracy: 0.5487 - val_loss: 0.9149 - val_accuracy: 0.5477\n",
      "Epoch 1468/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9037 - accuracy: 0.5489 - val_loss: 0.9123 - val_accuracy: 0.5447\n",
      "Epoch 1469/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9069 - accuracy: 0.5488 - val_loss: 0.9142 - val_accuracy: 0.5433\n",
      "Epoch 1470/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9074 - accuracy: 0.5442 - val_loss: 0.9136 - val_accuracy: 0.5483\n",
      "Epoch 1471/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9060 - accuracy: 0.5500 - val_loss: 0.9140 - val_accuracy: 0.5413\n",
      "Epoch 1472/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9071 - accuracy: 0.5483 - val_loss: 0.9127 - val_accuracy: 0.5423\n",
      "Epoch 1473/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9068 - accuracy: 0.5497 - val_loss: 0.9186 - val_accuracy: 0.5393\n",
      "Epoch 1474/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9053 - accuracy: 0.5468 - val_loss: 0.9154 - val_accuracy: 0.5420\n",
      "Epoch 1475/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9059 - accuracy: 0.5478 - val_loss: 0.9151 - val_accuracy: 0.5467\n",
      "Epoch 1476/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9052 - accuracy: 0.5452 - val_loss: 0.9118 - val_accuracy: 0.5453\n",
      "Epoch 1477/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9052 - accuracy: 0.5486 - val_loss: 0.9131 - val_accuracy: 0.5390\n",
      "Epoch 1478/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9051 - accuracy: 0.5476 - val_loss: 0.9108 - val_accuracy: 0.5377\n",
      "Epoch 1479/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9076 - accuracy: 0.5437 - val_loss: 0.9106 - val_accuracy: 0.5410\n",
      "Epoch 1480/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9063 - accuracy: 0.5476 - val_loss: 0.9135 - val_accuracy: 0.5410\n",
      "Epoch 1481/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9047 - accuracy: 0.5531 - val_loss: 0.9139 - val_accuracy: 0.5420\n",
      "Epoch 1482/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9060 - accuracy: 0.5494 - val_loss: 0.9125 - val_accuracy: 0.5483\n",
      "Epoch 1483/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9061 - accuracy: 0.5489 - val_loss: 0.9129 - val_accuracy: 0.5427\n",
      "Epoch 1484/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9055 - accuracy: 0.5478 - val_loss: 0.9160 - val_accuracy: 0.5403\n",
      "Epoch 1485/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9039 - accuracy: 0.5510 - val_loss: 0.9173 - val_accuracy: 0.5387\n",
      "Epoch 1486/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9054 - accuracy: 0.5444 - val_loss: 0.9113 - val_accuracy: 0.5443\n",
      "Epoch 1487/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9060 - accuracy: 0.5480 - val_loss: 0.9122 - val_accuracy: 0.5373\n",
      "Epoch 1488/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9052 - accuracy: 0.5484 - val_loss: 0.9116 - val_accuracy: 0.5423\n",
      "Epoch 1489/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9047 - accuracy: 0.5479 - val_loss: 0.9136 - val_accuracy: 0.5393\n",
      "Epoch 1490/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9060 - accuracy: 0.5504 - val_loss: 0.9176 - val_accuracy: 0.5357\n",
      "Epoch 1491/1800\n",
      "14000/14000 [==============================] - 2s 112us/step - loss: 0.9056 - accuracy: 0.5499 - val_loss: 0.9134 - val_accuracy: 0.5450\n",
      "Epoch 1492/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9041 - accuracy: 0.5504 - val_loss: 0.9132 - val_accuracy: 0.5450\n",
      "Epoch 1493/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9067 - accuracy: 0.5506 - val_loss: 0.9158 - val_accuracy: 0.5420\n",
      "Epoch 1494/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9051 - accuracy: 0.5474 - val_loss: 0.9160 - val_accuracy: 0.5370\n",
      "Epoch 1495/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9060 - accuracy: 0.5501 - val_loss: 0.9145 - val_accuracy: 0.5453\n",
      "Epoch 1496/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9051 - accuracy: 0.5467 - val_loss: 0.9230 - val_accuracy: 0.5387\n",
      "Epoch 1497/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9064 - accuracy: 0.5461 - val_loss: 0.9151 - val_accuracy: 0.5417\n",
      "Epoch 1498/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9046 - accuracy: 0.5496 - val_loss: 0.9109 - val_accuracy: 0.5440\n",
      "Epoch 1499/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9060 - accuracy: 0.5478 - val_loss: 0.9148 - val_accuracy: 0.5357\n",
      "Epoch 1500/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9042 - accuracy: 0.5479 - val_loss: 0.9127 - val_accuracy: 0.5390\n",
      "Epoch 1501/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9065 - accuracy: 0.5474 - val_loss: 0.9169 - val_accuracy: 0.5387\n",
      "Epoch 1502/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9079 - accuracy: 0.5484 - val_loss: 0.9130 - val_accuracy: 0.5373\n",
      "Epoch 1503/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9086 - accuracy: 0.5471 - val_loss: 0.9138 - val_accuracy: 0.5413\n",
      "Epoch 1504/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9058 - accuracy: 0.5471 - val_loss: 0.9142 - val_accuracy: 0.5377\n",
      "Epoch 1505/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9026 - accuracy: 0.5454 - val_loss: 0.9108 - val_accuracy: 0.5427\n",
      "Epoch 1506/1800\n",
      "14000/14000 [==============================] - 2s 125us/step - loss: 0.9047 - accuracy: 0.5441 - val_loss: 0.9161 - val_accuracy: 0.5350\n",
      "Epoch 1507/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9066 - accuracy: 0.5480 - val_loss: 0.9132 - val_accuracy: 0.5427\n",
      "Epoch 1508/1800\n",
      "14000/14000 [==============================] - 2s 169us/step - loss: 0.9044 - accuracy: 0.5521 - val_loss: 0.9170 - val_accuracy: 0.5390\n",
      "Epoch 1509/1800\n",
      "14000/14000 [==============================] - 3s 249us/step - loss: 0.9060 - accuracy: 0.5519 - val_loss: 0.9151 - val_accuracy: 0.5387\n",
      "Epoch 1510/1800\n",
      "14000/14000 [==============================] - 2s 124us/step - loss: 0.9062 - accuracy: 0.5521 - val_loss: 0.9143 - val_accuracy: 0.5427\n",
      "Epoch 1511/1800\n",
      "14000/14000 [==============================] - 2s 111us/step - loss: 0.9047 - accuracy: 0.5508 - val_loss: 0.9138 - val_accuracy: 0.5350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1512/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9056 - accuracy: 0.5521 - val_loss: 0.9150 - val_accuracy: 0.5387\n",
      "Epoch 1513/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9047 - accuracy: 0.5494 - val_loss: 0.9139 - val_accuracy: 0.5387\n",
      "Epoch 1514/1800\n",
      "14000/14000 [==============================] - 1s 107us/step - loss: 0.9065 - accuracy: 0.5466 - val_loss: 0.9167 - val_accuracy: 0.5387\n",
      "Epoch 1515/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9037 - accuracy: 0.5526 - val_loss: 0.9115 - val_accuracy: 0.5457\n",
      "Epoch 1516/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9042 - accuracy: 0.5493 - val_loss: 0.9142 - val_accuracy: 0.5347\n",
      "Epoch 1517/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9083 - accuracy: 0.5461 - val_loss: 0.9106 - val_accuracy: 0.5430\n",
      "Epoch 1518/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9076 - accuracy: 0.5463 - val_loss: 0.9117 - val_accuracy: 0.5420\n",
      "Epoch 1519/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9054 - accuracy: 0.5478 - val_loss: 0.9123 - val_accuracy: 0.5363\n",
      "Epoch 1520/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9052 - accuracy: 0.5467 - val_loss: 0.9130 - val_accuracy: 0.5387\n",
      "Epoch 1521/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9058 - accuracy: 0.5462 - val_loss: 0.9110 - val_accuracy: 0.5437\n",
      "Epoch 1522/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9050 - accuracy: 0.5484 - val_loss: 0.9203 - val_accuracy: 0.5353\n",
      "Epoch 1523/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9054 - accuracy: 0.5506 - val_loss: 0.9127 - val_accuracy: 0.5377\n",
      "Epoch 1524/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9053 - accuracy: 0.5476 - val_loss: 0.9121 - val_accuracy: 0.5433\n",
      "Epoch 1525/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9054 - accuracy: 0.5488 - val_loss: 0.9138 - val_accuracy: 0.5430\n",
      "Epoch 1526/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9054 - accuracy: 0.5505 - val_loss: 0.9135 - val_accuracy: 0.5437\n",
      "Epoch 1527/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9056 - accuracy: 0.5466 - val_loss: 0.9117 - val_accuracy: 0.5447\n",
      "Epoch 1528/1800\n",
      "14000/14000 [==============================] - 2s 120us/step - loss: 0.9066 - accuracy: 0.5496 - val_loss: 0.9127 - val_accuracy: 0.5420\n",
      "Epoch 1529/1800\n",
      "14000/14000 [==============================] - 2s 119us/step - loss: 0.9047 - accuracy: 0.5534 - val_loss: 0.9133 - val_accuracy: 0.5390\n",
      "Epoch 1530/1800\n",
      "14000/14000 [==============================] - 2s 113us/step - loss: 0.9038 - accuracy: 0.5499 - val_loss: 0.9180 - val_accuracy: 0.5363\n",
      "Epoch 1531/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9043 - accuracy: 0.5479 - val_loss: 0.9115 - val_accuracy: 0.5463\n",
      "Epoch 1532/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9061 - accuracy: 0.5468 - val_loss: 0.9145 - val_accuracy: 0.5440\n",
      "Epoch 1533/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9065 - accuracy: 0.5465 - val_loss: 0.9131 - val_accuracy: 0.5397\n",
      "Epoch 1534/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9052 - accuracy: 0.5486 - val_loss: 0.9139 - val_accuracy: 0.5440\n",
      "Epoch 1535/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9055 - accuracy: 0.5500 - val_loss: 0.9139 - val_accuracy: 0.5430\n",
      "Epoch 1536/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9048 - accuracy: 0.5489 - val_loss: 0.9163 - val_accuracy: 0.5393\n",
      "Epoch 1537/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9067 - accuracy: 0.5467 - val_loss: 0.9139 - val_accuracy: 0.5360\n",
      "Epoch 1538/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9053 - accuracy: 0.5476 - val_loss: 0.9119 - val_accuracy: 0.5457\n",
      "Epoch 1539/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9049 - accuracy: 0.5462 - val_loss: 0.9179 - val_accuracy: 0.5410\n",
      "Epoch 1540/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9053 - accuracy: 0.5499 - val_loss: 0.9133 - val_accuracy: 0.5420\n",
      "Epoch 1541/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9066 - accuracy: 0.5489 - val_loss: 0.9108 - val_accuracy: 0.5430\n",
      "Epoch 1542/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9046 - accuracy: 0.5479 - val_loss: 0.9111 - val_accuracy: 0.5423\n",
      "Epoch 1543/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9063 - accuracy: 0.5500 - val_loss: 0.9125 - val_accuracy: 0.5470\n",
      "Epoch 1544/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9075 - accuracy: 0.5452 - val_loss: 0.9157 - val_accuracy: 0.5437\n",
      "Epoch 1545/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9055 - accuracy: 0.5484 - val_loss: 0.9141 - val_accuracy: 0.5453\n",
      "Epoch 1546/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9063 - accuracy: 0.5486 - val_loss: 0.9120 - val_accuracy: 0.5440\n",
      "Epoch 1547/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9059 - accuracy: 0.5464 - val_loss: 0.9131 - val_accuracy: 0.5460\n",
      "Epoch 1548/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9057 - accuracy: 0.5456 - val_loss: 0.9116 - val_accuracy: 0.5423\n",
      "Epoch 1549/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9059 - accuracy: 0.5490 - val_loss: 0.9166 - val_accuracy: 0.5370\n",
      "Epoch 1550/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9047 - accuracy: 0.5494 - val_loss: 0.9115 - val_accuracy: 0.5450\n",
      "Epoch 1551/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9064 - accuracy: 0.5506 - val_loss: 0.9166 - val_accuracy: 0.5417\n",
      "Epoch 1552/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9060 - accuracy: 0.5431 - val_loss: 0.9155 - val_accuracy: 0.5390\n",
      "Epoch 1553/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9058 - accuracy: 0.5484 - val_loss: 0.9133 - val_accuracy: 0.5463\n",
      "Epoch 1554/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9082 - accuracy: 0.5471 - val_loss: 0.9126 - val_accuracy: 0.5400\n",
      "Epoch 1555/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9060 - accuracy: 0.5486 - val_loss: 0.9135 - val_accuracy: 0.5387\n",
      "Epoch 1556/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9057 - accuracy: 0.5447 - val_loss: 0.9158 - val_accuracy: 0.5403\n",
      "Epoch 1557/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9057 - accuracy: 0.5491 - val_loss: 0.9176 - val_accuracy: 0.5347\n",
      "Epoch 1558/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9037 - accuracy: 0.5485 - val_loss: 0.9139 - val_accuracy: 0.5477\n",
      "Epoch 1559/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9069 - accuracy: 0.5495 - val_loss: 0.9125 - val_accuracy: 0.5373\n",
      "Epoch 1560/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9045 - accuracy: 0.5447 - val_loss: 0.9150 - val_accuracy: 0.5403\n",
      "Epoch 1561/1800\n",
      "14000/14000 [==============================] - 2s 109us/step - loss: 0.9056 - accuracy: 0.5529 - val_loss: 0.9130 - val_accuracy: 0.5463\n",
      "Epoch 1562/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9043 - accuracy: 0.5484 - val_loss: 0.9140 - val_accuracy: 0.5403\n",
      "Epoch 1563/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9068 - accuracy: 0.5468 - val_loss: 0.9110 - val_accuracy: 0.5380\n",
      "Epoch 1564/1800\n",
      "14000/14000 [==============================] - 2s 114us/step - loss: 0.9062 - accuracy: 0.5470 - val_loss: 0.9118 - val_accuracy: 0.5423\n",
      "Epoch 1565/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9053 - accuracy: 0.5453 - val_loss: 0.9172 - val_accuracy: 0.5380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1566/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9065 - accuracy: 0.5476 - val_loss: 0.9117 - val_accuracy: 0.5443\n",
      "Epoch 1567/1800\n",
      "14000/14000 [==============================] - 2s 109us/step - loss: 0.9042 - accuracy: 0.5481 - val_loss: 0.9171 - val_accuracy: 0.5363\n",
      "Epoch 1568/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9040 - accuracy: 0.5460 - val_loss: 0.9166 - val_accuracy: 0.5370\n",
      "Epoch 1569/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9061 - accuracy: 0.5461 - val_loss: 0.9155 - val_accuracy: 0.5387\n",
      "Epoch 1570/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9051 - accuracy: 0.5464 - val_loss: 0.9154 - val_accuracy: 0.5347\n",
      "Epoch 1571/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9056 - accuracy: 0.5455 - val_loss: 0.9120 - val_accuracy: 0.5400\n",
      "Epoch 1572/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9051 - accuracy: 0.5485 - val_loss: 0.9152 - val_accuracy: 0.5420\n",
      "Epoch 1573/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9060 - accuracy: 0.5464 - val_loss: 0.9121 - val_accuracy: 0.5423\n",
      "Epoch 1574/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9081 - accuracy: 0.5436 - val_loss: 0.9171 - val_accuracy: 0.5417\n",
      "Epoch 1575/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9060 - accuracy: 0.5484 - val_loss: 0.9179 - val_accuracy: 0.5403\n",
      "Epoch 1576/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9058 - accuracy: 0.5509 - val_loss: 0.9130 - val_accuracy: 0.5460\n",
      "Epoch 1577/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9053 - accuracy: 0.5490 - val_loss: 0.9123 - val_accuracy: 0.5450\n",
      "Epoch 1578/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9066 - accuracy: 0.5455 - val_loss: 0.9120 - val_accuracy: 0.5400\n",
      "Epoch 1579/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9060 - accuracy: 0.5493 - val_loss: 0.9116 - val_accuracy: 0.5397\n",
      "Epoch 1580/1800\n",
      "14000/14000 [==============================] - 2s 125us/step - loss: 0.9086 - accuracy: 0.5440 - val_loss: 0.9119 - val_accuracy: 0.5413\n",
      "Epoch 1581/1800\n",
      "14000/14000 [==============================] - 2s 113us/step - loss: 0.9055 - accuracy: 0.5471 - val_loss: 0.9152 - val_accuracy: 0.5353\n",
      "Epoch 1582/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9048 - accuracy: 0.5478 - val_loss: 0.9169 - val_accuracy: 0.5393\n",
      "Epoch 1583/1800\n",
      "14000/14000 [==============================] - 2s 111us/step - loss: 0.9070 - accuracy: 0.5468 - val_loss: 0.9144 - val_accuracy: 0.5403\n",
      "Epoch 1584/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9067 - accuracy: 0.5456 - val_loss: 0.9165 - val_accuracy: 0.5403\n",
      "Epoch 1585/1800\n",
      "14000/14000 [==============================] - 1s 105us/step - loss: 0.9057 - accuracy: 0.5503 - val_loss: 0.9139 - val_accuracy: 0.5377\n",
      "Epoch 1586/1800\n",
      "14000/14000 [==============================] - 1s 106us/step - loss: 0.9060 - accuracy: 0.5419 - val_loss: 0.9136 - val_accuracy: 0.5393\n",
      "Epoch 1587/1800\n",
      "14000/14000 [==============================] - 2s 116us/step - loss: 0.9068 - accuracy: 0.5464 - val_loss: 0.9130 - val_accuracy: 0.5440\n",
      "Epoch 1588/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9054 - accuracy: 0.5444 - val_loss: 0.9118 - val_accuracy: 0.5483\n",
      "Epoch 1589/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9043 - accuracy: 0.5454 - val_loss: 0.9082 - val_accuracy: 0.5407\n",
      "Epoch 1590/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9072 - accuracy: 0.5464 - val_loss: 0.9146 - val_accuracy: 0.5463\n",
      "Epoch 1591/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9051 - accuracy: 0.5486 - val_loss: 0.9149 - val_accuracy: 0.5420\n",
      "Epoch 1592/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9060 - accuracy: 0.5473 - val_loss: 0.9122 - val_accuracy: 0.5443\n",
      "Epoch 1593/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9030 - accuracy: 0.5474 - val_loss: 0.9154 - val_accuracy: 0.5417\n",
      "Epoch 1594/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9035 - accuracy: 0.5524 - val_loss: 0.9092 - val_accuracy: 0.5460\n",
      "Epoch 1595/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9058 - accuracy: 0.5483 - val_loss: 0.9141 - val_accuracy: 0.5410\n",
      "Epoch 1596/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9055 - accuracy: 0.5441 - val_loss: 0.9163 - val_accuracy: 0.5363\n",
      "Epoch 1597/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9077 - accuracy: 0.5468 - val_loss: 0.9150 - val_accuracy: 0.5430\n",
      "Epoch 1598/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9059 - accuracy: 0.5479 - val_loss: 0.9144 - val_accuracy: 0.5437\n",
      "Epoch 1599/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9050 - accuracy: 0.5499 - val_loss: 0.9138 - val_accuracy: 0.5417\n",
      "Epoch 1600/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9077 - accuracy: 0.5448 - val_loss: 0.9159 - val_accuracy: 0.5460\n",
      "Epoch 1601/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9057 - accuracy: 0.5472 - val_loss: 0.9148 - val_accuracy: 0.5433\n",
      "Epoch 1602/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9067 - accuracy: 0.5471 - val_loss: 0.9146 - val_accuracy: 0.5417\n",
      "Epoch 1603/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9066 - accuracy: 0.5465 - val_loss: 0.9132 - val_accuracy: 0.5420\n",
      "Epoch 1604/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9053 - accuracy: 0.5465 - val_loss: 0.9163 - val_accuracy: 0.5403\n",
      "Epoch 1605/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9086 - accuracy: 0.5446 - val_loss: 0.9146 - val_accuracy: 0.5390\n",
      "Epoch 1606/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9052 - accuracy: 0.5435 - val_loss: 0.9078 - val_accuracy: 0.5507\n",
      "Epoch 1607/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9056 - accuracy: 0.5471 - val_loss: 0.9104 - val_accuracy: 0.5423\n",
      "Epoch 1608/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9063 - accuracy: 0.5479 - val_loss: 0.9095 - val_accuracy: 0.5470\n",
      "Epoch 1609/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9063 - accuracy: 0.5492 - val_loss: 0.9205 - val_accuracy: 0.5393\n",
      "Epoch 1610/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9056 - accuracy: 0.5476 - val_loss: 0.9170 - val_accuracy: 0.5303\n",
      "Epoch 1611/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9050 - accuracy: 0.5484 - val_loss: 0.9122 - val_accuracy: 0.5417\n",
      "Epoch 1612/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9056 - accuracy: 0.5457 - val_loss: 0.9123 - val_accuracy: 0.5370\n",
      "Epoch 1613/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9047 - accuracy: 0.5437 - val_loss: 0.9137 - val_accuracy: 0.5347\n",
      "Epoch 1614/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9029 - accuracy: 0.5493 - val_loss: 0.9162 - val_accuracy: 0.5360\n",
      "Epoch 1615/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9034 - accuracy: 0.5490 - val_loss: 0.9140 - val_accuracy: 0.5457\n",
      "Epoch 1616/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9063 - accuracy: 0.5474 - val_loss: 0.9096 - val_accuracy: 0.5463\n",
      "Epoch 1617/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9071 - accuracy: 0.5470 - val_loss: 0.9120 - val_accuracy: 0.5430\n",
      "Epoch 1618/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9058 - accuracy: 0.5467 - val_loss: 0.9150 - val_accuracy: 0.5367\n",
      "Epoch 1619/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9068 - accuracy: 0.5506 - val_loss: 0.9175 - val_accuracy: 0.5387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1620/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9042 - accuracy: 0.5498 - val_loss: 0.9116 - val_accuracy: 0.5497\n",
      "Epoch 1621/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9064 - accuracy: 0.5512 - val_loss: 0.9144 - val_accuracy: 0.5423\n",
      "Epoch 1622/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9061 - accuracy: 0.5496 - val_loss: 0.9094 - val_accuracy: 0.5470\n",
      "Epoch 1623/1800\n",
      "14000/14000 [==============================] - 4s 295us/step - loss: 0.9060 - accuracy: 0.5484 - val_loss: 0.9116 - val_accuracy: 0.5427\n",
      "Epoch 1624/1800\n",
      "14000/14000 [==============================] - 3s 200us/step - loss: 0.9045 - accuracy: 0.5471 - val_loss: 0.9157 - val_accuracy: 0.5400\n",
      "Epoch 1625/1800\n",
      "14000/14000 [==============================] - 2s 120us/step - loss: 0.9075 - accuracy: 0.5469 - val_loss: 0.9148 - val_accuracy: 0.5410\n",
      "Epoch 1626/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9083 - accuracy: 0.5459 - val_loss: 0.9143 - val_accuracy: 0.5380\n",
      "Epoch 1627/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9053 - accuracy: 0.5510 - val_loss: 0.9123 - val_accuracy: 0.5400\n",
      "Epoch 1628/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9046 - accuracy: 0.5475 - val_loss: 0.9162 - val_accuracy: 0.5357\n",
      "Epoch 1629/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9083 - accuracy: 0.5474 - val_loss: 0.9185 - val_accuracy: 0.5337\n",
      "Epoch 1630/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9062 - accuracy: 0.5456 - val_loss: 0.9123 - val_accuracy: 0.5440\n",
      "Epoch 1631/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9069 - accuracy: 0.5445 - val_loss: 0.9144 - val_accuracy: 0.5483\n",
      "Epoch 1632/1800\n",
      "14000/14000 [==============================] - 2s 117us/step - loss: 0.9078 - accuracy: 0.5452 - val_loss: 0.9134 - val_accuracy: 0.5417\n",
      "Epoch 1633/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9074 - accuracy: 0.5496 - val_loss: 0.9199 - val_accuracy: 0.5353\n",
      "Epoch 1634/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9074 - accuracy: 0.5494 - val_loss: 0.9126 - val_accuracy: 0.5420\n",
      "Epoch 1635/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9075 - accuracy: 0.5478 - val_loss: 0.9137 - val_accuracy: 0.5413\n",
      "Epoch 1636/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9064 - accuracy: 0.5480 - val_loss: 0.9136 - val_accuracy: 0.5430\n",
      "Epoch 1637/1800\n",
      "14000/14000 [==============================] - 1s 107us/step - loss: 0.9047 - accuracy: 0.5466 - val_loss: 0.9158 - val_accuracy: 0.5390\n",
      "Epoch 1638/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9059 - accuracy: 0.5473 - val_loss: 0.9134 - val_accuracy: 0.5463\n",
      "Epoch 1639/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9065 - accuracy: 0.5471 - val_loss: 0.9175 - val_accuracy: 0.5443\n",
      "Epoch 1640/1800\n",
      "14000/14000 [==============================] - 1s 98us/step - loss: 0.9064 - accuracy: 0.5489 - val_loss: 0.9213 - val_accuracy: 0.5437\n",
      "Epoch 1641/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9052 - accuracy: 0.5510 - val_loss: 0.9121 - val_accuracy: 0.5443\n",
      "Epoch 1642/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9065 - accuracy: 0.5508 - val_loss: 0.9137 - val_accuracy: 0.5433\n",
      "Epoch 1643/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9062 - accuracy: 0.5491 - val_loss: 0.9133 - val_accuracy: 0.5407\n",
      "Epoch 1644/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9065 - accuracy: 0.5491 - val_loss: 0.9135 - val_accuracy: 0.5383\n",
      "Epoch 1645/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9059 - accuracy: 0.5498 - val_loss: 0.9147 - val_accuracy: 0.5347\n",
      "Epoch 1646/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9038 - accuracy: 0.5513 - val_loss: 0.9150 - val_accuracy: 0.5413\n",
      "Epoch 1647/1800\n",
      "14000/14000 [==============================] - 2s 115us/step - loss: 0.9064 - accuracy: 0.5461 - val_loss: 0.9170 - val_accuracy: 0.5403\n",
      "Epoch 1648/1800\n",
      "14000/14000 [==============================] - 1s 103us/step - loss: 0.9039 - accuracy: 0.5534 - val_loss: 0.9120 - val_accuracy: 0.5383\n",
      "Epoch 1649/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9051 - accuracy: 0.5502 - val_loss: 0.9142 - val_accuracy: 0.5383\n",
      "Epoch 1650/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9052 - accuracy: 0.5451 - val_loss: 0.9135 - val_accuracy: 0.5393\n",
      "Epoch 1651/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9055 - accuracy: 0.5521 - val_loss: 0.9139 - val_accuracy: 0.5413\n",
      "Epoch 1652/1800\n",
      "14000/14000 [==============================] - 1s 96us/step - loss: 0.9065 - accuracy: 0.5476 - val_loss: 0.9149 - val_accuracy: 0.5397\n",
      "Epoch 1653/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9073 - accuracy: 0.5485 - val_loss: 0.9128 - val_accuracy: 0.5427\n",
      "Epoch 1654/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9041 - accuracy: 0.5486 - val_loss: 0.9128 - val_accuracy: 0.5423\n",
      "Epoch 1655/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9074 - accuracy: 0.5481 - val_loss: 0.9137 - val_accuracy: 0.5440\n",
      "Epoch 1656/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9059 - accuracy: 0.5498 - val_loss: 0.9146 - val_accuracy: 0.5420\n",
      "Epoch 1657/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9073 - accuracy: 0.5436 - val_loss: 0.9142 - val_accuracy: 0.5417\n",
      "Epoch 1658/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9047 - accuracy: 0.5466 - val_loss: 0.9140 - val_accuracy: 0.5417\n",
      "Epoch 1659/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9074 - accuracy: 0.5440 - val_loss: 0.9158 - val_accuracy: 0.5427\n",
      "Epoch 1660/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9063 - accuracy: 0.5485 - val_loss: 0.9105 - val_accuracy: 0.5380\n",
      "Epoch 1661/1800\n",
      "14000/14000 [==============================] - 1s 97us/step - loss: 0.9045 - accuracy: 0.5477 - val_loss: 0.9142 - val_accuracy: 0.5360\n",
      "Epoch 1662/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9069 - accuracy: 0.5516 - val_loss: 0.9125 - val_accuracy: 0.5400\n",
      "Epoch 1663/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9061 - accuracy: 0.5484 - val_loss: 0.9146 - val_accuracy: 0.5417\n",
      "Epoch 1664/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9091 - accuracy: 0.5469 - val_loss: 0.9189 - val_accuracy: 0.5400\n",
      "Epoch 1665/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9052 - accuracy: 0.5509 - val_loss: 0.9146 - val_accuracy: 0.5440\n",
      "Epoch 1666/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9060 - accuracy: 0.5504 - val_loss: 0.9100 - val_accuracy: 0.5453\n",
      "Epoch 1667/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9061 - accuracy: 0.5471 - val_loss: 0.9114 - val_accuracy: 0.5427\n",
      "Epoch 1668/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9055 - accuracy: 0.5484 - val_loss: 0.9128 - val_accuracy: 0.5383\n",
      "Epoch 1669/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9079 - accuracy: 0.5471 - val_loss: 0.9159 - val_accuracy: 0.5410\n",
      "Epoch 1670/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9051 - accuracy: 0.5478 - val_loss: 0.9153 - val_accuracy: 0.5370\n",
      "Epoch 1671/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9079 - accuracy: 0.5480 - val_loss: 0.9157 - val_accuracy: 0.5427\n",
      "Epoch 1672/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9080 - accuracy: 0.5471 - val_loss: 0.9146 - val_accuracy: 0.5413\n",
      "Epoch 1673/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9035 - accuracy: 0.5489 - val_loss: 0.9161 - val_accuracy: 0.5357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1674/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9059 - accuracy: 0.5462 - val_loss: 0.9141 - val_accuracy: 0.5433\n",
      "Epoch 1675/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9051 - accuracy: 0.5484 - val_loss: 0.9135 - val_accuracy: 0.5423\n",
      "Epoch 1676/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9088 - accuracy: 0.5473 - val_loss: 0.9141 - val_accuracy: 0.5427\n",
      "Epoch 1677/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9061 - accuracy: 0.5476 - val_loss: 0.9118 - val_accuracy: 0.5460\n",
      "Epoch 1678/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9074 - accuracy: 0.5491 - val_loss: 0.9132 - val_accuracy: 0.5390\n",
      "Epoch 1679/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9074 - accuracy: 0.5472 - val_loss: 0.9129 - val_accuracy: 0.5463\n",
      "Epoch 1680/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9064 - accuracy: 0.5514 - val_loss: 0.9160 - val_accuracy: 0.5367\n",
      "Epoch 1681/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9073 - accuracy: 0.5428 - val_loss: 0.9144 - val_accuracy: 0.5413\n",
      "Epoch 1682/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9049 - accuracy: 0.5454 - val_loss: 0.9135 - val_accuracy: 0.5423\n",
      "Epoch 1683/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9055 - accuracy: 0.5457 - val_loss: 0.9210 - val_accuracy: 0.5367\n",
      "Epoch 1684/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9064 - accuracy: 0.5485 - val_loss: 0.9147 - val_accuracy: 0.5377\n",
      "Epoch 1685/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9057 - accuracy: 0.5481 - val_loss: 0.9160 - val_accuracy: 0.5393\n",
      "Epoch 1686/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9052 - accuracy: 0.5462 - val_loss: 0.9118 - val_accuracy: 0.5377\n",
      "Epoch 1687/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9080 - accuracy: 0.5491 - val_loss: 0.9177 - val_accuracy: 0.5350\n",
      "Epoch 1688/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9057 - accuracy: 0.5484 - val_loss: 0.9119 - val_accuracy: 0.5410\n",
      "Epoch 1689/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9068 - accuracy: 0.5469 - val_loss: 0.9170 - val_accuracy: 0.5407\n",
      "Epoch 1690/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9058 - accuracy: 0.5478 - val_loss: 0.9161 - val_accuracy: 0.5400\n",
      "Epoch 1691/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9059 - accuracy: 0.5501 - val_loss: 0.9142 - val_accuracy: 0.5353\n",
      "Epoch 1692/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9057 - accuracy: 0.5495 - val_loss: 0.9130 - val_accuracy: 0.5450\n",
      "Epoch 1693/1800\n",
      "14000/14000 [==============================] - 2s 114us/step - loss: 0.9058 - accuracy: 0.5481 - val_loss: 0.9128 - val_accuracy: 0.5407\n",
      "Epoch 1694/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9042 - accuracy: 0.5479 - val_loss: 0.9148 - val_accuracy: 0.5350\n",
      "Epoch 1695/1800\n",
      "14000/14000 [==============================] - 1s 103us/step - loss: 0.9071 - accuracy: 0.5477 - val_loss: 0.9146 - val_accuracy: 0.5367\n",
      "Epoch 1696/1800\n",
      "14000/14000 [==============================] - 1s 102us/step - loss: 0.9059 - accuracy: 0.5516 - val_loss: 0.9210 - val_accuracy: 0.5343\n",
      "Epoch 1697/1800\n",
      "14000/14000 [==============================] - 1s 106us/step - loss: 0.9064 - accuracy: 0.5474 - val_loss: 0.9120 - val_accuracy: 0.5403\n",
      "Epoch 1698/1800\n",
      "14000/14000 [==============================] - 1s 104us/step - loss: 0.9050 - accuracy: 0.5469 - val_loss: 0.9180 - val_accuracy: 0.5330\n",
      "Epoch 1699/1800\n",
      "14000/14000 [==============================] - 1s 100us/step - loss: 0.9070 - accuracy: 0.5449 - val_loss: 0.9155 - val_accuracy: 0.5420\n",
      "Epoch 1700/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9074 - accuracy: 0.5482 - val_loss: 0.9150 - val_accuracy: 0.5410\n",
      "Epoch 1701/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9063 - accuracy: 0.5481 - val_loss: 0.9165 - val_accuracy: 0.5387\n",
      "Epoch 1702/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9082 - accuracy: 0.5469 - val_loss: 0.9129 - val_accuracy: 0.5387\n",
      "Epoch 1703/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9069 - accuracy: 0.5459 - val_loss: 0.9151 - val_accuracy: 0.5403\n",
      "Epoch 1704/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9079 - accuracy: 0.5453 - val_loss: 0.9163 - val_accuracy: 0.5400\n",
      "Epoch 1705/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9073 - accuracy: 0.5503 - val_loss: 0.9148 - val_accuracy: 0.5420\n",
      "Epoch 1706/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9069 - accuracy: 0.5500 - val_loss: 0.9153 - val_accuracy: 0.5430\n",
      "Epoch 1707/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9054 - accuracy: 0.5527 - val_loss: 0.9166 - val_accuracy: 0.5357\n",
      "Epoch 1708/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9053 - accuracy: 0.5469 - val_loss: 0.9190 - val_accuracy: 0.5327\n",
      "Epoch 1709/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9067 - accuracy: 0.5466 - val_loss: 0.9115 - val_accuracy: 0.5473\n",
      "Epoch 1710/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9049 - accuracy: 0.5522 - val_loss: 0.9120 - val_accuracy: 0.5453\n",
      "Epoch 1711/1800\n",
      "14000/14000 [==============================] - 2s 120us/step - loss: 0.9051 - accuracy: 0.5504 - val_loss: 0.9152 - val_accuracy: 0.5427\n",
      "Epoch 1712/1800\n",
      "14000/14000 [==============================] - 2s 116us/step - loss: 0.9080 - accuracy: 0.5451 - val_loss: 0.9173 - val_accuracy: 0.5363\n",
      "Epoch 1713/1800\n",
      "14000/14000 [==============================] - 2s 129us/step - loss: 0.9048 - accuracy: 0.5494 - val_loss: 0.9123 - val_accuracy: 0.5460\n",
      "Epoch 1714/1800\n",
      "14000/14000 [==============================] - 2s 113us/step - loss: 0.9048 - accuracy: 0.5469 - val_loss: 0.9130 - val_accuracy: 0.5477\n",
      "Epoch 1715/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9057 - accuracy: 0.5475 - val_loss: 0.9188 - val_accuracy: 0.5390\n",
      "Epoch 1716/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9076 - accuracy: 0.5450 - val_loss: 0.9124 - val_accuracy: 0.5403\n",
      "Epoch 1717/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9075 - accuracy: 0.5479 - val_loss: 0.9138 - val_accuracy: 0.5443\n",
      "Epoch 1718/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9066 - accuracy: 0.5479 - val_loss: 0.9145 - val_accuracy: 0.5437\n",
      "Epoch 1719/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9063 - accuracy: 0.5461 - val_loss: 0.9123 - val_accuracy: 0.5447\n",
      "Epoch 1720/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9079 - accuracy: 0.5446 - val_loss: 0.9124 - val_accuracy: 0.5420\n",
      "Epoch 1721/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9079 - accuracy: 0.5467 - val_loss: 0.9138 - val_accuracy: 0.5430\n",
      "Epoch 1722/1800\n",
      "14000/14000 [==============================] - 1s 99us/step - loss: 0.9056 - accuracy: 0.5457 - val_loss: 0.9106 - val_accuracy: 0.5460\n",
      "Epoch 1723/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9066 - accuracy: 0.5464 - val_loss: 0.9150 - val_accuracy: 0.5410\n",
      "Epoch 1724/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9067 - accuracy: 0.5477 - val_loss: 0.9143 - val_accuracy: 0.5410\n",
      "Epoch 1725/1800\n",
      "14000/14000 [==============================] - 2s 111us/step - loss: 0.9055 - accuracy: 0.5510 - val_loss: 0.9130 - val_accuracy: 0.5443\n",
      "Epoch 1726/1800\n",
      "14000/14000 [==============================] - 2s 130us/step - loss: 0.9061 - accuracy: 0.5496 - val_loss: 0.9143 - val_accuracy: 0.5373\n",
      "Epoch 1727/1800\n",
      "14000/14000 [==============================] - 2s 119us/step - loss: 0.9068 - accuracy: 0.5460 - val_loss: 0.9141 - val_accuracy: 0.5390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1728/1800\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.9070 - accuracy: 0.5481 - val_loss: 0.9193 - val_accuracy: 0.5387\n",
      "Epoch 1729/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9065 - accuracy: 0.5425 - val_loss: 0.9153 - val_accuracy: 0.5403\n",
      "Epoch 1730/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9076 - accuracy: 0.5467 - val_loss: 0.9210 - val_accuracy: 0.5337\n",
      "Epoch 1731/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9073 - accuracy: 0.5459 - val_loss: 0.9133 - val_accuracy: 0.5440\n",
      "Epoch 1732/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9044 - accuracy: 0.5481 - val_loss: 0.9128 - val_accuracy: 0.5427\n",
      "Epoch 1733/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9056 - accuracy: 0.5504 - val_loss: 0.9156 - val_accuracy: 0.5397\n",
      "Epoch 1734/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9061 - accuracy: 0.5467 - val_loss: 0.9157 - val_accuracy: 0.5457\n",
      "Epoch 1735/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9056 - accuracy: 0.5489 - val_loss: 0.9151 - val_accuracy: 0.5373\n",
      "Epoch 1736/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9071 - accuracy: 0.5497 - val_loss: 0.9140 - val_accuracy: 0.5423\n",
      "Epoch 1737/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9061 - accuracy: 0.5457 - val_loss: 0.9197 - val_accuracy: 0.5380\n",
      "Epoch 1738/1800\n",
      "14000/14000 [==============================] - 1s 95us/step - loss: 0.9050 - accuracy: 0.5496 - val_loss: 0.9101 - val_accuracy: 0.5457\n",
      "Epoch 1739/1800\n",
      "14000/14000 [==============================] - 1s 93us/step - loss: 0.9073 - accuracy: 0.5448 - val_loss: 0.9148 - val_accuracy: 0.5443\n",
      "Epoch 1740/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9053 - accuracy: 0.5509 - val_loss: 0.9164 - val_accuracy: 0.5423\n",
      "Epoch 1741/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9077 - accuracy: 0.5472 - val_loss: 0.9134 - val_accuracy: 0.5417\n",
      "Epoch 1742/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9065 - accuracy: 0.5450 - val_loss: 0.9102 - val_accuracy: 0.5480\n",
      "Epoch 1743/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9051 - accuracy: 0.5460 - val_loss: 0.9159 - val_accuracy: 0.5420\n",
      "Epoch 1744/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9066 - accuracy: 0.5504 - val_loss: 0.9102 - val_accuracy: 0.5453\n",
      "Epoch 1745/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9061 - accuracy: 0.5466 - val_loss: 0.9151 - val_accuracy: 0.5390\n",
      "Epoch 1746/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9061 - accuracy: 0.5482 - val_loss: 0.9148 - val_accuracy: 0.5393\n",
      "Epoch 1747/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9067 - accuracy: 0.5481 - val_loss: 0.9157 - val_accuracy: 0.5390\n",
      "Epoch 1748/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9058 - accuracy: 0.5512 - val_loss: 0.9133 - val_accuracy: 0.5460\n",
      "Epoch 1749/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9068 - accuracy: 0.5483 - val_loss: 0.9123 - val_accuracy: 0.5387\n",
      "Epoch 1750/1800\n",
      "14000/14000 [==============================] - 1s 87us/step - loss: 0.9078 - accuracy: 0.5429 - val_loss: 0.9137 - val_accuracy: 0.5427\n",
      "Epoch 1751/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9056 - accuracy: 0.5476 - val_loss: 0.9175 - val_accuracy: 0.5383\n",
      "Epoch 1752/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9066 - accuracy: 0.5494 - val_loss: 0.9177 - val_accuracy: 0.5440\n",
      "Epoch 1753/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9077 - accuracy: 0.5455 - val_loss: 0.9182 - val_accuracy: 0.5390\n",
      "Epoch 1754/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9049 - accuracy: 0.5482 - val_loss: 0.9141 - val_accuracy: 0.5443\n",
      "Epoch 1755/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9066 - accuracy: 0.5441 - val_loss: 0.9280 - val_accuracy: 0.5250\n",
      "Epoch 1756/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9068 - accuracy: 0.5439 - val_loss: 0.9133 - val_accuracy: 0.5460\n",
      "Epoch 1757/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9068 - accuracy: 0.5496 - val_loss: 0.9158 - val_accuracy: 0.5430\n",
      "Epoch 1758/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9080 - accuracy: 0.5439 - val_loss: 0.9159 - val_accuracy: 0.5363\n",
      "Epoch 1759/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9060 - accuracy: 0.5468 - val_loss: 0.9124 - val_accuracy: 0.5400\n",
      "Epoch 1760/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9074 - accuracy: 0.5461 - val_loss: 0.9154 - val_accuracy: 0.5343\n",
      "Epoch 1761/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9075 - accuracy: 0.5453 - val_loss: 0.9195 - val_accuracy: 0.5400\n",
      "Epoch 1762/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9052 - accuracy: 0.5461 - val_loss: 0.9167 - val_accuracy: 0.5407\n",
      "Epoch 1763/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9079 - accuracy: 0.5460 - val_loss: 0.9124 - val_accuracy: 0.5407\n",
      "Epoch 1764/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9048 - accuracy: 0.5501 - val_loss: 0.9174 - val_accuracy: 0.5343\n",
      "Epoch 1765/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9064 - accuracy: 0.5486 - val_loss: 0.9148 - val_accuracy: 0.5437\n",
      "Epoch 1766/1800\n",
      "14000/14000 [==============================] - 1s 85us/step - loss: 0.9069 - accuracy: 0.5461 - val_loss: 0.9123 - val_accuracy: 0.5483\n",
      "Epoch 1767/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9066 - accuracy: 0.5459 - val_loss: 0.9140 - val_accuracy: 0.5427\n",
      "Epoch 1768/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9060 - accuracy: 0.5481 - val_loss: 0.9132 - val_accuracy: 0.5403\n",
      "Epoch 1769/1800\n",
      "14000/14000 [==============================] - 1s 86us/step - loss: 0.9040 - accuracy: 0.5491 - val_loss: 0.9209 - val_accuracy: 0.5293\n",
      "Epoch 1770/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9074 - accuracy: 0.5472 - val_loss: 0.9216 - val_accuracy: 0.5353\n",
      "Epoch 1771/1800\n",
      "14000/14000 [==============================] - 1s 90us/step - loss: 0.9069 - accuracy: 0.5488 - val_loss: 0.9151 - val_accuracy: 0.5413\n",
      "Epoch 1772/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9076 - accuracy: 0.5457 - val_loss: 0.9170 - val_accuracy: 0.5380\n",
      "Epoch 1773/1800\n",
      "14000/14000 [==============================] - 1s 92us/step - loss: 0.9066 - accuracy: 0.5440 - val_loss: 0.9146 - val_accuracy: 0.5427\n",
      "Epoch 1774/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9073 - accuracy: 0.5465 - val_loss: 0.9141 - val_accuracy: 0.5447\n",
      "Epoch 1775/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9061 - accuracy: 0.5486 - val_loss: 0.9151 - val_accuracy: 0.5407\n",
      "Epoch 1776/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9068 - accuracy: 0.5458 - val_loss: 0.9161 - val_accuracy: 0.5393\n",
      "Epoch 1777/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9084 - accuracy: 0.5427 - val_loss: 0.9124 - val_accuracy: 0.5453\n",
      "Epoch 1778/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9072 - accuracy: 0.5450 - val_loss: 0.9167 - val_accuracy: 0.5387\n",
      "Epoch 1779/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9085 - accuracy: 0.5458 - val_loss: 0.9219 - val_accuracy: 0.5353\n",
      "Epoch 1780/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9067 - accuracy: 0.5502 - val_loss: 0.9186 - val_accuracy: 0.5373\n",
      "Epoch 1781/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9036 - accuracy: 0.5474 - val_loss: 0.9162 - val_accuracy: 0.5397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1782/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9058 - accuracy: 0.5441 - val_loss: 0.9117 - val_accuracy: 0.5430\n",
      "Epoch 1783/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9044 - accuracy: 0.5479 - val_loss: 0.9154 - val_accuracy: 0.5417\n",
      "Epoch 1784/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9077 - accuracy: 0.5473 - val_loss: 0.9132 - val_accuracy: 0.5443\n",
      "Epoch 1785/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9055 - accuracy: 0.5482 - val_loss: 0.9105 - val_accuracy: 0.5370\n",
      "Epoch 1786/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9063 - accuracy: 0.5439 - val_loss: 0.9130 - val_accuracy: 0.5393\n",
      "Epoch 1787/1800\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.9038 - accuracy: 0.5492 - val_loss: 0.9172 - val_accuracy: 0.5367\n",
      "Epoch 1788/1800\n",
      "14000/14000 [==============================] - 1s 83us/step - loss: 0.9067 - accuracy: 0.5425 - val_loss: 0.9167 - val_accuracy: 0.5473\n",
      "Epoch 1789/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9062 - accuracy: 0.5501 - val_loss: 0.9157 - val_accuracy: 0.5367\n",
      "Epoch 1790/1800\n",
      "14000/14000 [==============================] - 1s 82us/step - loss: 0.9058 - accuracy: 0.5489 - val_loss: 0.9201 - val_accuracy: 0.5383\n",
      "Epoch 1791/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9059 - accuracy: 0.5510 - val_loss: 0.9202 - val_accuracy: 0.5367\n",
      "Epoch 1792/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9071 - accuracy: 0.5451 - val_loss: 0.9128 - val_accuracy: 0.5390\n",
      "Epoch 1793/1800\n",
      "14000/14000 [==============================] - 2s 108us/step - loss: 0.9086 - accuracy: 0.5466 - val_loss: 0.9156 - val_accuracy: 0.5407\n",
      "Epoch 1794/1800\n",
      "14000/14000 [==============================] - 1s 101us/step - loss: 0.9048 - accuracy: 0.5503 - val_loss: 0.9129 - val_accuracy: 0.5363\n",
      "Epoch 1795/1800\n",
      "14000/14000 [==============================] - 1s 89us/step - loss: 0.9064 - accuracy: 0.5452 - val_loss: 0.9126 - val_accuracy: 0.5413\n",
      "Epoch 1796/1800\n",
      "14000/14000 [==============================] - 1s 91us/step - loss: 0.9074 - accuracy: 0.5449 - val_loss: 0.9135 - val_accuracy: 0.5380\n",
      "Epoch 1797/1800\n",
      "14000/14000 [==============================] - 1s 102us/step - loss: 0.9081 - accuracy: 0.5436 - val_loss: 0.9156 - val_accuracy: 0.5393\n",
      "Epoch 1798/1800\n",
      "14000/14000 [==============================] - 1s 103us/step - loss: 0.9069 - accuracy: 0.5494 - val_loss: 0.9122 - val_accuracy: 0.5433\n",
      "Epoch 1799/1800\n",
      "14000/14000 [==============================] - 1s 88us/step - loss: 0.9051 - accuracy: 0.5455 - val_loss: 0.9158 - val_accuracy: 0.5383\n",
      "Epoch 1800/1800\n",
      "14000/14000 [==============================] - 1s 84us/step - loss: 0.9076 - accuracy: 0.5454 - val_loss: 0.9172 - val_accuracy: 0.5353\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "analysis = model.fit(X_train, y_train, batch_size=batch_size,epochs=1800,verbose=1,validation_data=(X_valid, y_valid))\n",
    "trainTime = (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.46905460357666  minutes\n"
     ]
    }
   ],
   "source": [
    "print(trainTime/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8638582332928976\n",
      "Test accuracy: 0.5913333296775818\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])      # this is the categorical_crossentropy\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score =  0.43255081754534436\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(np.round(y_pred),axis=1) # Choose the prediction with the highest probability\n",
    "y_pred_one_hot = to_categorical(y_pred)\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred_one_hot, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results(analysis,\"fasttext_CNN_2400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove\n",
    "corpus = Corpus() \n",
    "glove_data = list(tokenized_tweet)\n",
    "corpus.fit(glove_data, window=10)\n",
    "glove = Glove(no_components=5, learning_rate=0.05)\n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [list(nltk.word_tokenize(doc)) for doc in df['Tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    TaggedDocument(words, ['d{}'.format(idx)])\n",
    "    for idx, words in enumerate(corpus)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(corpus, size=200, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(model.docvecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(\n",
    "        model.docvecs, \n",
    "        sentiment,\n",
    "        train_size=0.85, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "# print(len(X_test))\n",
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentiment = df['Sentiment Polarity']\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        train_size=0.82352942, \n",
    "        shuffle = False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.536\n",
      "F1-Score =  0.5276445713091461\n",
      "[[660 167  73]\n",
      " [503 317 280]\n",
      " [168 201 631]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.SVC(kernel='linear',decision_function_shape='ovr', class_weight='balanced',random_state=0)\n",
    "lin_clf.fit(X_train, y_train)\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.44466666666666665\n",
      "F1-Score =  0.44523749815667407\n",
      "[[394 309 197]\n",
      " [344 461 295]\n",
      " [197 324 479]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "dtree_model.fit(X_train, y_train) \n",
    "y_pred = dtree_model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value =  26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "error_rate = []\n",
    "# Will take some time\n",
    "best_k = 0\n",
    "k=0\n",
    "for i in range(1,100):\n",
    " \n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(X_train,y_train)\n",
    " pred_i = knn.predict(X_test)\n",
    " f=f1_score(y_test, pred_i, average='macro')\n",
    " if f>best_k:\n",
    "        best_k = f\n",
    "        k=i\n",
    " error_rate.append(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,100),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "markerfacecolor='red', markersize=10)\n",
    "plt.title('F1-Score vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.savefig('/Users/gaurav/Desktop/Hinglish/data/k/k_ex6-doc2vec-1.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Best K value = \",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.5306666666666666\n",
      "F1-Score =  0.5360376649309543\n",
      "[[535 297  68]\n",
      " [378 516 206]\n",
      " [118 341 541]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "clf = knn.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.49833333333333335\n",
      "F1-Score =  0.48059343256631576\n",
      "[[742 108  50]\n",
      " [673 226 201]\n",
      " [295 178 527]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-53adc00c182e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMNB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Score = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    608\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    609\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "y_pred = MNB.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/gaurav/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.531\n",
      "F1-Score =  0.522934425433744\n",
      "[[572 230  98]\n",
      " [411 324 365]\n",
      " [125 178 697]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "log_model = log_model.fit(X_train, y_train)\n",
    "y_pred = log_model.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.969930366675059  minutes\n",
      "Accuracy Score =  0.5346666666666666\n",
      "F1-Score =  0.5403893532185551\n",
      "[[501 335  64]\n",
      " [334 532 234]\n",
      " [ 93 336 571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight='balanced')\n",
    "import time\n",
    "start_time=time.time()\n",
    "model.fit(X_train, y_train) \n",
    "duration = time.time()-start_time\n",
    "print(duration/60, \" minutes\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy Score = \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-Score = \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
